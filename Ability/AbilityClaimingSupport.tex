\chapter{Claiming support (and claimed support)}
\label{sec:abil-access-supp}

\paragraph*{Overview}

\begin{note}
  The present {\color{red} section} is about claiming support.
  Or, more precisely, claiming support and claimed support --- we are interested in both an activity and the result of that activity.

  The purpose of the following discussion of claiming support with respect to the {\color{red} overall project} is simple:

  Reasoning with ability, obtaining some conclusion.
  Incompatible with intuitive understanding of part of such reasoning and, in particular, an common idea appealed to in various arguments.

  In order to make such an argument we require some background constraints on such reasoning.
  So, this {\color{red} section} works though those background constraints.

  This then provides sufficiently precise context for what we arguing against, and what we are arguing for.

  And, as part of providing sufficiently precise context will include a rough template of the considerations which motivate argument.

  In other words, context, and also preview.
\end{note}

\begin{note}
  Two things to keep in mind.

  \begin{enumerate}
  \item These constraints are partial.
  \item Consequence of constraints that matters.
  \end{enumerate}

  Enough to identify certain ways in which an agent may fail to perform the reasoning of interest.

  Benefit of not building in `too much'.

  However, also possible to endorse additional constraints.
  In particular, rule out alternative.
  If so, also a problem.
  We will not give much attention to this.
  Argument rests on plausibility when applied to particular case.
  If agree with constraints and agree with particular case, then this is an indirect argument against stronger constraints.


  Consequence of constraints that matters.
  Preview of considerations that matter, but additional step.

  However, postpone final constraint until argument proper.
  Primarily because for the moment, enough to interpret what we are argument against and for --- consequence isn't required.
  Secondary, this constraint where it matters in the argument.
  Third, surrounding motivation and context within literature.

  Welcome to turn to \autoref{sec:second-conditional} following this section.
\end{note}

\paragraph*{Plan}

\begin{note}
  \begin{enumerate}
  \item `Claimed support' is a term, but with certain pragmatic implications.
  \item Two ideas.
  \item Assumptions from these ideas.
  \item Working through assumptions with respect to particular consequence.
  \item Additional comments.
  \end{enumerate}
\end{note}

\begin{note}
  Roughly speaking, the two ideas:
  \begin{enumerate}
  \item Possible that there are defeaters for claimed support.
  \item Claimed support involves reasoning that defeaters do not obtain.
  \end{enumerate}
\end{note}



\section{`Claiming'}
\label{sec:claiming}

\begin{note}[Introducing support]
  Initial clarification is with respect to claiming support.
  Emphasis on `\emph{claim}'.

  The thesis is not about when and why an agent has \emph{support}.

  There are three primary reasons why we focus on claimed support.

  First, neutral for main thread of argument on what support amounts to.
  Interest is with structure of claim, and background assumption that if success in claiming then structure of support follows structure of claim.

  Second, whether or not an agent has support often seems secondary.
  It may be that any claimed support for a proposition is support for that proposition, but perhaps not.
  \begin{illustration}[A box of flan(nels)]
    \label{illu:flan-nels}
    Suppose `flan' is written on the side of a container.
    I may claim support that the container contains flan.
    And, it may be that the writing on the side of the container is support for the box containing flan.
    However, the straps ensuring the container remains closed is unfortunately placed, and if moved would reveal the side of the container reads `flannels'.
  \end{illustration}

  The unfortunate placing of the straps does not seem to prevent \emph{claiming} support, but I'm not sure whether it is right to say that the writing on the side of the box (straps in place) \emph{does} provide support that the box containing flan.
  So, speaking in terms of claiming support leaves open whether what is claimed reflects on whether an agent has support.\nolinebreak
  \footnote{
    In particular, claiming allows focus on internal constrains, while remaining silent on whether having support is (in part) determined by external factors.
  }
  \(^{,}\)\nolinebreak
  \footnote{
    Distinction between propositional and doxastic support.
    Propositional, support agent has whether or not made a claim.
    Doxastic is successful claim and propositional support.
    So, both require that the agent has support.
    Claimed support is the agentive component of doxastic support.
    Not interested in whether the agent also has propositional support, though more or less assume.
  }
  \(^{,}\)\nolinebreak
  \footnote{
    {
      \color{red}
      English is somewhat difficult.
      It is somewhat unfortunate that `an agent has claimed support for \(\phi\)' may be read `there is support which the agent has claimed for \(\phi\)'.
      Still, this seems to follow more easily from `support claimed'.
      So, `claimed support' emphasises the claim, while `support claimed' emphasises support.
    }
  }

  Third, and following from the second, focusing on claimed support allows us to make no assumption about the relationship between claimed support and support.
  To elaborate, consider enthymematic inferences.
  One may hold that an agent may claim support for some conclusion via enthymematic inference, but hold that the support the agent has is understood from the perspective of the (corresponding) complete inference.\nolinebreak
  \footnote{
    Cf.\ \textcite{Moretti:2019wx}.
  }
  Alternatively, one may hold that the enthymematic argument is an adequate support relation (at least with respect to context in which the inference was made).

  Hence, one may question whether the structure of claimed support follows the structure of support.

  An important consequence of this final point is that we will only be interested in why (and when) an agent claims support for and from ability rather than why (or when) an agent \emph{has} an ability.
\end{note}

\section{Three basic assumptions}
\label{sec:three-basic-assumpt}

\subsection{Proposition and evaluation}

\begin{note}[Value proposition]
  Reasoning and claims to support focus.
  Briefly introduce a pair of propositions to clarify claim to support and reasoning.

  \begin{restatable}[Claimed support is for the value of a proposition]{assumption}{assuCSVP}\label{assu:CSVP}
    When an agent claims support for some proposition, the agent claims that the proposition has some value.
    Where:
    \begin{itemize}
    \item A proposition is some information. (Mode of presentation) And,
    \item A value is an assessment of that information.
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
  \autoref{assu:CSVP} fixes terminology.
  To illustrate, when stating the conclusion of the reasoning sketched above we used the proposition that \emph{the area of the rectangle is \(133\text{cm}^{2}\)}.
  The proposition refers to the state of affairs in which the area of the rectangle is \(133\text{cm}^{2}\), and speaking a little more precisely, the agent claimed that the proposition has the value `true' --- though it may be the value turns out to be `false'.
  Or, perhaps if the agent was a little unsure about the accuracy of the ruler, that the proposition has the value `likely', `probable', or some quantitative credence.
  And, some other instance of reasoning may have concluded that the proposition has the value `desirable' --- e.g.\ if the agent was searching for a rectangle of some approximate size.\nolinebreak
  \footnote{
    Nothing in particular hangs on the distinction between different values.
    If you prefer, you may expand the proposition (state of affairs) to include additional factors, and consider only the values `true' and `false'.
    For example, the proposition that \emph{I desire the bath to be warm} is false, as opposed to the proposition that \emph{the bath is warm} is valued undesirable by me.
  }

  Core idea is that claim of support is that things are a certain way.
  Proposition, what the thing is.
  Value, the way it is.
\end{note}

\begin{note}
    \begin{itemize}
  \item \(p\) has the value `true'. \hfill (\emph{p} is true.)
  \item \(p\) has the value `ought to be'. \hfill (\emph{p} ought to be the case.)
  \item \(p\) has the value `desirable'. \hfill (\emph{p} is desirable.)
  \item \(p\) has the value `improbable'. \hfill (\emph{p} is improbable.)\nolinebreak
    \footnote{
      Probability is somewhat interesting.
      The value of the probability of \(p\) is below some threshold.
      E.g.\ the value of the probability of \(p\) is \(0.1\).
      So, on a surface reading the thing that is in a certain way is the probability of \(p\) rather than \(p\).
    }
  \end{itemize}
\end{note}

\begin{note}
In most cases the value will be clear (i.e. that the proposition is true, though sometimes that the proposition is desirable), and so we will talk of claiming support for the proposition.
  A handful of additional examples will be provided when illustrating the next proposition.
\end{note}

\begin{note}
  Nothing hangs on distinction between values.
  Reduce everything to truth and falsity.
  However, we do not assume this, and if you do not think this is the case either, then I would like to not suggest that the assumptions and arguments to follow concern only those propositions which may be evaluated as true or false.
\end{note}

\subsection{Culmination of reasoning}

\begin{note}[Reasoning proposition]
  \begin{restatable}[Claiming support is the result of reasoning]{assumption}{assuCSRR}\label{assu:CS-culmination-of-R}
    Claiming support some proposition \(\phi\) having value \(v\) is an instance of reasoning.
    And, claimed support some proposition \(\phi\) having value \(v\) is the culmination of some instance of reasoning.
  \end{restatable}
\end{note}

\begin{note}
  Key thing here is that result of premises and steps of reasoning.

  The role of~\autoref{assu:CS-culmination-of-R} is primarily to ensure that claiming support always guarantee the existence of premises and steps.
  With the exception of some broad constraints to be outlined in further assumptions below, we (will) have little to say about the specifics of what the reasoning consists of.
\end{note}

\begin{note}
  Reasoning, some mental activity.
\end{note}

\begin{note}[Quick examples]
  \begin{itemize}
  \item \(S\) testified that \(p\), so \(p\) is true.
  \item \(p\) would satisfy every member of the group, so \(p\) ought to be the case.
  \item The song is produced by \(S\), so it is desirable that I listen to it.
  \item The device reads \(p\) and is reliable, so \emph{not}-\(p\) is improbable.
  \end{itemize}
\end{note}

\begin{note}
  Instances of reasoning may culminate in other ways, so we are only interested in a specific type of reasoning.
\end{note}

\begin{note}[Claiming support]
  Expand on this below.
  Briefly mention that this falls short of \emph{establishing} that \(\phi\) has value \(v\).
  \emph{Claimed} support means there's always some possible defeater.
\end{note}

\begin{note}[Understanding `having value \(v\)']
  In a deductive case, if the premises are true, then the conclusion is true.
  Means-end reasoning for desire.
  The value is important.
  If it is true that it past 6pm, then it is true the shop is closed.
  Provides value of shop being closed.

  However, if agent desires that it is past 6pm, then it doesn't follow that the agent desires that the shop is closed.
  Question an agent as to why they think their desires conform to truth --- is-ought problem.

  Means-end reasoning.
  It is true that there is cheese at the centre of the maze.
  And, it is desirable that I obtain the cheese at the centre of the maze.
  Further, it is true that I may only obtain the cheese at the centre of the maze by solving the maze.
  Therefore, it is desirable that I solve the maze.
\end{note}

\subsection{`Confined' reasoning}
\label{sec:no-closure}

\begin{note}
  Assumptions \ref{assu:CSVP} and \ref{assu:CS-culmination-of-R} are designed to be general and straightforward.

  However, combined they allow for a subtlety that will become important.
  The subtlety is this:
  From \autoref{assu:CSVP} claimed support is for the value of a proposition, and from \autoref{assu:CS-culmination-of-R}, claimed support is the result of some reasoning.
  In turn, if an agent has information that some proposition \(\phi\) having value \(v\) requires that some other proposition \(\psi\) has value \(v'\), then it is a consequence of the agent's claimed support for \(\phi\) having value \(v\) that \(\psi\) has value \(v'\).
  Yet, as claimed support is the result of some reasoning, it does not immediately follow that the agent has claimed support for \(\psi\) having value \(v'\).
  For, it need not be the case that the agent performs any reasoning about \(\psi\) having value \(v'\).

  In other words, as claimed support it is tied to reasoning, it is not immediate that reasoning about a proposition having some value extends to any (held) consequence of that proposition.

  This subtlety is intuitive, but given the importance it will have, and the observation that it does not directly follow from Assumptions \ref{assu:CSVP} and \ref{assu:CS-culmination-of-R}, we formulate it as an explicit assumption.
\end{note}

\begin{note}
  \begin{restatable}[Confined Reasoning]{assumption}{assuRClosure}\label{assu:R-closure}
    Reasoning about some proposition \(\phi\) having value \(v\) does not necessarily apply to anything which follows from \(\phi\) having value \(v\).
  \end{restatable}
  Following from above, \autoref{assu:R-closure} denies that if \(\psi\) having value \(v'\) follows from \(\phi\) having value \(v\), then an agent's reasoning about \(\phi\) having value \(v\) need not apply to \(\psi\) having value \(v'\).

  For example, an agent's reasoning about it being true that it is raining does not (necessarily) apply to it being true that the sheets that they have put out to dry are now getting wet.

  It may that the agent concludes that it is beneficial that it is raining given the recent drought, but it does not (necessarily) follow that the agent concludes that it is beneficial that the sheets are getting wet.
  Likewise, the agent may be confident that it is raining, but it does not confident that the sheets are getting wet as the agent may have forgot they put the sheets out to dry.

  Likewise, an agent's reasoning about it not being true that two friends are playing tic-tac-toe does not (necessarily) apply to it being true that the two friends are playing a competitive game.
  For, the agent's reasoning concerns the mutual interest the friends share in tic-tac-toe, and that interest may not extend to competitive games in general.
\end{note}

\begin{note}
  Applied to claiming support.
  It is not necessarily the case that claimed support for \(\phi\) having value \(v\) is claimed support for \(\psi\) having value \(v'\).\nolinebreak
  \footnote{
    No immediate `closure' principle for claimed support:
    \begin{itemize}
    \item \((\phi \rightarrow \psi) \rightarrow (\text{CS}\phi \rightarrow \text{CS}\psi)\)
    \end{itemize}
  }
\end{note}

\begin{note}
  Two notes on terminology:

  First, `following from' is understood broadly.
  The relevant consequence may be logical, semantic, dialectic, and so on.
  Further, whatever follows need not follow \emph{as a matter of} logic, semantics, dialectics, and so on.
  Rather, what follows may follow as a matter of the agent's perspective.
  Indeed, we will not have particular interest in reasoning from any perspective other than that of the agent who has performed the instance of reasoning.

  Second, `applies' is vague, but I seem no way of clarifying what `applies' amounts to in any significant without expanding on what reasoning is, but such an expansion is beyond what will be required for the following arguments.
  We will, however, provide a handful of additional examples in \autoref{sec:claim-supp-independence} when we \hyperref[independence-and-assu:R-closure]{return} to \autoref{assu:R-closure}.
\end{note}

\begin{note}
  There are two ways in which \autoref{assu:R-closure} may be expanded upon that are of interest.

  \begin{enumerate}
  \item Present reasoning, present consequence.
  \item Past reasoning present consequence.
  \end{enumerate}

  Both.
\end{note}

\subsection{Summary}
\label{sec:summary}


\section{Two ideas}
\label{sec:two-ideas}

\subsection{Idea 1}
\label{sec:idea-1}

\begin{note}
  \begin{restatable}[\mistaken{-} and \misled{}]{definition}{defMoM}\label{def:MoM}
    Some instance of reasoning that culminates with \(\phi\) having value \(v\).
    \begin{itemize}
      \item The reasoning is \emph{\mistaken{}} by involving appeal to some proposition \(\psi\) having value \(v'\) which does not have value \(v'\).
    \item The reasoning is \emph{\misled{}} if \(\phi\) does not have value \(v\).
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  \begin{restatable}[\twodefeaters{-} --- \twodefeaters{}]{idea}{ideaDefeatersForCS}\label{idea:defs-for-CS}
    \mistaken{-} and \misled{} are possible defeaters for claimed support in the sense that:

    Were the agent to consider the claimed support was \mom{}, then the agent would retract claimed support is problematic.\nolinebreak
    \footnote{
      Common to distinguish between countervailing and undercutting defeaters.
      Countervailing, support for some other proposition.
      Undercutting, force of claimed support is mitigated.

      Both misled and mistaken are instances of being undercut.
      For, if mistaken or misled then the support is no good.

      Neither are clearly cases of countervailing.
      For, no relation to other support is required.
      However, presence of countervailing implies misled.
      Countervailing does not imply mistaken, though may in some cases demonstrate so.
    }
    And, always some way.
  \end{restatable}
\end{note}

\begin{note}
    Intuition here is that of \mistaken{} is instance of undercutting and \misled{} is a consequence of rebutting, mainly.

  This is mismatched.
  Rebutting implies \misled{}.
  Yet, may be undercutting which does not reduce to \mistaken{}.

  Purpose is that both are straightforward problems relate to basic assumption about claiming support.
  Relation to broader characterisation is present, but have nothing to say about these kinds of defeaters beyond relation to specific instances.
\end{note}

\phantlabel{first-mention-undercutting-defeater} % first mention of undercutting defeaters
\begin{note}[Quick intuition]
  The basic idea behind \autoref{idea:defs-for-CS} is that of \emph{undercuts} undercutting defeaters.

  \begin{quote}
    The second kind of defeater attacks the connection between P and Q rather than attacking Q directly.
    \dots

    This second kind of defeater is, roughly speaking, a reason for thinking that, under these circumstances, knowing-that-P is not a good way to find out whether Q.
    \dots

    A type II defeater is any reason for believing that \({\sim}(P => Q)\) which is not also a reason for believing that \({\sim}Q\).\nolinebreak
    \mbox{}\hfill\mbox{(\cite[43]{Pollock:1974uk})}
  \end{quote}
  Where `\(=>\)' is the subjunctive conditional. (\Citeyear[42]{Pollock:1974uk})

  With \citeauthor{Pollock:1974uk}'s original formulation, the defeater attacks the link.\nolinebreak
  \footnote{
    See \textcite[196,fn.166]{Pollock:1999tm} for a brief note of the history of undercutting defeaters.
    \textcite{Pollock:1974uk} is more-or-less a direct expansion of discussion in~\textcite{Pollock:1970un}.
  }

  However, generalise.
  That there's a relation of claimed support, evidence, or what have you between \(P\) and \(Q\).

  Generalisation by \citeauthor{Bergmann:2005ws}\nolinebreak
  \footnote{
    I am also inclined to \citeauthor{Worsnip:2018aa}'s sketch of undercutting defeaters, which references~\citeauthor{Bergmann:2005ws}.
    \begin{quote}
      Undercutting defeaters, which are easiest to think of in the context of the attitude of belief, are supposed to be considerations that undermine the justification of a belief in a proposition p not necessarily by providing (sufficient) positive evidence to think that p is false, but rather merely by suggesting (perhaps misleadingly) that one’s reasons for believing p are no good, in a way that neutralizes or mitigates their justificatory or evidential force.\linebreak
      \mbox{}\hfill\mbox{(\Citeyear[29]{Worsnip:2018aa})}
    \end{quote}
  }
  \begin{quote}
    \emph{d} is an \emph{undercutting defeater} for \emph{b} iff \emph{d} is a defeater for \emph{b} which is (or is an epistemically appropriate basis for) the belief that one's actual ground or reason for \emph{b} is not indicative of \emph{b}'s truth.\linebreak
    \mbox{}\hfill\mbox{(\citeyear[424]{Bergmann:2005ws})}
  \end{quote}

  Similar generalisation, but similar to \citeauthor{Pollock:1974uk} the relation is useful.
  So, generalise the subjunctive conditional.


\end{note}

\begin{note}
  \autoref{def:MoM} is `only' a definition.
  Still, suggestive terminology.
  Hence, \twodefeaters{} makes explicit the idea behind the suggestive terminology.

  However, definition and \emph{idea} rather than assumption
  We do not assume this idea.
  In part, interested in the possibility of such `defeaters' and we have no interest in situations where an agent discovers that their claimed support is \mom{}.
  In larger part, unclear what the idea amounts to in practice.
  So, instead, provide {\color{red} assumptions} below that clarifies how the possibility of being \mom{} matters.

  Before these {\color{red} assumptions}, {\color{red} some more basic assumptions} regarding how being \mom{} relates to claimed support.

  Still, \twodefeaters{} is sufficiently intuitive that we will refer to \mom{} as `(two) types of defeaters'.
\end{note}

\subsection{Idea 2}
\label{sec:idea-2}

\begin{note}[Summarising \nfcs{}]
  Limitation on strength of claimed support.

  Plausibly holds with respect to various other attitudes.
  Belief because can't rule out.

  Issue here is that compatible with claimed support being a very weak attitude.
  For example, agent is allowed to assume some arbitrary proposition \(\psi\) has value \(v'\) when claiming support for \(\phi\) having value \(v\).
  Possibility of being \mistaken{} with respect to \(\psi\) has value \(v'\), and hence possibility of being \misled{} with respect to \(\phi\) having value \(v\).

  Still, interest is in something stronger than this.

  The (epistemic) possibility of being \mom{} is as a worry.
  Goal, roughly, is to establish good ground for appealing to \(\phi\) having value \(v\) in further reasoning.
  So, \nfcs{} limits the strength of claimed support in reasoning, but also need additional assumptions to ensure sufficiently strong.
\end{note}

\begin{note}[\eiS{}]
  Definition of \mom{}, and from \nfcs{}, (epistemic) possibility that claimed support is \mom{}.
  To ensure sufficiently strong, idea is that agent never requires that claimed support is not \mom{}.

  So, because epistemic possibility, should work out however things turn out.

  % \begin{definition}[Dependence and independence]
  %   An agent's claimed support for \(\phi\) \emph{depends} on some value of \(\psi\) just in case the agent would not claim support for \(\phi\) given any other value of \(\psi\).

  %   An agent's claimed support for \(\phi\) is \emph{independent} of \(\psi\) just in case the agent's claimed support does not depend on the value of \(\psi\).
  % \end{definition}

  \begin{restatable}[\eiS{-}]{idea}{ideaEIS}\label{idea:eiS}
    Claimed support for \(\phi\) having value \(v\) indicates that \(\phi\) has value \(v\) regardless (from the perspective of the agent) of whether the claimed support for \(\phi\) having value \(v\) is \mom{}.

    Entertain possibility that \(\phi\) does not have value \(v\) while maintaining claimed support.
  \end{restatable}
  {
    \color{red}
    Old footnotes\nolinebreak
    \footnote{
      Possibly goes against externalism, but I don't think this is right.
      External circumstances may impact the support the agent has.
      However, as these are external, it seems this condition plausibly holds for \emph{claiming} support.
      This is how you get puzzles for externalism.
      In both cases, it's fine for the agent to claim support, but the external circumstances impact whether the agent \emph{has} support.
      The internalist/externalist divide would seem to affect the conditions on claiming.

      Way to expand on this is reconstructing bootstrapping examples with and without \eiS{}.
      If the agent would only get basic support if reliable, then it's not clear that bootstrapping is a problem.
    }
  }
\end{note}

\begin{note}
  \autoref{idea:defs-for-CS} places limitation on claimed support.

  \autoref{idea:eiS} goes in the opposite direction.
  Claimed support to be a relatively strong attitude.
\end{note}

\begin{note}
  Internalist flavour, specifically `mentalism' in the sense of \citeauthor{Feldman:2001uy} where:
  \begin{quote}
    \dots a person's beliefs are justified only by things that are \dots internal to the person's mental life.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[233]{Feldman:2001uy})}\nolinebreak
    \footnote{
      See also~\textcite[\SS4,9]{Pappas:2017vi}.
    }
  \end{quote}
  Result of reasoning, and indication is part of that reasoning.
  Reasoning is internal to an individual's mental life, and hence internalist in this sense.
  
  Indication of \autoref{idea:eiS} need not amount to justification --- it may, but this will not be important.
  This is also not to require sufficient.
  These two ideas may be developed in various ways.
  Not only indicates from perspective of the agent, but is neither \mom{} and ways in which \mom{} are counterfactually distant.
  However, ideas for the moment.
  Assumptions are what will matter.
\end{note}
  
\section{Summary}
\label{sec:summary-1}

\begin{note}
  Two key ideas: \ideaCSA{} and \ideaCSB{}.
  These provide some characterisation of claimed support.

  We revised \autoref{idea:defs-for-CS} to an explicit assumption: \autoref{assu:supp:nfactive}.
  From \autoref{assu:supp:nfactive} claimed support is such that possibility of being \mom{}.
  This limits the strength.

  In turn, \autoref{idea:eiS} pushes for claimed support to be sufficiently strong that it compensates for such possibilities.

  For this paper, significant interest with \autoref{idea:eiS}.
  Different ways of reasoning, and how these deal with the concern about possibility of being \mom{}.

  In particular, how defeaters work.

  Introduce an assumption in relation to \autoref{idea:eiS} that mirrors \autoref{assu:supp:nfactive} from \autoref{idea:defs-for-CS}.
\end{note}

\section{Refining ideas through assumptions}
\label{sec:assumpt-from-ideas}

\begin{note}
  Presented as ideas, first negative, second positive.

  However, make precise defeater and `regardless'.

  Tackle these together.

  Start with simple part of idea 1.
  Then, definition to capture defeat, and assumption about `regardless'.
  Start with \requ{}, then \expec{} as a special case.
\end{note}

\subsection{Presence}
\label{sec:presence}

\begin{note}[Agents are fallible]
  The following assumption states how these two types of defeaters provide a limitation on claiming support.

  \begin{restatable}[\nfcs{--} -- \nfcs{}]{assumption}{assuNFCS}\label{assu:supp:nfactive}
    When claiming support for a proposition and agent is not in a position to rule out the (epistemic) possibility that the claimed support is \nmom{}.
  \end{restatable}

  In other words, claimed support is not `factive': Claimed support for \(\phi\) having value \(v\) does not entail \(\phi\) has value \(v\).
\end{note}

\begin{note}
  I take it to be intuitive that agents are fallible in many cases of claiming support.
  It is not too difficult to think of ways in which claimed support may be misleading or mistaken.
  As noted above, claiming support for what the time is from glancing at a clock seems sufficient, but clocks may be incorrectly set (misled) or broken (mistake).
  Similarly, a sample of \(1,000\) rolls may mislead me into thinking that a die is unbiased, or an overloaded operator may lead to a mistake in claiming support for the proposition that \(x = 4\) is an expression of equality rather than variable assignment.
\end{note}

\begin{note}
  \begin{itemize}
  \item Illustrations
  \item What `possibility' amounts to
  \item Relation to `genuine' defeaters
  \item Scope of possibility.
  \end{itemize}
\end{note}

\begin{note}[M\&M Illustration]
  To illustrate:

  Suppose I glance at the clock on the wall.
  The clock reads 11:45a, so I claim support that it is 11:45a.
  However, it may be the case that the clock is incorrectly set, and the time is 11:15a, or 12:15p, etc.\
  By claiming support from the time expressed by the clock, I would have been \emph{misled} about what the time actually is.
  For, it is not true that the time is 11:45a.
  Though, in all other respects, there may be no fault with claiming that the time is as expressed by the clock and so the claim to support is not mistaken.

  By contrast, suppose I glace at the clock on the wall.
  The clock reads 11:45a, so I claim support that it is 11:45a.
  By claiming support from the time expressed by the clock, I would have been \emph{mistaken} about what the time actually is.
  For, claimed support by appeal to a functioning clock.
  Though, despite the clock being broken, it is 11:45a and so the claim to support is not misleading.

  Combining, claimed support for the time from a broken clock expressing the wrong time would be both \misled{} \emph{and} \mistaken{}.\nolinebreak
  \footnote{
    A second illustration:
    Consider a smoke detector, designed to sound an alarm if and only if sufficient levels of smoke are detected.
    Hence, if the alarm sounds, one may claim support there being smoke in the room where the alarm is installed.
    One may be misled; the alarm may have malfunctioned, so no fire.
    Or, one may be mistaken; the same type of alarm may be installed in a different room, wouldn't be a useful indicator.
  }

  {
    \color{red}
    Of course, clocks are typically glanced at, and a glance at a clock is often insufficient to determine whether the clock is incorrectly set or broken.
    Hence, the \emph{possibility} that a clock is incorrectly set or broken --- or more broadly the possibility that claimed support is misleading or mistaken --- does not prevent an agent from claiming support.
    So, ensuring that to-be-claimed support would be \mom{} is not a necessary condition for claiming support.
  }
\end{note}

\begin{note}[`Possibility' modal]
  Rather than fix a specific account of the `possibility' modal used, here are a handful compatible interpretations:

  \begin{enumerate}[label=\Alph*., ref=(\Alph*)]
  \item\label{CS:I:Never} \emph{In principle} it is not possible for any agent to rule out the possibility that claimed support is not misleading or mistaken.
  \item\label{CS:I:Resources} It is not possible for a \emph{resource bound agent} to rule out the possibility that claimed support is not misleading or mistaken.
  \item\label{CS:I:Class} There is a restricted class of propositions for which and agent is required to claim support, and it is not possible for any agent to rule out the possibility that claimed support for a proposition belonging the class is \nmom{}.
  \end{enumerate}

  To illustrate, consider the proposition that there is an external world:
  \ref{CS:I:Never} denies that there could be, e.g.\ proof of an external world.
  \ref{CS:I:Resources} denies that agents of interest could not demonstrate such a proof even if it were to exist.
  \ref{CS:I:Class} allows an agent may not be required to claim support for the existence of an external world.

  I expect the intended application of claimed support will be compatible with each interpretation, and specifically with respect to \ref{CS:I:Class}, that the propositions will belong to the highlighted class.\nolinebreak
  \footnote{
    I favour the combination of \ref{CS:I:Resources} and \ref{CS:I:Class}, and to leave open whether an idealised agent may rule out the possibility of being misled or mistaken with respect to some propositions when claiming support.
  }\(^{,}\)\nolinebreak
  \footnote{
    In particular, true of ability.
  }
\end{note}

\begin{note}
  \nfcs{} states that an agent is never in a position to rule out the possibility that the claimed support is not misled or mistaken.
  This does not entail that there are defeaters, nor that there are any possible defeaters --- only that defeaters are an epistemic possibility.

  Still, in some cases, this may seem absurd.
  Suppose in front of me are two apples and two pears.
  So, four pieces of fruit.

  There are two responses here.

  First, not an instance of claiming support.

  Second, outline various way in which the claimed support may be \mom{}.
  Those apples and pears may not be real pieces of fruit, they may be replicas.\nolinebreak
  \footnote{
    So beings the process of attempting to quarantine fallibility from infallibility.

    There are two pairs of objects in front of me, and the objects appear to be fruit.
    So, there are four objects in front of me, which appear to be fruit.

    There are two pairs of objects hence there are four objects.

    But I may be hallucinating.

    There appear to be two pairs of objects in front of me, which appear to be fruit.
    So, there appear to be four objects in front of me, which appear to be fruit.

    Whenever there are two pairs of objects, there are four objects.

    Perhaps it is impossible to be \mom{}, but then stronger than claiming support.

    Likewise:

    Any object is identical with itself --- but I doubt one needs to claim support for reflexivity of equality.

    Similarly, it doesn't seem to be the case that I need to claim support for the proposition that my name is Humpty --- no matter what my birth certificate says, I get to decide what my name is.
  }
\end{note}

\subsection{\requ{3}}
\label{sec:two-assumpt-regard}
\label{sec:claim-supp-requ}
\label{sec:claim-supp-independence}

\begin{note}
  However, \autoref{idea:eiS} are delicate.
  Following \autoref{idea:defs-for-CS} defeaters, but the idea leans on the agent `discovering' (in some non-factive sense) that the claimed support is \mom{}.
  So, would defeat, but this does not necessarily indicate a problem with claimed support.

  Now, claimed support is necessarily weak enough to leave open the possibility of being \mom{}.
  However, discovering after claiming support does not have any immediate consequences for how to deal with the possibilities when claiming support.

  Indeed, it may not simply be the case that entertaining the possibility that one \emph{is} \mom{} is not enough to highlight a problem with claimed support.
  For, claiming support is compatible with such possibility, in general (though perhaps not for certain instances).

  To illustrate:

  \begin{illustration}[Textbook answers]
    \label{illu:textbook-answers}
    Answer in textbook.
    Reasoning is only good if I get to that answer.
    So, if not answer, then reasoning is bad.
  \end{illustration}

  Recognise the possibility, but still succeed in claiming support.
  Indeed, possibility that the author was \mom{} in claimed support for exercise.
  Even so, if the author claimed support then there's no clear problem.

  Of course, this is not to say that there may be other constraints.
  If answer is not the case, then it may be that the agent's information state falls short of some ideal (i.e.\ only truths).
  Still, no problem from the perspective of claiming support alone.

  Might need additional information to recognise the problem.

  Again, indicating doesn't reduce to considerations against ways in which the agent may be \mom{}.

  And, while it may be the case that `discovering' being \mom{} amounts to a defeater for claimed support, there is no immediate link between this and what happens when claiming support.
\end{note}

\begin{note}
  Still, there are cases where the possibility of being \mom{} does present a problem.

  \begin{illustration}
    Suppose some conditional that admits of:
    \(P \rightarrow (Q \rightarrow R)\)

    To

    \((P \land Q) \rightarrow R\)

    Then, appeal to \(P \rightarrow (Q \rightarrow R)\).
    Question for whether the instance also holds with respect to \((P \land Q) \rightarrow R\).
  \end{illustration}

  Intuitively, possibility of being \mistaken{}.
  And, some consideration regarding whether \(P \rightarrow (Q \rightarrow R)\) holds for instances.
\end{note}

\begin{note}
  These illustrations are fairly distinct.
  Hence, various different dimensions to account for intuition diverging between the two illustrations.

  In particular, \mistaken{} versus \misled{}.
  This is difficult, though, as it may be the case that relevant thing applies to both.

  Being \mom{} is a way in which claimed support may be defeated, and these place indirect limits on reasoning itself.
  So, distinguish between the result of reasoning and reasoning (i.e.\ between claimed support and claiming support).
  Connect the possibility of being \mom{} to some part of reasoning.
  One such limitation.
\end{note}

\begin{note}
  First, the idea of a \requ{} of claiming support.

  \begin{restatable}[\requ{3} of claimed support]{definition}{defRequisite}\label{def:requisite}
    \(\psi\) has value \(v'\) is \requ{} of claiming support that \(\phi\) has value \(v\) if, from agent's perspective:
    \begin{enumerate}
    \item \(\psi\) not having value \(v'\) is possible.
    \item If \(\psi\) were not to have value \(v'\) then some step of reasoning would involve being \mom{} --- no making that step of reasoning.
    \item That step has consequence of \(\psi\) having value \(v'\) which persists through to conclusion of reasoning.
    \end{enumerate}

    \requ{2} of claimed support if \requ{} of claiming support.
  \end{restatable}
  Intuitively, non-temporary consequence of some step of reasoning in isolation.

  So, problem is clear.
  If \requ{} fails, then reasoning fails as a whole.
\end{note}

\begin{note}
  \begin{restatable}[\eiS{-} --- \eiS{}]{assumption}{assuEIS}\label{assu:supp:independence}
    Claiming support for \(\phi\) having value \(v\) involves:
    \begin{itemize}
    \item Reasoning about whether or not any \requ{} has value.
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}

  From~\autoref{assu:CS-culmination-of-R}, claimed support is the result of reasoning.
  \autoref{assu:supp:independence} provides addition constraints on what such reasoning involves.
  This is quite weak and rather uninformative.
  Still, primary purpose of \eiS{} is that we may expand on what the relevant reasoning involves.

  {\color{blue}
    In other words, claimed support covers all ways in which something follows from claiming support and is such that reasoning would not work without it.
    Not possible to claim support against a restricted selection of possibilities.
  }

  {\color{red}
    With \misled{}, claiming support does not come for free.
    With \mistaken{}, do not get to take on board premises and steps for free.
    (So to speak.)
  }

  More details on \autoref{assu:supp:independence}, after talking through \autoref{def:requisite}.
  However, important to note that \autoref{assu:supp:independence} does not give an account of what the reasoning is.

  Plausible there are constraints on the reasoning.
  \emph{However}, for us, it is either the lack of reasoning, or that it is not possible to do the required reasoning --- though not necessarily not possible in general (\nI{} for details).
\end{note}

\begin{note}[`Unrecognised' \requ{1}]
  May add:
  \begin{itemize}
  \item Reasoning about `unrecognised' \requ{1}.
  \end{itemize}
  Difficulty is what this amounts to.

  An alternative way to strengthen is to have some requirement concerning a search for \requ{1}.
\end{note}

\begin{note}
  Well, this definition and assumption may seem arbitrary.
  That much I concede.
  The key point is that proposition having value is an unavoidable consequence of some step of reasoning.

  With respect to \autoref{illu:textbook-answers}, that the reasoning is good is not a consequence of a step of reasoning.
  Of course, the conclusion of reasoning will be a \requ{}.
  In this case, \autoref{assu:supp:independence} is trivial.

  However, we are not searching for a complete account of possible defeaters of interest.
  Rather, a clear account of something sufficiently troublesome.

  However complex things get when additional aspects of reasoning are taken into account, what this definition captures seems clear enough, even if part of that clarity is obtained by arbitrary simplification.
\end{note}

\begin{note}
  Regular conditional and subjunctive.
\end{note}

\begin{note}
  The subjunctive here does, generally speaking, highlight a possible defeater for reasoning.

  Subjunctive because what follows from entertaining possibility.
  This then allows `discovering'.

  Of course, given that subjunctive, questions about how to evaluate.
  However, not counterfactual.
  So, given that possibility, do not need to consider cases where entertaining possibility requires some revision to the reasoning that the agent has performed.

  The final clause seems to explicit a plausible implicit consequence of the first clause.

  For \(\lnot p \leadsto \lnot q\), \(\lnot p \rightarrow \lnot q\), so \(q \rightarrow p\).

  Plausible, but this is not quite right.
  Consider reasoning by cases.
  If not that case, then a problem, but does not have the consequence that the case holds.
  Hence, persists.\nolinebreak
  \footnote{
    This is not to deny a slightly more complex clause.
    Rather, easier this way.
  }
\end{note}

\begin{note}
  Really important here is that being a \requ{} does not imply that the reasoning involves direct appeal.

  {
    \color{red}
    Indeed, this distinguishes from \citeauthor{Sgaravatti:2013wu}, which requires belief in each of premises.
  }
\end{note}

\begin{note}
  Not the case that any thing that is appealed to is a \requ{}.
  For, may add in certain additional things.
  In other words, careful to make sure that the subjunctive part is there.
\end{note}

\begin{note}[\autoref{assu:supp:independence} and reasoning]
  However, important point is that claimed support is tied to instance of reasoning.

  Given \nfcs{} it need not be the case that an agent completely rules out possibility of defeater obtaining --- i.e.\ of being \mom{}.
  Appeal to claim support in reasoning that defeaters do not obtain.
  Hence, reasoning does not require ruling out defeaters.
  So, \autoref{assu:supp:independence} does not require claimed support against defeaters.

  Still worry that reasoning is too weak.
  Additional requirements are compatible with \autoref{assu:supp:independence}, such as investigating unrecognised defeaters.
  However, do not \emph{assume} this.

  Again, primary purpose of \eiS{} is that we may expand on what the relevant reasoning involves.

  No clear assumptions regarding this in any detail.
  Part of the interest is in what is required of such reasoning.

  Appeal in argument is with respect to absence of reasoning regarding defeater.
  In turn, argument for what the reasoning involved amounts to.
  And, argument against a (plausible) necessary condition.
\end{note}


\begin{note}
  \begin{restatable}[]{proposition}{propReasondefRequisite}\label{prop:reason-requ}
    {
      \color{red} This should be an argument for why a \requ{} amounts to something that needs consideration.
    }
    If \requ{} then possible defeater.
  \end{restatable}

  So, suppose some \(\psi\) is \requ{} of some reasoning.
  Then, not only would reasoning would be \mom{} if \(\psi\) is not the case.
  But, in addition, some structural component would be bad.
  That is, connect the possibility of being \mom{} to some part of reasoning.
\end{note}

\begin{note}
  \eiS{} does not deny that things may need to be a certain way for an agent to claim, or to be in a position to, claim support.
  It may be the case that no agent would be in a position to claim support that the speed of light is constant if the speed of light were not constant.
  Still, in claiming support an agent must expect that possible defeaters do not obtain, e.g.\ that the laws of nature are constant, and that no mistakes have been made when observing relevant phenomena.
\end{note}

{
  \color{blue}
  What I really need for \nI{} is that there's no way to go without expectation.
  Right, okay, and the point is not that really that there's nothing else for the agent to do.
  There might be, but the point of the ability case is that it doesn't seem there needs to be.
  \emph{In addition}, it also seem implausible that there could be, but the argument doesn't depend on ruling out this possibility.
}

\begin{note}
  Following is an immediate consequence of \autoref{assu:supp:independence}:

  \begin{restatable}[Reason about recognised \requ{1}]{proposition}{propRecogniseDefeaters}\label{prop:CS-only-if-reason-recognised-defeaters}
    If recognised \requ{} at time of reasoning and does not reason, not an instance of claiming support.
  \end{restatable}
\end{note}

  \begin{note}
  \begin{itemize}
  \item If result of reasoning to \(\phi\) having value \(v\) is such that agent considers that reasoning fails if \(\phi\) does not have value \(v\), then reasoning is not an instance of claiming support.
  \item Not possible that instance of reasoning to \(\phi\) having value \(v\) is claimed support only if \(\phi\) has value \(v\).
  \item Claimed support for \(\phi\) having value \(v\) never requires that \(\phi\) has value \(v\).
  \end{itemize}
\end{note}

\begin{note}
  \color{red}
    \begin{itemize}
    \item Always possibility of \mom{} from \nfcs{}.
    \item This means that the agent has no guarantee that \(\phi\) has value \(v\) --- or better put the agent considers it to be an (epistemic) possibility that their claimed support is \mom{}.
    \item However, if the agent requires that \(\phi\) is the case, then there is no possibility of the claimed support being \emph{mistaken}.
    \item Well, no reasoning against being mistaken with respect to claimed support for this expectation.
  \end{itemize}

  Again, it does not seem impossible for an agent to adopt an attitude that recognises the possibility but assumes regardless.
\end{note}

\begin{note}
  \phantlabel{independence-and-assu:R-closure}
  Important consequence of \autoref{assu:R-closure}, block:

  S did not reason about possibility that Q is false.
  If Q is false, then P must also be false.
  Hence, P may be false.
  S did not reason about the possibility that P is false.

  \begin{note}
  Examples:
  \begin{itemize}
  \item Possibility that the trains are on strike.
  \item No Indication of strike, so do not consider live possibility.
  \item Read newspaper.
  \item Newspaper reported strike.
  \item Consequence of possibility is that the newspaper misreported.
  \item Reasoning does not extend to newspaper.
  \end{itemize}

  \begin{itemize}
  \item Out of milk.
  \item Then come to hold that there is milk in the fridge.
  \item Hallucinating.
  \item Does not extend.
  \end{itemize}

  \begin{itemize}
  \item Turing machine reduction.
  \item If possible then also possible.
  \item So, give up.
  \end{itemize}
\end{note}
\end{note}

\subsection{\expec{3}}
\label{sec:claim-supp-expect}
\label{sec:claim-supp-nai}

\begin{note}
  In the previous section introduced the notion of a \requ{} and used this notion to refine \ideaCSB{} into an assumption.
  Assumption is relatively weak.
  Some reasoning about recognised \requ{1}.
  However, no commitments to what such reasoning must amount to.

  In the present section we introduce a second definition and proposition.
\end{note}

\begin{note}
  Our primary interest is with the introduction of \requ{1}.
  For, this is a case where the agent will not necessarily have performed any reasoning about the \requ{}.

  Introduce definition, first instance of failure to claim support.

  Build on below after examples.
  In particular, some corollaries.
\end{note}

\begin{note}[Expectation, assumption]
  Start with the definition:

  \begin{restatable}[\expec{3} of claimed support]{definition}{defExpectation}\label{def:expectation}
    If claimed support for \(\phi\) having value \(v\) and then come to consider \(\psi\) has value \(v'\) as \requ{} of claimed support that \(\phi\) has value \(v\), then \(\psi\) has value \(v'\) is an \emph{\expec{}} of the claimed support for \(\phi\) having value \(v\).
  \end{restatable}

  An \expec{} is a \requ{} of claimed support.

  So, an expectation is a specific instance of a \requ{}.
  In claiming support for \(\phi\) having value \(v\), the reasoning about \(\psi\) having value \(v'\) indirectly as an unrecognised \requ{}.
  However, after claiming support.

  The different terminology allows us to easy talk about \requ{1} given novel information.
\end{note}

\begin{note}
  Claiming support is an instance of reasoning.
  From \eiS{}, enough to go even if \mom{}.
  At time of claiming support, agent may not recognise certain possibilities.
  This doesn't prevent the agent from claiming support.

  Claimed support, so reasoning.
  Part of that reasoning, unrecognised defeaters do not obtain.
  Once the agent recognises, this is now expected.

  Expectation that \(\phi\) relative to claimed support for \(\psi\) is, roughly, that \(\phi\) is a recognised possible part of previously unrecognised\dots
\end{note}

\begin{note}[What expectation amounts to]
  \(\phi\) has value \(v\).
  Expects \(\psi\) has value \(v'\) relative to further information about \(\phi\) and \(\psi\).

  Extension of \autoref{assu:supp:independence} from \requ{1} to \expec{1}.
\end{note}

\begin{note}
  \begin{restatable}[Reasoning about expectations]{assumption}{assuCSNoExp}\label{assu:independence-expec}
    Reasoning.
    Appeal to claimed support for \(\psi\) having value \(v'\) such that \(\xi\) having value \(v''\) is an \expec{} of that claimed support for \(\psi\) having value \(v'\).
    Then:

    Claimed support for \(\phi\) having value \(v\) involves:
    \begin{itemize}
    \item Reasoning about \(\xi\) having value \(v''\) as \expec{} to \(\psi\) having value \(v'\).
    \end{itemize}
  \end{restatable}
  So, reclaiming support for \(\psi\) having value \(v'\).
  Hence, reasoning about \(\xi\) having value \(v''\) without appealing to claimed support for \(\psi\) having value \(v'\).
\end{note}

\begin{note}
  Intuition here is that \expec{}, no direct consideration.
  So, reasoning to \(\phi\) having value \(v\), sure.
  However, reasoning does not address the expectation.
\end{note}

\begin{note}
  For example, there appears to be a bowl of fruit in the centre of the table, and so I claim support by visual inspection that there is a bowl of fruit in the centre of the table.

  Well, things are as they appear.

  Oh, plastic fruit in particular.
\end{note}

\begin{note}
  \begin{restatable}[Claiming support Nai]{proposition}{propCSNai}\label{prop:CS-nai}
    Reasoning that \(\phi\) has value \(v\) is not an instance of claiming support for \(\phi\) having value \(v\) if \expec{} with no reasoning about it as \expec{}.
  \end{restatable}

  For, expectation leads to a (recognised) \requ{} for current instance of claiming support.
  As, if \expec{} does not hold, then problem with appeal to that claimed support.
  Of course, the limited upshot given assumptions made is that the agent needs to do some reasoning.

  {
    \color{red}
    This is not a consequence of assumption \autoref{assu:supp:independence} alone.
    For, \autoref{assu:supp:independence} only talks about reasoning.
    And, in this case there is some reasoning.
  }
\end{note}

\begin{note}
  Expectation alone doesn't seem so bad.
  Haven't shown that \(\phi\) is really important to the reasoning.
  However, add in requisite and things are bad.
  Requisite alone also isn't enough, as may be able to deal with this.
  Possible defeaters.
  So, it's that \(\phi\) is involved and the agent hasn't dealt with the possible defeater that leads to \(\phi\) being involved.

  \begin{proof}
    This assumption expands on \eiS{}.
    Basically, if require \(\phi\) has value \(v\) then no account of why \(\phi\) given possibility that \(\phi\) does not have value \(v\).

    Point is that claiming support, so result of compatible with possibility that \(\phi\) is not the case.
    However, also such that still indicates \(\phi\).
    But, no account if this possibility obtains.
  \end{proof}

  This is the strongest assumption.
  Intuitively, independent grounds for dismissing defeater.

  Quite delicate.
  Good reasoning against unrecognised defeaters.
  However, this does not extend if one (or more) of those defeaters is recognised.

  The point is not that the defeater is unlikely.
  Rather, claimed support is such that it involves considerations against possible defeaters, and those considerations are such that they deal with the possible defeater.
\end{note}

\begin{note}
  Note, however:

  \begin{itemize}
  \item Haven't placed significant constraints on reasoning involved.
  \item That it is quite possible that the same reasoning for the unrecognised reapplies to the now recognised defeater.
  \end{itemize}
\end{note}

\begin{note}
  Consequence of this is that added reasoning about possible defeater is a `new' instance of claiming support.
\end{note}

\begin{note}
  Basic issue is that when claimed support for \(\phi\), did not consider \(\psi\).
  \autoref{prop:CS-nai} does not state that the agent is required to give up claimed support.
  Nor appealing to the claimed support to claim support for other propositions.
  Nor in other forms of reasoning.
  Denied is that result of reasoning is claiming support.
  In particular, because claimed support for \(\phi\) does not address possibility.
  So, not clear that indicates value.

  And,~\autoref{prop:CS-nai} adds in that reasoning against when unknown is not enough.
\end{note}

\subsection{Two optional assumptions}

\begin{note}
  Finally, two optional assumptions.
\end{note}

\begin{note}
  One assumption about reasoning.
  \begin{restatable}[May appeal to previously claimed support]{assumption}{assuCSbyPCS}\label{assu:appeal-to-previous-CS}
    May appeal to previously claimed support --- i.e.\ do not need to \emph{reclaim} support.
  \end{restatable}

  Note, this does not guarantee that appeal will be successful.
  Basically, excluding \expec{}, sufficient to reason that claimed support.
\end{note}

\begin{note}
  \begin{restatable}[Claiming support persists]{assumption}{assuCSPersists}\label{assu:CS-persists}
    {
      \color{red}
      I don't need this.
      It makes more sense to require reasoning about all \expec{} and then allow that something weaker is not an instance of claiming support.

      Alternative is to further restrict assumption.
      Nothing really hangs on this, so could do.
      Still, various way in which other assumptions could be weakened that would still allow for things to go through.
      Point is, this seems to conflict with motivating ideas.
    }
    Claimed support may persist given introduction of \expec{}.
  \end{restatable}

  This is a optional assumption.
  Alternative is that retract claimed support.
  Everything that follows is compatible with retraction.
  However, weaker.
  Hence, go with this assumption.
\end{note}

\begin{note}
  \autoref{assu:CS-persists} is important.
  Note the `may'.
  Motivation is that we get a \requ{}.
  However, there's no suggestion that the \requ{} is not the case.

  Claiming support is the result of an instance of reasoning.
  And, the instance was fine.
  So, would have been a \requ{} (and will be a \requ{} if reclaim).
  However, was not at the time.
  And, only a possibility.

  So, keep result, but relative to expectation.
  Now, you don't need to think that this continues to be claimed support.

  Pairs with \autoref{assu:appeal-to-previous-CS}.
  Intuitively, same expectations are inherited.
  However, the details do not matter to us.
  Again, what follows holds granting this assumption, rather than anything stronger.
\end{note}

\begin{note}
  Still, it may be helpful to state a general idea that will follow from argument.

  \begin{restatable}[]{thought}{thoughtDismissingDefeaters}\label{thought:dismissing-defeaters}
    If in position to deal with defeater, then need not rule out possibility to greatest extent possible.

    Reasoning against unconsidered defeaters, well, recognised defeaters were sufficient to consider, something like this.
  \end{restatable}

  Expand on this idea below with responses to the `even if' test.
  Emphasise is that the argument does not build in strong assumptions about what reasoning involves.
\end{note}

\section{Illustrations}

\begin{note}
  Collection of assumptions, expanding on two ideas, and propositions building on these.
  Work through how these assumptions combine in some cases.
  Also drawing out intuition.

  To start, familiar case, distinguish from circularity and related idea.
  Then, looking at \autoref{prop:CS-nai}.
  Pair of simple illustrations.
  Then, final illustration to highlight intuition and draw out some tension.
  After these, corollary of \autoref{prop:CS-nai} which summarises, some discussion, and an idea.
\end{note}

\subsection{Illustrations with respect to ideas}

\begin{note}[Testimony 1]
  \begin{illustration}[Testimony 1]\label{illu:CS:test:basic}
    \mbox{}
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item\label{ex:eiS:tt:test} \nagent{11} testified that they are trustworthy when speaking on matters regarding their personal character.
    \item Any agent and proposition, agent testified that proposition is the case only if proposition is the case.
    \item \nagent{11} testified that p is the case only if p is the case.
    \item\label{ex:eiS:tt:ok} \nagent{11} is trustworthy when speaking on matters regarding their personal character.
    \end{enumerate}
  \end{illustration}

  I take the reasoning of~\autoref{illu:CS:test:basic} to be intuitively problematic.

  I am also somewhat confident that you will have seen some variant of the reasoning in relation to circularity before.

  The goal for the moment is to explain why the two ideas expressed in relation to claiming support (\nfcs{} and \eiS{}) highlight a way in which the reasoning is problematic.
  And, to distinguish the way in which the ideas highlight a problem from a pair of nearby considerations.
\end{note}

\begin{note}
  Observe, however, that the intuitive problem is not that the agent has any reason(ing) to think that \nagent{11} is \emph{not} trustworthy when speaking on matters regarding their personal character.

  Rather, the intuitive problem is that the agent does not have any reason(ing) to think that \nagent{11} \emph{is} trustworthy when speaking on matters regarding their personal character.

  In particular, that that \nagent{11} is not trustworthy when speaking on matters regarding their personal character is simply a possibility.
  It may be the case that \nagent{11} is trustworthy.\nolinebreak
  \footnote{
    \color{red}
    It's not like this suggests that they are not trustworthy.
    Asking for directions.
    These are fine, but addition is not.
  }
\end{note}

\begin{note}
  Following, let us consider why the reasoning of~\autoref{illu:CS:test:basic} is intuitively problematic from the perspective of claiming support.\nolinebreak
  \footnote{
    Of course, the reasoning of \autoref{illu:CS:test:basic} seems problematic without constraints on the purpose.
    However, our interest is with claiming support.
  }

  \ideaCSA{} and \ideaCSB{}.

  The role of \ideaCSA{} is simple: It is possible for the agent's reasoning to be \mom{}.
  For example.

  Possibility of \mistaken{}.
  Well, misheard, speaking sarcastically.
  Possibility of \misled{}.
  Possible that S is not trustworthy.

  It is the possibility of being \misled{} that is of interest.

  Here, \ideaCSB{}.
  In order for the reasoning to be an instance of claiming support, the reasoning should indicate that \nagent{11} is not trustworthy on matters regarding their personal character regardless of whether the reasoning that \nagent{11} is trustworthy on matters regarding their personal character is \mom{}.

  In particular, it should be possible for the agent to entertain the possibility that \nagent{11} is not trustworthy on matters regarding their personal character while maintaining that their reasoning indicates that \nagent{11} is trustworthy on matters regarding their personal character.
\end{note}

\begin{note}[The problem]
  The problem, then, is that it does not seem possible for the agent to entertain the possibility that \nagent{11} is not trustworthy when speaking on matters regarding their personal character while maintaining that their reasoning indicates that \nagent{11} is trustworthy when speaking on matters regarding their personal character.

  For, it may be the case that \nagent{11} is not trustworthy when speaking on matters regarding their personal character.
  And, \nagent{11}'s testimony involves speaking on a matter regarding their personal character.
  Hence, by entertaining the the possibility that \nagent{11} is not trustworthy on matters regarding their personal character, the agent is required to entertain the possibility that \nagent{11}'s statement did not amount to an instance of testimony.
  And, if \nagent{11}'s statement did not amount to an instance of testimony then it would seem the agent lacks a line of reasoning that indicates that \nagent{11} is trustworthy when speaking on matters regarding their personal character.
\end{note}

\begin{note}
  The preceding is only an expression of an intuition.
  \ideaCSA{} and \ideaCSB{} are ideas, and the arguments that follow will rest on the assumptions and propositions drawn from these ideas, rather than the ideas themselves.
  Still, to the extent motivation for those assumptions and propositions rest on these ideas, \autoref{illu:CS:test:basic} highlights the constraints the ideas place on claiming support.

  \begin{itemize}
  \item given \ideaCSA{}, the agent is required to consider the possibility that conclusion of their reasoning is not the case, and
  \item given \ideaCSB{}, the agent is required to hold that their reasoning indicates that the conclusion of their reasoning is not the case regardless of whether the possibility that conclusion of their reasoning is not the case obtains.
  \end{itemize}
  The reasoning of \autoref{illu:CS:test:basic} fails to be an instance of claiming support because the possibility that \nagent{11} is not trustworthy when speaking on matters regarding their personal character is sufficient to undercut the premise that \nagent{11} testified.
\end{note}

\begin{note}
  Now, granting that the above identifies a problem, an immediate question is:
  Is the problem an instance of (vicious) circularity?\nolinebreak
  \footnote{
    In advance of following discussion, variation on~\textcite{Sorensen:1991wh}.

    Claim support for the following proposition from the following sentence:

    \begin{quote}
      Some sentences are typed on a computer.
    \end{quote}

    In line with suggestions of \citeauthor{Sorensen:1991wh}, seems fine.
    No difficulty with ideas as compatible with something else happening.
    But, background that this is so incredibly unlikely.
  }

  Circularity is certainly in the ballpark, but I do not think there is a straightforward reduction.
\end{note}

\begin{note}
  First, the problem was motivated by view the agent's reasoning as an instance of claiming support and applying the two basic ideas of claiming support (\ideaCSA{} and \ideaCSB{}).
  And, in general, it seems that circularity extends beyond the scope of claiming support.

  For example, consider knowledge:
  The reasoning of \autoref{illu:CS:test:basic} seems problematic when view from the perspective of establishing knowledge.
  Yet, from such a viewpoint it seems \ideaCSA{} would not apply --- if the agent had come to know that \nagent{11} is trustworthy when speaking on matters regarding their personal character then it would not be possible (at least relative to the conclusion of their reasoning) that \nagent{11} is not trustworthy.
  Hence, neither \ideaCSA{} nor \ideaCSB{} would apply.

  To be clear, our interest is not that the claiming support explains why the reasoning is problematic.
  Rather, the point is that the sketch given of why the reasoning is problematic when viewed as an instance of claiming support is distinct from circularity, as it seems circularity would extend to cases for which \ideaCSA{} nor \ideaCSB{} would not apply.
\end{note}

\begin{note}
  Second, the term `circularity' suggests that the reasoner has taken the conclusion of the reasoning for granted.

  For example, consider what \citeauthor{Sgaravatti:2013wu} terms the `Justification Account' of circularity.\nolinebreak
  \footnote{
    As \citeauthor{Sgaravatti:2013wu} notes, the Justification Account of circularity is a rewriting of the third type of `epistemic dependence' considered by \citeauthor{Pryor:2004ws}~(\citeyear[359]{Pryor:2004ws}).
    Neither \citeauthor{Pryor:2004ws} nor \citeauthor{Sgaravatti:2013wu} endorse the Justification Account, but I take the spirit of the account to sufficient for interest.
    Still, the considerations which follow also apply to distinguish the {\color{red} problem identified} from \citeauthor{Sgaravatti:2013wu}'s favoured account (\Citeyear[\S3]{Sgaravatti:2013wu}) and the fifth type of `epistemic dependence' considered by \citeauthor{Pryor:2004ws}~(\citeyear[359]{Pryor:2004ws}).
  }

  \begin{quote}
    \begin{enumerate}[label=(JA), ref=(JA)]
    \item\label{sg:JA} An argument is circular if and only if for you to have justification to believe the premisses, it is necessary that you have justification to believe the conclusion.\nolinebreak
      \mbox{}\hfill\mbox{(\Citeyear[754]{Sgaravatti:2013wu})}
    \end{enumerate}
  \end{quote}
  Where `justification to believe' is to be read as in terms of having formed the belief in an epistemically appropriate way as opposed to (merely) possessing sufficient resources to form formed the belief in an epistemically appropriate way.\nolinebreak
  \footnote{
    Or, however you prefer to characterise \citeauthor{Firth:1978vi}'s (\Citeyear{Firth:1978vi}) distinction between doxastic and propositional justification (or warrant).
    See also \citeauthor{Silva:2020aa} (\Citeyear{Silva:2020aa}) --- esp.\ fn.\ 1.
  }
  (\citeauthor[Cf.][754--755]{Sgaravatti:2013wu})

  Observe, \ref{sg:JA} applies to \autoref{illu:CS:test:basic} only if the agent requires a justified belief that \nagent{11} is trustworthy prior to the conclusion of the agent's reasoning.

  Such may be the case, and plausibly is, but to the extent that the instance of claiming support is an instance of forming a justified belief, the problem highlighted by appeal to \ideaCSA{} and \ideaCSB{} relied only on entertaining the possibility that \nagent{11} is not trustworthy.
  Still, that it was necessary for the agent to have claimed support for \nagent{11} being trustworthy in order to claim support for the premises does not follow without additional argument --- no matter how plausible this may be.\nolinebreak
  \footnote{
    Though I have doubts about whether this really is the case.
  }

  % {
  % \color{red}
  % Necessary, as could argue that this is an implicit assumption.
  % Hence, .
  % Given plausibility, possible.

  % Yet, equally, that these two things don't go together regardless of perspective on premise.

  % And, in this sense order of explanation would be reversed.
  % Still a question of why required.
  % }

  %   Admittedly this is a somewhat delicate point.
  %   One may argue that \ref{sg:JA} (or some variant) explains why it is (intuitively) not possible for the agent to entertain possibility that \nagent{11} is not trustworthy given their reasoning.

  %   Indeed, even if it is the case that the agent is required to have claimed support (or a justified belief) for \nagent{11} being trustworthy to claim support for the premises, the problem identified via \ideaCSB{} would remain distinct and would seem at best to motivate such an additional restriction.
  Leaves open the possibility that problem highlighted by \ideaCSA{} and \ideaCSB{} does not reduce.
  Hence, seems that distinguish intuitions from \ideaCSA{} and \ideaCSB{} from intuitions about why or how the agent introduced \nagent{11} testifying as a premise.
\end{note}

\begin{note}
  The basic intuition, really, is that from \ideaCSA{} there is the possibility of being \mom{}.
  In particular, \mistaken{} about testimony.
  So, various ways in which this premise may fail.
  The conclusion not holding is one such way.
  And, if this is the case then whatever considerations the agent has for testimony, those considerations do not extend.
\end{note}

\begin{note}
  Still, rather than toy in the abstract, let's investigate further by granting the agent with a way of claiming support for the initial premise of the reasoning.
  The problem identified by \ideaCSA{} and \ideaCSB{} will remain, but to press the problem of circularity will require stronger assumptions.
\end{note}

\begin{note}[Testimony 2]
  \begin{illustration}[Testimony 2]\label{illu:CS:test:with-CS-for-premise}
    \mbox{}
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item I was assured that \nagent{11} will be honest with me throughout the meeting.
    \item\label{ex:eiS:tt:test} \nagent{11} testified that they are trustworthy on matters regarding their personal character.
    \item Any agent and proposition, agent testified that proposition is the case only if proposition is the case.
    \item \nagent{11} testified that p is the case only if p is the case.
    \item\label{ex:eiS:tt:ok} \nagent{11} is trustworthy on matters regarding their personal character.
    \end{enumerate}
  \end{illustration}

  \autoref{illu:CS:test:with-CS-for-premise} seems intuitively problematic to a similar degree as \ref{illu:CS:test:basic}.

  The prior assurance does not help, at least given context that the friend was not aware of what \nagent{11} would say.

  However, the prior assurance does provide a clear account of how the agent introduced \nagent{11} testifying as a premise.
\end{note}

\begin{note}
  Problem here remains.
  Now, two instances of claiming support.

  Observe, vouched for particular instance, but not general.
  Assurance went for statements in general, but now have information about particular statement.
  Seems okay in various cases.

  \begin{itemize}
  \item The venue will be crowded.
  \item A squirrel took the birdseed.
  \item \TeX is Turing-complete
  \end{itemize}
  (Observe, in these instances neither a \requ{} nor an \expec{}.)
  Assurance is sufficient.
  In general, so long as appeal to instance of testimony while granting that content of that instance of testimony (and hence the testimony itself) may fail, then there is no tension with the assumptions made regarding claimed support.

  Yet, the reasoning seems to remain problematic with respect to self-attribution of trustworthiness.
\end{note}

\begin{note}
  The issue for \ref{sg:JA} is that it does not seem necessary for the agent to have justification to believe that \nagent{11} is trustworthy on matters regarding their personal character in order to have justification to believe that \nagent{11} would be honest throughout the meeting.

  Instead, it seems that there is a limitation on the scope of the assurance that is sensitive to the content of what \nagent{11} said (or would say).
  In turn, the agent's reasoning is problematic because the reasoning exceeds the relevant limitation.
  And, while it may be the case that would need justification for conclusion to have unlimited justification for the premises, the limitation alone is sufficient identify the problem.

  This is preferred understanding of the problem raised by \ideaCSA{} and \ideaCSB{}.
\end{note}

\begin{note}
  However, granting that the problem arises from some limitation, it is important to keep in mind that the limitation arises from entertaining some possibility as opposed to assuming that the possibility obtains.

  An instance of a limitation arising from assuming that the possibility obtains is the fourth type of dependence between premise and conclusion considered by \citeauthor{Pryor:2004ws}.

  \begin{quote}
    [Type 4] dependence between premise and conclusion is that the conclusion be such that evidence \emph{against it} would (to at least some degree) undermine the kind of justification you purport to have for the premises.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[359]{Pryor:2004ws})}
  \end{quote}

  Again, plausible.

  Issue:
  \begin{enumerate}
  \item Evidence undermines the kind of justification the agent purports to have for the premises.
  \end{enumerate}

  Seems to hold for \autoref{illu:CS:test:basic}.
  Would undermine appeal to \nagent{11}'s testimony.
  However, fails for \autoref{illu:CS:test:with-CS-for-premise}.
  Would not undermine the companion's assurance, even if viewed as an instance of testimony.

  Run this through the other instances suggested.

  And, as \citeauthor{Pryor:2004ws} notes, \emph{kind} is important.
  However, it seems kind is not the only problem.
\end{note}

\begin{note}
  Also compatible with \citeauthor{Pryor:2004ws}'s objection to type 4 being sufficient to identify problematic reasoning.
  Details are in the following footnote.\footnote{
  Compatible with \citeauthor{Pryor:2004ws}'s objection to type 4 dependence.

  % \begin{illustration}
    % \mbox{}
    % \vspace{-\baselineskip}
    \begin{quote}
      Suppose you're watching a cat stalk a mouse. Your visual experiences justify you in believing:

      \begin{enumerate}[label=(\arabic*), ref=(\arabic*)]
        \setcounter{enumi}{10}
      \item\label{illu:Pryor:cat:1} The cat sees the mouse.
      \end{enumerate}

      You reason:

      \begin{enumerate}[label=(\arabic*), ref=(\arabic*), resume]
      \item\label{illu:Pryor:cat:2} If the cat sees the mouse, then there are some cases of seeing.
      \item\label{illu:Pryor:cat:3} So there are some cases of seeing.\nolinebreak
        \mbox{}\hfill\mbox{(\citeyear[361]{Pryor:2004ws})}
      \end{enumerate}
    \end{quote}
  % \end{illustration}

  Setting aside whether this is fine.

  Following \citeauthor{Pryor:2004ws}:

  Bad, given proposal, as if no cases of seeing, then the cat is not seeing. (\citeyear[361]{Pryor:2004ws})

  \citeauthor{Pryor:2004ws}'s position is as follows:

  \begin{quote}
    I don't think you need antecedent justification to believe \ref{illu:Pryor:cat:3}, before your experiences can give you justification to believe \ref{illu:Pryor:cat:1}.
    I also think it's plausible that your perceptual justification to believe \ref{illu:Pryor:cat:1} contributes to the credibility of \ref{illu:Pryor:cat:3}.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[361]{Pryor:2004ws})}
  \end{quote}

  This is compatible with \ideaCSA{} and \ideaCSB{}, and the assumptions and premises which have followed.
  You need not agree with \citeauthor{Pryor:2004ws}

  No clear trouble.
  The possibility alone isn't going to do enough.
  Still seems possible for 1 to hold up.
  Would count against, but not clear that entertaining possibility raises issue for claimed support for premise.
  Indeed, also compatible with the cat not seeing, but if this is the case then it's not clear why no cases of seeing is any more important than the singular case.
  }
\end{note}

\begin{note}
  Of course, still some question about why entertaining the possibility is sufficient.
  And, why there does not seem to be considerations for certain consequences of claimed support.

  Nothing insightful beyond broad account.

  Given this, the purpose of the assumptions made is to narrow down a clearer problem.
  No reasoning, and as an instance of this when there is the impossibility of such reasoning.

  Examples of the former.
\end{note}

\subsection{Illustrations with respect to assumptions}

\begin{note}
  Previous section.
  \ideaCSA{} and \ideaCSB{}.
  Motivation for assumptions, and effort to clarify in contrast to other intuitions.
  Fell short of an account of the intuition.

  \autoref{assu:supp:nfactive}, \autoref{assu:supp:independence}.
  And, from these \autoref{prop:CS-nai}.

  Key here is lack of reasoning.
  This allows for the possibility that some variant instance of reasoning would succeed in claiming support.
  Indeed, we will suggest.
\end{note}

\begin{note}
  Two short, then one in some detail.
\end{note}

\subsection{Spot the difference}

\begin{note}[Spot the difference]
  \begin{illustration}[Spot the difference]\label{illu:CS:spot-the-diff}
    The agent has been working through a spot-the-difference to pass some time.

    Though the time is not completely passed, the agent examined the two images with what seems sufficient care to claim support that they have found all the differences.
    However, the agent did not keep track of the number of differences.

    The agent announces `I have found all the differences' and their companion responds `All fifteen?'.

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*)]
      \setcounter{enumi}{-1}
    \item\label{illu:CS:spot-the-diff:info} If I have found all the differences, I have found fifteen differences.
    \end{enumerate}

    The agent then reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*), resume]
    \item Exhaustive search.
    \item\label{illu:CS:spot-the-diff:all} I have found for all the differences.
    % \item\label{illu:CS:spot-the-diff:info} My companion has testified that there are fifteen differences.
    % \item\label{illu:CS:spot-the-diff:cond} If I have found all the differences, I have found fifteen differences.
    \item\label{illu:CS:spot-the-diff:fif} So, I have found fifteen differences. \hfill (From \ref{illu:CS:spot-the-diff:info} and \ref{illu:CS:spot-the-diff:all})
    \end{enumerate}
  \end{illustration}

  Before going further, structure of this.

  Claimed support for having found all the differences.
  The reasoning is mentioned but not stated in the illustration.
  Rather, present is distinct instance of reasoning after being provided with information.
  If not 15, then problem.
  However, the present reasoning does not consider possibility.
  Instead, consequence of previously claimed support.
\end{note}



\begin{note}
    Providing additional information about what the agent has claimed support for.
  Recall, \autoref{assu:CSVP}, information rather than states of affairs.
  \nolinebreak
  \footnote{
    Still slight issue.
    Offering a redescription.
    You met Clark Kent, so you met Superman.
    In this case, rather than claiming support for meeting Superman, provided information is seen as an equivalent formulation.
    It is possible to read \autoref{illu:CS:spot-the-diff} in this way, and this might be the most natural interpretation.
    However, it is not the interpretation under which see the problem.
    Rather, problem is where the conditional is explicit.
    Unlike Superman case, proper conditional.
  }
\end{note}

\begin{note}
  Information leads to \requ{}.

  And, present reasoning does not include reasoning about \requ{}.



  Simple for \requ{}.
  \expec{} as agent did not have information about how many differences, and was not keeping track.
\end{note}

\begin{note}
  Problem:
  Possibility of not fifteen.
  No reasoning about this expectation.
  Problem is that the agent has not considered whether the novel information places a limitation on their appeal to having found all the differences.
\end{note}

\begin{note}
  Argued above against circularity.
  Here, additional consideration.

  If the agent were to have had the information first time, then plausibly an instance of circularity.
  And, may think that this is also circularity as must also all must amount to fifteen.
\end{note}

\begin{note}
  This doesn't rule out some additional reasoning.
  \begin{enumerate}
  \item Exhausted search.
  \end{enumerate}
  Difference here is that the agent is not only appealing to having found.
  In addition, considerations that lead them to claiming that support.

  Whether you think this is enough is up to you.
  On the one hand, claimed support for no more differences.\nolinebreak
  \footnote{
    Indeed, reasoning framed with all as I think it is much less clear here.
  }
  So, what matters is not that found all but rather that exhaustivity of search.

  On the other hand, the agent did not keep track of the number of differences.
  So, may hold that they should go back and count.\nolinebreak
  \footnote{
    Looking ahead, \nI{}.
    Difficulty here is that don't need to go to \(\phi\).
    Indeed, note somewhere that \nI{} really only clearly takes hold when need some sort of factivity in play.
    We'll return to this.
  }
\end{note}

\begin{note}
  So, doesn't seem like circularity should apply here.
  For, if it does, then consider the variant as no improvement.
\end{note}

\subsection{Where's Wally}

\begin{note}
  \autoref{illu:CS:spot-the-diff} had something that could be obtained from the reasoning if re-examined.
  Just need to add a counter.

  Now, something that follows if the reasoning was \nmom{}.
\end{note}

\begin{note}
  \begin{illustration}[Where's Wally]
    \label{illu:CS:wheres-wally}
    Searching for Wally.
    On front of book is an image of wally in contrast to a number of other characters.
    Takes not of a number of features.
    Glasses, hat, striped jumper.
    In isolation, necessary but insufficient.
    Combined, sufficient.

    Search through the image.
    I've found Wally.
    Did you spot the cane first?

    The question carries implicit information:
    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:wheres-wally}.\arabic*)]
      \setcounter{enumi}{-1}
    \item\label{illu:CS:wheres-wally:info} The individual identified is Wally only if the individual is holding a cane.
    \end{enumerate}

    The agent then reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:wheres-wally}.\arabic*), resume]
    \item Collection of features sufficient.
    \item\label{illu:CS:wheres-wally:ante} Had features.
    % \item The individual identified is Wally only if the individual is holding a cane.
    \item The individual was holding a cane. \hfill (From \ref{illu:CS:wheres-wally:info} and \ref{illu:CS:wheres-wally:ante})
    \end{enumerate}
  \end{illustration}

  As with \autoref{illu:CS:spot-the-diff}, the reasoning of \autoref{illu:CS:wheres-wally} is such that the individual was holding the cane is an expectation of the claimed support that the individual was Wally, and no reasoning about it.
\end{note}

\begin{note}
  Problem.
  \requ{} and \expec{}.
  It's not clear need to give up claimed support, but does not extend to having a cane.

  In contrast to \ref{illu:CS:spot-the-diff}, does not seem there is anything weaker to fall back on.
  However, no strong claim here.
  Rely on stronger principles about claiming support.
\end{note}

\subsection{A trip to the zoo}

\begin{note}
  Illustrations \ref{illu:CS:spot-the-diff} and \ref{illu:CS:wheres-wally} looked at \expec{1} and reasoning.
  Final illustration is no different, structurally similar to \autoref{illu:CS:wheres-wally}.
  However, surrounding discussion to clarify details.

  After discussion, a corollary and a conjecture.
\end{note}

\begin{note}
  Zebra.

  Dretske is about knowledge.
  Problem for knowledge as factive.

  Still, don't need factive move.
  Possible not zebra, but vision is sufficient to expect that such a possibility does not obtain.

  Key here is that claiming support is never going to be strong enough to establish knowledge, at least to the extent that knowledge is factive.
\end{note}

\begin{note}
  \begin{illustration}[A trip to the zoo]
    \label{illu:CS:dretske-zebra}
    \mbox{}
    \vspace{-\baselineskip}
  \begin{quote}
    You take your son to the zoo, see several zebras, and, when questioned by your son, tell him they are zebras.
    Do you know they are zebras?
    Well, most of us would have little hesitation in saying that we did know this.
    We know what zebras look like, and, besides, this is the city zoo and the animals are in a pen clearly marked ``Zebras.''
    Yet, something's being a zebra implies that it is not a mule and, in particular, not a mule cleverly disguised by the zoo authorities to look like a zebra.
    Do you know that these animals are not mules cleverly disguised by the zoo authorities to look like zebras?

    \mbox{ }\hfill \(\vdots\) \hfill\mbox{ }

    Did you examine the animals closely enough to detect such a fraud?\linebreak
    \mbox{}\hfill\mbox{(\citeyear[1015--1016]{Dretske:1970to})}
  \end{quote}
  \vspace{-\baselineskip}
  \end{illustration}
\end{note}

\begin{note}
  \citeauthor{Dretske:1970to}'s presentation focuses on knowledge, so let us briefly form a parallel with respect to claiming support:

  \begin{illustration}
    \label{illu:dretske-zebra-var}
    \mbox{}
    `What if those animals are mules cleverly disguised by the zoo authorities to look like zebras?'
    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:wheres-wally}.\arabic*)]
      \setcounter{enumi}{-1}
    \item If zebra, then not cleverly disguised mule.
    \end{enumerate}
    Reasons as follows:
    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:wheres-wally}.\arabic*)]
    \item That animal appears to be a zebra.
    \item That animal is a zebra.
    \item That animal is not a cleverly disguised mule.
    \end{enumerate}
  \end{illustration}

  As with Illustrations~\ref{illu:CS:spot-the-diff} and~\ref{illu:CS:wheres-wally}, no reasoning about the possibility that the animal is a cleverly disguised mule.
  However, given conditional, \expec{} of claimed support for zebra.

  Introduction of additional consequence, so same structure as~\autoref{illu:CS:wheres-wally}.
  And, plausible that the agent may reason about the possibility that the animal is a cleverly disguised mule in a way sufficient to claim support.\nolinebreak
  \footnote{
    \citeauthor{Dretske:1970to} has a number of suggestions.
    \begin{quote}
    You have some general uniformities on which you rely, regularities to which you give expression by such remarks as, ``That isn't very likely'' or ``Why should the zoo authorities do that?''
    Granted, the hypothesis (if we may call it that) is not very plausible, given what we know about people and zoos.
    But the question here is not whether this alternative is plausible, not whether it is more or less plausible than that there are real zebras in the pen, but whether you know that this alternative hypothesis is false.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[1016]{Dretske:1970to})}
  \end{quote}
  }
\end{note}

\begin{note}
  if think that doesn't know, then not too much of an issue.
  However, does know?
  Indeed, \citeauthor{Dretske:1970to}.

  No clear tension.
  Knowledge and claiming support, different.

  However, problem identified.
\end{note}

\begin{note}
  \begin{enumerate}[label=K\Alph*., ref=K\Alph*]
  \item\label{Dretske:No-C:cond:no-k-then-ep} If an agent does not know that \(\phi\) is true, then \(\phi\) being false is an epistemic possibility for that agent.
  \item\label{Dretske:No-C:cond:ep-then-no-k} If \(\phi\) being false is an epistemic possibility for some agent, then that agent does not know that \(\phi\) is true.
  \end{enumerate}
  When taken together, (\ref{Dretske:No-C:cond:no-k-then-ep}) and (\ref{Dretske:No-C:cond:ep-then-no-k}) state that: An agent knows that \(\phi\) is true if and only if \(\phi\) being false is not an epistemic possibility for the agent.
  Still, our interest will primarily be with (\ref{Dretske:No-C:cond:ep-then-no-k}).\nolinebreak
  \footnote{
    \label{fn:factivity-two-readings}
    Contrast to `factivity':
    \begin{itemize}
    \item If \(S\) knows that \(\phi\), then \(\phi\).
    \end{itemize}
    This may be read in at least two different ways.
    \begin{itemize}
    \item First, relation between epistemic state of the agent and state of the world:\newline
      \mbox{} \qquad If \(S\) knows that \(\phi\), then the state of the world is such that \(\phi\) is the case.
    \item Second, how things appear from epistemic state:\newline
      \mbox{} \qquad If \(S\) knows that \(\phi\) then every way the state of the world may be for \(S\) includes \(\phi\).
    \end{itemize}

    The two reading are independent of one another.

    For example, suppose you walked to the shop but the only epistemic possibility entertained by your friend is that you drove to the shop.
    Here, it is not possible for your friend to know that you drove to the shop on the first reading of factivity, but the second reading is not ruled out.

    Conversely, suppose it is the case that you walked to the shop but your friend considers it epistemically possibly that you drove.
    Here, knowing on the second reading of factivity is ruled out, but the first reading is not ruled out.

    Of course, you may endorse both readings of factivity.
    Our focus is on the `weaker' reading as we have made no connexion between claiming support and the state of the word.
    (Perhaps it is of some interest to note that \citeauthor{Dretske:1970to} explicitly denies the second reading, but not the first.)
  }\(^{,}\)\nolinebreak
  \footnote{
    The dogmatism paradox (\cite[39,43--45]{Kripke:2011wv};\cite[148]{Harman:1973ww}) seems to concern the second reading of factivity from~\autoref{fn:factivity-two-readings}, and intuitions concerning evidence.

  Roughly stated, the paradox pairs the following two propositions:
  \begin{enumerate}[label=D\arabic*., ref=(D\arabic*)]
  \item\label{dog:1} If an agent is aware that they know that \(\phi\), then the agent may disregard any evidence against \(\phi\).
  \item\label{dog:2} Rational agents respect their evidence
    (\cite[Cf.][\S2]{Kelly:2016wk})
  \end{enumerate}
  Given~\ref{dog:2}, it seems no agent should not disregard any instance of evidence, even if the antecedent of~\ref{dog:1} is satisfied.

  And, it seems \ref{dog:1} is motivated by factivity.
  For, if the agent is aware that they know that \(\phi\) then the agent knows that \(\phi\).
  And, as knowledge is factive it follows (by second reading) that \(\phi\) is the case.
  In turn, if it is the case that \(\phi\) then any evidence against \(\phi\) is evidence for something that is not the case.
  Hence, the agent may disregard any evidence against \(\phi\).


  Indeed, the second reading of factivity seems required.
  For, it seems an agent is only (apparently) in a position disregard any evidence against \(\phi\) because there knowledge that \(\phi\) guarantees that \(\phi\) is the case.
  If \emph{not}-\(\phi\) is (merely) an epistemic impossibility, and it is not clear why evidence may require an agent to revise what they consider possible.

  Note:
  Neither \citeauthor{Kripke:2011wv} (nor \citeauthor{Harman:1973ww}) make explicit mention of the agent being aware that they know \(\phi\) when formulating the Dogmatism paradox.
      Still, the paradox is clearer with this stated, as it's require addition work to find issue with a permission (to disregard evidence) if an agent is not aware that they have such a permission.

      More generally, I agree with \citeauthor{Zhaoqing:2015vj}'s (\Citeyear{Zhaoqing:2015vj}) proposal to understand the paradox in terms of knowledge attribution rather than of knowledge proper.
  }
  \citeauthor{Dretske:1970to} observes that endorsing (\ref{Dretske:No-C:cond:no-k-then-ep}) and (\ref{Dretske:No-C:cond:ep-then-no-k}) leads to closure.
  The following is a reconstruction.\nolinebreak
  \footnote{
    Specifically, the following passage:
    \begin{quote}
      A slightly more elaborate form of the same argument goes like this:
      If \(S\) does not know whether or not \(Q\) is true, then for all he knows it might be false.
      If \(Q\) is false, however, then \(P\) must also be false.
      Hence, for all \(S\) knows, \(P\) may be false.
      Therefore, \(S\) does not know that \(P\) is true.\nolinebreak
      \mbox{}\hfill\mbox{(\citeyear[1011]{Dretske:1970to})}
    \end{quote}
    Note: (\ref{Dretske:No-C:cond:no-k-then-ep}) is a reformulation of the first conditional of the passage, while a formulation (\ref{Dretske:No-C:cond:ep-then-no-k}) seems required to move from `\(P\) may be false' to `\(S\) does not know that \(P\) is true'.
  }
\end{note}

\begin{note}[Closure argument]
  Let \(S\) be some agent and suppose:
  \begin{enumerate}[label=\arabic*., ref=\arabic*]
  \item\label{Dretske:No-C:k-entail} \(S\) knows that \(\phi\) entails \(\psi\).
  \item\label{Dretske:No-C:dunno-psi} \(S\) does not know that \(\psi\) is true.
  \end{enumerate}
  Consider the following argument:
  \begin{enumerate}[label=\arabic*., ref=\arabic*,resume]
  \item\label{Dretske:No-C:ep-not-psi} \(\psi\) being false is an epistemic possibility for \(S\).%
    \hfill (\ref{Dretske:No-C:cond:no-k-then-ep} \& \ref{Dretske:No-C:dunno-psi})
  \item\label{Dretske:No-C:no-ep-no-entail} \(\phi\) not entailing \(\psi\) is not an epistemic possibility for \(S\)%
    \hfill (\ref{Dretske:No-C:cond:ep-then-no-k} \& \ref{Dretske:No-C:k-entail})
  \item\label{Dretske:No-C:ep-not-psi-and-phi}  \(\phi\) being true while \(\psi\) is false is not an epistemic possibility for \(S\).%
    \hfill (\ref{Dretske:No-C:no-ep-no-entail})
  \item\label{Dretske:No-C:ep-not-phi} \(\phi\) may be false.%
    \hfill (\ref{Dretske:No-C:ep-not-psi} \& \ref{Dretske:No-C:ep-not-psi-and-phi})
  \item\label{Dretske:No-C:not-k-phi} \(S\) does not know that \(\phi\) is true.%
    \hfill (\ref{Dretske:No-C:cond:ep-then-no-k} \& \ref{Dretske:No-C:ep-not-phi})
  \end{enumerate}

  Hence, we have shown that, given (\ref{Dretske:No-C:cond:no-k-then-ep}) and (\ref{Dretske:No-C:cond:ep-then-no-k}), (\ref{Dretske:No-C:k-entail}) and (\ref{Dretske:No-C:dunno-psi}) imply (\ref{Dretske:No-C:not-k-phi}).

  That is to say, we have shown:
  \begin{enumerate}[label=K\Alph*., ref=(K\Alph*)]
    \setcounter{enumi}{2}
  \item\label{K:closure:from-arg} If \(S\) knows that \(\phi\) entails \(\psi\) and \(S\) does not know that \(\psi\) is true, then \(S\) does not know that \(\phi\) is true.%
    \mbox{} \hfill \((K_{S}(\phi \rightarrow \psi) \land \lnot K_{S}\psi) \rightarrow \lnot K_{S}\phi\)
  \end{enumerate}
  And rewriting:\nolinebreak
  \footnote{
    \((\phi \land \lnot\psi) \rightarrow \lnot\xi\) iff \(\phi \rightarrow (\lnot\psi \rightarrow \lnot\xi)\) iff \(\phi \rightarrow (\xi \rightarrow \psi)\).
  }
  \begin{enumerate}[label=K\Alph*\('\)., ref=(K\Alph*\('\))]
    \setcounter{enumi}{2}
  \item\label{K:closure:standard} If \(S\) knows that \(\phi\) entails \(\psi\), then if \(S\) knows that \(\phi\) is true then \(S\) knows that \(\psi\) is true.%
    \mbox{} \hfill \(K_{S}(\phi \rightarrow \psi) \rightarrow (K_{S}\phi \rightarrow K_{S}\psi)\)
  \end{enumerate}
\end{note}

\begin{note}
  Return to \autoref{illu:CS:dretske-zebra}.

  Let us assume you know that:
  \begin{itemize}
  \item If the animals are zebras then the animals are not cleverly disguised mules. And,
  \item The animals are zebras.
  \end{itemize}

  If \ref{K:closure:standard} holds, then you also know that the animals are not cleverly disguised mules.
  However, following \citeauthor{Dretske:1970to}'s intuition, you do not know that the animals are cleverly disguised mules.

  Hence, to accommodate \citeauthor{Dretske:1970to}'s intuition, either (\ref{Dretske:No-C:cond:no-k-then-ep}) or (\ref{Dretske:No-C:cond:ep-then-no-k}) must be rejected.
  \citeauthor{Dretske:1970to} rejects (\ref{Dretske:No-C:cond:ep-then-no-k}).\nolinebreak
  \footnote{
    See below.
  }
\end{note}

\begin{note}
  We now return to claiming support.

  \autoref{assu:supp:nfactive} requires that claiming support for \(\phi\) is compatible with the (epistemic) possibility that the claimed support is \nmom{}.
  And, the claimed support is \misled{} just in case \(\phi\) is not the case.
  Hence~\autoref{assu:supp:nfactive} requires that claimed support for \(\phi\) is compatible with the (epistemic) possibility that \(\phi\) is not the case.

  Therefore, the result of substituting `claimed support' from `knowledge' in (\ref{Dretske:No-C:cond:ep-then-no-k}) conflicts with \autoref{assu:supp:nfactive}.
  And so~\autoref{assu:supp:nfactive} parallels \citeauthor{Dretske:1970to}'s rejection of (\ref{Dretske:No-C:cond:ep-then-no-k}).
  However, \citeauthor{Dretske:1970to}'s rejection of (\ref{Dretske:No-C:cond:ep-then-no-k}) is motivated by a rejection of~\ref{K:closure:standard}.
\end{note}

\begin{note}[Link]
  The refinement of~\autoref{idea:eiS} through Assumptions \ref{assu:supp:independence} and \ref{assu:independence-expec} has lead to two propositions close to~\ref{K:closure:standard}.

  \autoref{prop:CS-only-if-reason-recognised-defeaters} and \autoref{prop:CS-nai}.
  Both may be phrased in closure-like ways.

  \begin{enumerate}[label=P\ref{prop:CS-only-if-reason-recognised-defeaters}\('\).]
  \item If \(\psi\) having value \(v'\) is a \requ{} of claiming support for \(\phi\), then if the agent has claimed support for \(\phi\) having value \(v\) then the agent has reasoned about whether \(\psi\) has value \(v'\).\newline
    \mbox{}\hfill \((\text{CS}\phi \leadsto \psi) \rightarrow (\text{CS}\phi \rightarrow \text{R}\psi)\)
  \end{enumerate}

  \begin{enumerate}[label=P\ref{prop:CS-nai}\('\).]
  \item If \(\psi\) having value \(v'\) is a \expec{} of claimed support for \(\phi\), then if the agent appeals claimed support for \(\phi\) having value \(v\) then the agent has reasoned about whether \(\psi\) has value \(v'\).\newline
    \mbox{}\hfill \((\text{CS}\phi \leadsto \psi) \rightarrow (\text{A}(\text{CS}\phi) \rightarrow \text{R}\psi)\)
  \end{enumerate}

  Both build on \autoref{def:requisite}.
  A \requ{}.
  This is a complex parallel to knowing that \(\phi\) entails \(\psi\).
  However, somewhat general, and applies to \(K\) also.
  {\color{red} (Strictly speaking, because of contraposition, make this more explicit below)}

  \autoref{assu:supp:independence} then requires reasoning.

  Turning to \ref{assu:independence-expec}, extend \requ{} to \expec{} through \autoref{def:expectation}.
  In turn, require reasoning when appealing to claimed support.

  In both cases, requiring something with respect to \(\psi\) having value \(v'\) given some state of the agent an principle which relates \(\psi\) having value \(v'\) to that state.

  For sure, appealing, or having claimed support is distinct, so the closure is not that with respect to an \emph{an} epistemic operator such as knowledge.
  However, the tension here is in terms of viewing the rejection of \ref{K:closure:standard} as the endorsement of a `locality constraint'.
  {\color{red} What this means.}
  And, seem to violate such a constraint.
\end{note}

\begin{note}[`Locality constraint']
  \begin{quote}
    To know that \(x\) is \(A\) is to know that \(x\) is \(A\) within a framework of relevant alternatives, \(B\), \(C\), and \(D\).
    This set of contrasts, together with the fact that \(x\) is \(A\), serve to define what it is that is known when one knows that \(x\) is \(A\).
    One cannot change this set of contrasts without changing what a person is said to know when he is said to know that \(x\) is \(A\).\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[1022]{Dretske:1970to})}
  \end{quote}

  Where:
  \begin{quote}
    A relevant alternative is an alternative that might have been realized in the existing circumstances if the actual state of affairs had not materialized.\nolinebreak
    \footnote{
      \citeauthor{Dretske:1970to} adds:
  \begin{quote}
    \dots alternatives that \emph{might} have been realized in the existing circumstances if the actual state of affairs had not materialized.
    \dots are not relevant alternatives.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[fn.6][1021]{Dretske:1970to})}
  \end{quote}
    }
    \nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[1021]{Dretske:1970to})}
  \end{quote}
  Different from a \requ{}.
\end{note}

\begin{note}
  Point is not direct clash.\nolinebreak
  \footnote{Two problems.

    First, \citeauthor{Dretske:1970to} seems to go with no recognition at time, compatible with claiming support at time.
    So, would need instance of appealing to knowledge for some other purpose.
    Restating is not sufficient, assumptions made are compatible with persistence (as noted).

    Second, only get no need to rule out from \citeauthor{Dretske:1970to}, which does not require no reasoning.
  }
  At issue, rather, it the degree to which possibility is compatible with the absence of reasoning.
  That is, if reject closure, is this due to reasoning or due to requirements placed on such reasoning?\nolinebreak
  \footnote{
    (Problem here, but also extends to \nI{}.)
  }

  There is some subtlety, however.
  Kind of closure seems to break for many attitudes.
  This is not at issue, distinguishing feature of claiming support is closure, and the constraints this places on an agent.
  However, reject for stronger attitudes, then why for weaker?
\end{note}

\begin{note}
  Reasoning, but haven't placed constraints.
  So, this allows for something that may be quite weak.
  % I am here only restating what has gone before, but the added context may help.
  No reasoning, then leaves open possibility that does lead to a problem with the reasoning performed.

  Consider again relevant alternatives from internalist perspective.
  It seems, agent determines whether relevant or not will require reasoning.

  Consider:
  \begin{quote}
    `What if those reports about the zoo authorities cleverly disguising animals to look like other animals?
    If there are, could those animals be cleverly disguised mules?'
  \end{quote}
  Perhaps not a relevant alternative if the sense of `might' is non-epistemic, but if epistemic, then seems a problem.
\end{note}

\begin{note}
  To summarise.

  \citeauthor{Dretske:1970to}'s case.
  Rejection of closure.
  Question whether assumptions are okay.
  Argued that these are given understanding of claimed support, and that they plausibly extend to knowledge (and other attitudes intuitively stronger than that of having claimed support).
  For, rejection of closure plausibly amounts to rejection on strength of reasoning, rather than requirement to reason.

  Focus on this point for two reasons:
  First, distinguishing feature of claiming support and following will be about claiming support.
  Second, appeal to similar limitation later.
\end{note}

\newpage

\subsection{A corollary and a conjecture}

\begin{note}
  Talked about `closing principle'.
  Make this precise.
\end{note}

\begin{note}[Generalising point for K example]
  Generalise.
  Any time the agent appeals to a consequence.
  And, this is straightforward, because consequence is only going to hold with the antecedent.

  \begin{corollary}\label{corr:eiS:C:contraposition}
    Suppose an agent has prior claimed support for:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item\label{corr:cond:p} \(\phi\) having value \(v'\). And,
    \item\label{corr:cond:pq} If \(\phi\) has value \(v\) then \(\psi\) has value \(v'\).
  \end{enumerate}
  Such that the agent claimed support for \ref{corr:cond:p} prior to \ref{corr:cond:pq} and as such the reasoning involved in claiming support for \ref{corr:cond:p} did not entertain the possibility of \(\psi\) not having value \(v'\).
  And, further suppose the agent holds that:
  \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
    \item The claimed support for \ref{corr:cond:pq} (also) implies that if \(\psi\) does not have value \(v'\) then \(\phi\) does not have value \(v\).
  \end{enumerate}
  Then, if the agent engages in reasoning such that:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
    \item The agent does not appeal to anything other premises other than~\ref{corr:cond:p} and ~\ref{corr:cond:pq} from their prior claimed support, some form of conditional detachment applied to ~\ref{corr:cond:p} and~\ref{corr:cond:pq} to conclude that \(\psi\) has value \(v'\).
    \end{enumerate}
    Such that remains possible that \(\psi\) does not have value \(v'\).
    The reasoning is not an instance of claiming support.
  \end{corollary}

  \autoref{corr:eiS:C:contraposition} is a summary of the common problem between illustrations \ref{illu:CS:spot-the-diff},~\ref{illu:CS:wheres-wally}, and~\ref{illu:dretske-zebra-var}.
  And, as such captures sufficient conditions for \autoref{prop:CS-nai}.
\end{note}

\begin{note}
  Observe, from \autoref{prop:CS-nai} we have that reasoning that \(\psi\) has value \(v'\) is not an instance of claiming support {\color{red} if \expec{} with no reasoning about it as \expec{}}.

  By assumption, no reasoning about \(\psi\) not having value \(v'\) when claiming support for \(\phi\) having value \(v\).

  Therefore, to establish \autoref{corr:eiS:C:contraposition} we need only show that \(\psi\) having value \(v'\) is a \expec{} of the claimed support for \(\phi\) having value \(v\).

  And, the agent has come to consider \(\psi\) having value \(v'\) as a \requ{} of that claimed support as:
  \begin{itemize}
  \item Possible that \(\psi\) does not have value \(v'\), by assumption.
  \item If \(\psi\) does not have value \(v'\) then \(\phi\) does not have value \(v\), and hence the claimed support for \(\phi\) having value \(v\) would be \misled{}.
  \item And, as \(\phi\) having value \(v\) implies \(\psi\) has value \(v'\) it must be the case that \(\psi\) having value \(v'\) persists through to the conclusion of reasoning.
  \end{itemize}
\end{note}

\begin{note}
  Again, intuition is that claimed support for \(\phi\), but novel information about a possible defeater.
  So, it's no good to appeal to prior claimed support --- without additional reasoning about that claimed support --- as the claimed support did not take into account the possible defeater.
\end{note}

\begin{note}
  In general, expect this not to be much of a concern.

  Three considerations.
\end{note}

\begin{note}[Not claiming support]
  First, the obvious, claiming support and may not be the case that agent is claiming support in relevant reasoning.
\end{note}


\begin{note}[Deal with \requ{}]
  Second, in many cases claimed support for \(\phi\) is not going to hold up regardless of whether \(\psi\), so plausible reasoning about \(\psi\) as a \requ{}.

  For example:

  Alarm ringing, so fire.
  If no fire, not alarm ringing.
  However, even if consider the possibility that there isn't really a fire, clear that the alarm is ringing.
\end{note}

\begin{note}
  Strengthening, this will also not apply if the agent has claimed support that \(\phi \rightarrow \psi\) and \(\lnot \phi \rightarrow \psi\) and appeals.
  For, no \requ{} in this case.
\end{note}

\begin{note}[Requires contraposition]
  Finally, contraposition.
  It is not clear that contraposition always holds.

  And, without contraposition, retain claimed support for \(\phi\), and even if \mom{} \(\phi\) provides enough to think that \(\psi\) is the case.
  In particular, a variation of~\ref{corr:eiS:C:contraposition} does not \emph{necessarily} hold with respect to conditional probability.

  \begin{idea}\label{conj:eiS:C:probability}
    Assuming that sufficiently high probability is sufficient for claiming support.

    It is not necessarily the case that an agent may not claim support for \(\psi\) having value \(v'\) by appeal to:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item\label{corr:prob:p} Claimed support for \(\phi\) having value \(v'\) such that no consideration of \(\psi\).
    \end{enumerate}

    Some time after \ref{corr:prob:p}:

    \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
  \item\label{corr:prob:pq} Claimed support for \(\psi\) having value \(v'\) when \(\phi\) has value \(v\).
    \end{enumerate}

    If:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
    \item The agent does not appeal to any other premises other than claimed support for~\ref{corr:prob:p},~\ref{corr:prob:pq} and some principle regarding conditional probability.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{idea}

  Follows from the simple observation that conditional probability does not require that \(\phi\) is false when \(\psi\) is false.

  For example, set some threshold \(t\) and consider a probability distribution such that:
  \(P(\phi) > t\), \(P(\psi \mid \phi) > t\).
  It is consistent with such a distribution that \(P(\lnot\phi \mid \lnot\psi) = 0\).\nolinebreak
  \footnote{
    For example, if \(t = .0\), then let \(P(\phi) = .9\), \(P(\psi) = .92\), \(P(\phi \land \psi) = .81\), \(P(\lnot\phi \land \lnot\psi) = 0\).
  }
  And, therefore, from an agent's perspective it need not be the case that \(\phi\) would be false if \(\psi\) were false.
  In other words, it may be that entertaining possibility that \(\psi\) is false is just entertaining a restricted instance of \(\phi\) being true.
  Hence, \(\psi\) being true is not a \requ{} of \(\phi\) being true.

  Still,  \(\psi\) being true may be an `\emph{unrecognised} \requ{}' of \(\phi\) being true.
  However, we have made no assumptions regarding such `unrecognised \requ{1}'.

  {
    \color{red}
    Some care here, though.
    As the issue with possible defeaters is distinct from the probability of such defeaters.
    Indeed, given possibility, probability is typically low.
    Yet, this does not say anything about whether claimed support would hold up if the defeater turned out to be the case.

    The point of this {\color{red} idea} is to highlight an instance of a conditional that does not contrapose, and so does not lead to a \requ{}.
  }
\end{note}

\begin{note}
  These kinds of issues are fundamental to the argument.
  Issue is with a way of claiming support, rather than the possibility of claiming support.
  And, the issue is a result of the two assumptions made regarding claiming support.

  If something stronger or weaker, then the issue does not (necessarily) arise.
  Take it for granted that testimony.
  Knowledge excludes (epistemic) possibilities associated with defeaters.

  So, even if agent fails to claim support, may have done something interesting!

  However, focus is on claiming support.
  Possible defeaters, and some defence against those defeaters obtaining.

  Really important thing from these illustrations is that no particular assumptions about reasoning.
  Illustrations all relied on absence of reasoning.
  So, although somewhat strong, still plausibly weak.
  Mentioned at many times things that seem sufficient.
  However, did not rely on these.

  So, claiming support is this odd thing.
  We will argue for additional proposition.
  \nI{}.
  Again, this will not rely on assumptions about reasoning.
\end{note}

\section{Summary of assumptions}

\begin{note}
  Claiming support.

  Two key ideas:

  \begin{enumerate}
  \item From \nfcs{}, always possible.
  \item From \eiS{}, doesn't depend.
  \end{enumerate}
  Second in part motivated by the first.

  Intuitively, stronger than belief, but weaker than knowledge.

  {
    \color{red}
    Claiming support is strong in the sense that it requires the agent's reasoning to hold up even if things are not how the agent thinks.
    However, strength is mitigated as bar for expectation may be set low.
  }

  Consequence of the first is way of establishing that reasoning does not result in claiming support.
  These assumptions are important.
  Argument relies on these assumptions.

  May be that it is possible to revise, but seem to capture something sufficiently interesting.
\end{note}

\begin{note}
  Well, it's a little more complex.
  What the argument really depends on is \ESU{} and \nI{}.
  Specifically \nI{}.

  It's not clear to me that these assumptions are strictly speaking required for \nI{}.
  And, some motivation of \nI{} independently of these.
  Still, this is as far as I got with \nI{}.

  Just so happens that these two assumptions also offer a nice `functional' characterisation.
  Therefore, appeal to these in order to set the stage.
\end{note}

\hozline{}

\subsection{Test}

\begin{note}
  To help fix intuition, I suggest a test to clarify what is meant by `expect': The `even if\dots' test.
  So long as an agent may provide an adequate responses to the test, the agent will be in a position to claim support.
\end{note}

\begin{note}[The `Even if\dots' test]
  The `Even if\dots' test queries whether an agent's claimed support permits an agent to expect that some (epistemically) possible defeater fails to obtain `even if' it does obtain.

  For example, even if \(0.999\dots = 1\), there must be \emph{some} difference between \(0.999\dots\) and \(1\) --- no matter how small --- and some difference between to things is sufficient to establish that they are not equal.

  Implied in this response is something like the observation that \(0.9 = (1 - 0.1)\) and \(0.99 = (1 - 0.01)\), and so \(0.999\dots = (1 - 0.000\dots 1)\), hence \(1 = (0.999\dots + 0.000\dots 1)\), and because \(0.999\dots\) refers to some quantity, \(0.000\dots 1\) likewise refers to some quantity.
  It seems reasonable for an agent to expect that the Archimedean property does not hold for real numbers.

  The example given is an instance of the applied to the possibility that the agent's claimed support that \(0.999\dots \ne 1\) may be misleading, as the antecedent supposes that \(0.999\dots = 1\).

  Generalising, we have outlined two kinds of defeaters that would prevent an agent from claiming support.
  The two types of defeaters suggest two basic instances of the test:
  \begin{enumerate}
  \item[(ML)] Even if \(\phi\) does not have value my claimed support indicates, I consider it to be the case that\dots
  \item[(MT)] Even if I some part (or whole) of my claimed support for the value of \(\phi\) is mistaken, I consider it to be the case that\dots
  \end{enumerate}
  Below we provide three examples for each basic instance of the test, two (plausibly) successful responses and one (plausibly) unsuccessful response..\nolinebreak
  \footnote{
    You may think that some of the adequate responses I suggest are too weak, but for future purposes I require only that some positive answer many be given, and so you may strengthen the requirements on a positive answer as you see fit.
  }
\end{note}

\begin{note}[Even if: misled]
  We being with two plausibly satisfactory responses to being misled.

  \begin{enumerate}[label=(ML\arabic*), ref=(ML\arabic*), series=ML_counter]
  \item\label{ML:asleep} Even if that person is not sleeping, their eyes have been closed for a long time and their breathing is slow.
  \item\label{ML:lying} Even if you are telling the truth, the scientific consensus is against you.
  \end{enumerate}

  With \ref{ML:asleep} the agent has claimed support for the proposition that the person is sleeping.
  It's not too hard to give the impression of being asleep, so there is some possibility that the person is awake and support claimed is misleading.
  Still, even if the person is awake, the person is exhibiting sufficient signs of being asleep for the agent to expect that they are not misled.

  Turning to \ref{ML:lying}, it may be that the person is telling the truth and if the person is indeed telling the truth then any claimed support for a conflicting proposition must be mistaken.
  However, scientific consensus seems sufficient to claim support for the relevant conflicting proposition --- one expects that scientific consensus is not misleading given the rigours of the scientific process.
  Scientific consensus does not (at least typically) require that the person is not telling the truth (though will imply that to be the case).

  In contrast, consider an unsatisfactory response.

  \begin{enumerate}[label=(ML\arabic*), ref=(ML\arabic*), resume*=ML_counter]
  \item\label{ML:forgery} Even if plagiarised, it's not worth thinking about. (I.e.\ don't worry about claiming support).
  \end{enumerate}
  If the certificate is a forgery, then the claimed support for the proposition that the certificate is not a forgery would be misleading.

  Seems the reasoning here is too little.
  Hence, that the certificate self-certifies it's authenticity is no response to the (possibility) that it is a forgery.
  Immediate conflict with \eiS{} because it seems quite unreasonable to expect that the certificate is not a forgery based on it's self-certification.

  Of course, many certificates do self-certify (it would be excessive effort to identify a certificate and then be required to find information about what the certificate is for), and perhaps a simple observation that there are no signs of tampering may be a sufficient response to the `even if\dots' test.
\end{note}

\begin{note}[Even if: mistaken]
  Turning to the possibility of mistaken support, consider the following two instances of the `even if\dots' test.

  \begin{enumerate}[label=(MT\arabic*), ref=(MT\arabic*), series=MT_counter]
  \item\label{MT:fake-wound} Even if that is a fake wound, I have no way to tell and the actions of the (apparently) wounded would be a feat of acting.
  \item\label{MT:misquote} Even if the newspaper has quoted the wrong person, the paper has a strong record of accurate reporting.
  \end{enumerate}

  With respect to~\ref{MT:fake-wound}, it seems a mistake to treat a fake wound as indicate the presence of an actual wound, as a fake wound does not require a genuine would but likewise a fake wound may cover a genuine wound.
  The response to the `Even if\dots' test notes that the behaviour of the (apparently) wounded person is sufficiently consistent with their expectations of the behaviour of a person with the (apparent) wound, and would lead to be surprised if the person was not in fact wounded.

  Turning to~\ref{MT:misquote}, if the paper has quoted the wrong person then it would be a mistake to claim support that the person said whatever-it-is-they-said, though it may still be the case that the person did say whatever-it-is-they-said.
  Even so, the strong record of the paper seems sufficient for the agent to expect that the newspaper has not misattributed or imagined the quote on the relevant occasion.

  In contrast, consider an unsatisfactory response.

  \begin{enumerate}[label=(MT\arabic*), ref=(MT\arabic*), resume*=MT_counter]
  \item Even if this library does not using LCC indexing, the library does not have a copy of `Measurement Theory' because as search for `H61 .R593' returns no results.
  \end{enumerate}
  Holding that a library does not have a copy of a book because a search for the book under a particular indexing system would be a mistake.
  For, if the library does not use the particular indexing system then a search using that indexing system will always fail, regardless of whether or not the library has a copy of the book.

  In turn, a failed search for an LCC index in the library's database does not seems sufficient for an agent to claim that the library does not have a copy of the book unless the agent is in a position to claim support that the library uses LCC indexing.
  Following, it seems the failed response to the `Even if\dots' test may be supplemented by noting that the library is a research library, and therefore likely uses LCC indexing, etc.\
\end{note}


\section{Closing focus on claimed support}

\begin{note}[Closing support]
  To summarise, claim of support.
  Certain kind of independence.
  Only interested in support, and not how this relates to attitudes.
  Somewhat intuitive, but no claims that this is the only understanding of support.

  For the moment, this provides clarity for understanding of support.
  Below, use to argue for failure to claim support.
\end{note}

\begin{note}[Something to emphasise]
  \color{red}
  Something to emphasise here is that this means that there's a way for an agent to claim support without being certain that \(\phi\) is the case.
  I don't have any answers for what this is.
  However, I do take this to be highly intuitive.
\end{note}


\begin{note}[Adequate]
  Kind of reasoning that we, the folk, do.
  Distinction for claiming support is that this is different from whether the agent has support, and we may set issues about whether the agent has support.

  Our interest is what is required for an agent to \emph{claim} support for (premises and) steps of reasoning, rather than what is required for an agent to \emph{have} support for (premises and) steps of reasoning.

  Use support as opposed to justification.
  Initial focus is on epistemic/doxastic attitudes.
  However, practical reasoning.
  For example, means-end.
  Support considered quite general to also include this.
\end{note}

\begin{note}
  Highlight again \phantref{dogmatism-wrt-nI}{below}.
\end{note}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End: