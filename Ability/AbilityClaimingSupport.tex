 \chapter{Claiming support}
\label{cha:claiming-support}

\begin{note}
  \color{red}
  Note somewhere that the step doesn't have to be deductive.
\end{note}

\paragraph*{Overview}

\begin{note}
  The present chapter is about claiming support.
  Or, more precisely, claiming support and claimed support --- we are interested in both an activity and the result of that activity.

  The purpose of the following discussion of claiming support with respect to the {\color{red} overall project} is as follows:

  Reasoning with ability, obtaining some conclusion.
  Incompatible with intuitive understanding of part of such reasoning and, in particular, an common idea appealed to in various arguments.

  In order to make such an argument we require some background constraints on such reasoning.
  Hence, in this chapter we work though those background constraints.

  This then provides sufficiently precise context for \autoref{cha:claiming-support-use} in which we state in detail what we arguing against, and what we are arguing for.
  And, provide background for~\autoref{part:tension} in which we argue for a principle restricting claiming support (specifically \autoref{sec:second-conditional}).

  And, as part of providing sufficiently precise context will include a rough template of the considerations which motivate argument.

  In other words, context, and also preview.
\end{note}

\begin{note}
  Two things to keep in mind.

  \begin{enumerate}
  \item These constraints are partial.
  \item Consequence of constraints that matters.
  \end{enumerate}

  Enough to identify certain ways in which an agent may fail to perform the reasoning of interest.

  Benefit of not building in `too much'.

  However, also possible to endorse additional constraints.
  In particular, rule out alternative.
  If so, also a problem.
  We will not give much attention to this.
  Argument rests on plausibility when applied to particular case.
  If agree with constraints and agree with particular case, then this is an indirect argument against stronger constraints.


  Consequence of constraints that matters.
  Preview of considerations that matter, but additional step.

  However, postpone final constraint until argument proper.
  Primarily because for the moment, enough to interpret what we are argument against and for --- consequence isn't required.
  Secondary, this constraint where it matters in the argument.
  Third, surrounding motivation and context within literature.

  Welcome to turn to \autoref{sec:second-conditional} following this section.
\end{note}

\paragraph{Plan}


\section{Epistemic states}
\label{sec:epistemic-states}

\begin{note}
  What an epistemic state is.
\end{note}

\begin{note}
  \begin{restatable}[An epistemic state]{definition}{defEState}
    \begin{enumerate}
    \item \epPAd{2} \world{1}
    \item \epVAd{2} \world{1}
    \end{enumerate}
    Where,
    \begin{itemize}
    \item \epVAd{2} \world{1} are candidates for the actual \world{}.
    \item \epPAd{2} \world{1} are candidates for the actual \world{}, if the actual world is not an \epVAd{0} \world{1}.
    \end{itemize}
  \end{restatable}
\end{note}

\begin{note}
  Worlds, plausibility ordering.
  Here, 
  However, binary ordering.
  And:
  allow that ordering may be world dependent.
  do not require that the actual world is among the most plausible.
\end{note}

\paragraph{\ep{1}}

\begin{note}
  In these examples, \PAd{0} rather than possible.
  \PAd{2} does not mean `likely'.

  This is a somewhat imprecise distinction, but it helps to narrow focus.
  It is possible, but not \PAd{0}, that there is no external world.
  It is possible, but not \PAd{0}, that the moon does not exist.
  It is possible, but not \PAd{0}, that the clock on my phone is incorrect.

  And so on.

  Move from extreme to less extreme.

  Plausibility is somewhat arbitrary, conspiracy theories, etc.
  Nothing in the paper rests on this distinction.
  However, clarify focus.
\end{note}

\begin{note}
  Not interested in sceptical scenarios.
\end{note}

\section{`Claiming'}
\label{sec:claiming}

\begin{note}[Introducing support]
  Initial clarification is with respect to claiming support.
  Emphasis on `\emph{claim}'.

  The thesis is not about when and why an agent has \emph{support}.

  There are three primary reasons why we focus on claimed support.

  First, neutral for main thread of argument on what support amounts to.
  Interest is with structure of claim, and background assumption that if success in claiming then structure of support follows structure of claim.

  Second, whether or not an agent has support often seems secondary.
  It may be that any claimed support for a proposition is support for that proposition, but perhaps not.
  \begin{illustration}[A box of flan(nels)]
    \label{illu:flan-nels}
    Suppose `flan' is written on the side of a container.
    I may claim support that the container contains flan.
    And, it may be that the writing on the side of the container is support for the box containing flan.
    However, the straps ensuring the container remains closed is unfortunately placed, and if moved would reveal the side of the container reads `flannels'.
  \end{illustration}

  The unfortunate placing of the straps does not seem to prevent \emph{claiming} support, but I'm not sure whether it is right to say that the writing on the side of the box (straps in place) \emph{does} provide support that the box containing flan.
  So, speaking in terms of claiming support leaves open whether what is claimed reflects on whether an agent has support.\nolinebreak
  \footnote{
    In particular, claiming allows focus on internal constrains, while remaining silent on whether having support is (in part) determined by external factors.
  }
  \(^{,}\)\nolinebreak
  \footnote{
    Distinction between propositional and doxastic support.
    Propositional, support agent has whether or not made a claim.
    Doxastic is successful claim and propositional support.
    So, both require that the agent has support.
    Claimed support is the agentive component of doxastic support.
    Not interested in whether the agent also has propositional support, though more or less assume.
  }
  \(^{,}\)\nolinebreak
  \footnote{
    {
      \color{red}
      English is somewhat difficult.
      It is somewhat unfortunate that `an agent has claimed support for \(\phi\)' may be read `there is support which the agent has claimed for \(\phi\)'.
      Still, this seems to follow more easily from `support claimed'.
      So, `claimed support' emphasises the claim, while `support claimed' emphasises support.
    }
  }

  Third, and following from the second, focusing on claimed support allows us to make no assumption about the relationship between claimed support and support.
  To elaborate, consider enthymematic inferences.
  One may hold that an agent may claim support for some conclusion via enthymematic inference, but hold that the support the agent has is understood from the perspective of the (corresponding) complete inference.\nolinebreak
  \footnote{
    Cf.\ \textcite{Moretti:2019wx}.
  }
  Alternatively, one may hold that the enthymematic argument is an adequate support relation (at least with respect to context in which the inference was made).

  Hence, one may question whether the structure of claimed support follows the structure of support.

  An important consequence of this final point is that we will only be interested in why (and when) an agent claims support for and from ability rather than why (or when) an agent \emph{has} an ability.
\end{note}

\section{Basic assumptions}
\label{sec:basic-assumptions}

\begin{note}
  Overview of basic assumptions.
\end{note}


\subsection{Propositions and values}
\label{sec:basic-assumptions:props-and-vals}

\begin{note}[Value proposition]
  Reasoning and claims to support focus.
  Briefly introduce a pair of propositions to clarify claim to support and reasoning.

  \begin{restatable}[Claimed support is for a proposition having some value]{assumption}{assuCSVP}
    \label{assu:CSVP}
    When an agent claims support for some proposition \(\phi\) having value \(v\), the agent assigns value \(v\) to the \world{} described by \(\phi\).
    Where propositions individuate \world{1} from the perspective of the agent.
  \end{restatable}

  \autoref{assu:CSVP} fixes terminology.
  To illustrate, when stating the conclusion of the reasoning sketched above we used the proposition that \emph{the area of the rectangle is \(133\text{cm}^{2}\)}.
  The proposition refers to the \world{} in which the area of the rectangle is \(133\text{cm}^{2}\), and speaking a little more precisely, the agent claimed that the proposition has the value `true' --- though it may be the value turns out to be `false'.
  Or, perhaps if the agent was a little unsure about the accuracy of the ruler, that the proposition has the value `likely', `probable', or some quantitative credence.
  And, some other instance of reasoning may have concluded that the proposition has the value `desirable' --- e.g.\ if the agent was searching for a rectangle of some approximate size.\nolinebreak
  \footnote{
    Nothing in particular hangs on the distinction between different values.
    If you prefer, you may expand the proposition (\world{}) to include additional factors, and consider only the values `true' and `false'.
    For example, the proposition that \emph{I desire the bath to be warm} is false, as opposed me assigned the proposition that \emph{the bath is warm} the value `undesirable'.
  }
\end{note}

\begin{note}
  Core idea is that claim of support is that the \world{} is a certain way.
  Proposition, what the thing is.
  Value, the way it is.

  A handful of instances:
  \begin{itemize}
  \item \(p\) is assigned the value `true'. \hfill (\emph{p} is true.)
  \item \(p\) is assigned the value `ought to be'. \hfill (\emph{p} ought to be the case.)
  \item \(p\) is assigned the value `desirable'. \hfill (\emph{p} is desirable.)
  \item \(p\) is assigned the value `improbable'. \hfill (\emph{p} is improbable.)
  \end{itemize}
\end{note}

\begin{note}
In most cases the value will be clear (i.e. that the proposition is true, though sometimes that the proposition is desirable), and so we will talk of claiming support for the proposition.
  A handful of additional examples will be provided when illustrating the next proposition.
\end{note}

\begin{note}
  Nothing hangs on distinction between values.
  Reduce everything to truth and falsity.
  However, we do not assume this, and if you do not think this is the case either, then I would like to not suggest that the assumptions and arguments to follow concern only those propositions which may be evaluated as true or false.
\end{note}


\subsection{Culmination of reasoning}
\label{sec:basic-assumptions:culmination-of-reasoning}

\begin{note}[Reasoning proposition]
  \begin{restatable}[Claiming support is the result of reasoning]{assumption}{assuCSRR}
    \label{assu:CS-culmination-of-R}
    Claiming support some proposition \(\phi\) having value \(v\) is an instance of reasoning.
    And, claimed support some proposition \(\phi\) having value \(v\) is the culmination of some instance of reasoning.
  \end{restatable}
\end{note}

\begin{note}
  Key thing here is that result of premises and steps of reasoning.

  The role of~\autoref{assu:CS-culmination-of-R} is primarily to ensure that claiming support always guarantee the existence of premises and steps.
  With the exception of some broad constraints to be outlined in further assumptions below, we (will) have little to say about the specifics of what the reasoning consists of.
\end{note}

\begin{note}
  Reasoning, some mental activity.
\end{note}

\begin{note}[Quick examples]
  \begin{itemize}
  \item \(S\) testified that \(p\), so \(p\) is true.
  \item \(p\) would satisfy every member of the group, so \(p\) ought to be the case.
  \item The song is produced by \(S\), so it is desirable that I listen to it.
  \item The device reads \(p\) and is reliable, so \emph{not}-\(p\) is improbable.
  \end{itemize}
\end{note}

\begin{note}
  Instances of reasoning may culminate in other ways, so we are only interested in a specific type of reasoning.
\end{note}

\begin{note}[Claiming support]
  Expand on this below.
  Briefly mention that this falls short of \emph{establishing} that \(\phi\) has value \(v\).
  \emph{Claimed} support means there's always some possible defeater.
\end{note}

\begin{note}[Understanding `having value \(v\)']
  In a deductive case, if the premises are true, then the conclusion is true.
  Means-end reasoning for desire.
  The value is important.
  If it is true that it past 6pm, then it is true the shop is closed.
  Provides value of shop being closed.

  However, if agent desires that it is past 6pm, then it doesn't follow that the agent desires that the shop is closed.
  Question an agent as to why they think their desires conform to truth --- is-ought problem.

  Means-end reasoning.
  It is true that there is cheese at the centre of the maze.
  And, it is desirable that I obtain the cheese at the centre of the maze.
  Further, it is true that I may only obtain the cheese at the centre of the maze by solving the maze.
  Therefore, it is desirable that I solve the maze.
\end{note}

\subsubsection{Delicacy}

\begin{note}
  Reasoning that concludes that \(\phi\) has value \(v\) is distinct from reasoning that concludes that it is \emph{A} that \(\phi\) has value \(v\).

  This distinction is important.
\end{note}

\begin{note}
  \begin{quote}
    I \(\{\) wish, hope, imagine, conjecture, \dots \(\}\) that \(\phi\) has value \(v\)
  \end{quote}
  These are all compatible with holding that \(\phi\) does not have value \(v\).

  Rather than rely on intuitive evaluations of adjectives, consider the following proposition-value pair.
  \begin{quote}
    That \(X\) is asleep is likely.
  \end{quote}

  Two ways of understanding.
  \begin{enumerate}
  \item I have made some assumptions and given these, \(X\) is asleep.
  \item For every proposition-value pair \(\psi\) having value \(v'\) I have appealed to, I hold it to be the case that \(\psi\) has value \(v'\).
    However, for various proposition-values I consider it \epPAd{} that \(\psi\) does not have value \(v'\).
    Hence, although I hold it to be the case that \(X\) is asleep, there a various ways in which the \world{} could be such that I would not maintain that \(X\) is asleep if the \world{} is in such a way.
  \end{enumerate}
  The second option is involved, but captures a straightforward distinction.
\end{note}

\begin{note}
  Contrast the two instance of reasoning of~\autoref{fig:Rover}.
  \begin{figure}[h!]
    \mbox{}\hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item
        \label{fig:Rover:CS:1}
        Rover is tired.
      \item
        \label{fig:Rover:CS:2}
        Rover will fall asleep soon.
      \end{enumerate}
      \caption{}
      \label{fig:Rover:CS}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}[label=\arabic*\('\).,ref=(\arabic*\('\))]
      \item
        \label{fig:Rover:nCS:1}
        \emph{Supposing} Rover is tired.
      \item
        \label{fig:Rover:nCS:2}
        Rover will fall asleep soon.
      \end{enumerate}
      \caption{}
      \label{fig:Rover:nCS}
    \end{subfigure}
    \hfill\mbox{}
    \caption{Two instance of reasoning}
    \label{fig:Rover}
  \end{figure}
\end{note}

\begin{note}
  The two instances of reasoning are distinguishing by whether or not the premise that Rover is tired is a supposition or not.

  With \autoref{fig:Rover:nCS} the premise does not concern the actual state of Rover, and hence the conclusion (also) does not concern the actual state of Rover.
  Of course, if Rover is (in fact tired) then it may be the case that Rover will fall asleep soon, but the agent to obtain~\ref{fig:Rover:nCS:2} from~\ref{fig:Rover:nCS:1} while holding that Rover is not tried.

  By contrast,~\autoref{fig:Rover:CS} is an instance of reasoning about how things are.
  The agent is holding that it is the case that Rover is tired, and therefore it is the case that Rover will fall asleep soon.
\end{note}

\begin{note}
  We do not place any constraints on reasoning that concludes that \(\phi\) has value \(v\) in general.
  Still, claiming support will be an instance of this.
\end{note}

\paragraph{Incompatible with externalism}

\begin{note}
  Incompatible with externalism.
  It either being the case that \(\phi\) has value \(v\) or that \(\phi\) does not have value \(v\) doesn't matter.

  This does not mean that there's no place for externalism.
  If claiming support is viewed as a component of something broader, say justification, then other components may be independent of the agent's reasoning.

  Further, does not go as far as \emph{access} internalism.
  Here, we're interested in necessary conditions.
  Failure is something that may be recognised.
\end{note}

\begin{note}
  Agent's own state.
  Consistency.

  Does not think that some proposition-value pair appealed to has some other value.
  Conclusion, then reject premises.
  If premise, then something that the agent thinks is not the case.
\end{note}

\begin{note}
  \color{red}
  Internalist flavour, specifically `mentalism' in the sense of \citeauthor{Feldman:2001uy} where:
  \begin{quote}
    \dots a person's beliefs are justified only by things that are \dots internal to the person's mental life.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[233]{Feldman:2001uy})}\nolinebreak
    \footnote{
      See also~\textcite[\S4,9]{Pappas:2017vi}.
    }
  \end{quote}
  Result of reasoning, and indication is part of that reasoning.
  Reasoning is internal to an individual's mental life, and hence internalist in this sense.\nolinebreak
  \footnote{
    \color{red}
    Intuitively, external circumstances may impact the \emph{support} the agent has.
    However, as these are external, it seems external circumstances does not impact \emph{claiming} support.

    This is how you get puzzles for externalism.
    In both cases, it's fine for the agent to claim support, but the external circumstances impact whether the agent \emph{has} support.
    The internalist/externalist divide would seem to affect the conditions on claiming.

    Way to expand on this is reconstructing bootstrapping examples with and without \eiS{}.
    If the agent would only get basic support if reliable, then it's not clear that bootstrapping is a problem.
  }

  However, the internal/external divide is somewhat difficult.
  For, what is appealed to in an instance of reasoning that amounts to claiming support need not be internal.
\end{note}

\begin{note}[Illustration of I/E]
  \color{red}
  To illustrate, post has arrived.
  Heard the something drop from the letterbox.
  Something dropped.
  Could be a flyer.
  However, sign on the window and penalty.

  Reasoning, but appeal to things `external' to one's mental life.
  First, to something having dropped.
  Concern is that it is not the post.
  Appeal to the sign in the window.
  Not claiming support because I have reasoned about these things.
  Rather, claiming support because of what these considerations suggest is the case independently of my reasoning.

  In other words, it may be that I claim support that the post has arrived because I have reasoned about these things.
  Hence, claiming support is internal to my mental life.
  However, if I did not reason about the flyer and the sign in the window (or similar things) then the reasoning would not be an instance of claiming support.
  Hence, what matters when claiming support may be external to my mental life.
\end{note}

\subsection{\indicateN{2}}
\label{sec:basic-assumptions:indication}

\begin{note}
  The final basic assumption we make is, strictly speaking, optional, but will be important for ensuring that claiming support is feasible.

  We begin with a definition, and then state the assumption with respect to the definition.
\end{note}

\begin{note}
  \begin{restatable}[\indicateN{2}]{definition}{defIndicate}
    \label{def:indication}
    An instance of reasoning performed by some agent \vAgent{} which concludes that \(\phi\) has value \(v\) \emph{\indicateV{1}} \(\psi\) has value \(v'\) if and only if:
    \begin{itemize}
    \item It is not \epPAd{}, relative to \vAgent{}' epistemic state, that \(\psi\) has value \(v'\) while \(\psi\) does not have value \(v'\).
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  \begin{restatable}[\indicateN{2}]{assumption}{assuIndicate}
    \label{assu:indication}
    If agent has claimed support for some proposition \(\phi\) having value \(v\), then the agent's claimed support extends to any proposition-value pair \indicateVed{} by \(\phi\) having value \(v\).
  \end{restatable}
\end{note}

\begin{note}
  Two notes on terminology:

  First, `following from' is understood broadly.
  The relevant consequence may be logical, semantic, dialectic, and so on.
  Further, whatever follows need not follow \emph{as a matter of} logic, semantics, dialectics, and so on.
  Rather, what follows may follow as a matter of the agent's perspective.
  Indeed, we will not have particular interest in reasoning from any perspective other than that of the agent who has performed the instance of reasoning.
\end{note}

\begin{note}
  Do not need to recognise that I have run 100m in order to have run 100m.
  Do not need to recognise that I have claimed support in order to have claimed support.

  Do not need to recognise that I have run 10m in order to have run 100m.
  Do not need to recognise that I have reasoned about any proposition-value pair appealed to in order for reasoning to \indicateV{0}.

  Core intuition extends.
  This much is unavoidable.
  And, without further assumptions, there is no need to build in this idea of explicit reasoning, recognition, or access.
  So, to the extent that there is tension, clear to reject recognition over core intuition.
  Of course, if no tension, then free to build whatever else you like into claiming support.

  Term this `an observers' standpoint'.
\end{note}

\begin{note}
  \begin{itemize}
    \item It is true that \(\psi\) has value \(v'\).
    \item It is true that it is true that \(\psi\) has value \(v'\).
    \item It is not the case that \(\psi\) does not have value \(v'\).
    \end{itemize}
\end{note}

\begin{note}
  \color{red}
  Important thing.
  Claimed support and \indicateN{0} are relative to an agent's epistemic state.
  If an agent has claimed support, and this indicates, then the claimed support doesn't necessarily apply given novel information.
  Hence, will also not indicate.
  Indeed, given novel information, did not \indicateN{} \emph{prior} to novel information either.
\end{note}

\subsection{Summary of basic assumptions}
\label{sec:summary}

\begin{note}
  Assumptions \ref{assu:CSVP},~\ref{assu:CS-culmination-of-R}, and~\ref{assu:indication} are general assumptions about claiming support.

\color{red} \dots
\end{note}

\section{Ideas regarding claiming support}
\label{sec:two-ideas}

\begin{note}
    In \ref{sec:basic-assumptions} we made three assumptions regarding the kind of thing claiming support it.
  In the present section we introduce two ideas to narrow down the type of thing claiming support is.
\end{note}

\begin{note}
  From \autoref{assu:CSVP}, claiming support is an instance of reasoning that concludes that some proposition \(\phi\) has some value \(v\).
  Again, the conclusion of an instance of claiming support is \emph{unqualified}.
  If an agent concludes that the grass is wet, then the agent has claimed support that the grass is wet.
  The agent has not (merely) concluded that the grass is wet so long as it rained last night, or that the sun is not to warm, etc.\

  Still, \autoref{assu:CSVP} only places a restriction on how an instance of reasoning concludes.
  To illustrate, it is compatible with \autoref{assu:CSVP} that an agent concludes that the grass is wet arbitrarily.
  Consider:
  \begin{enumerate}
  \item\label{ex:assu:CSVP:lim:1} Birds are singing, so the grass is wet.
  \item\label{ex:assu:CSVP:lim:2} I dreamt of rain, so the grass is wet.
  \end{enumerate}
  It is not clear how birds signing or dreams of rain relate to the grass being wet, but \autoref{assu:CSVP} is satisfied given that the conclusion of both~\ref{ex:assu:CSVP:lim:1} and~\ref{ex:assu:CSVP:lim:2} is that the grass is wet.
\end{note}

\begin{note}
  To narrow claiming support further we introduce a basic idea, \ideaCSA{}.
  \ideaCSA{} states, roughly, that an instance of reasoning that concludes \(\phi\) has value \(v\) is an instance of claiming support that \(\phi\) has value \(v\) \emph{only if} the agent would conclude that \(\phi\) has value \(v\) were it to be the case that the actual \world{} is some \epPAd{} \world{}.

  This is a substantial idea, but the constraint it places should not be overestimated.
  First, this idea does not require that an agent claims support for \(\phi\) having value \(v\) only if \(\phi\) has value \(v\).
  Second, this idea does not constrain how or why the agent would conclude that \(\phi\) has value \(v\) were it to be the case that the actual \world{} is some \epPAd{} \world{}.

  I doubt that the (seemingly) arbitrary instances of reasoning \label{ex:assu:CSVP:lim:1} and \label{ex:assu:CSVP:lim:1} satisfy this idea.
  Though, strictly speaking, they are compatible.
  It may be the case that the agent would conclude that the grass is wet from bird song \emph{even if} the grass is not wet.
  And, perhaps, the agent may hold that their dreams of rain do distinguish between wet and dry grass.

  Still our interest is with what \ideaCSA{} rules out, rather than with what \ideaCSA{} permits.
  And, \ideaCSA{} rules out claiming support if some \epPAd{} \world{} such that the agent would not conclude that \(\phi\) has value \(v\).

  Indeed, our general interest is with a structural consequence of \ideaCSA{} with respect to instances of reasoning.
  To obtain this structural consequence we will first relate \ideaCSA{} to steps of reasoning through an intermediary idea, \ideaCSB{}, and then introduce the structural consequence as \ideaCSB{}.
\end{note}

\subsection{\ideaCSA{1}}
\label{sec:ideaCSB}

\begin{note}
  \color{red}
  This is the strength of claiming support.
  There are two important aspects.
  \begin{itemize}
  \item Relation to agent's own epistemic state.
  \item Relation to how things are.
  \end{itemize}
\end{note}

\begin{note}[Overview of \ideaCSA{}]
  Above we paraphrased \ideaCSA{} as holding that that an instance of reasoning that concludes \(\phi\) has value \(v\) is an instance of claiming support that \(\phi\) has value \(v\) \emph{only if} the agent would conclude that \(\phi\) has value \(v\) were it to be the case that the actual \world{} is some \epPAd{} \world{}.

  We now state \ideaCSA{} explicitly.
\end{note}

\begin{note}[Statement of \ideaCSA{}]
  \begin{restatable}[\ideaCSA{0} --- \ideaCSA{}]{idea}{iCSA}
    \label{idea:defs-for-CS}
    An agent \vAgent{} has claimed support for \(\phi\) having value \(v\) \emph{only if} \(\phi\) having value \(v\) is a \sink{} with respect to the agent's current epistemic state with no constraints.
\end{restatable}
\end{note}

\begin{note}[Statement of a \sink{0}]
  Where:
  \begin{restatable}[A \sink{0}]{notion}{defSink}
    \label{def:sink}
    \(\phi\) having value \(v\) is a \emph{\sink{}} with respect to an agent \vAgent{}' epistemic state \(\eState{\vAgent{}}\) and collection of proposition-value pairs \(\Phi\) just in case:

    For any \epPAd{} \world{} \(s\) compatible with \(\eState{\vAgent{}}\) and \(\Phi\).
    \begin{enumerate}[label=\(\circlearrowright\)\arabic*., ref=(\(\circlearrowright\)\arabic*)]
    \item
      \label{def:sink:restrict}
      If \vAgent{} were to relax \(\eState{\vAgent{}}\) to  \(\eState{\vAgent{}}[']\) such that \(s\) is compatible with being the actual \world{} relative to \(\eState{\vAgent{}}[']\), then either:
      \begin{enumerate}[label=\alph*., ref=(\(\circlearrowright\)1\alph*)]
      \item
        \label{def:sink:restrict:phi:get}
        If \vAgent{} were to reason about whether \(\phi\) has value \(v\) from \(\eState{\vAgent{}}[']\) together with \(\Phi\), \vAgent{} would conclude that \(\phi\) has value \(v\).
      \end{enumerate}
      Or:
      \begin{enumerate}[label=\alph*., ref=(\(\circlearrowright\)1\alph*), resume]
      \item
        \label{def:sink:restrict:psi}
        There is some proposition-value pair \(\psi\) having value \(v'\) such that
        \begin{enumerate}[label=\roman*., ref=(\(\circlearrowright\)1b\roman*)]
        \item
          \label{def:sink:restrict:psi:get}
          If \vAgent{} were to reason from about whether \(\psi\) has value \(v'\) from \(\eState{\vAgent{}}[']\) together with \(\Phi\), \vAgent{} would conclude that \(\psi\) has value \(v'\), and
        \item
          \label{def:sink:restrict:psi:recurse}
          \(\phi\) having value \(v\) is a \sink{} with respect to \(\eState{\vAgent{}}[']\) and the collection \(\Phi\) \emph{combined with} \(\psi\) having value \(v'\).
        \end{enumerate}
      \end{enumerate}
      \vspace{-\baselineskip}
    \end{enumerate}
  \end{restatable}
\end{note}

\begin{note}
  \ideaCSA{}, then, reduces to specifying the proposition-value pair, initial epistemic state, and collection of proposition-value pairs for the recursively denied property of being a \sink{}.\nolinebreak
  \footnote{
    Observe that both the agent's epistemic state and the collection of proposition-value pairs are revised when passed to the recursive clause~\ref{def:sink:restrict:psi:recurse}.
  }

  Clause \ref{def:sink:restrict:phi:get} specifies a base case, while clause \ref{def:sink:restrict:psi} specifies the relevant recursive step.
\end{note}

\begin{note}[Key idea of \sink{}]
  The key idea of some proposition-value pair \(\phi\) having value \(v\) being a \sink{} is that for any \epPAd{} \world{} that the agent may entertain, the agent has some way of concluding that \(\phi\) has value \(v\).

  In other words, the agent the agent would conclude that \(\phi\) has value \(v\) even if\dots\space --- where the ellipses indicate some description of an \epPAd{} \world{}.
\end{note}

\begin{note}[A three step process]
  In order to ensure the agent has some way of concluding that \(\phi\) has value \(v\), the quantification of all \epPAd{} \world{1} is important.
  Still, the core of \autoref{def:sink} is a type of nested subjunctive conditional which constraints, in part, how the agent may conclude that \(\phi\) has value \(v\).

  Let us break down the core of evaluating whether \autoref{def:sink} holds as a three-step process:
  \begin{enumerate}[label=\Alph*., ref=\Alph*]
  \item
    \label{ideaCSA:sink:step:A}
    Identify some \epPAd{} \world{}.
  \item
    \label{ideaCSA:sink:step:B}
    Relax the agent's epistemic state such that the \epPAd{} \world{} is compatible with being the actual \world{}.
  \item
    \label{ideaCSA:sink:step:C}
    Consider whether the agent would conclude some proposition-value pair from the relaxed epistemic state together with certain proposition-value pairs.
  \end{enumerate}
\end{note}

\begin{note}[Satisfying step~\ref{ideaCSA:sink:step:B}]
  Step~\ref{ideaCSA:sink:step:A} is arbitrary choice.
  Step~\ref{ideaCSA:sink:step:B}, however, relies on the idea of relaxing an agent's epistemic state to be compatible with some \epPAd{} \world{} being the actual \world{}.

  We provide an intuitive description:

  Suppose an agent has concluded that \(\psi\) has value \(v'\) but consider it \epPAd{} that \(\psi\) does not have value \(v'\).
  As the agent has concluded that \(\psi\) has value \(v'\), any \epP{} in which \(\psi\) does not have value \(v'\) is not a candidate for the actual \world{}.
  Hence, to for the agent's epistemic state to be relaxed so that the relevant \epPAd{} \world{} is a candidate for the actual \world{}, a minimal change is made to the agent's epistemic state such that the agent has not concluded that \(\psi\) has value \(v'\).\nolinebreak
  \footnote{
    Note, that if the agent holds that \(\psi\) not having value \(v\) places constraints on other proposition-value pairs, then the agent's epistemic state will also be relaxed with respect to those proposition-value pairs.
    For example, suppose \(\phi\) does not have value \(v'\) because \(\psi\) has value \(\overline{v'}\).
    And, suppose, the agent holds that \(\chi\) has value \(v''\) whenever \(\psi\) has value \(\overline{v'}\).
    Then, if the agent has concluded that \(\chi\) does not have value \(v''\), the minimal change will also involve dropping the conclusion that \(\chi\) does not have value \(v''\).
  }
  Note, this minimal change does \emph{not} require the agent to conclude that \(\psi\) does not have value \(v'\), nor does the minimal change require the agent to have not concluded that some proposition-value pair that suggests (but does not entail) that \(\psi\) has value \(v\).

  With this rough understanding of relaxing a epistemic state, we now observe two ways in which Step~\ref{ideaCSA:sink:step:C} may be satisfied.\nolinebreak
  \footnote{
    I implicitly assume that relaxing an epistemic state does not introduce novel \epPAd{} \world{1}.
    Still, if this assumption is discarded, then further consideration is required.

    For,~\autoref{def:sink} does not require the agent to `relax' the collection of proposition-value pairs obtained from an instance of the recursive step.
    Consider the following case:

    \eState{} is relaxed to \eState{}{'} which allows for \(\psi_{1}\) having value \(v_{1}\).
    The agent then reasons to \(\psi_{2}\) having value \(v_{2}\).
    Hence, \(\psi_{2}\) having value \(v_{2}\) is part of the collection of propositions.
    However, \eState{}{'} allows that \(\psi_{2}\) not having value \(v_{2}\) as a novel \epPAd{}.
    So, we consider a further relaxation, \eState{}{''}, which allows for \(\psi_{2}\) not having value \(v_{2}\).
    Yet, as the agent concluded \(\psi_{2}\) has value \(v_{2}\) from \eState{}{'}, the agent may appeal to \(\psi_{2}\) having value \(v_{2}\) with respect to~\eState{}{''}.

    Hence,~\autoref{def:sink} implicitly rules out certain novel \epPAd{} \world{1}.
    However, this reasoning does not extend to ruling out for novel \world{1} that are compatible with proposition-value pairs the agent has reasoned to.

    So, depending on your intuition (if you have any) then the definition may need to be revised to extend relaxing to the collection.
    However, without clear intuition, and as excluding such a possibility will increase the complexity of the definition, I leave the assumption implicit.
  }
\end{note}

\begin{note}[Option 1]
  First, the relaxed epistemic state may (still) allow the agent to conclude that \(\psi\) has value \(v'\).
  For example, the relaxed epistemic state may still strongly suggest that \(\psi\) has value \(v'\).

  Hence,~\ref{def:sink:restrict:phi:get} applies and no further investigation is necessary with respect to the \epPAd{} \world{}.

  Consider the following reasoning:
  \begin{enumerate}
  \item The clock is in the centre of the library, and has been seen by many people.
  \item The clock is functioning.
  \end{enumerate}
  And, suppose the agent considers it \epPAd{} that the clock is not functioning.
  Hence, to entertain the relevant \epP{}, the conclusion that the clock is functioning would need to be relaxed.
  However, a non-functioning clock may still be in the centre of the library and seen by many people.
  And, as it is plausible that someone would have noticed that the clock is not functioning, it seems the agent may still conclude that the clock is functioning.
\end{note}

\begin{note}[Option 2]
  Second, clause~\ref{def:sink:restrict:psi} allows for the possibility for the agent reason to \(\phi\) has value \(v\) by establishing any number of intermediary proposition-value pairs.
  And, if the reapplication of clause~\ref{def:sink:restrict:psi} terminates, then it will terminate by the agent concluding that \(\psi\) has value \(v'\).

  For example, suppose the agent considers it epistemically possible that the clock is not functioning and no-one has noticed that the clock is broken.
  In such a case, the agent's relaxed epistemic state will not include that the clock has been seen by many people.
  Still, the agent may observe that:
  \begin{enumerate}
    \setcounter{enumi}{-1}
  \item It is exam week so the library is busy and many students will be sensitive to what time it is.
  \end{enumerate}
  Hence, it seems the agent may conclude that the clock has been seen by many people, and with this intermediary proposition-value pair in hand then conclude that the clock is functioning.
\end{note}

\begin{note}[Additional examples]
  For a handful of additional examples, consider the instances of reasoning in \autoref{fig:ideaCSA:basic-examples}.
  In each instance, it seems plausible that the agent may conclude the conclusion from the premise, and further, to continue to maintain the premise even if the conclusion is not the case.
  Hence, each instance of reasoning plausibly satisfies \ideaCSA{}.

  \begin{figure}[h!]
    \mbox{}\hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item That persons' eyes have been closed for a long time and their breathing is slow.
      \item That person is asleep.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item A newspaper with a strong record of accurate reporting and reported that \(S\) said \(p\).
      \item \(S\) said \(p\).
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill\mbox{}

    \mbox{}\hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item S knows me very well.
      \item Whatever S has gifted me satisfies some desire I have.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item The die has rolled even in \(5251\) of \(6000\) samples.
      \item The die is biased.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill\mbox{}
    \caption{}
    \label{fig:ideaCSA:basic-examples}
  \end{figure}

  \color{red}
  Intuitive `even if\dots' test.

  \begin{enumerate}[label=\ref{fig:ideaCSA:basic-examples}\alph*., ref=(\ref{fig:ideaCSA:basic-examples}\alph*)]
  \item Even if not asleep\dots
  \item Even if \(S\) did not say \(p\), \dots
  \item Even if the gift does not satisfy some desire I have \dots
  \item Even if the die is not biased \dots
  \end{enumerate}
\end{note}

\begin{note}[Independence of claiming support]
  An important for emphasis, though inessential for practice, feature of \ideaCSA{} is that whether an agent has claimed support for \(\phi\) having value \(v\) is independent of whether \(\phi\) (actually) has value \(v\).

  For, \ideaCSA{} requires the agent would reason to \(\phi\) having value \(v\) were the agent to entertain any \epPAd{} \world{} as a candidate for the actual \world{}.
  Hence the agent would conclude that \(\phi\) (actually) has value \(v\).
  However, no requirement is placed on the agent \emph{concluding} that \(\phi\) has value \(v\) and \(\phi\) having value \(v\).

  In this respect, \ideaCSA{} is distinct, though compatible with, variants of safety and sensitivity applied to claiming support.
\end{note}

\begin{note}[An extreme example]
  \color{red}
  The `Even if\dots' test queries whether an agent's claimed support permits an agent to expect that some (epistemically) possible defeater fails to obtain `even if' it does obtain.

  For example, even if \(0.999\dots = 1\), there must be \emph{some} difference between \(0.999\dots\) and \(1\) --- no matter how small --- and some difference between to things is sufficient to establish that they are not equal.

  Implied in this response is something like the observation that \(0.9 = (1 - 0.1)\) and \(0.99 = (1 - 0.01)\), and so \(0.999\dots = (1 - 0.000\dots 1)\), hence \(1 = (0.999\dots + 0.000\dots 1)\), and because \(0.999\dots\) refers to some quantity, \(0.000\dots 1\) likewise refers to some quantity.
  It seems reasonable for an agent to expect that the Archimedean property does not hold for real numbers.

  The example given is an instance of the applied to the possibility that the agent's claimed support that \(0.999\dots \ne 1\) may be misleading, as the antecedent supposes that \(0.999\dots = 1\).

  Generalising, we have outlined two kinds of defeaters that would prevent an agent from claiming support.
  The two types of defeaters suggest two basic instances of the test:
  \begin{enumerate}
  \item[(ML)] Even if \(\phi\) does not have value my claimed support indicates, I consider it to be the case that\dots
  \item[(MT)] Even if I some part (or whole) of my claimed support for the value of \(\phi\) is mistaken, I consider it to be the case that\dots
  \end{enumerate}
  Below we provide three examples for each basic instance of the test, two (plausibly) successful responses and one (plausibly) unsuccessful response..\nolinebreak
  \footnote{
    You may think that some of the adequate responses I suggest are too weak, but for future purposes I require only that some positive answer many be given, and so you may strengthen the requirements on a positive answer as you see fit.
  }
\end{note}

\begin{note}[Safety and sensitivity]
  We borrow the following definitions of safety and sensitivity from~\citeauthor{Zalabardo:2017td}:

  \begin{quote}
    S's belief that p is \emph{safe} just in case, if S believed p, p would be true.\newline
    \mbox{}\hfill\mbox{(\citeyear[1]{Zalabardo:2017td})}
  \end{quote}

  \begin{quote}
    S's belief that p is \emph{sensitive} just in case, if p were false, S wouldn't believe p.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[2]{Zalabardo:2017td})}
  \end{quote}

  In both definitions, `S's claimed support for p (being true)' may be substituted for `S's belief that p'.

  Further, both definitions consist of a subjunctive conditional which concerns the value that p has.
  In the case of safety, p has the value true, and in the case of sensitivity, p is false.
  And, indeed, it follows from either definition that if S believes that p then p is true.\nolinebreak
  \footnote{
    In the case of safety, this is immediate.
    In the case of sensitivity, if S believes that p and p is false, then it follows by sensitivity that S doesn't believe p.
    Hence, either S believes that p and p is true, or S does not believe that p.

    Note, however, that while both safety and sensitivity ensure that S believes that p only if p is true, the two conditions are distinguished by which possibilities the relevant subjunctive antecedent quantifiers over.
  }

  So, given that the definition of a \sink{} is compatible with the agent concluding that p is true when p is (actually) false and safety and sensitivity rule out such a possibility, \ideaCSA{} does not follow from either safety or sensitivity, and conversely, neither safety nor sensitivity follow from \ideaCSA{}.

  Still, as the definition of a \sink{} is \emph{merely} compatible with the agent concluding that p is true when p is (actually) false, there is no restriction on placing either safety, sensitivity, or some other condition on claiming support in conjunction with \ideaCSA{}.

  Indeed, \ideaCSA{} is stated as a necessary condition to allow for additional restrictions.
  However, the importance of the foregoing observation is that without additional constraints, and evaluation of whether an agent has claimed support may be separated from how things actually are.
  Even if \(\phi\) does not have value \(v\), it may be the case that an agent would reason to \(\phi\) having value \(v\).
  What matters, rather, is that there is no \epPAd{} \world{} for which the agent would not reason to \(\phi\) having value \(v\).
\end{note}

\begin{note}[Problem with evaluating subjunctive conditionals]
  Though we have developed \ideaCSA{} in some detail, the central role of (nested) subjunctive conditionals leaves \ideaCSA{} somewhat unclear.
  For, without a detailed account of what it is for an agent to relax an epistemic state, and a detail account of reasoning about whether some proposition has some value, we lack a way to verify that any given proposition-value pair is a \sink{} with respect to an agent's epistemic state.

  Still, \ideaCSA{} is an idea.
  We will appeal to \ideaCSA{} to \emph{motivate} further ideas and assumptions, but we will not draw any consequences from \ideaCSA{}.
  Indeed, prior to stating the assumption that we will draw consequences from, we will refine \ideaCSA{} through two additional ideas.

  First, \ideaCSB{}, about what a step needs to do.
  Second, \ideaCSC{}, about when a step fails structurally.

  We will then, finally, develop \ideaCSC{} into an assumption that we will draw consequences from.
\end{note}

\begin{note}[Summary of \ideaCSA{}]
  Again, the key idea of some proposition-value pair \(\phi\) having value \(v\) being a \sink{} is that for any \epPAd{} \world{} that the agent may entertain, the agent has some way of concluding that \(\phi\) has value \(v\).
  And, the key idea of \ideaCSA{} is that an agent has claimed support for \(\phi\) having value \(v\) pair only if \(\phi\) having value \(v\) is a \sink{} with respect to the agent's (present) epistemic state.
  Hence, an agent has claimed support for \(\phi\) having value \(v\) only if, for any \epPAd{} \world{} that the agent may entertain, the agent has some way of concluding that \(\phi\) has value \(v\).

  In short, then, \ideaCSA{} states that an agent has claimed support for \(\phi\) having value \(v\) \emph{only if} there is no \epPAd{} \world{} such that if the agent considered the \epPAd{} \world{} as a candidate for the actual \world{}, then the agent would not conclude that \(\phi\) has value \(v\).

  Both this short characterisation, and the definition of a \sink{} on which \ideaCSA{} relies involve complex subjunctive conditionals.
  Still, the functional role of \ideaCSA{} is relatively straightforward:
  To ensure that the conclusion of the agent's reasoning is about how things are, and not (merely) how things would be if the various propositions have particular values.
\end{note}

\begin{note}[Moving to \ideaCSB{}/Looking ahead to \ideaCSC{}]
  As I suspect that this intuition is sufficiently clear, we will move on.

  The following two ideas, \ideaCSB{} and \ideaCSC{} will focus claiming, rather than claimed, support.
  And, in further contrast to \ideaCSA{}, both \ideaCSB{} and \ideaCSC{} will consider specific configurations of an agent's epistemic state.

  In particular, \ideaCSB{} will focus on a substantive constraint on an agent's reasoning given certain \epVAd{} \world{1}.
  And, \ideaCSC{} will focus on structural constraints on an agent's reasoning given certain \epVAd{} \world{1}.

  Still, we will appeal to \ideaCSA{} to motivate \ideaCSB{}, and as we will appeal to \ideaCSB{} to motivate \ideaCSC{}, \ideaCSA{} also (indirectly) motivates \ideaCSC{}.
\end{note}

\subsection{\ideaCSB{1}}
\label{sec:ideaCSB}

\begin{note}[Introducing \ideaCSB{}]
  \ideaCSA{} provided a general constraint on having \emph{claimed} support.
  We now turn our attention to \emph{claiming} support.

  \begin{itemize}
  \item We first state \ideaCSB{}.
  \item We then provide some broad intuition and make a number of clarifying remarks.
  \item Following, we motivate \ideaCSB{} from \ideaCSA{} by observing how \ideaCSA{} seems to entail \ideaCSB{} \emph{and} \ideaCSA{} may be recovered from \ideaCSB{}.
  \item Relate to defeaters.
  \item As with \ideaCSA{}, \ideaCSB{} contains some difficulties.
    Hence, \ideaCSC{}.
  \end{itemize}
\end{note}

\paragraph{Statement of \ideaCSB{}}

\begin{note}[Statement of \ideaCSB{}]
  \begin{restatable}[\ideaCSB{0} --- \ideaCSB{}]{idea}{ideaEIS}
    \label{idea:CS:B}
    For any agent \vAgent{}, and any instance of reasoning:
    \begin{itemize}[leftmargin=*]
    \item
      If:
      \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
      \item
        \label{idea:CS:B:step}
        The reasoning relies on some step \(\delta\) which moves from premises \(\chi_{i}\) having values \(v_{i}''\) to the conclusion that \(\xi\) has value \(v'''\).
        \begin{itemize}
        \item
          Such that:
          \begin{enumerate}[label=\alph*., ref=(\alph*)]
          \item
            \label{idea:CS:B:step:commit}
            \vAgent{} is committed to it being the case that if \(\psi\) does not have value \(v'\) then either:
            \begin{enumerate}[label=\roman*., ref=(\roman*)]
            \item
              \label{idea:CS:B:step:commit:p}
              Some premise \(\chi_{i}\) of \(\delta\) does not have value \(v_{i}''\).
            \item
              \label{idea:CS:B:step:commit:c}
              \(\xi\) does not have value \(v'''\).
            \end{enumerate}
          \end{enumerate}
        \item
          And:
          \begin{enumerate}[label=\alph*., ref=(\alph*), resume]
          \item
            \label{idea:CS:B:step:psi-ep}
            Prior to making \(\delta\) there is some \epVAd{} \world{} such that \(\psi\) does not have value \(v'\) and \(\xi\) does not have value \(v'''\).
          % \item
            % \label{idea:CS:B:step:connexion}
            % If \(\xi\) does not have value \(v''\) then \(\psi\) does not have value \(v''\).
          \end{enumerate}
        \end{itemize}
      \end{enumerate}
    \item
      Then, the instance of reasoning is an instance of claiming support for \(\phi\) having value \(v\) \emph{only if}:
      \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
      \item
        \label{idea:CS:B:prior-reasoning}
        The agent --- prior to making \(\delta\) --- may witness some reasoning which \indicateV{1} that \(\psi\) has value \(v'\).\nolinebreak
        \footnote{
          This clause is non-committal about the details of the reasoning that \indicateV{1} that \(\psi\) has value \(v'\).
          In particular:
          With respect to \autoref{denied-claim}, the reasoning include the reasoning of some other agent.
          And, with respect to \autoref{prop:EAS}, the reasoning may involve appeal to some unwitnessed reasoning.
        }
      \end{enumerate}
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\paragraph{Clarifying \ideaCSB{}}

\begin{note}
  As with \ideaCSA{}, \ideaCSB{} is a necessary condition.
  In contrast, \ideaCSB{} concerns claiming, rather than claimed, support.
  In particular, \ideaCSB{} focuses on a condition that any step of reasoning must satisfy in order for the instance of reasoning to be an instance of claiming support.
\end{note}

\begin{note}
  Intuitively:
  Suppose it is not possible for the agent to witness some reasoning which \indicateV{1} that \(\psi\) has value \(v'\).
  Then, the agent would not be in a position to distinguish between \(\psi\) having value \(v'\) and \(\psi\) not having value \(v'\) with respect to the actual \world{}.
  Hence, hence the agent would be committed to uncertainty about whether the premises or the conclusion of the step reflect the actual \world{}.
  So, the agent would be committed to the step being uninformative with regards to how things actually are.

  In other words, if an agent is committed to it being that case that some step of reasoning in informative about the actual \world{} \emph{just in case} some proposition \(\psi\) has value \(v\), then it must be possible for the agent to witness some reasoning which \indicateV{1} that \(\psi\) has value \(v'\).
\end{note}

\begin{note}
  This intuition is brief, and in place of a detailed account \ideaCSB{} in isolation, we will clarify \ideaCSB{} by observing both how \ideaCSB{} is motivated by \ideaCSA{} and how \ideaCSB{} is (significantly) weaker than \ideaCSA{}.

  Before doing so, we make two brief observations.
\end{note}

\begin{note}
  First, a subtle, but important, distinction is that the reasoning must \emph{rely} on the relevant step.
  Intuitively, some instance of reasoning which concludes that \(\phi\) has value \(v\) relies on a step of reasoning just in case the reasoning requires both the premises and conclusion of the step to actually have their respective values in order to conclude that \(\phi\) has value \(v\).

  In other words, \ideaCSB{} does not extend to steps made where the step is part of some hypothetical reasoning, such as reasoning by cases.
  We provide an explicit characterisation of reliance on a step in~\autoref{sec:assumpt-from-ideas}.
\end{note}

\begin{note}
  The refinement is useful in two respects.
  \begin{itemize}
  \item Relates directly to claiming support, rather than whether an agent has claimed support.
  \item Does not employ the notion of a \sink{}, nor the relaxation of an epistemic state.
  \end{itemize}
  Indeed, \ideaCSB{} is strictly weaker than \ideaCSA{}.
  Still, we will appeal to \ideaCSA{} in order to motivate \ideaCSB{}, hence \ideaCSB{} is characterised as a refinement of \ideaCSA{}.
\end{note}

\begin{note}
  Second, we only require that the agent \emph{may} witness some reasoning that \emph{\indicateV{1}} that \(\psi\) has value \(v'\).
  In other words, we do not require that the agent does witness some reasoning, nor that the relevant reasoning would explicitly concludes that \(\psi\) has value \(v'\).
  Simply, we have no interest in any stronger constraints than those presented.
\end{note}

\paragraph{Motivation from \ideaCSA{}}

\begin{note}
  Two parts.

  First, if \ideaCSB{} fails to hold, then \ideaCSA{} fails to hold.

  Second, \ideaCSA{} plausibly follows from \ideaCSB{} when all \epPAd{} \world{1} are \epVAd{}.
\end{note}

\begin{note}
  First, failure.
\end{note}

\begin{note}
  Second, relative equivalence.
\end{note}

\begin{note}
  Suppose \ref{idea:CS:B:step} holds and \ref{idea:CS:B:prior-reasoning} does not.


  Focus on the step.
  Treat this as instance of claiming support.

  Question is not whether the agent may claim support for \(\psi\) having value \(v'\), but whether the agent may claim support for \(\xi\) having value \(v''\).

  So, relax so that \(\xi\) not having value \(v''\) is a candidate for the actual \world{}.
  Know this is possible given \ref{idea:CS:B:step:psi-ep}.
  Further, for any \epVAd{} \world{} in which \(\xi\) does not have value \(v''\), \(\psi\) does not have value \(v'\).

  Now, no reasoning for \(\psi\) having value \(v'\) with respect to agent's current epistemic state.
  So, no reasoning for \(\psi\) having value \(v'\) given relaxed epistemic state.
  For, minimal change to be compatible with \epVAd{} \world{}.
  Hence, relaxed epistemic state only lacks various proposition-value pairs from current epistemic state.
  So, \(\xi\) having value \(v''\) is not a \sink{} with respect to current epistemic state.

  And, as reasoning relies on step, and the conclusion of the step is not a \sink{}, then conclusion of reasoning is not a \sink{}.

  So, if fail, then surely a failure of \ideaCSA{}.
\end{note}

\begin{note}
  Still, weaker.
  Satisfying \ideaCSB{} isn't going to ensure \ideaCSA{} is satisfied.

  Two reasons.
  First, step of reasoning.
  This does not extend to the reasoning as a whole.
  Still, if extend to every step then still.
  For\dots

  Second, only concerns candidates for the actual \world{}.
  \ideaCSA{} considers not only \epVAd{} \world{1}, but any \epPAd{} \world{}.

  However, if \epVAd{} and \epPAd{} \world{1} are the same, then plausibly come down to the same thing.

    For, the underlying issue is that if no motivation for \(\psi\) having value \(v'\), then no account of why the step of reasoning is about how things actually are, rather than what follows from a restriction of how things actually are.
  \(\psi\) not having value \(v'\) remains a candidate, and so long as this is the case, then concluding that \(\xi\) has value \(v''\) is not a conclusion about what is the case.

  Hence, if every step of reasoning satisfies \ideaCSB{} from \epPAd{} \world{}, and the reasoning for \(\psi\) having value \(v'\) is sufficient, then it seems \ideaCSA{} will also be satisfied.

  Again, to emphasise.
  At issue is not the agent getting something wrong.

  Still, if distinct motivation, then disregard \ideaCSA{}.
  And, indeed, as \ideaCSB{} will be used to motivate \ideaCSC{}, it may be possible to disregard \ideaCSB{} also.
\end{note}

\begin{note}
  So, the reasoning.
\end{note}

\begin{note}
  Again, necessary condition, so we will not look into this further.
  Instead, \ideaCSC{} will develop a constraint on such reasoning.

  Okay for `hunches' or `intuition'.
    \begin{quote}
    Okay for the agent's reasoning to be the hunch.
    So long as hunch includes this subjunctive component.
  \end{quote}
\end{note}

\begin{note}
  Handful of important points.
  \begin{itemize}
  \item I need to be careful not to suggest that the agent \emph{regonises} that \(\psi\) does(n't) have value \(v'\).
    Though, this may be relaxed.
  \item Explicit premises and conclusion are candidates.
  Hence, \label{idea:CS:B:step:commit} constrains the reasoning in general.
  \end{itemize}
\end{note}

\hozlinedash


\paragraph{???}

\begin{note}
  \color{red}
  An instance of reasoning is an instance of claiming support \emph{only if} for any proposition-value pair \(\psi\) having value \(v'\) that would restrict the scope of the reasoning to instances where \(\psi\) having value \(v'\), the agent has reasoned (past or present) to \(\psi\) having value \(v'\) which ensures that the scope of the proposed instance of claiming support extends to \ep{} that \(\psi\) having value \(v'\)
\end{note}

\begin{note}
  \color{red}
  Note, the step.
  As before, this is about how things are.
  Therefore, will not apply to instances such as reasoning by cases.
  For, these will not be steps from \(\chi_{i}\) having values \(v_{i}''\).

  Necessary condition.
\end{note}

\begin{note}
  However, the agent's perspective is limited.
  We do not include a clause that holds that the agent recognises.

  Delicate.
  Committed.
  We (attempt to) make precise in \autoref{sec:claim-supp-requ}.
  For the moment, intuitive.
  Paired with an intuitive worry: agent may be committed even if they do not recognise.

  Balance, the agent's reasoning may satisfy without recognition.

  Here, \indicateV{1} terminology of \ref{idea:CS:B:prior-reasoning}.
  If explicitly concludes, then \indicateV{1}.
  However, if implicitly concludes, then \indicateV{1}.

  Difficulty is that commitment allows possibility even when not possible to recognise.
  In principle, at least.
  Relative to agent's epistemic state.
  Important, \ep{}.

  This does not completely diminish the concern, still possible that agent does not recognise how they are committed.
  However, I am not clear on how to resolve this.
  So, leave this open.

  On the other hand, \indicateN{0} may be too weak.
  Certain problems may need to be recognised.
  This, we also leave open.
\end{note}


\paragraph{\illu{3}}

\subparagraph{Clear failure}

\begin{note}
  Fair coin.
  Flipped.
  The coin landed heads.

  Trivial, but without clear limitations on reasoning, mostly trivial.
  Here, given that it's a coin, there's no way to tell.
\end{note}

\begin{note}
  This library uses either LCC or DDC indexing.
  \begin{enumerate}
  \item A search for `H61 .R593' returned no results.
  \item The library does not have a copy of `Measurement Theory'.
  \end{enumerate}

  Holding that a library does not have a copy of a book because a search for the book under a particular indexing system would be a mistake.
  For, if the library does not use the particular indexing system then a search using that indexing system will always fail, regardless of whether or not the library has a copy of the book.

  In turn, a failed search for an LCC index in the library's database does not seems sufficient for an agent to claim that the library does not have a copy of the book unless the agent is in a position to claim support that the library uses LCC indexing.
  Following, it seems the failed response to the `Even if\dots' test may be supplemented by noting that the library is a research library, and therefore likely uses LCC indexing, etc.\
\end{note}

\subparagraph{Spot the difference}

\begin{note}[Spot the difference]
  \begin{illustration}[Spot the difference]
    \label{illu:CS:spot-the-diff}
    The agent has been working through a spot-the-difference to pass some time.

    Though the time is not completely passed, the agent examined the two images with what seems sufficient care to claim support that they have found all the differences.
    However, the agent did not keep track of the number of differences.

    The agent announces `I have found all the differences' and their companion responds `All fifteen?'.

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*)]
      \setcounter{enumi}{-1}
    \item\label{illu:CS:spot-the-diff:info} If I have found all the differences, I have found fifteen differences.
    \end{enumerate}

    The agent then reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*), resume]
    \item Exhaustive search.
    \item\label{illu:CS:spot-the-diff:all} I found all the differences.
    % \item\label{illu:CS:spot-the-diff:info} My companion has testified that there are fifteen differences.
    % \item\label{illu:CS:spot-the-diff:cond} If I have found all the differences, I have found fifteen differences.
    \item\label{illu:CS:spot-the-diff:fif} So, I have found fifteen differences. \hfill (From \ref{illu:CS:spot-the-diff:info} and \ref{illu:CS:spot-the-diff:all})
    \end{enumerate}
  \end{illustration}

  Before going further, structure of this.

  The agent performed some reasoning, and concluded that they found all the differences.
  However, that reasoning is mentioned but not stated in the \illu{0}.
  Rather, present is distinct instance of reasoning after being provided with information.
  ``If not 15, then problem''.
  Present reasoning appeals to past reasoning, and draws out consequence of this given new information.
  Important: the present reasoning does not consider possibility that the agent did not find all 15 differences.
  Instead, consequence of conclusion of previous instance of reasoning.
  Still, epistemically possible that the agent did not find 15 differences.
\end{note}

\begin{note}
    Providing additional information about what the agent has claimed support for.
  Recall, \autoref{assu:CSVP}, information rather than \world{}.
  \nolinebreak
  \footnote{
    Still slight issue.
    Offering a redescription.
    You met Clark Kent, so you met Superman.
    In this case, rather than claiming support for meeting Superman, provided information is seen as an equivalent formulation.
    It is possible to read \autoref{illu:CS:spot-the-diff} in this way, and this might be the most natural interpretation.
    However, it is not the interpretation under which see the problem.
    Rather, problem is where the conditional is explicit.
    Unlike Superman case, proper conditional.
  }
\end{note}

\begin{note}
  Information leads to \requ{}.

  Possibility of not fifteen.
  And, not merely that the agent performed the reasoning, but that the reasoning identified all.
  If not fifteen, then not all, so would involve appeal to something that is not the case.

  And, present reasoning does not include reasoning about \requ{}.
\end{note}

\begin{note}[Avoiding the problem]
  This doesn't rule out some additional reasoning.
  \begin{enumerate}
  \item Exhausted search.
  \end{enumerate}
  Difference here is that the agent is not only appealing to having found.
  In addition, what they recall about reasoning.
  What matters is not that found all but rather that exhaustivity of search.
  This is not specific to 15.
  Up to some \(k\) such that agent is still confident that they performed an exhaustive search.

  Whether you think this is enough is up to you.
  On the one hand, intuitive that this does enough.\nolinebreak
  \footnote{
    Indeed, reasoning framed with all as I think it is much less clear here.
  }

  On the other hand, the agent did not keep track of the number of differences.
  So, may hold that they should go back and count.\nolinebreak
  \footnote{
    Looking ahead, \nI{}.
    Difficulty here is that don't need to go to \(\phi\).
    Indeed, note somewhere that \nI{} really only clearly takes hold when need some sort of factivity in play.
    We'll return to this.
  }

  {
    \color{red} As observed in the footnote above, the trick here is that the agent doesn't really `need' to go to having found all the differences.

    Alternatively, not enough to show that the reasoning is bad.
    E.g.\ then I would have been deceived, some trick, etc.
    Something \emph{I} wouldn't count as a difference.
  }
\end{note}

\begin{note}
  Argued above against circularity.
  Here, additional consideration.

  If the agent were to have had the information first time, then plausibly an instance of circularity.
  And, may think that this is also circularity as must also all must amount to fifteen.
\end{note}

\subparagraph{Where's Wally}

\begin{note}
  \autoref{illu:CS:spot-the-diff} had something that could be obtained from the reasoning if re-examined.
  Just need to add a counter.

  Now, something that follows if the reasoning was \nmom{}.
\end{note}

\begin{note}
  \begin{illustration}[Where's Wally]
    \label{illu:CS:wheres-wally}
    Searching for Wally.
    On front of book is an image of wally in contrast to a number of other characters.
    Takes not of a number of features.
    Glasses, hat, striped jumper.
    In isolation, necessary but insufficient.
    Combined, sufficient.

    Search through the image.
    I've found Wally.
    Did you spot the cane first?

    The question carries implicit information:
    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:wheres-wally}.\arabic*)]
      \setcounter{enumi}{-1}
    \item\label{illu:CS:wheres-wally:info} The individual identified is Wally only if the individual is holding a cane.
    \end{enumerate}

    The agent then reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:wheres-wally}.\arabic*), resume]
    \item Collection of features sufficient.
    \item\label{illu:CS:wheres-wally:ante} Had features.
    % \item The individual identified is Wally only if the individual is holding a cane.
    \item The individual was holding a cane. \hfill (From \ref{illu:CS:wheres-wally:info} and \ref{illu:CS:wheres-wally:ante})
    \end{enumerate}
  \end{illustration}

  As with \autoref{illu:CS:spot-the-diff}, the reasoning of \autoref{illu:CS:wheres-wally} is such that the individual was holding the cane is an \requ{} of the claimed support that the individual was Wally, and no reasoning about it.
\end{note}

\begin{note}
  Problem.
  \requ{}.
  Agent didn't notice, so possibility.
  And, agent is appealing to it being Wally.
  Not merely that they identified as Wally.

  It's not clear need to give up claimed support, but does not extend to having a cane.

  In contrast to \ref{illu:CS:spot-the-diff}, does not seem there is anything weaker to fall back on.
  However, no strong claim here.
  Rely on stronger principles about claiming support.
\end{note}

\paragraph{Defeaters}

\begin{note}
  \begin{proposition}
    No indication if the agent only considers their reasoning to indicate that \(\phi\) has value \(v\) only if \(\phi\) has value \(v\).
  \end{proposition}
\end{note}


\begin{note}
  \phantlabel{first-mention-undercutting-defeater} % first mention of undercutting defeaters
  Undercutting.

  Following~\citeauthor{Moretti:2018va}:
  \begin{quote}
    A \emph{rebutting} defeater for a belief that \(P\) of \(S\) is, roughly, a reason of \(S\) for believing the negation of \(P\) or for believing some proposition \(Q\) incompatible with \(P\).
    Whereas an \emph{undercutting} defeater for a belief that \(P\) of \(S\) is, roughly, a reason of \(S\) that attacks the connection between S's ground for believing \(P\) and \(P\)[.]\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear{Moretti:2018va})}
  \end{quote}
\end{note}

\begin{note}
  An epistemic defeaters is something that is the case.
  As a plausible consequence, possibility of undercutting and rebutting defeaters.
  So, here, \epP{} of either.
\end{note}

\begin{note}
  However, does not entail that there are defeaters, nor that there are a defeater is a genuine (i.e.\ non-epistemic) possibility --- only that defeat is an \epP{}.
\end{note}

\begin{note}
  In this respect, the \epPAd{} of a rebutting or undercutting defeater may be viewed a kind of undercutting defeater\dots
\end{note}

\begin{note}[Quick intuition]
  \emph{Undercutting} defeaters.

  Type II defeaters.

  \begin{quote}
    The second kind of defeater attacks the connection between \(P\) and \(Q\) rather than attacking \(Q\) directly.

    \mbox{}\hfill\(\vdots\)\hfill\mbox{}

    A type II defeater is any reason for believing that \({\sim}(P => Q)\) which is not also a reason for believing that \({\sim}Q\).\nolinebreak
    \mbox{}\hfill\mbox{(\cite[43]{Pollock:1974uk})}
  \end{quote}
  Where `\(=>\)' is the subjunctive conditional. (\Citeyear[42]{Pollock:1974uk})

  With \citeauthor{Pollock:1974uk}'s original formulation, the defeater attacks the link.\nolinebreak
  \footnote{
    See \textcite[196,fn.166]{Pollock:1999tm} for a brief note of the history of undercutting defeaters.
    \textcite{Pollock:1974uk} is more-or-less a direct expansion of discussion in~\textcite{Pollock:1970un}.
  }

  However, generalise.
  That there's a relation of claimed support, evidence, or what have you between \(P\) and \(Q\).

  Generalisation by \citeauthor{Bergmann:2005ws}\nolinebreak
  \footnote{
    I am also inclined to \citeauthor{Worsnip:2018aa}'s sketch of undercutting defeaters, which builds on~\citeauthor{Bergmann:2005ws}'s.
    \begin{quote}
      Undercutting defeaters, which are easiest to think of in the context of the attitude of belief, are supposed to be considerations that undermine the justification of a belief in a proposition p not necessarily by providing (sufficient) positive evidence to think that p is false, but rather merely by suggesting (perhaps misleadingly) that one’s reasons for believing p are no good, in a way that neutralizes or mitigates their justificatory or evidential force.\linebreak
      \mbox{}\hfill\mbox{(\Citeyear[29]{Worsnip:2018aa})}
    \end{quote}
  }
  \begin{quote}
    \emph{d} is an \emph{undercutting defeater} for \emph{b} iff \emph{d} is a defeater for \emph{b} which is (or is an epistemically appropriate basis for) the belief that one's actual ground or reason for \emph{b} is not indicative of \emph{b}'s truth.\newline
    \mbox{}\hfill\mbox{(\citeyear[424]{Bergmann:2005ws})}
  \end{quote}

  Similar generalisation, but similar to \citeauthor{Pollock:1974uk} the relation is useful.
  So, generalise the subjunctive conditional.
\end{note}

\begin{note}
  \color{red}
  Idea is that the \epVAd{} \world{} acts as an undercutting defeater.
  Incorporating \ideaCSA{}, not getting a \sink{} is going to be an undercutting defeater.
\end{note}



\section{\ideaCSC{1}}
\label{sec:ideaCSC}

\begin{note}
  Started with \ideaCSA{}.
  Necessary condition for an agent having claimed support.
  \ideaCSB{}, necessary condition for an instance of reasoning to be an instance of claiming support.
  In particular, \ideaCSB{} focuses on steps of reasoning.
  Still, \ideaCSB{} left open reasoning.
  With \ideaCSC{} we identify a structural constraint on any such reasoning.

  As with \ideaCSB{}, focus is on \epVAd{} \world{1}.
\end{note}

\begin{note}
  Basic idea.
  If some step which required \(\psi\) to have value \(v'\), yet \(\psi\) not having value \(v'\) was \epVAd{} when making the step, then from consequence of step to \(\psi\) having value \(v'\) is no good.
\end{note}

\begin{note}
  \begin{restatable}[\ideaCSC{0} --- \ideaCSC{}]{idea}{iCSC}
    \label{idea:cs:imp-stp}
    An instance of reasoning is an instance of claiming support \emph{only if} the reasoning does not contain any \impotent{0} steps.
  \end{restatable}
\end{note}

\begin{note}
  Where:
  \begin{restatable}[\impotent{2} steps of reasoning]{notion}{defImpotence}
    A step of reasoning \(\delta\), made by agent \vAgent{}, from premises \(\chi_{1},\dots,\chi_{j}\) having values \(v_{1}, \dots, v_{j}\) to conclusion \(\psi\) having value \(v'\) is \emph{\impotent{}} just in case:

    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item \(\psi\) not having vale \(v'\) is \epVAd{} prior to making \(\delta\).
    \item Some premise \(\chi_{i}\) having value \(v_{i}\) is obtained from a prior step of reasoning \(\delta'\) such that:
      \begin{enumerate}[label=\alph*., ref=(2\alph*)]
      \item
        \label{idea:CS:B:step:commit}
        When making step \(\delta'\), \vAgent{} was committed to it being the case that if \(\psi\) does not have value \(v'\) then either:
        \begin{enumerate}[label=\roman*., ref=(2a\roman*)]
        \item
          \label{idea:CS:B:step:commit:p}
          Some premise \(\rho_{j}\) of \(\delta'\) does not have value \(v_{j}\).
        \item
          \label{idea:CS:B:step:commit:c}
          \(\chi_{i}\) does not have value \(v_{i}\).
        \end{enumerate}
      \end{enumerate}
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  Focusing in on the structure of some instance of reasoning.
\end{note}

\begin{note}
  \impotent{} because, does not go anywhere.
\end{note}

\begin{note}
  \color{red}
  Note, it's not the case that making step \(\delta\) alone is sufficient for a problem.
  For, agent may go on to conclude that \(\psi\) has value \(v'\) from some independent instance of reasoning.
\end{note}

\begin{note}
  If \autoref{idea:CS:B} is satisfied, then reasoning.
  \autoref{idea:cs:imp-stp} is weaker.

  So, this is a structural constraint.
  Motivated by foundational constraint.
\end{note}

\begin{note}
  First, the `circularity' here is inessential.
  Rather, observation that \(\delta\) won't apply outside of \(\psi\) having the case that \(\v\).


  Indeed, circularity is difficult here.
  For, necessary condition on claiming support.
  Reasoning that \indicateV{1} \(\psi\) has value \(v'\).
  It does not follow that the reasoning which \indicateV{1} needs to be an instance of claiming support.

  So, something like \citeauthor{Sgaravatti:2013wu} is not necessary going to hold.
  For, it does not follow that that demanding justification.
  Only a part of justification.
\end{note}

\begin{note}
  \autoref{idea:cs:imp-stp} as this is the thing that's going to do the work.
  Hence, following is compatible with rejecting \autoref{idea:CS:B} while maintaining \autoref{idea:cs:imp-stp}.

  Likewise, no doubt.
  So nothing of the kind Jackson suggests.

  This also extends to \citeauthor{Wright:2011wn}.
  For, \citeauthor{Wright:2011wn} relies on the idea of doubt.

  The issue here is what is required in order to doubt.
  One may need to revise one's epistemic state.

  Of course, if idea of claiming support is taken generally, then it should be the case that for any possibility, there is something which suggests that actual \world{} is something else.
  So, get back to current epistemic state, so to speak.

  So, if satisfy claiming support, then may satisfy doubt idea.
  However, ideal.
  Pointing out the issue here does not require such a general thing as doubt.
\end{note}

\begin{note}
  Instead, as \(\psi\) not having value \(v'\) is an \ep{}, it is possible that \(\psi\) does not have value \(v'\).
  And, if \(\psi\) does not have value \(v'\), then step \(\delta'\) does not apply to how things are.
  Hence, observing that \(\psi\) having value \(v'\) follows in turn from the conclusion of step \(\delta'\) (together with other premises) is uninformative about how things are.
\end{note}


\subparagraph{Potency}

\begin{note}
  Potent.
  However, this does not follow.
  For, sufficient condition for impotence.
  Hence, no negation.
\end{note}

\begin{note}
  Key thing.
  When looking at whether it is possible to go from \(X\) to \(\psi\), we don't need to question whether going from \(X\) to \(\psi\) would be an instance of claiming support.
  Instead, only need to pay attention to this structural issue.
\end{note}

\begin{note}
  If some steps from \(X\) to \(\psi\) are impotent.
  Then, if these are the only steps then failure to claim support.
  Hence, if intuition about claiming support, then great.
  So other steps of reasoning must be possible, if intuition is sound.

  However, more basic is whether it is possible to go from \(X\) to \(\psi\) without introducing \(\psi\) along the way.
  This intuition need not commit to success of claiming support.
  However, still important.

  Examples where it's not clear that it is possible to claim support, but still no problem with the reasoning.

  Maybe examples from before.
  You may worry about whether the agent's reasoning is such that they have indication that the premise appealed to is the case regardless.
  Still, it seems clear that there's no additional proposition.
  Either because deductive, and hence no possibility.
  Or, because getting premise is sufficient, and get premise without the conclusion.
\end{note}

\subparagraph{Previous \illu{1}}



\subparagraph{Circularity?}

\begin{note}[Circularity?]
  View this in terms of circularity.
  Must get \(\phi\) having value \(v\) without appealing to \(\phi\) having value \(v\).
  However, this is not general circularity.
  Only interested in cases where \(\phi\) not having value \(v\) is \epVAd{}.
  And, motivation is that if need \(\phi\) to have value \(v\), then reasoning doesn't indicate how things are.

  What matters is that this rests on \(\phi\) being the case.
\end{note}

\subparagraph{\illu{2} to be revised}

\begin{note}[Testimony 1]
  \begin{illustration}[Testimony 1]
    \label{illu:CS:test:basic}
    \mbox{}
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item\label{ex:eiS:t:basic:test} \nagent{11} testified that they are trustworthy when speaking on matters regarding their personal character.
    \item Any agent and proposition, agent testified that proposition is the case only if proposition is the case.
    \item \nagent{11} testified that p is the case only if p is the case.
    \item\label{ex:eiS:t:basic:ok} \nagent{11} is trustworthy when speaking on matters regarding their personal character.
    \end{enumerate}
  \end{illustration}

  I take the reasoning of~\autoref{illu:CS:test:basic} to be intuitively problematic.

  I am also somewhat confident that you will have seen some variant of the reasoning in relation to circularity before.

  The goal for the moment is to explain why the two ideas expressed in relation to claiming support (\nfcs{} and \eiS{}) highlight a way in which the reasoning is problematic.
  And, to distinguish the way in which the ideas highlight a problem from a pair of nearby considerations.
\end{note}

\begin{note}
  Observe, however, that the intuitive problem is not that the agent has any reason(ing) to think that \nagent{11} is \emph{not} trustworthy when speaking on matters regarding their personal character.

  Rather, the intuitive problem is that the agent does not have any reason(ing) to think that \nagent{11} \emph{is} trustworthy when speaking on matters regarding their personal character.

  In particular, that that \nagent{11} is not trustworthy when speaking on matters regarding their personal character is simply a possibility.
  It may be the case that \nagent{11} is trustworthy.\nolinebreak
  \footnote{
    \color{red}
    It's not like this suggests that they are not trustworthy.
    Asking for directions.
    These are fine, but addition is not.
  }
\end{note}

\begin{note}
  Following, let us consider why the reasoning of~\autoref{illu:CS:test:basic} is intuitively problematic from the perspective of claiming support.\nolinebreak
  \footnote{
    Of course, the reasoning of \autoref{illu:CS:test:basic} seems problematic without constraints on the purpose.
    However, our interest is with claiming support.
  }

  \ideaCSA{} and \ideaCSB{}.

  The role of \ideaCSA{} is simple: It is possible for the agent's reasoning to be \mom{}.
  For example.

  Possibility of \mistaken{}.
  Well, misheard, speaking sarcastically.
  Possibility of \misled{}.
  Possible that S is not trustworthy.

  It is the possibility of being \misled{} that is of interest.

  Here, \ideaCSB{}.
  In order for the reasoning to be an instance of claiming support, the reasoning should indicate that \nagent{11} is not trustworthy on matters regarding their personal character regardless of whether the reasoning that \nagent{11} is trustworthy on matters regarding their personal character is \mom{}.

  In particular, it should be possible for the agent to entertain the possibility that \nagent{11} is not trustworthy on matters regarding their personal character while maintaining that their reasoning indicates that \nagent{11} is trustworthy on matters regarding their personal character.
\end{note}

\begin{note}[The problem]
  The problem, then, is that it does not seem possible for the agent to entertain the possibility that \nagent{11} is not trustworthy when speaking on matters regarding their personal character while maintaining that their reasoning indicates that \nagent{11} is trustworthy when speaking on matters regarding their personal character.

  For, it may be the case that \nagent{11} is not trustworthy when speaking on matters regarding their personal character.
  And, \nagent{11}'s testimony involves speaking on a matter regarding their personal character.
  Hence, by entertaining the the possibility that \nagent{11} is not trustworthy on matters regarding their personal character, the agent is required to entertain the possibility that \nagent{11}'s statement did not amount to an instance of testimony.
  And, if \nagent{11}'s statement did not amount to an instance of testimony then it would seem the agent lacks a line of reasoning that indicates that \nagent{11} is trustworthy when speaking on matters regarding their personal character.
\end{note}

\begin{note}
  The preceding is only an expression of an intuition.
  \ideaCSA{} and \ideaCSB{} are ideas, and the arguments that follow will rest on the assumptions and propositions drawn from these ideas, rather than the ideas themselves.
  Still, to the extent motivation for those assumptions and propositions rest on these ideas, \autoref{illu:CS:test:basic} highlights the constraints the ideas place on claiming support.

  \begin{itemize}
  \item given \ideaCSA{}, the agent is required to consider the possibility that conclusion of their reasoning is not the case, and
  \item given \ideaCSB{}, the agent is required to hold that their reasoning indicates that the conclusion of their reasoning is not the case regardless of whether the possibility that conclusion of their reasoning is not the case obtains.
  \end{itemize}
  The reasoning of \autoref{illu:CS:test:basic} fails to be an instance of claiming support because the possibility that \nagent{11} is not trustworthy when speaking on matters regarding their personal character is sufficient to undercut the premise that \nagent{11} testified.
\end{note}

\begin{note}
  Now, granting that the above identifies a problem, an immediate question is:
  Is the problem an instance of (vicious) circularity?\nolinebreak
  \footnote{
    In advance of following discussion, variation on~\textcite{Sorensen:1991wh}.

    Claim support for the following proposition from the following sentence:

    \begin{quote}
      Some sentences are typed on a computer.
    \end{quote}

    In line with suggestions of \citeauthor{Sorensen:1991wh}, seems fine.
    No difficulty with ideas as compatible with something else happening.
    But, background that this is so incredibly unlikely.
  }

  Circularity is certainly in the ballpark, but I do not think there is a straightforward reduction.
\end{note}

\begin{note}
  First, the problem was motivated by view the agent's reasoning as an instance of claiming support and applying the two basic ideas of claiming support (\ideaCSA{} and \ideaCSB{}).
  And, in general, it seems that circularity extends beyond the scope of claiming support.

  For example, consider knowledge:
  The reasoning of \autoref{illu:CS:test:basic} seems problematic when view from the perspective of establishing knowledge.
  Yet, from such a viewpoint it seems \ideaCSA{} would not apply --- if the agent had come to know that \nagent{11} is trustworthy when speaking on matters regarding their personal character then it would not be possible (at least relative to the conclusion of their reasoning) that \nagent{11} is not trustworthy.
  Hence, neither \ideaCSA{} nor \ideaCSB{} would apply.

  To be clear, our interest is not that the claiming support explains why the reasoning is problematic.
  Rather, the point is that the sketch given of why the reasoning is problematic when viewed as an instance of claiming support is distinct from circularity, as it seems circularity would extend to cases for which \ideaCSA{} nor \ideaCSB{} would not apply.
\end{note}

\begin{note}
  Second, the term `circularity' suggests that the reasoner has taken the conclusion of the reasoning for granted.

  For example, consider what \citeauthor{Sgaravatti:2013wu} terms the `Justification Account' of circularity.\nolinebreak
  \footnote{
    As \citeauthor{Sgaravatti:2013wu} notes, the Justification Account of circularity is a rewriting of the third type of `epistemic dependence' considered by \citeauthor{Pryor:2004ws}~(\citeyear[359]{Pryor:2004ws}).
    Neither \citeauthor{Pryor:2004ws} nor \citeauthor{Sgaravatti:2013wu} endorse the Justification Account, but I take the spirit of the account to sufficient for interest.
    Still, the considerations which follow also apply to distinguish the {\color{red} problem identified} from \citeauthor{Sgaravatti:2013wu}'s favoured account (\Citeyear[\S3]{Sgaravatti:2013wu}) and the fifth type of `epistemic dependence' considered by \citeauthor{Pryor:2004ws}~(\citeyear[359]{Pryor:2004ws}).
  }

  \begin{quote}
    \begin{enumerate}[label=(JA), ref=(JA)]
    \item\label{sg:JA} An argument is circular if and only if for you to have justification to believe the premisses, it is necessary that you have justification to believe the conclusion.\nolinebreak
      \mbox{}\hfill\mbox{(\Citeyear[754]{Sgaravatti:2013wu})}
    \end{enumerate}
  \end{quote}
  Where `justification to believe' is to be read as in terms of having formed the belief in an epistemically appropriate way as opposed to (merely) possessing sufficient resources to form formed the belief in an epistemically appropriate way.\nolinebreak
  \footnote{
    Or, however you prefer to characterise \citeauthor{Firth:1978vi}'s (\Citeyear{Firth:1978vi}) distinction between doxastic and propositional justification (or warrant).
    See also \citeauthor{Silva:2020aa} (\Citeyear{Silva:2020aa}) --- esp.\ fn.\ 1.
  }
  (\citeauthor[Cf.][754--755]{Sgaravatti:2013wu})

  Observe, \ref{sg:JA} applies to \autoref{illu:CS:test:basic} only if the agent requires a justified belief that \nagent{11} is trustworthy prior to the conclusion of the agent's reasoning.

  Such may be the case, and plausibly is, but to the extent that the instance of claiming support is an instance of forming a justified belief, the problem highlighted by appeal to \ideaCSA{} and \ideaCSB{} relied only on entertaining the possibility that \nagent{11} is not trustworthy.
  Still, that it was necessary for the agent to have claimed support for \nagent{11} being trustworthy in order to claim support for the premises does not follow without additional argument --- no matter how plausible this may be.\nolinebreak
  \footnote{
    Though I have doubts about whether this really is the case.
  }

  % {
  % \color{red}
  % Necessary, as could argue that this is an implicit assumption.
  % Hence, .
  % Given plausibility, possible.

  % Yet, equally, that these two things don't go together regardless of perspective on premise.

  % And, in this sense order of explanation would be reversed.
  % Still a question of why required.
  % }

  %   Admittedly this is a somewhat delicate point.
  %   One may argue that \ref{sg:JA} (or some variant) explains why it is (intuitively) not possible for the agent to entertain possibility that \nagent{11} is not trustworthy given their reasoning.

  %   Indeed, even if it is the case that the agent is required to have claimed support (or a justified belief) for \nagent{11} being trustworthy to claim support for the premises, the problem identified via \ideaCSB{} would remain distinct and would seem at best to motivate such an additional restriction.
  Leaves open the possibility that problem highlighted by \ideaCSA{} and \ideaCSB{} does not reduce.
  Hence, seems that distinguish intuitions from \ideaCSA{} and \ideaCSB{} from intuitions about why or how the agent introduced \nagent{11} testifying as a premise.
\end{note}

\begin{note}
  The basic intuition, really, is that from \ideaCSA{} there is the possibility of being \mom{}.
  In particular, \mistaken{} about testimony.
  So, various ways in which this premise may fail.
  The conclusion not holding is one such way.
  And, if this is the case then whatever considerations the agent has for testimony, those considerations do not extend.
\end{note}

\begin{note}
  Still, rather than toy in the abstract, let's investigate further by granting the agent with a way of claiming support for the initial premise of the reasoning.
  The problem identified by \ideaCSA{} and \ideaCSB{} will remain, but to press the problem of circularity will require stronger assumptions.
\end{note}

\begin{note}[Testimony 2]
  \begin{illustration}[Testimony 2]
    \label{illu:CS:test:with-CS-for-premise}
    \mbox{}
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item I was assured that \nagent{11} will be honest with me throughout the meeting.
    \item\label{ex:eiS:tt:test} \nagent{11} testified that they are trustworthy on matters regarding their personal character.
    \item Any agent and proposition, agent testified that proposition is the case only if proposition is the case.
    \item \nagent{11} testified that p is the case only if p is the case.
    \item\label{ex:eiS:tt:ok} \nagent{11} is trustworthy on matters regarding their personal character.
    \end{enumerate}
  \end{illustration}

  \autoref{illu:CS:test:with-CS-for-premise} seems intuitively problematic to a similar degree as \ref{illu:CS:test:basic}.

  The prior assurance does not help, at least given context that the friend was not aware of what \nagent{11} would say.

  However, the prior assurance does provide a clear account of how the agent introduced \nagent{11} testifying as a premise.
\end{note}

\begin{note}
  Problem here remains.
  Now, two instances of claiming support.

  Observe, vouched for particular instance, but not general.
  Assurance went for statements in general, but now have information about particular statement.
  Seems okay in various cases.

  \begin{itemize}
  \item The venue will be crowded.
  \item A squirrel took the birdseed.
  \item \TeX is Turing-complete
  \end{itemize}
  (Observe, in these instances not a \requ{}.)
  Assurance is sufficient.
  In general, so long as appeal to instance of testimony while granting that content of that instance of testimony (and hence the testimony itself) may fail, then there is no tension with the assumptions made regarding claimed support.

  Yet, the reasoning seems to remain problematic with respect to self-attribution of trustworthiness.
\end{note}

\begin{note}
  The issue for \ref{sg:JA} is that it does not seem necessary for the agent to have justification to believe that \nagent{11} is trustworthy on matters regarding their personal character in order to have justification to believe that \nagent{11} would be honest throughout the meeting.

  Instead, it seems that there is a limitation on the scope of the assurance that is sensitive to the content of what \nagent{11} said (or would say).
  In turn, the agent's reasoning is problematic because the reasoning exceeds the relevant limitation.
  And, while it may be the case that would need justification for conclusion to have unlimited justification for the premises, the limitation alone is sufficient identify the problem.

  This is preferred understanding of the problem raised by \ideaCSA{} and \ideaCSB{}.
\end{note}

\begin{note}
  However, granting that the problem arises from some limitation, it is important to keep in mind that the limitation arises from entertaining some possibility as opposed to assuming that the possibility obtains.
\end{note}

\begin{note}[\citeauthor{Pryor:2004ws}'s Type 4]
  An instance of a limitation arising from assuming that the possibility obtains is the fourth type of dependence between premise and conclusion considered by \citeauthor{Pryor:2004ws}.

  \begin{quote}
    [Type 4] dependence between premise and conclusion is that the conclusion be such that evidence \emph{against it} would (to at least some degree) undermine the kind of justification you purport to have for the premises.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[359]{Pryor:2004ws})}
  \end{quote}

  Again, plausible.

  Issue:
  \begin{enumerate}
  \item Evidence undermines the kind of justification the agent purports to have for the premises.
  \end{enumerate}

  Seems to hold for \autoref{illu:CS:test:basic}.
  Would undermine appeal to \nagent{11}'s testimony.
  However, fails for \autoref{illu:CS:test:with-CS-for-premise}.
  Would not undermine the companion's assurance, even if viewed as an instance of testimony.

  Run this through the other instances suggested.

  And, as \citeauthor{Pryor:2004ws} notes, \emph{kind} is important.
  However, it seems kind is not the only problem.
\end{note}

\begin{note}
  Also compatible with \citeauthor{Pryor:2004ws}'s argument that type 4 over-generates.
  Details are in the following footnote.\footnote{
  Compatible with \citeauthor{Pryor:2004ws}'s objection to type 4 dependence.

  % \begin{illustration}
    % \mbox{}
    % \vspace{-\baselineskip}
    \begin{quote}
      Suppose you're watching a cat stalk a mouse. Your visual experiences justify you in believing:

      \begin{enumerate}[label=(\arabic*), ref=(\arabic*)]
        \setcounter{enumi}{10}
      \item\label{illu:Pryor:cat:1} The cat sees the mouse.
      \end{enumerate}

      You reason:

      \begin{enumerate}[label=(\arabic*), ref=(\arabic*), resume]
      \item\label{illu:Pryor:cat:2} If the cat sees the mouse, then there are some cases of seeing.
      \item\label{illu:Pryor:cat:3} So there are some cases of seeing.\nolinebreak
        \mbox{}\hfill\mbox{(\citeyear[361]{Pryor:2004ws})}
      \end{enumerate}
    \end{quote}
  % \end{illustration}

  Setting aside whether this is fine.

  Following \citeauthor{Pryor:2004ws}:

  Bad, given proposal, as if no cases of seeing, then the cat is not seeing. (\citeyear[361]{Pryor:2004ws})

  \citeauthor{Pryor:2004ws}'s position is as follows:

  \begin{quote}
    I don't think you need antecedent justification to believe \ref{illu:Pryor:cat:3}, before your experiences can give you justification to believe \ref{illu:Pryor:cat:1}.
    I also think it's plausible that your perceptual justification to believe \ref{illu:Pryor:cat:1} contributes to the credibility of \ref{illu:Pryor:cat:3}.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[361]{Pryor:2004ws})}
  \end{quote}

  This is compatible with \ideaCSA{} and \ideaCSB{}, and the assumptions and premises which have followed.
  You need not agree with \citeauthor{Pryor:2004ws}

  No clear trouble.
  The possibility alone isn't going to do enough.
  Still seems possible for 1 to hold up.
  Would count against, but not clear that entertaining possibility raises issue for claimed support for premise.
  Indeed, also compatible with the cat not seeing, but if this is the case then it's not clear why no cases of seeing is any more important than the singular case.
  }
\end{note}

\begin{note}
  Of course, still some question about why entertaining the possibility is sufficient.
  And, why there does not seem to be considerations for certain consequences of claimed support.

  Nothing insightful beyond broad account.

  Given this, the purpose of the assumptions made is to narrow down a clearer problem.
  No reasoning, and as an instance of this when there is the impossibility of such reasoning.

  Examples of the former.
\end{note}

\subsection{Summary of ideas}
\label{sec:summary-1}

\begin{note}
  \ideaCSA{}, necessary condition on having claimed support.
  \ideaCSB{}, necessary condition on step of reasoning for instance of reasoning to be an instance of claiming support.
  \ideaCSC{}, structural constraint on a step of reasoning.
\end{note}

\section{Refining the ideas into an assumption}
\label{sec:assumpt-from-ideas}

\begin{note}
  Two ideas, \ideaCSA{} and \ideaCSB{}.
  Possibility, and requirement from this.
  As noted, claiming support is still quite general, and this is by design.
\end{note}

\begin{note}
  \ideaCSB{}.
  Claiming support indicates regardless.

  Developing this.

  Key idea is reasoning.

  What it is to `appeal' to a proposition-value pair.
  Develop this through a series of definitions.
  These are, unfortunately, complex.

  The basic idea, however, is sort of okay.
  What we are interested in is proposition-value pairs that are important to the premises.

  Term this a \requ{}.

  Of course, in a broader sense of `appeal', reasoning involves appeal to proposition-value pairs which are not \ep{1}.
  However, no particular interest in these.
  The sense of appeal is stronger.
\end{note}

\subsection{\result{3} and \requ{1}}
\label{sec:claim-supp-requ}

\begin{note}
  To develop \ideaCSA{} and \ideaCSB{} into assumptions we start by defining a `\requ{}' of some instance of reasoning.

  Both \ideaCSA{} and \ideaCSB{} concern propositions having values appealed to in reasoning.
  In turn, the role of a \requ{} is to, on the one hand provide a sufficiently clear account of an important proposition-value pairs.

  Of course, one may hold that additional proposition-value pairs, or indeed other factors beyond \requ{1} are important for claiming support.
  Our interest, however, will be limited to \requ{1} (and an extension of \requ{1}).
  For, our interest is with providing sufficient conditions to highlight failures of claiming support.
\end{note}

\begin{note}
  The basic idea behind a `\requ{}' of a step of reasoning is simple:
  \begin{restatable}[A \requ{0} of (making a step of) some instance of reasoning]{idea}{ideaRequisite}
    A \requ{} is a proposition-value pair, e.g.\ \(\psi\) having value \(v'\), such that
    \begin{enumerate}
    \item \(\phi\) not having value \(v'\) is an \ep{}.
    \item Involved in reasoning.
    \item Important for reasoning.
    \end{enumerate}
  \end{restatable}

  Follows from some step of the reasoning.
  Subjunctive.
  If \(\psi\) did not have value \(v'\), then premises fail to indicate.
  Of course, there may be other ways in which reasoning may fail to indicate.
  For example, positive: if \(\chi\) were to have value \(v''\)\dots
  However, we're only focusing on proposition-value pairs.
\end{note}

\begin{note}
  To make this precise, we first define a `\result{}' of making a step of some instance of reasoning.
  This will then allow us to identify specific instances of \requ{1}.
  Leads to a general definition.
  Important distinction between (kinds of) \prequ{1} and \crequ{1}.

  Given \requ{} in general, \ideaCSB{} is going to require some stuff.
  However, specifically with respect to (kinds of) \prequ{1}.
\end{note}

\subsubsection{\result{3}}
\label{sec:def-of-result}

\paragraph{Definition}

\begin{note}
  \begin{restatable}[\result{3} of (making a step of) some reasoning]{definition}{defResult}
    \label{def:result}
    Let \(R\) be some instance of reasoning which concludes that \(\phi\) has value \(v\).

    \(\psi\) has value \(v'\) is \emph{\result{}} of a step \(\delta\) of reasoning \(R\) if and only if:
    \begin{enumerate}[label=\arabic*., ref=\named{P:\arabic*}]
    \item
      \label{def:result:ep}
      \(\psi\) not having value \(v'\) is an \ep{}.
    \item
      \label{def:result:conseq}
      Making step \(\delta\) while holding that \(\psi\) does not have value \(v'\), relative to other commitments of the agent (if any), would involve either:
      \begin{enumerate}[label=\alph*., ref=\named{P:2\alph*}]
      \item
        \label{def:result:conseq:a}
        A premise having some other value.
      \item
        \label{def:result:conseq:c}
        The conclusion having some other value.
      \end{enumerate}
    \item
      \label{def:requ:persists}
      No other part of the reasoning that concludes that \(\phi\) has value \(v\) involves a step \(\delta'\) such that \(\psi\) having value \(v'\) satisfies \ref{def:result:conseq} with respect to \(\delta'\).
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  A `\result{}' of a step of reasoning is a complex thing.
  First, at least one step.
  And, no step which avoids.
  Local and global.

  Key interest is following from reasoning, so global.
  But also important to pinpoint step, so local.
\end{note}

\paragraph*{Detailing \autoref{def:result} through an example with a variation}

\begin{note}
  Consider the following reasoning:
  \begin{example}\mbox{}
    The agent is working for some company, and is in a room of an office building which has a clock on the wall.
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item\label{result:ex:temp:w} The clock appears to be working
    \item\label{result:ex:temp:f} The clock is working. \hfill \CStepA{}: From \ref{result:ex:temp:w}
    \item\label{result:ex:temp:t} The clock reads 5:05pm.
    \item\label{result:ex:temp:c} It is 5:05pm. \hfill \CStepB{}: From \ref{result:ex:temp:f} \& \ref{result:ex:temp:t}
    \item\label{result:ex:temp:t-to-d} If it is after 5pm, no meetings may be started.
    \item\label{result:ex:temp:d} No meetings may be started.
      \hfill \CStepC{}: From~\ref{result:ex:temp:c} \&~\ref{result:ex:temp:t-to-d}
    \end{enumerate}
  \end{example}

  \ref{def:result:ep} requires that \(\psi\) not having value \(v'\) is an \ep{}.
  Our interest is only in proposition-value pairs `involved' in some instance of reasoning that may have some other value from the perspective of the agent.

  It is plausible that neither \ref{result:ex:temp:t} nor \ref{result:ex:temp:t-to-d} are \ep{1} for the agent.
  For, we may assume that~\ref{result:ex:temp:t} is obtained by visual inspection, and that \ref{result:ex:temp:t-to-d} is part of the company's rule-book.

  Still, we may consider the remaining proposition-value pairs as \ep{}.
  For, the clock may not be working, and, as the agent appeals to the clock working in order to reason to it being 5:05pm, it (also) may not be 5:05pm.
  In particular, it may be that it is 4:55pm, and so there is a few minutes in which someone may start a meeting.
  So,~\ref{result:ex:temp:w},~\ref{result:ex:temp:f},~\ref{result:ex:temp:c}, and~\ref{result:ex:temp:d} are all candidates for being \result{1}
\end{note}

\begin{note}
  Still, given \ref{def:result:ep}, any \ep{} proposition-value pair is a candidate for being a \result{}.
  For example, it being the case that it will rain tomorrow, or that one would enjoy what follows the 10o'clock news this evening.
  Hence, \ref{def:result:conseq} ensures that the proposition value pair is relevant to the instance reasoning.
\end{note}

\begin{note}
  Let us consider Steps B and C in detail:

  If the clock is not working, the \CStepB{} would involve appealing to something that is not the case, and hence \ref{result:ex:temp:f} satisfies \ref{def:result:conseq:a} with respect to \CStepB{}.
  Likewise, if the time is not 5:05pm, then \CStepB{} would involve moving to something that is not the case, and hence \ref{result:ex:temp:c} satisfies \ref{def:result:conseq:c}.

  Similarly, the time being 5:05pm satisfies \ref{def:result:conseq:a} with respect to \CStepC{}, and the that no meeting may be started satisfies \ref{def:result:conseq:c}.\nolinebreak
  \footnote{
    Note, however, that the clock working does not satisfy \ref{def:result:conseq:a} with respect to \CStepC{}, as the step moves from what the time is, not the report of what the time is by a working clock.
  }

  And, without any background constraints, no other proposition-value pairs seems to satisfy~\ref{def:result:conseq}.
\end{note}

\begin{note}
  Still,~\ref{def:result:conseq} mentions `other commitments' of the agent `(if any)'.
  Hence, the time being 5:05pm is not the only proposition-value pair which satisfies \ref{def:result:conseq:c}.
  For,~\ref{result:ex:temp:t-to-d} is a commitment of the agent:
  If the meeting may be started, then the time is not 5:05p.
  So, that no meetings may be started \emph{also} satisfies \ref{def:result:conseq:c} with respect to \CStepB{}.
\end{note}

\begin{note}[Summary]
  The preceding is summarised in~\autoref{fig:def:result:conseq:table}, with \CStepA{} also included.
  \begin{figure}[!h]
    \centering
    \begin{tabular}{  c | c | c | c  }
      & \CStepA{} & \CStepB{} & \CStepC{} \\
      \hline
      \ref{def:result:conseq:a} & \ref{result:ex:temp:w} & \ref{result:ex:temp:f} & \ref{result:ex:temp:c} \\
      \hline
      \ref{def:result:conseq:c} & \ref{result:ex:temp:f} & \ref{result:ex:temp:c}, \ref{result:ex:temp:d}  & \ref{result:ex:temp:d}
    \end{tabular}
    \caption{Proposition-value pairs satisfying \ref{def:result:conseq} with respect to steps.}
    \label{fig:def:result:conseq:table}
  \end{figure}
\end{note}

\begin{note}
  The final clause of \ref{def:result} to consider is \ref{def:requ:persists}.
  As noted, the basic idea behind \ref{def:requ:persists} is to ensure that the relevant proposition-value pair matters to the conclusion of the instance of reasoning for which the step is a part.

  The notion of a `part' of reasoning is left intuitive.
  However, that the relevant `parts' of reasoning provides sufficient information to observe that the relevant proposition-value pairs identified all satisfy \ref{def:requ:persists}.
  For, that no meetings may be started is the conclusion of the instance of reasoning, and both steps A and B are involved in obtaining this conclusion.

  Hence,~\ref{result:ex:temp:f},~\ref{result:ex:temp:c} and~\ref{result:ex:temp:d} are all \result{1} of the instance of reasoning with respect to \CStepB{}, and~\ref{result:ex:temp:c} and~\ref{result:ex:temp:d} are \result{1} of reasoning with respect to \CStepC{}.\nolinebreak
  \footnote{
    And both \ref{result:ex:temp:w} and \ref{result:ex:temp:f} are \result{1} with respect to \CStepA{}.
  }
  Intuitively, each proposition-value pair is involved in obtaining the conclusion.
\end{note}

\begin{note}
  Still, to illustrate why~\ref{def:requ:persists} is important, consider the agent receiving a memo prior to their reasoning, which states the following:
  \begin{enumerate}[label=\arabic*\('\), ref=(\arabic*\('\))]
  \item\label{result:ex:temp:memo} If, and only if, the clock is not working, no meetings shall be held.
  \end{enumerate}
  Let us assume the memo is stamped, and therefore that the information contained is not an \ep{}.

  The agent now has the option of reasoning by cases.
  If the clock is working, then the agent reasons to the conclusion that no meetings may be started as in~\ref{result:ex:temp:f} to~\ref{result:ex:temp:d}, above.
  However, if the clock is not working, then the agent may obtain the conclusion from \ref{result:ex:temp:memo}.
  In particular, the agent would not need to appeal to the clock working in order to appeal to the clock not working, so \ref{result:ex:temp:f} would not be a \result{} of \CStepB{}.
  And, likewise the agent would obtain the conclusion without appealing to the time being 5:05pm.
  Hence, \ref{result:ex:temp:c} would neither be a \result{} of \CStepB{} nor of \CStepC{}.

  So, only \ref{result:ex:temp:d} would be a \result{} of reasoning by cases.
\end{note}

\begin{note}
  The details here are secondary to the key idea:

  Not only does \(\psi\) having value \(v'\) follow as a result of making the step of reasoning, but making the step of reasoning is such that the conclusion of reasoning is obtained in part by making the relevant step of reasoning.

  If the agent has the option of reasoning by cases, then the agent's reasoning does not depend any proposition-value pair that is unique to a particular case.
  Hence, that proposition-value pair will not be a \result{}.
\end{note}

\begin{note}
  Determining whether a proposition-value pair is a \result{} of some step of reasoning is, in general, difficult.
  For, \ref{def:requ:persists} is a global property.
  And, in general, some instance of reasoning may contain multiple steps, numerous instances of reasoning by cases, and so on.

  Naturally, complex reasoning is difficult, and ideas applied are significant.
  We will not have any direct interest in a complex of step --- in particular, our focus will be on straightforward (sub-)instances of reasoning which involve a single step.
  However, in the case that the step is part of a larger complex, \ref{def:requ:persists} is important to highlight why some proposition-value pair associated with the step matters.
\end{note}

\subsubsection{\requ{3}}
\label{sec:def-of-requ}

\begin{note}
  With the definition of a \result{} in hand, we not turn to defining \requ{1}.
\end{note}

\begin{note}
  Intuitively, a \requ{} of a step of reasoning is a non-disposable consequence of some step of reasoning and the reasoning as a whole, whose failure is epistemic possibility for the agent, and is such that the failure of the \requ{} would mean that the step of reasoning appealed to something that is not the case.

  The definition of a \result{} clarified how a proposition-value pair is important in some instance of reasoning, but the definition of a \result{} alone does not account for why it is not possible for the agent to conclude the instance of reasoning without (indirectly) appealing to the proposition-value pair.
  To capture the mentioned role of proposition-value pair, the definition of a \requ{} is broken down into three distinct types of \requ{}, with the definition of a \result{} being used to clarify two basic \requ{}-types.
\end{note}

\begin{note}
  The definition of a \requ{} is as follows:
  \begin{restatable}[\requ{3} of a step of reasoning]{definition}{defRequisite}
    \label{def:requsite}
    \(\psi\) has value \(v'\) is a \emph{\requ{}} of a step of reasoning that concludes that \(\phi\) has value \(v\) (from an agent's perspective) if and only if:
    \begin{enumerate}[label=\arabic*., ref=\named{R:\arabic*}]
    \item[] \(\psi\) having value \(v'\) is either:
      \begin{enumerate}
      \item
        A \prequ{}.
      \item
        A \crequ{}.
      \item
        A \cprequ{}.
      \end{enumerate}
      \vspace{-\baselineskip}
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  Before proceeding to define the distinct types of \requ{}, a quick note on the definitions that follow.

  As with the definition of a \result{}, each definition of a \requ{}-type focuses on some step of reasoning.
  However, as with the definition of a \result{}, each definition of a \requ{}-type will include a `global' clause which ensures that the proposition-value pair is not only important for the step of reasoning, but for the instance of reasoning as a whole.
  The clause present in each of the definitions is as follows:
  \begin{itemize}
  \item
    \requGlobalClause{}
  \end{itemize}
  This clause means that the collection of definitions is circular.
  We a \requ{} is in part defined in terms of a \prequ{}, and in turn a \prequ{} is in part defined in terms of a \requ{}.
  However, the circularity is benign.
  In is simply a convenient way to quantify over all other \requ{}-types.
  Semantically, the result of expanding each definition is a check that no other proposition-value pair is one of the three \requ{}-types defined.\nolinebreak
  \footnote{
    Though, syntactically, expanding each definition results in a proposition of unbounded length.
  }
\end{note}

\paragraph{\pandcrequ{3}}

\begin{note}
  We begin by defining \prequ{1} and \crequ{1}.
  These two definitions build on the definition of a \result{}.\nolinebreak
  \footnote{
    The reason for separating these definitions is

    First, the separation of the definitions helps reduce the complexity of the respective definitions.
    Second, separation helps shift focus.
    With \result{}, involvement.
    With \requ{}, importance.
  }
\end{note}

\subparagraph*{\prequ{3}}

\begin{note}
  \begin{restatable}[\prequ{2} of a step of reasoning]{definition}{defRequisiteP}
    \label{def:prequ}
    \(\psi\) has value \(v'\) is a \emph{\prequ{0}} of some step \(\delta\) of reasoning if and only if

    \begin{enumerate}[label=\arabic*., ref=\named{pR:\arabic*}]
    \item
      \(\psi\) has value \(v'\) is a \result{0} of the \emph{premises} of Step \(\delta\).\nolinebreak
      \footnote{
        I.e.\ by satisfying~\ref{def:result:conseq:a} of~\autoref{def:result}.
      }
    \item
      \label{def:prequ:subjunctive}
      It is not \epVAd{0} for the agent to make Step \(\delta\) without either:
      \begin{enumerate}[label=\alph*., ref=\named{pR:2\alph*}]
      \item
        \label{def:prequ:subjunctive:psi}
        \(\psi\) having value \(v'\) prior to Step \(\delta\), or
      \item
        \label{def:prequ:subjunctive:other}
        the other commitments (if any) which lead to \(\psi\) having value \(v'\) being a \result{0} of Step \(\delta\) prior to making Step \(\delta\).
      \end{enumerate}
    \item
      \requGlobalClause{}
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}[Summary of \prequ{0}]
  In short, a \prequ{0} is simply a \result{0} which follows from the \emph{premises} of the step of reasoning with the added constraint regarding the relevant commitments of the agent, if there are any.
\end{note}

\begin{note}
  To illustrate the important of \ref{def:prequ:subjunctive}, consider the agent having the following commitments prior to the instance of reasoning:

  \begin{enumerate}[label=B\(^{+}\)\arabic*., ref=(B\(^{+}\)\arabic*)]
  \item
    \label{result:ex:temp:repair}
    If the clock is working, then it was repaired yesterday.
  \item
    \label{result:ex:temp:chime}
    If the clock is working, then it chimes on the hour.
  \end{enumerate}

  \CStepB{} involved appeal to the proposition-value pair that the clock is working.
  So, the consequents of both conditionals are \result{1} of \CStepB{} (of the reasoning from \ref{result:ex:temp:f} to \ref{result:ex:temp:d}).\nolinebreak
  \footnote{
    I.e.\ excluding the possibility instance of reasoning by cases introduced by \ref{result:ex:temp:memo}.
  }
  Hence, the consequents of both conditionals are candidates for being \requ{1}.

  However, the two consequents differ with respect to whether it would be \epVAd{} for the agent to make \CStepB{}.
  If the clock was not repaired yesterday, then it seems the agent would refrain from appealing to the clock functioning.
  By contrast, if the clock does not chime on the hour, the agent may hold that \ref{result:ex:temp:chime} is false, rather than being committed to the clock being broken.

  Of course, this evaluation assumes further information.
  First, that the clock was in need of repair, and second that the agent does not consider whether the clock chimes to be important for whether the clock is telling the correct time.

  In general, the possible \result{1}, and hence \prequ{1}, of a step of reasoning may be substantial, given the range of commitments an agent may have.
  Still, the key idea of \ref{def:prequ:subjunctive} is hopefully clear:
  \begin{itemize}
  \item
    A \prequ{} of a step of reasoning is a result of that step of reasoning that is not only involved in making the step, but is also important to maintaining that what the agent appeals to when making the step is appropriate.
  \end{itemize}
\end{note}

\begin{note}
  Note, also, that \ref{result:ex:temp:f} is clearly a \prequ{0} with respect to \CStepB{}.
  And, \ref{result:ex:temp:c} is clearly a \prequ{} with respect to \CStepC{}.
\end{note}

\subparagraph{\crequ{3}}

\begin{note}[Moving to \crequ{0}]
  The definition of a \crequ{0} is the same as the definition of a \prequ{0}, but for attention on the conclusion, rather than the premises of the step of reasoning.
\end{note}

\begin{note}
  \begin{restatable}[\crequ{2} of a step of reasoning]{definition}{defRequisiteC}
    \label{def:crequ}
    \(\psi\) has value \(v'\) is a \emph{\crequ{0}} of a step of reasoning if and only if
    \begin{enumerate}[label=\arabic*., ref=\named{cR:\arabic*}]
    \item
      \(\psi\) has value \(v'\) is a \result{0} of the \emph{conclusion} of Step \(\delta\).\nolinebreak
      \footnote{
        I.e.\ by satisfying~\ref{def:result:conseq:c} of~\autoref{def:result}.
      }
    \item
      \label{def:crequ:subjunctive}
      It is not \epVAd{} for the agent to make Step \(\delta\) without either:
      \begin{enumerate}[label=\alph*., ref=\named{cR:2\alph*}]
      \item \(\psi\) having value \(v'\), or
      \item the other commitments (if any) which lead to \(\psi\) having value \(v'\) being a \result{0} of Step \(\delta\).
      \end{enumerate}
    \item
      \requGlobalClause{}
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  Intuitively, moving to something that is not the case, such that no making the step.
\end{note}

\begin{note}
  For example, consider the following two conditionals with respect to \CStepC{}:
  \begin{enumerate}[label=C\(^{+}\)\arabic*., ref=(C\(^{+}\)\arabic*)]
  \item
    \label{result:ex:temp:B:summon}
    If no meetings may be started, then I may not summon my team for a meeting.
  \item
    \label{result:ex:temp:B:see}
    If no meetings may be started, then I won't see \nagent{12} until tomorrow, at the earliest.
  \end{enumerate}
  The consequents of both conditionals are \result{1} of making \CStepC{}, and as they follow from what \CStepC{} establishes, both consequents are candidates for being \crequ{1}.
  However, while the agent may not give up \ref{result:ex:temp:B:summon}, it seems the agent would easily give up \ref{result:ex:temp:B:see} if \nagent{12} were to (unexpectedly) visit the office.
  Hence, only the consequent of \ref{result:ex:temp:B:summon} is a \crequ{1} of \CStepC{}.
\end{note}

\begin{note}
  As before, the possible \result{1}, and hence \crequ{1}, of a step of reasoning may be substantial, given the range of commitments an agent may have.
  Still, the key idea of \ref{def:crequ:subjunctive} is hopefully clear:
  \begin{itemize}
  \item
    A \crequ{} of a step of reasoning is a result of that step of reasoning that is not only involved in making the step, but is also important for maintaining that what follows from making the step is appropriate.
  \end{itemize}
\end{note}

\begin{note}
  Note, also, that \ref{result:ex:temp:d} is clearly a \crequ{} of \CStepC{}.
  And, both \ref{result:ex:temp:c} and~\ref{result:ex:temp:d} are clearly \crequ{1} of \CStepB{}.
\end{note}

\subparagraph*{Summarising \prequ{1} and \crequ{1}}

\begin{note}
  From the perspective of their definition, \crequ{1} and \prequ{1} are distinguished only by how \(\psi\) having value \(v'\) is a \result{0}.
  In the case of \prequ{1}, \(\psi\) having value \(v'\) is a \result{0} of the premises, while in the case of \cprequ{1}, it is a \result{0} of the conclusion.
\end{note}

\begin{note}[No \crequ{1} wrt.\ deductive reasoning]
  \phantlabel{crequ-only-non-deductive}
  As noted, we distinguish \prequ{1} and \crequ{1} in part for the definition to follow, but also due to the kind of reasoning the definitions apply to.
  For, in contrast to \prequ{1}, there are no \crequ{1} in the case of purely deductive reasoning.

  For, in the case of deductive reasoning, any conclusion of the step of reasoning follows from the relevant premises, in the sense that it is not \epVAd{} for the agent to jointly hold that the premises of the step have their respective values while the conclusion of the step does not have some value.\nolinebreak
  \footnote{
    This is only to state that, with respect to \emph{conditional detachment}, it is not \epVAd{} for an agent to hold that \(\phi\) is true and \(\phi \rightarrow \psi\) is true and not to hold that \(\psi\) is false.
    And, it is compatible with this statement that the agent holds both the premises but does not entertain \(\psi\) as either true or false.
  }

  Hence, in order for \(\psi\) having value \(v'\) to be a \crequ{}, the step of reasoning must introduce something which does not directly follow from the premises.
  For example, moving from inductive considerations for \(\phi\) being true to \(\phi\) being true.
\end{note}

\begin{note}
  \phantlabel{step-a-non-deductive}
  Indeed, \CStepA{} is an example of a non-deductive step.
  
  It does not deductively follow from the clock appearing to be working that the clock is working.
\end{note}

\paragraph{\cprequ{3}}

\begin{note}
  We now turn to the third (and final) type of \requ{}.
  In contrast to \pandcrequ{1}, this type of \requ{} builds on parts of the definition of a \result{}, and on the definition \crequ{}.

  The key idea is that:
  \begin{itemize}
  \item
    In the case of non-deductive reasoning, a step of reasoning may introduce a proposition-value pair which interacts with the premises of the step to yield further proposition-value pairs that are important for maintaining that what follows from making the step is appropriate.
  \end{itemize}
  Hence, follow from the note \hyperref[crequ-only-non-deductive]{above}, \cprequ{1} are unique to non-deductive reasoning.
\end{note}

\begin{note}
  \begin{restatable}[\cprequ{2} of (a step of) reasoning]{definition}{defRequisiteCP}
    \label{def:cprequ}
    \(\psi\) has value \(v'\) is a \emph{\cprequ{0}} of a step of reasoning \(\delta\) iff
    \begin{enumerate}[label=\arabic*., ref=\named{cpR:\arabic*}]
    \item
      \label{def:cprequ:result}
      \(\psi\) has value \(v'\) is a \result{0} of the step of reasoning \(\delta\).
    \item It is the case that:
      \label{def:cprequ:subjunctive}
      \begin{enumerate}[label=\alph*., ref=\named{cpR:2\alph*}]
      \item
        \label{def:cprequ:subjunctive:chi}
        \(\chi_{i}\) having values \(v''_{i}\) are \crequ{1} of \(\delta\).
      \item
        \label{def:cprequ:subjunctive:unique}
        \(\psi \ne \chi_{i}\) for any \(i\).
      \item
        \label{def:cprequ:subjunctive:relation}
        It is not \epVAd{} for the agent to jointly hold:
          \begin{enumerate}
          \item
            The \prequ{1} of \(\delta\),
          \item
            that \(\chi_{i}\) have values \(v''_{i}\), and
          \item
            that \(\psi\) does not have value \(v'\).
          \end{enumerate}
      \end{enumerate}
    \item
      \requGlobalClause{}
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  As with the definitions of \pandcrequ{1}, the first clause of the definition of a \cprequ{} requires that \(\psi\) having value \(v'\) is a \result{0} of the step of reasoning \(\delta\).
  However, unlike the definitions of \pandcrequ{1}, \ref{def:cprequ:result} does not constrain the way in which \(\psi\) having value \(v'\) is a \result{0}.

  Instead, the relevant clarification is found in~\ref{def:cprequ:subjunctive}.
  In short,~\ref{def:cprequ:subjunctive} holds when:
  \begin{enumerate}[label=\alph*.]
  \item There are some proposition-value pairs which follow from the conclusion of the step,
  \item \(\psi\) having value \(v'\) is not (merely) a \crequ{}, and
  \item \(\psi\) having value \(v'\) follows from those proposition-value pairs.
  \end{enumerate}
  In other words, then, the importance of \(\psi\) having value \(v'\) to the step of reasoning is introduced by the proposition-values pairs \(\chi_{i}\) having values \(v''_{i}\) being a \crequ{}.

  In this respect, \ref{def:cprequ:subjunctive:unique} is important to ensure that \(\psi\) having value \(v'\) is not a \crequ{}.
  For, \(\chi\) having value \(v''\) trivially follows from \(\chi\) having value \(v''\), and hence without the restriction imposed by \ref{def:cprequ:subjunctive:unique}, any \crequ{} would also be a \cprequ{}.
\end{note}

\begin{note}
  As noted \hyperref[step-a-non-deductive]{above}, \CStepA{} is a non-deductive step.
  It is not the case that the clock is working follows deductive from the appearance that the clock is working.
  So, with respect to \CStepA{}, that it is the case that the clock is working is a relevant \(\chi_{i}\) having value \(v''\) instance of \ref{def:crequ:subjunctive}.

  And, as \CStepB{} involved the clock working as a premise, both conditionals we considered as commitments prior to the instance of reasoning may lead to \cprequ{1} with respect to \CStepA{}.
  Restated:

  \begin{enumerate}[label=A\(^{+}\)\arabic*., ref=(A\(^{+}\)\arabic*)]
  \item
    \label{result:ex:temp:repair}
    If the clock is working, then it was repaired yesterday.
  \item
    \label{result:ex:temp:chime}
    If the clock is working, then it chimes on the hour.
  \end{enumerate}

  In both cases, the consequents of the conditionals follow from a \crequ{} of \CStepA{} --- the conclusion of the step itself.
  Hence, the consequents of both conditionals are relevant instance of \(\psi\) having value \(v'\).

  As before, it seems that (granting a natural interpretation of the agent's epistemic state), that it is not \epVAd{} for the agent to hold that the clock is working \emph{and} that the clock was not repaired yesterday, hence the consequent of \ref{result:ex:temp:repair} is plausibly a \cprequ{} of \CStepA{}.

  And, as before, by contrast it seems \epVAd{} for the agent to abandon \ref{result:ex:temp:chime} if the clock does not chime, and so the consequent of \ref{result:ex:temp:chime} it plausibly not a \cprequ{} of \CStepA{}.
\end{note}

\hozline

\begin{note}[No further interactions]
  An important observation to make is that any proposition-value pair which follows from a \cprequ{} is also a \cprequ{}.
  In short, this is because something being a \cprequ{} of some step requires the step to have introduced a novel proposition-value pair, and assessing whether some proposition-value pair is a \cprequ{} does not involve steps which may introduce novel proposition-value pairs.\nolinebreak
  \footnote{
    In more detail:

    Suppose \(\psi\) having value \(v'\) is a \cprequ{} of some step of reasoning.
    And, suppose that \(\psi_{+}\) having value \(v'_{+}\) follows from the combination of some \crequ{1} of the step, the \prequ{1} of the step. and \(\psi\) having value \(v'\) (and is distinct from any \(\chi_{i}\)).

    If so, then \(\psi_{+}\) having value \(v'_{+}\) satisfies \ref{def:cprequ:subjunctive}.
    For, if \(\psi_{+}\) were not to have value \(v'_{+}\), then \(\psi\) would not have value \(v'\).
    Hence, holding that \(\psi_{+}\) were not to have value \(v'_{+}\) would not be \epVAd{}.
  }

  Hence, the combination of \prequ{1}, \crequ{1}, and \cprequ{1} exhaust the scope of the intuitive idea of a \requ{}.
\end{note}

\paragraph{Summary}

\begin{note}
  Key thing with \requ{1} is that the proposition-value pair is important for making the step.

  This is a difficult boundary to draw.
  Only interested in things which deductively follow and are important.
  Consequence of this is that in deductive steps, any \crequ{} is also a \prequ{}.
\end{note}


\begin{note}
  \autoref{def:requsite} is how we build on \ideaCSA{} and \ideaCSB{}.
  For, the definition of a \requ{} applies to reasoning in general, claiming support is an instance of reasoning, and hence applies to instances of claiming support.
  In particular, in instances of claiming support:
  {
    \color{reword}
    Conclusion is a \requ{}, as epistemically possible that it does not hold, and non-disposable.
    Moving from sub-premises to sub-conclusions plausibly involves a \requ{}, given the epistemic possibility that a conclusion of an instance of claiming support does not hold.

    So, \ideaCSA{} for possibility.
    Dealing with \requ{1} for \ideaCSB{}.
    Indeed, \ideaCSB{} will focus on \requ{} for step, rather than reasoning in general.
  }

  Still, as \autoref{def:requsite} is quite complex, we will first work through the clauses and how they combine in some detail before providing a handful of \illu{1}.
\end{note}

\paragraph{\illu{3}}

\begin{note}
  Four \illu{1}.
  The first pair identify \requ{1}.
  Second pair concern consequences of steps of reasoning which fail to be \requ{1}.
\end{note}

\begin{note}
  \begin{illustration}
    \label{illu:requ:bank}
    `Where is the nearest bank?'
    Reason that `next to the post office' is an appropriate response.
  \end{illustration}
  However, friend is asking about where the nearest bank in the sense of financial establishment, rather than river bank.
  If appropriate disambiguation, then appealed to something that is not the case.
  Hence, that `river bank' is not the appropriate disambiguation is a \requ{}.

  Note, however, that if agent did not learn about ambiguity of `bank' then no \requ{}.
\end{note}

\begin{note}
  We will see many more examples of \requ{1} below.
  For the moment, we offer a second, abstract, instance of a \requ{} and then an instance of something which is not a \requ{}.
\end{note}

\begin{note}
  \begin{illustration}
    \label{illu:requ:import-export}
    Suppose we have some conditional `\(\rightarrow\)' that admits of import-export.\nolinebreak
    \footnote{
      For example, the material conditional, but not necessarily the natural language conditional expressed in certain `if \dots then \dots' constructions {\color{red} Vann}.
    }
    I.e.:
    \begin{quote}
      \(\phi \rightarrow (\psi \rightarrow \xi)\) if and only if \((\phi \text{ and } \psi) \rightarrow \xi\)
    \end{quote}
    And, suppose an agent's reasoning has the structure:
    \begin{enumerate}
    \item \(\phi\)
    \item \(\phi \rightarrow (\psi \rightarrow \xi)\)
    \item \(\psi \rightarrow \xi\)
    \end{enumerate}
    Such that possible \(\phi \rightarrow (\psi \rightarrow \xi)\) is not the case.
  \end{illustration}

  Here, \((\phi \text{ and } \psi) \rightarrow \xi\) is a \prequ{} of the step from 2 to 3.
  For, if \(\phi \rightarrow (\psi \rightarrow \xi)\) then also \((\phi \text{ and } \psi) \rightarrow \xi\).
  Hence, if \((\phi \text{ and } \psi) \rightarrow \xi\) is not the case, then \(\phi \rightarrow (\psi \rightarrow \xi)\) is also not the case.
\end{note}

\begin{note}
  In these two \illu{1}, something that would highlight a fault in reasoning.
  No all things that would highlight faults in reasoning are \requ{1}.
\end{note}


\begin{note}
  {
    \color{red}
    This is a \requ{}.
    Point is that should indicate that the textbook answer is the same!
    It doesn't follow that it is the same.
    But, should indicate at least.

    Or, if textbook having the wrong answer is not \epVAd{}, not a \requ{}, because not a \result{}.
    Agent doesn't need to indicate this is the case.
  }
  \begin{illustration}[Textbook answers]
    \label{illu:textbook-answers}
    Suppose an agent is working through a logic textbook with practice problems at the end of each chapter to test a student's understanding.

    For any given question, the following conditional holds with respect to the agent:
    \begin{itemize}
    \item If my answer to the problem is incorrect, then I {\color{red} appealed to something that is not the case or moved to something that is not the case}.
    \end{itemize}
  \end{illustration}
  Possible that the agent {\color{red} appealed to something that is not the case or moved to something that is not the case}.

  The proposition of interest here is:
  \begin{itemize}
  \item My answer is not incorrect.
  \item Or, the textbook has the same answer.
  \end{itemize}

  Not a \requ{} of any intermediate step of reasoning, as these don't get the answer.
  Not a \requ{} of final step, because there's no plausible consequence relation.
  Making the step doesn't imply anything about the textbook.

  Similarly, for if the textbook has not made a mistake, then same answer.

  Because, although it something not being the case would ensure the step of reasoning is bad, it does not follow that by making the step of reasoning, it is a consequence that there is no mistake.

  Key point is that a \requ{} follows from some part of the agent's reasoning, not from things that would hold if the agent's reasoning is successful.
\end{note}

\subsubsection{Being \mistaken{} or \misled{}}

\begin{note}
  \begin{restatable}[\mistaken{0} and \misled{}]{definition}{defMoM}\label{def:MoM}
    Some reasoning such that reasoning culminates with \(\phi\) having value \(v\).
    \begin{itemize}
      \item The reasoning is \emph{\mistaken{}} if \(\psi\) having value \(v'\) is a \prequ{} and \(\psi\) does not have value \(v'\).
    \item The reasoning is \emph{\misled{}} if \(\psi\) having value \(v'\) is either a \crequ{} or a \cprequ{} and \(\psi\) does not have value \(v'\).
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}

  Generalise to reasoning.
  \mom{} just in case there exists some step that is \mom{}, respectively.
\end{note}

\begin{note}[M\&M \illu{2}]
  To illustrate:

  \begin{illustration}[Clock]
    \label{illu:mom:clock}
    Suppose I glance at the clock on the wall.
    The clock reads 11:45a, so I reason that it is 11:45a.
  \end{illustration}

  Two possibilities:
  \begin{enumerate}
  \item Clock is not functioning.
  \item Clock is incorrectly set.
  \end{enumerate}

  If not functioning.
  By claiming support from the time expressed by the clock, I would have been \emph{\misled{}} about what the time actually is.
  For, not functioning.
  However, not necessarily \mistaken{}.
  For, might be that the time is 11:45a.

  If incorrectly set.
  By claiming support from the time expressed by the clock, I would have been \emph{\mistaken{}} about what the time actually is.

  However, not necessarily \misled{}.
  For, claimed support by appeal to a functioning clock.
  Though, despite the clock being broken, it is 11:45a and so the claim to support is not misleading.

  Combining, claimed support for the time from a broken clock expressing the wrong time would be both \misled{} \emph{and} \mistaken{}.\nolinebreak
  \footnote{
    A second \illu{0}:
    Consider a smoke detector, designed to sound an alarm if and only if sufficient levels of smoke are detected.
    Hence, if the alarm sounds, one may claim support there being smoke in the room where the alarm is installed.
    One may be misled; the alarm may have malfunctioned, so no fire.
    Or, one may be mistaken; the same type of alarm may be installed in a different room, wouldn't be a useful indicator.
  }

  {
    \color{red}
    Of course, clocks are typically glanced at, and a glance at a clock is often insufficient to determine whether the clock is incorrectly set or broken.
    Hence, the \emph{possibility} that a clock is incorrectly set or broken --- or more broadly the possibility that claimed support is misleading or mistaken --- does not prevent an agent from claiming support.
    So, ensuring that to-be-claimed support would be \mom{} is not a necessary condition for claiming support.
  }
\end{note}

\paragraph{Summary}

\begin{note}
  Not the case that any thing that is appealed to is a \requ{}.
  For, may add in certain additional things.
  In other words, careful to make sure that the subjunctive part is there.
\end{note}

\begin{note}
  Really important here is that being a \requ{} does not imply that the reasoning involves direct appeal.
  {
    \color{red}
    Indeed, this distinguishes from \citeauthor{Sgaravatti:2013wu}, which requires belief in each of premises.
  }
\end{note}

\subsubsection{The assumption}
\label{sec:two-assumpt-relat-to-requ}

\begin{note}
  Now turn to \ideaCSB{}.
\end{note}

\begin{note}
  \begin{restatable}[\eiS{0} --- \eiS{}]{assumption}{assuCSRReq}
    \label{assu:supp:independence}
    Let \vAgent{} be an agent and suppose that:
    \begin{enumerate}[label=\Alph*., ref=(\Alph*)]
    \item
      \label{assu:supp:ind:step}
      \(\psi\) having value \(v'\) is a \requ{} of some step \(\delta\) of some instance of reasoning that concludes with \(\phi\) having value \(v\).
    \end{enumerate}

    The instance of reasoning that concludes with \(\phi\) having value \(v\) is an instance of claiming support \emph{only if}:

    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item
      \label{assu:supp:ind:indicate}
      \vAgent{} may --- prior to making \(\delta\) --- may witness some reasoning which \indicateV{1} that \(\psi\) has value \(v'\).
    \end{enumerate}
    And:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*),resume]
    \item
      \label{assu:supp:ind:circular}
      If \(\delta\) is a non-deductive step then:
      \begin{enumerate}[label=\alph*., ref=(\alph*)]
      \item
        \label{assu:supp:ind:circular:p}
        If \(\psi\) having value \(v'\) is a \prequ{} of \(\delta\) then:
        \begin{itemize}
        \item
          The reasoning of \ref{assu:supp:ind:indicate} does not involve appeal to a proposition-value pair that is only obtained from conclusion of \(\delta\).
        \end{itemize}
      \item
        \label{assu:supp:ind:circular:cp}
        If \(\psi\) having value \(v'\) is  a \cprequ{} of \(\delta\) then:
        \begin{itemize}
        \item
          The reasoning of \ref{assu:supp:ind:indicate} does not involve appeal to a proposition-value pair that is only obtained from the step of reasoning and \crequ{1} which leads to \(\psi\) having value \(v'\) being a \prequ{}.
        \end{itemize}
      \end{enumerate}
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  \autoref{assu:supp:independence} consists of two clauses, where the first clause requires the existence of some reasoning, and the second clause places constraints on that reasoning if a certain condition holds.

  So, to capture the intuition behind \autoref{assu:supp:independence}, let us focus on \ref{assu:supp:ind:indicate} which requires past or present reasoning about any \requ{} of the instance of reasoning.
  We will then turn to \ref{assu:supp:ind:circular} to clarify why restrictions are placed on the reasoning about certain \requ{1} with the core intuition in hand.
\end{note}

\paragraph{Clause 1}

\begin{note}
  If \(\psi\) having value \(v'\) is a \requ{} of some step \(\delta\), then three important things follow:
  \begin{itemize}
  \item \(\psi\) not having value \(v'\) is an \ep{} for the agent, \emph{and}
  \item If \(\psi\) does not have value \(v'\), the step would involve some premise or conclusion having some other value.
  \item \(\psi\) having value \(v'\) is important not only for the agent making the step, but also for the instance of reasoning as a whole.
  \end{itemize}

  In other words, if \(\psi\) were not to have value \(v'\), then not only the step of reasoning, but the instance of reasoning as whole would be undercut as the agent would appeal to proposition-value pair which is not the case.
  

  Hence, if the agent has not previously engaged in reasoning that indicates that \(\psi\) has value \(v'\), or does not engage in reasoning that indicates that \(\psi\) has value \(v'\) as part of the present reasoning, then the reasoning that the agent has performed does not indicate that \(\phi\) has value \(v\) regardless of whether \dots

  \emph{because} if it is the case that \(\psi\) does not have value \(v'\), then

  and, nothing that indicates that this is not the case.
\end{note}

\begin{note}
  \begin{enumerate}
  \item If clock is working, then it was repaired yesterday.
  \end{enumerate}
  So, without this being the case, time from a broken clock.

  \begin{enumerate}
  \item If may call a meeting, then bad time.
  \end{enumerate}

  If bank is disambiguated differently, then no an answer to the question.

  If conditional doesn't hold, then \mistaken{}.

  If textbook answer is different, then something.
\end{note}

\begin{note}
  Due to being a \requ{}, important for the step of reasoning that proposition-value pair is such.


  The agent's reasoning does not indicate that the relevant conclusion holds regardless of whether premises and conclusion have respective values, because there is some proposition-value pair that the agent's reasoning require to being the case.

  It is the case that if proposition-value pair holds, then indicates.
  However, does not indicate \emph{regardless}.
\end{note}

\subparagraph{???}

\begin{note}
  {
    \color{red}
    (Where 2 is motivated by possibility that it doesn't hold. If only with consequence, then only when does hold.)
  }

    Reasoning about how the considerations the agent has cited indicate \(\phi\) even when \requ{} does not have value.

    So, any \requ{}, compatible with that being false.
    Recognise the possibility, claiming support is limited in that way.
    However, that possibility alone does not prevent appeal to the premise.

    There is a subtly.
    Agent may grant that the conclusion would not be the case.
    That's not the worry.
    Instead, the worry is whether appealing to the premise is fine.

    Perhaps Moore's proof is useful here.
    It is true that no external world is possibility.
    However, this doesn't prevent me from appealing to perception of two hands.
    Would need that this is only okay if I actually have two hands.
    But, this is far too much.

  \autoref{assu:supp:independence} expresses a necessary condition from \ideaCSB{}.
  The basic idea is that a \requ{} has the possibility to highlight a fault in agent's reasoning.
  So, if an agent has failed to reason about whether a \requ{} has {\color{red} value}, then the agent's reasoning fails to indicate that \(\phi\) has value \(v\) regardless of whether {\color{red} some problem with premise or conclusion}.
  {\color{red} In particular, with the \requ{} not having value.}

  \autoref{assu:supp:independence} does not include any particular constraint on what the reasoning about a \requ{} amounts to {\color{red} other than \requ{} not having value.}
\end{note}

\subparagraph{Reasoning}

\begin{note}
  Before turning to the details of \autoref{assu:supp:independence}, an immediate clarification is in order:
  \ref{assu:supp:ind:indicate} requires that the agent does or has reasoned about any \requ{1} of the relevant instance of reasoning.
  However, we do not require the relevant reasoning to be explicitly recognised by the agent.
  Holding that some instance of reasoning is an instance of claiming support is the attribution of a property to some activity of the agent.
  However, it is a property of interest from our perspective as observers of the agent, and from this is does not follow that the agent needs to reflexively recognise that their reasoning is an instance of claiming support.

  Of course, an agent may recognise that their reasoning would not satisfy \autoref{assu:supp:independence} and explicitly reason about a \requ{1} in light of such a recognition.
  However, the observation that an agent may adjust their reasoning in order to ensure that they do not fail to satisfy \autoref{assu:supp:independence} does not, in turn, require that it must always be possible for the agent to recognise that their reasoning does \autoref{assu:supp:independence}, nor that the recognition of such satisfaction is itself important for claiming support.
\end{note}

\begin{note}
  First, in case of \requ{} being the conclusion of the subinstance of reasoning, there is nothing to say that the premises appealed to aren't doing the work.
  Remember X, so X.
  Well, not X.
  However, saw X.
  That's all that's needed to indicate X.

  There is no suggestion in the definition of a \requ{} or in the assumption that the premises appealed to are not sufficient.
  Likewise for other \requ{}.

  Remember a dalmation with a red collar?
  Yes.
  Oh, then you remember spotty(???)
  Yes.
  Same X here, but now it's not the conclusion of the instance of claiming support.

  There is nothing about the definition or assumption that suggests there is any problem here.
\end{note}

\paragraph{The second clause}


\begin{note}
  {
    \color{red}
    I need separate clauses here because, there's nothing clearly wrong with taking some result of the step of inference that doesn't lead to the feedback.
    At issue is not the step itself, but the step paired with some result of the step.
  }

  {
    \color{red}
    Key observation here is that in the deductive case, the premises alone are sufficient to get the conclusion, so they will also be good to get anything else which deductively follows.
    The agent doesn't introduce anything new.
    So, the non-deductive qualification makes sense.
  }


  Intuitively\dots refined \ideaCSB{} with the idea of a \requ{}.
  And, necessary conditions given certain types of \requ{}.
\end{note}

\begin{note}
  One may question whether the agent needs to reason about \crequ{1}.
  For, while {\color{red} XXX} does not constrain how the agent reasons, still some reasoning.

  The observation is simple.
  If no reasoning, then possible that agent would retract step in recognition of conclusion.
  This is a point observed by \citeauthor{Harman:1973ww}.

  In other words, reasoning about \crequ{} ensures that the step of reasoning, and hence the instance of reasoning is `stable' with respect to the agent's present epistemic state.
\end{note}

\hozline

\begin{note}
  Still, circularity in general is a bit of an issue.

  Rules out some cases of reasoning.
  Claiming support for memory, some like circular reasoning.

  One limitation is that memory is not clearly a \requ{}.
  In appeal to memory, supposing that memory is not correct does not establish that moving from something false or to something false.
  My memory is quite bad, but I remember X.
  Still leaves specific memory, but that's a different issue.
\end{note}


\paragraph{Other observations}

\begin{note}
  Various ways in which assumption is limited.
\end{note}

\begin{note}
  Claiming support?
\end{note}

\begin{note}
  Second, epistemic plausibility.
  Narrower than mere possibility.
  This is, of course, difficult.
\end{note}

\begin{note}
  Third, basic appeal.

  Pryor.\nolinebreak
  \footnote{
    Ried is a different issue.
  }
  \autoref{assu:supp:independence} does not rule this out.
  For, no limitations placed on what reasoning for \requ{} is.
\end{note}

\begin{note}
  You don't need to agree with these.
  Epistemic possibility and memory does introduce a \requ{} for general reliability, so there is an issue for claiming support without reasoning which indicates.
  The point is that for present purposes we do not need to, nor shall we, assume such a strong variant of \autoref{assu:supp:independence}.
\end{note}

\begin{note}[Strengthen?]
  Of course, one may wish to strengthen this necessary condition by specifying additional constraints on what is involved in reasoning about a \requ{}.

  For example, suppose \(\psi\) having value \(v'\) is a \requ{} of reasoning that concludes with \(\phi\) has value \(v\).
  If the reasoning that concludes with \(\phi\) having \(v\) is an instance of claiming support, then it seems reasoning that amounts to it being nice if \(\psi\) has value \(v'\), or that it is not obvious that \(\psi\) does not have value \(v'\) seems inadequate.

  In short, while \autoref{assu:supp:independence} may be a necessary condition, it does not seem the strongest necessary condition of its kind.

  Still, for our purposes \autoref{assu:supp:independence} will be sufficient.
  Either the lack of reasoning, or that it is not possible to do the required reasoning --- though not necessarily not possible in general (\nI{} for details).
\end{note}

\begin{note}[`Unrecognised' \requ{1}]
  Above, strength.
  Worry that reasoning is too weak
  A few other ways.

  `Unrecognised' \requ{1}.
  Definition of a \requ{} requires that conditions hold from perspective of an agent.
  Possible that there are `unrecognised' \requ{1}.
  And, expand~\autoref{assu:supp:independence} to cover these.

  Or, alternatively have some requirement concerning a search for \requ{1}.

  Former is weaker than the latter, but both extend beyond the agent's perspective.
  Inclined to think that some suggestion along these lines is plausible with respect to \ideaCSB{}.
  However, avoid building in assumptions that are not required.

  This is not, however, to grant arbitrary strengthening.
  Core argument is that one possible strengthening does \emph{not} hold. (\ESU{}).
\end{note}

\begin{note}
  \eiS{} does not deny that things may need to be a certain way for an agent to claim, or to be in a position to, claim support.
  It may be the case that no agent would be in a position to claim support that the speed of light is constant if the speed of light were not constant.
  Still, in claiming support an agent must expect that possible defeaters do not obtain, e.g.\ that the laws of nature are constant, and that no mistakes have been made when observing relevant phenomena.
\end{note}

\begin{note}
  A final worry, about reasoning that is non-linear.
  However, set this aside.
  Appeal is enough to avoid this, maybe.
  And, doesn't prevent agent from considering how proposition-value pairs would work.
  Nor does it prevent the agent from appealing to proposition-value pairs that do follow from the step of reasoning, but also follow from some prior reasoning.
\end{note}

\hozline

\paragraph{Meta-proposition-value pairs}

\subparagraph*{Meta-proposition-value pairs: Steps of reasoning}

\begin{note}
  Meta-proposition-value pairs are a distinct concern.
  For, though it may be that reasoning about some proposition-value pair applies to any meta-proposition-value pair concerning that source proposition-value pair, it is not clear that any combination of reasoning about the premises or conclusions of a step of reasoning will apply to the step of reasoning itself.
\end{note}

\begin{note}
  The important observation with respect to \requ{1} is that they are defined in terms of \result{1}, and hence for a meta-proposition-value pairs about a step of reasoning to be of concern, it may not reduce to issues concerning the \requ{1} of the step.

  For example, consider the following proposition-value pair.
  \begin{itemize}
  \item By making this step of reasoning I am not appealing to a proposition-value pair that is not the case.
  \end{itemize}
  As the proposition-value pair reduces to a question of whether the agent is appealing to proposition-value pairs that the agent is appealing to when making the step of reasoning, the combined reasoning about those proposition-value pairs may apply to the meta-proposition-value pair.
\end{note}

\begin{note}
  Hence, for the meta-proposition-value pair to be of interest as an objection, it must concern the step itself.
  For example.
  \begin{itemize}
  \item This step of reasoning is a \(\{\text{good},\text{suitable},\text{rational},\dots\}\) step of reasoning.
  \end{itemize}
  The relevant adjective is unimportant.
  Rather, the idea is that whatever the adjective is, it does not reduce to the proposition-value pairs appealed to in making the step.

  However, any meta-proposition-value pair of this kind will fail to be a \requ{1} of the step of reasoning \emph{because} it does reduce to issues concerning the \requ{1} of the step.
\end{note}

\begin{note}
  \color{red}
  Leaves open the possibility that you may hold the agent needs to have some reasoning to indicate the relevant proposition.
  However, this does not follow from the assumptions made.
  Therefore, we may take a neutral stance on such propositions.
\end{note}

\subparagraph*{Summary of meta-proposition-value pairs}

\begin{note}
  To summarise, if a meta-proposition-value pair follows from a \requ{0} of reasoning, then while it may be the case that the meta-proposition-value is also a \requ{0} of reasoning, the reasoning about the source-\requ{0} may be taken to apply to the meta-proposition-value.
  Hence, \autoref{assu:supp:independence} does not require that an agent explicitly reasons about such meta-proposition-value pairs.

  And, conversely, if a meta-proposition-value pair does not follow from a \requ{0} of reasoning, then \autoref{assu:supp:independence} does not require that an agent reasons about such meta-proposition-value pairs, neither explicitly nor implicitly.
\end{note}


\subsubsection{Proposition}
\label{sec:proposition}

\begin{note}
  Following is an immediate consequence of \ref{assu:supp:nfactive} and \autoref{assu:supp:independence}:

  \begin{restatable}[Reason about recognised \requ{1}]{proposition}{propRecogniseDefeaters}
    \label{prop:CS-only-if-reason-recognised-defeaters}
    \requ{}, and:
    For any such recognised \requ{} at time of reasoning and does not reason, not an instance of claiming support.
  \end{restatable}
\end{note}

  \begin{note}
  \begin{itemize}
  \item If result of reasoning to \(\phi\) having value \(v\) is such that agent considers that reasoning fails if \(\phi\) does not have value \(v\), then reasoning is not an instance of claiming support.
  \item Not possible that instance of reasoning to \(\phi\) having value \(v\) is claimed support only if \(\phi\) has value \(v\).
  \item Claimed support for \(\phi\) having value \(v\) never requires that \(\phi\) has value \(v\).
  \end{itemize}
\end{note}

\begin{note}
  \color{red}
    \begin{itemize}
    \item Always possibility of \mom{} from \nfcs{}.
    \item This means that the agent has no guarantee that \(\phi\) has value \(v\) --- or better put the agent considers it to be an (epistemic) possibility that their claimed support is \mom{}.
    \item However, if the agent requires that \(\phi\) is the case, then there is no possibility of the claimed support being \emph{mistaken}.
    \item Well, no reasoning against being mistaken with respect to claimed support for this \requ{}.
  \end{itemize}

  Again, it does not seem impossible for an agent to adopt an attitude that recognises the possibility but assumes regardless.
\end{note}

\begin{note}
  Important consequence of \autoref{sec:basic-assumptions:props-and-vals}, block:

  S did not reason about possibility that Q is false.
  If Q is false, then P must also be false.
  Hence, P may be false.
  S did not reason about the possibility that P is false.

  \begin{note}
  Examples:
  \begin{itemize}
  \item Possibility that the trains are on strike.
  \item No Indication of strike, so do not consider live possibility.
  \item Read newspaper.
  \item Newspaper reported strike.
  \item Consequence of possibility is that the newspaper misreported.
  \item Reasoning does not extend to newspaper.
  \end{itemize}

  \begin{itemize}
  \item Out of milk.
  \item Then come to hold that there is milk in the fridge.
  \item Hallucinating.
  \item Does not extend.
  \end{itemize}

  \begin{itemize}
  \item Turing machine reduction.
  \item If possible then also possible.
  \item So, give up.
  \end{itemize}
\end{note}
\end{note}


\subsection{Persistence}
\label{sec:persistence}

\begin{note}
  \autoref{assu:supp:nfactive} and \autoref{assu:supp:independence} are about the activity of claiming support.
  Key thing is a \requ{}.

  However, nothing about the role of claimed support in reasoning.
  Seems plausible that appeal to claimed support.
  And, many cases will concern appeal to claimed support.
  Hence, make this explicit.
\end{note}

\begin{note}[Assumption]
  \begin{restatable}[Claimed support persists]{assumption}{assuCSPersists}
    \label{assu:CS-persists}
    In case of claiming support for \(\phi\) having value \(v\) such that \(\psi\) having value \(v'\) is a \requ{}, then appeal to previously claimed support for \(\psi\) having value \(v'\) is sufficient for reasoning about \(\psi\) having value \(v'\).
  \end{restatable}
\end{note}

\begin{note}[Intuition]
  The content of \autoref{assu:CS-persists} is clearest when viewed from the perspective of the constraints \autoref{assu:supp:independence} places on claiming support:

  Suppose \(\psi\) having value \(v'\) is a \requ{} of claiming support for \(\phi\) having value \(v\) then by \autoref{assu:supp:independence}, the agent must reason about whether \(\psi\) has value \(v'\).
  Still, by definition \(\psi\) has value \(v'\) is a \requ{} of claiming support for \(\psi\) has value \(v'\).
  Therefore, as the agent has claimed support for \(\psi\) having value \(v'\), the agent has reasoned about whether \(\psi\) has value \(v'\).
  And, in some cases an agent reasoning that they have reasoned about whether \(\psi\) has value \(v'\) is sufficient satisfy the constraint of \autoref{assu:supp:independence} that an agent reasons about \requ{1}.
  Hence, appeal to previously claimed support for \(\psi\) having value \(v'\) involves reasoning that the agent has reasoned about whether \(\psi\) has value \(v'\).
\end{note}

\begin{note}
  For example, consider the following reasoning:

  \begin{enumerate}
  \item If \(\psi\) has value \(v'\), then \(\phi\) has value \(v\).
  \item \(\psi\) has value \(v'\).
  \item So, \(\phi\) has value \(v\).
  \end{enumerate}

  \(\psi\) has value \(v'\) is a \requ{}.

  \begin{enumerate}
  \item I have claimed support for \(\psi\) having value \(v'\).
  \end{enumerate}

  Natural expression:

  \begin{enumerate}
  \item If \(\psi\) has value \(v'\), then \(\phi\) has value \(v\).
  \item I have claimed support for \(\psi\) having value \(v'\).
  \item \(\psi\) has value \(v'\)
  \item So, \(\phi\) has value \(v\).
  \end{enumerate}

  However, this formulation suggests.
  \(\psi\) has value \(v'\) from claimed support for \(\psi\) having value \(v'\).
  Strictly, this need not be the case.
  Most, if not all, \illu{1} will have this form.
  However, important is dealing with \requ{}, and not how agent gets to \(\psi\) having value \(v'\).
\end{note}

\begin{note}
  Intuitively, previous reasoning was good, so don't need to go through the details again.
  Note, this does not guarantee that appeal will be successful.

  Following section deals in part with this issue.
\end{note}

\begin{note}
  Strictly speaking, however, \autoref{assu:CS-persists} and following are not required.
  As we will see, restriction is new `defeaters'.
  If \autoref{assu:CS-persists} does not hold, then reasoning about these.
  However, \autoref{assu:CS-persists} is plausible.
  Hence, additional assumptions.
\end{note}



\section{\illu{3}}
\label{sec:CS:illustrations}

\begin{note}
  Collection of assumptions, expanding on two ideas, and propositions building on these.
  Work through how these assumptions combine in some cases.
  Also drawing out intuition.

  To start, familiar case, distinguish from circularity and related idea.
  Then, looking at \autoref{prop:CS-only-if-reason-recognised-defeaters}.
  Pair of simple \illu{1}.
  Then, final \illu{0} to highlight intuition and draw out some tension.
  After these, corollary of \autoref{prop:CS-only-if-reason-recognised-defeaters} which summarises, some discussion, and an idea.
\end{note}


\subsection{\illu{3} with respect to assumptions}
\label{sec:illustrations-wrt-assumption}

\begin{note}
  Previous section.
  \ideaCSA{} and \ideaCSB{}.
  Motivation for assumptions, and effort to clarify in contrast to other intuitions.
  Fell short of an account of the intuition.

  \autoref{assu:supp:nfactive}, \autoref{assu:supp:independence}.
  And, from these \autoref{prop:CS-only-if-reason-recognised-defeaters}.

  Key here is lack of reasoning.
  This allows for the possibility that some variant instance of reasoning would succeed in claiming support.
  Indeed, we will suggest.
\end{note}

\begin{note}
  Two short, then one in some detail.
\end{note}



\subsubsection{A trip to the zoo}

\begin{note}
  \illu{3} \ref{illu:CS:spot-the-diff} and \ref{illu:CS:wheres-wally} looked at reasoning and \requ{1}.
  Final \illu{0} is no different, structurally similar to \autoref{illu:CS:wheres-wally}.
  However, surrounding discussion to clarify details.

  After discussion, a corollary and a conjecture.
\end{note}

\begin{note}
  Zebra.

  Dretske is about knowledge.
  Problem for knowledge as factive.

  Still, don't need factive move.
  Possible not zebra, but vision is sufficient to expect that such a possibility does not obtain.

  Key here is that claiming support is never going to be strong enough to establish knowledge, at least to the extent that knowledge is factive.
\end{note}

\begin{note}
  \begin{illustration}[A trip to the zoo]
    \label{illu:CS:dretske-zebra}
    \mbox{}
    \vspace{-\baselineskip}
  \begin{quote}
    You take your son to the zoo, see several zebras, and, when questioned by your son, tell him they are zebras.
    Do you know they are zebras?
    Well, most of us would have little hesitation in saying that we did know this.
    We know what zebras look like, and, besides, this is the city zoo and the animals are in a pen clearly marked ``Zebras.''
    Yet, something's being a zebra implies that it is not a mule and, in particular, not a mule cleverly disguised by the zoo authorities to look like a zebra.
    Do you know that these animals are not mules cleverly disguised by the zoo authorities to look like zebras?

    \mbox{ }\hfill \(\vdots\) \hfill\mbox{ }

    Did you examine the animals closely enough to detect such a fraud?\linebreak
    \mbox{}\hfill\mbox{(\citeyear[1015--1016]{Dretske:1970to})}
  \end{quote}
  \vspace{-\baselineskip}
  \end{illustration}
\end{note}

\begin{note}
  \citeauthor{Dretske:1970to}'s presentation focuses on knowledge, so let us briefly form a parallel with respect to claiming support:

  \begin{illustration}
    \label{illu:dretske-zebra-var}
    \mbox{}
    `What if those animals are mules cleverly disguised by the zoo authorities to look like zebras?'
    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:wheres-wally}.\arabic*)]
      \setcounter{enumi}{-1}
    \item If zebra, then not cleverly disguised mule.
    \end{enumerate}
    Reasons as follows:
    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:wheres-wally}.\arabic*)]
    \item That animal appears to be a zebra.
    \item That animal is a zebra.
    \item That animal is not a cleverly disguised mule.
    \end{enumerate}
  \end{illustration}

  As with \illu{3}~\ref{illu:CS:spot-the-diff} and~\ref{illu:CS:wheres-wally}, no reasoning about the possibility that the animal is a cleverly disguised mule.
  However, given conditional, \requ{} when moving from appearance to animal.

  Introduction of additional consequence, so same structure as~\autoref{illu:CS:wheres-wally}.
  And, plausible that the agent may reason about the possibility that the animal is a cleverly disguised mule in a way sufficient to claim support.\nolinebreak
  \footnote{
    \citeauthor{Dretske:1970to} has a number of suggestions.
    \begin{quote}
    You have some general uniformities on which you rely, regularities to which you give expression by such remarks as, ``That isn't very likely'' or ``Why should the zoo authorities do that?''
    Granted, the hypothesis (if we may call it that) is not very plausible, given what we know about people and zoos.
    But the question here is not whether this alternative is plausible, not whether it is more or less plausible than that there are real zebras in the pen, but whether you know that this alternative hypothesis is false.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[1016]{Dretske:1970to})}
  \end{quote}
  }
\end{note}

\begin{note}
  if think that doesn't know, then not too much of an issue.
  However, does know?
  Indeed, \citeauthor{Dretske:1970to}.

  No clear tension.
  Knowledge and claiming support, different.

  However, problem identified.
\end{note}

\begin{note}
  \begin{enumerate}[label=K\Alph*., ref=K\Alph*]
  \item\label{Dretske:No-C:cond:no-k-then-ep} If an agent does not know that \(\phi\) is true, then \(\phi\) being false is an epistemic possibility for that agent.
  \item\label{Dretske:No-C:cond:ep-then-no-k} If \(\phi\) being false is an epistemic possibility for some agent, then that agent does not know that \(\phi\) is true.
  \end{enumerate}
  When taken together, (\ref{Dretske:No-C:cond:no-k-then-ep}) and (\ref{Dretske:No-C:cond:ep-then-no-k}) state that: An agent knows that \(\phi\) is true if and only if \(\phi\) being false is not an epistemic possibility for the agent.
  Still, our interest will primarily be with (\ref{Dretske:No-C:cond:ep-then-no-k}).\nolinebreak
  \footnote{
    \label{fn:factivity-two-readings}
    Contrast to `factivity':
    \begin{itemize}
    \item If \(S\) knows that \(\phi\), then \(\phi\).
    \end{itemize}
    This may be read in at least two different ways.
    \begin{itemize}
    \item First, relation between epistemic state of the agent and actual \world{}:\newline
      \mbox{} \qquad If \(S\) knows that \(\phi\), then the \world{} is such that \(\phi\) is the case.
    \item Second, how things appear from epistemic state:\newline
      \mbox{} \qquad If \(S\) knows that \(\phi\) then every way the \world{} may be for \(S\) includes \(\phi\).
    \end{itemize}

    The two reading are independent of one another.

    For example, suppose you walked to the shop but the only epistemic possibility entertained by your friend is that you drove to the shop.
    Here, it is not possible for your friend to know that you drove to the shop on the first reading of factivity, but the second reading is not ruled out.

    Conversely, suppose it is the case that you walked to the shop but your friend considers it epistemically possibly that you drove.
    Here, knowing on the second reading of factivity is ruled out, but the first reading is not ruled out.

    Of course, you may endorse both readings of factivity.
    Our focus is on the `weaker' reading as we have made no connexion between claiming support and the state of the word.
    (Perhaps it is of some interest to note that \citeauthor{Dretske:1970to} explicitly denies the second reading, but not the first.)
  }\(^{,}\)\nolinebreak
  \footnote{
    The dogmatism paradox (\cite[39,43--45]{Kripke:2011wv};\cite[148]{Harman:1973ww}) seems to concern the second reading of factivity from~\autoref{fn:factivity-two-readings}, and intuitions concerning evidence.

  Roughly stated, the paradox pairs the following two propositions:
  \begin{enumerate}[label=D\arabic*., ref=(D\arabic*)]
  \item\label{dog:1} If an agent is aware that they know that \(\phi\), then the agent may disregard any evidence against \(\phi\).
  \item\label{dog:2} Rational agents respect their evidence
    (\cite[Cf.][\S2]{Kelly:2016wk})
  \end{enumerate}
  Given~\ref{dog:2}, it seems no agent should not disregard any instance of evidence, even if the antecedent of~\ref{dog:1} is satisfied.

  And, it seems \ref{dog:1} is motivated by factivity.
  For, if the agent is aware that they know that \(\phi\) then the agent knows that \(\phi\).
  And, as knowledge is factive it follows (by second reading) that \(\phi\) is the case.
  In turn, if it is the case that \(\phi\) then any evidence against \(\phi\) is evidence for something that is not the case.
  Hence, the agent may disregard any evidence against \(\phi\).


  Indeed, the second reading of factivity seems required.
  For, it seems an agent is only (apparently) in a position disregard any evidence against \(\phi\) because there knowledge that \(\phi\) guarantees that \(\phi\) is the case.
  If \emph{not}-\(\phi\) is (merely) an epistemic impossibility, and it is not clear why evidence may require an agent to revise what they consider possible.

  Note:
  Neither \citeauthor{Kripke:2011wv} (nor \citeauthor{Harman:1973ww}) make explicit mention of the agent being aware that they know \(\phi\) when formulating the Dogmatism paradox.
      Still, the paradox is clearer with this stated, as it's require addition work to find issue with a permission (to disregard evidence) if an agent is not aware that they have such a permission.

      More generally, I agree with \citeauthor{Zhaoqing:2015vj}'s (\Citeyear{Zhaoqing:2015vj}) proposal to understand the paradox in terms of knowledge attribution rather than of knowledge proper.
  }
  \citeauthor{Dretske:1970to} observes that endorsing (\ref{Dretske:No-C:cond:no-k-then-ep}) and (\ref{Dretske:No-C:cond:ep-then-no-k}) leads to closure.
  The following is a reconstruction.\nolinebreak
  \footnote{
    Specifically, the following passage:
    \begin{quote}
      A slightly more elaborate form of the same argument goes like this:
      If \(S\) does not know whether or not \(Q\) is true, then for all he knows it might be false.
      If \(Q\) is false, however, then \(P\) must also be false.
      Hence, for all \(S\) knows, \(P\) may be false.
      Therefore, \(S\) does not know that \(P\) is true.\nolinebreak
      \mbox{}\hfill\mbox{(\citeyear[1011]{Dretske:1970to})}
    \end{quote}
    Note: (\ref{Dretske:No-C:cond:no-k-then-ep}) is a reformulation of the first conditional of the passage, while a formulation (\ref{Dretske:No-C:cond:ep-then-no-k}) seems required to move from `\(P\) may be false' to `\(S\) does not know that \(P\) is true'.
  }
\end{note}

\begin{note}[Closure argument]
  Let \(S\) be some agent and suppose:
  \begin{enumerate}[label=\arabic*., ref=\arabic*]
  \item\label{Dretske:No-C:k-entail} \(S\) knows that \(\phi\) entails \(\psi\).
  \item\label{Dretske:No-C:dunno-psi} \(S\) does not know that \(\psi\) is true.
  \end{enumerate}
  Consider the following argument:
  \begin{enumerate}[label=\arabic*., ref=\arabic*,resume]
  \item\label{Dretske:No-C:ep-not-psi} \(\psi\) being false is an epistemic possibility for \(S\).%
    \hfill (\ref{Dretske:No-C:cond:no-k-then-ep} \& \ref{Dretske:No-C:dunno-psi})
  \item\label{Dretske:No-C:no-ep-no-entail} \(\phi\) not entailing \(\psi\) is not an epistemic possibility for \(S\)%
    \hfill (\ref{Dretske:No-C:cond:ep-then-no-k} \& \ref{Dretske:No-C:k-entail})
  \item\label{Dretske:No-C:ep-not-psi-and-phi}  \(\phi\) being true while \(\psi\) is false is not an epistemic possibility for \(S\).%
    \hfill (\ref{Dretske:No-C:no-ep-no-entail})
  \item\label{Dretske:No-C:ep-not-phi} \(\phi\) may be false.%
    \hfill (\ref{Dretske:No-C:ep-not-psi} \& \ref{Dretske:No-C:ep-not-psi-and-phi})
  \item\label{Dretske:No-C:not-k-phi} \(S\) does not know that \(\phi\) is true.%
    \hfill (\ref{Dretske:No-C:cond:ep-then-no-k} \& \ref{Dretske:No-C:ep-not-phi})
  \end{enumerate}

  Hence, we have shown that, given (\ref{Dretske:No-C:cond:no-k-then-ep}) and (\ref{Dretske:No-C:cond:ep-then-no-k}), (\ref{Dretske:No-C:k-entail}) and (\ref{Dretske:No-C:dunno-psi}) imply (\ref{Dretske:No-C:not-k-phi}).

  That is to say, we have shown:
  \begin{enumerate}[label=K\Alph*., ref=(K\Alph*)]
    \setcounter{enumi}{2}
  \item\label{K:closure:from-arg} If \(S\) knows that \(\phi\) entails \(\psi\) and \(S\) does not know that \(\psi\) is true, then \(S\) does not know that \(\phi\) is true.%
    \mbox{} \hfill \((K_{S}(\phi \rightarrow \psi) \land \lnot K_{S}\psi) \rightarrow \lnot K_{S}\phi\)
  \end{enumerate}
  And rewriting:\nolinebreak
  \footnote{
    \((\phi \land \lnot\psi) \rightarrow \lnot\xi\) iff \(\phi \rightarrow (\lnot\psi \rightarrow \lnot\xi)\) iff \(\phi \rightarrow (\xi \rightarrow \psi)\).
  }
  \begin{enumerate}[label=K\Alph*\('\)., ref=(K\Alph*\('\))]
    \setcounter{enumi}{2}
  \item\label{K:closure:standard} If \(S\) knows that \(\phi\) entails \(\psi\), then if \(S\) knows that \(\phi\) is true then \(S\) knows that \(\psi\) is true.%
    \mbox{} \hfill \(K_{S}(\phi \rightarrow \psi) \rightarrow (K_{S}\phi \rightarrow K_{S}\psi)\)
  \end{enumerate}
\end{note}

\begin{note}
  Return to \autoref{illu:CS:dretske-zebra}.

  Let us assume you know that:
  \begin{itemize}
  \item If the animals are zebras then the animals are not cleverly disguised mules. And,
  \item The animals are zebras.
  \end{itemize}

  If \ref{K:closure:standard} holds, then you also know that the animals are not cleverly disguised mules.
  However, following \citeauthor{Dretske:1970to}'s intuition, you do not know that the animals are cleverly disguised mules.

  Hence, to accommodate \citeauthor{Dretske:1970to}'s intuition, either (\ref{Dretske:No-C:cond:no-k-then-ep}) or (\ref{Dretske:No-C:cond:ep-then-no-k}) must be rejected.
  \citeauthor{Dretske:1970to} rejects (\ref{Dretske:No-C:cond:ep-then-no-k}).\nolinebreak
  \footnote{
    See below.
  }
\end{note}

\begin{note}
  We now return to claiming support.

  \autoref{assu:supp:nfactive} requires that claiming support for \(\phi\) is compatible with the (epistemic) possibility that the claimed support is \nmom{}.
  And, the claimed support is \misled{} just in case \(\phi\) is not the case.
  Hence~\autoref{assu:supp:nfactive} requires that claimed support for \(\phi\) is compatible with the (epistemic) possibility that \(\phi\) is not the case.

  Therefore, the result of substituting `claimed support' from `knowledge' in (\ref{Dretske:No-C:cond:ep-then-no-k}) conflicts with \autoref{assu:supp:nfactive}.
  And so~\autoref{assu:supp:nfactive} parallels \citeauthor{Dretske:1970to}'s rejection of (\ref{Dretske:No-C:cond:ep-then-no-k}).
  However, \citeauthor{Dretske:1970to}'s rejection of (\ref{Dretske:No-C:cond:ep-then-no-k}) is motivated by a rejection of~\ref{K:closure:standard}.
\end{note}

\begin{note}[Link]
  The refinement of~\ideaCSB{} through \autoref{assu:supp:independence} has lead to a proposition close to~\ref{K:closure:standard}

  \begin{enumerate}[label=P\ref{prop:CS-only-if-reason-recognised-defeaters}\('\).]
  \item If \(\psi\) having value \(v'\) is a \requ{} of claiming support for \(\phi\), then if the agent has claimed support for \(\phi\) having value \(v\) then the agent has reasoned about whether \(\psi\) has value \(v'\).\newline
    \mbox{}\hfill \((\phi \leadsto \psi) \rightarrow (\text{CS}\phi \rightarrow \text{R}\psi)\)
  \end{enumerate}

  Both build on \autoref{def:requisite}.
  A \requ{}.
  This is a complex parallel to knowing that \(\phi\) entails \(\psi\).
  However, somewhat general, and applies to \(K\) also.
  {\color{red} (Strictly speaking, because of contraposition, make this more explicit below)}

  \autoref{assu:supp:independence} then requires reasoning.

  Requiring something with respect to \(\psi\) having value \(v'\) given some state of the agent an principle which relates \(\psi\) having value \(v'\) to that state.

  For sure, appealing, or having claimed support is distinct, so the closure is not that with respect to an \emph{an} epistemic operator such as knowledge.
  However, the tension here is in terms of viewing the rejection of \ref{K:closure:standard} as the endorsement of a `locality constraint'.
  {\color{red} What this means.}
  And, seem to violate such a constraint.
\end{note}

\begin{note}[`Locality constraint']
  \begin{quote}
    To know that \(x\) is \(A\) is to know that \(x\) is \(A\) within a framework of relevant alternatives, \(B\), \(C\), and \(D\).
    This set of contrasts, together with the fact that \(x\) is \(A\), serve to define what it is that is known when one knows that \(x\) is \(A\).
    One cannot change this set of contrasts without changing what a person is said to know when he is said to know that \(x\) is \(A\).\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[1022]{Dretske:1970to})}
  \end{quote}

  Where:
  \begin{quote}
    A relevant alternative is an alternative that might have been realized in the existing circumstances if the actual state of affairs had not materialized.\nolinebreak
    \footnote{
      \citeauthor{Dretske:1970to} adds:
  \begin{quote}
    \dots alternatives that \emph{might} have been realized in the existing circumstances if the actual state of affairs had not materialized.
    \dots are not relevant alternatives.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[fn.6][1021]{Dretske:1970to})}
  \end{quote}
    }
    \nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[1021]{Dretske:1970to})}
  \end{quote}
  Different from a \requ{}.
\end{note}

\begin{note}
  Point is not direct clash.\nolinebreak
  \footnote{Two problems.

    First, \citeauthor{Dretske:1970to} seems to go with no recognition at time, compatible with claiming support at time.
    So, would need instance of appealing to knowledge for some other purpose.
    Restating is not sufficient, assumptions made are compatible with persistence (as noted).

    Second, only get no need to rule out from \citeauthor{Dretske:1970to}, which does not require no reasoning.
  }
  At issue, rather, it the degree to which possibility is compatible with the absence of reasoning.
  That is, if reject closure, is this due to reasoning or due to requirements placed on such reasoning?\nolinebreak
  \footnote{
    (Problem here, but also extends to \nI{}.)
  }

  There is some subtlety, however.
  Kind of closure seems to break for many attitudes.
  This is not at issue, distinguishing feature of claiming support is closure, and the constraints this places on an agent.
  However, reject for stronger attitudes, then why for weaker?
\end{note}

\begin{note}
  Reasoning, but haven't placed constraints.
  So, this allows for something that may be quite weak.
  % I am here only restating what has gone before, but the added context may help.
  No reasoning, then leaves open possibility that does lead to a problem with the reasoning performed.

  Consider again relevant alternatives from internalist perspective.
  It seems, agent determines whether relevant or not will require reasoning.

  Consider:
  \begin{quote}
    `What if those reports about the zoo authorities cleverly disguising animals to look like other animals?
    If there are, could those animals be cleverly disguised mules?'
  \end{quote}
  Perhaps not a relevant alternative if the sense of `might' is non-epistemic, but if epistemic, then seems a problem.
\end{note}

\begin{note}
  To summarise.

  \citeauthor{Dretske:1970to}'s case.
  Rejection of closure.
  Question whether assumptions are okay.
  Argued that these are given understanding of claimed support, and that they plausibly extend to knowledge (and other attitudes intuitively stronger than that of having claimed support).
  For, rejection of closure plausibly amounts to rejection on strength of reasoning, rather than requirement to reason.

  Focus on this point for two reasons:
  First, distinguishing feature of claiming support and following will be about claiming support.
  Second, appeal to similar limitation later.
\end{note}

\newpage

\subsection{A corollary and a conjecture}

\begin{note}
  Talked about `closing principle'.
  Make this precise.
\end{note}

\begin{note}[Generalising point for K example]
  Generalise.
  Any time the agent appeals to a consequence.
  And, this is straightforward, because consequence is only going to hold with the antecedent.

  \begin{corollary}\label{corr:eiS:C:contraposition}
    Suppose an agent has prior claimed support for:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item\label{corr:cond:p} \(\phi\) having value \(v'\). And,
    \item\label{corr:cond:pq} If \(\phi\) has value \(v\) then \(\psi\) has value \(v'\).
  \end{enumerate}
  Such that the agent claimed support for \ref{corr:cond:p} prior to \ref{corr:cond:pq} and as such the reasoning involved in claiming support for \ref{corr:cond:p} did not entertain the possibility of \(\psi\) not having value \(v'\).
  And, further suppose the agent holds that:
  \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
    \item The claimed support for \ref{corr:cond:pq} (also) implies that if \(\psi\) does not have value \(v'\) then \(\phi\) does not have value \(v\).
  \end{enumerate}
  Then, if the agent engages in reasoning such that:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
    \item The agent does not appeal to anything other premises other than~\ref{corr:cond:p} and ~\ref{corr:cond:pq} from their prior claimed support, some form of conditional detachment applied to ~\ref{corr:cond:p} and~\ref{corr:cond:pq} to conclude that \(\psi\) has value \(v'\).
    \end{enumerate}
    Such that remains possible that \(\psi\) does not have value \(v'\).
    The reasoning is not an instance of claiming support.
  \end{corollary}

  \autoref{corr:eiS:C:contraposition} is a summary of the common problem between \illu{1} \ref{illu:CS:spot-the-diff},~\ref{illu:CS:wheres-wally}, and~\ref{illu:dretske-zebra-var}.
  And, as such captures sufficient conditions for \autoref{prop:CS-only-if-reason-recognised-defeaters}.
\end{note}

\begin{note}
  Observe, from \autoref{prop:CS-only-if-reason-recognised-defeaters} we have that reasoning that \(\psi\) has value \(v'\) is not an instance of claiming support {\color{red} if \requ{} with no reasoning about it}.

  By assumption, no reasoning about \(\psi\) not having value \(v'\) when claiming support for \(\phi\) having value \(v\).

  Therefore, to establish \autoref{corr:eiS:C:contraposition} we need only show that \(\psi\) having value \(v'\) is a \requ{} of the claimed support for \(\phi\) having value \(v\).

  And, the agent has come to consider \(\psi\) having value \(v'\) as a \requ{} of that claimed support as:
  \begin{itemize}
  \item Possible that \(\psi\) does not have value \(v'\), by assumption.
  \item If \(\psi\) does not have value \(v'\) then \(\phi\) does not have value \(v\), and hence the claimed support for \(\phi\) having value \(v\) would be \misled{}.
  \item And, as \(\phi\) having value \(v\) implies \(\psi\) has value \(v'\) it must be the case that \(\psi\) having value \(v'\) persists through to the conclusion of reasoning.
  \end{itemize}
\end{note}

\begin{note}
  Again, intuition is that claimed support for \(\phi\), but novel information about a possible defeater.
  So, it's no good to appeal to prior claimed support --- without additional reasoning about that claimed support --- as the claimed support did not take into account the possible defeater.
\end{note}

\begin{note}
  In general, expect this not to be much of a concern.

  Three considerations.
\end{note}

\begin{note}[Not claiming support]
  First, the obvious, claiming support and may not be the case that agent is claiming support in relevant reasoning.
\end{note}


\begin{note}[Deal with \requ{}]
  Second, in many cases claimed support for \(\phi\) is not going to hold up regardless of whether \(\psi\), so plausible reasoning about \(\psi\) as a \requ{}.

  For example:

  Alarm ringing, so fire.
  If no fire, not alarm ringing.
  However, even if consider the possibility that there isn't really a fire, clear that the alarm is ringing.
\end{note}

\begin{note}
  Strengthening, this will also not apply if the agent has claimed support that \(\phi \rightarrow \psi\) and \(\lnot \phi \rightarrow \psi\) and appeals.
  For, no \requ{} in this case.
\end{note}

\begin{note}[Requires contraposition]
  Finally, contraposition.
  It is not clear that contraposition always holds.

  And, without contraposition, retain claimed support for \(\phi\), and even if \mom{} \(\phi\) provides enough to think that \(\psi\) is the case.
  In particular, a variation of~\ref{corr:eiS:C:contraposition} does not \emph{necessarily} hold with respect to conditional probability.

  \begin{idea}\label{conj:eiS:C:probability}
    Assuming that sufficiently high probability is sufficient for claiming support.

    It is not necessarily the case that an agent may not claim support for \(\psi\) having value \(v'\) by appeal to:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item\label{corr:prob:p} Claimed support for \(\phi\) having value \(v'\) such that no consideration of \(\psi\).
    \end{enumerate}

    Some time after \ref{corr:prob:p}:

    \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
  \item\label{corr:prob:pq} Claimed support for \(\psi\) having value \(v'\) when \(\phi\) has value \(v\).
    \end{enumerate}

    If:
    \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume]
    \item The agent does not appeal to any other premises other than claimed support for~\ref{corr:prob:p},~\ref{corr:prob:pq} and some principle regarding conditional probability.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{idea}

  Follows from the simple observation that conditional probability does not require that \(\phi\) is false when \(\psi\) is false.

  For example, set some threshold \(t\) and consider a probability distribution such that:
  \(P(\phi) > t\), \(P(\psi \mid \phi) > t\).
  It is consistent with such a distribution that \(P(\lnot\phi \mid \lnot\psi) = 0\).\nolinebreak
  \footnote{
    For example, if \(t = .0\), then let \(P(\phi) = .9\), \(P(\psi) = .92\), \(P(\phi \land \psi) = .81\), \(P(\lnot\phi \land \lnot\psi) = 0\).
  }
  And, therefore, from an agent's perspective it need not be the case that \(\phi\) would be false if \(\psi\) were false.
  In other words, it may be that entertaining possibility that \(\psi\) is false is just entertaining a restricted instance of \(\phi\) being true.
  Hence, \(\psi\) being true is not a \requ{} of \(\phi\) being true.

  Still,  \(\psi\) being true may be an `\emph{unrecognised} \requ{}' of \(\phi\) being true.
  However, we have made no assumptions regarding such `unrecognised \requ{1}'.

  {
    \color{red}
    Some care here, though.
    As the issue with possible defeaters is distinct from the probability of such defeaters.
    Indeed, given possibility, probability is typically low.
    Yet, this does not say anything about whether claimed support would hold up if the defeater turned out to be the case.

    The point of this {\color{red} idea} is to highlight an instance of a conditional that does not contrapose, and so does not lead to a \requ{}.
  }
\end{note}

\begin{note}
  These kinds of issues are fundamental to the argument.
  Issue is with a way of claiming support, rather than the possibility of claiming support.
  And, the issue is a result of the two assumptions made regarding claiming support.

  If something stronger or weaker, then the issue does not (necessarily) arise.
  Take it for granted that testimony.
  Knowledge excludes (epistemic) possibilities associated with defeaters.

  So, even if agent fails to claim support, may have done something interesting!

  However, focus is on claiming support.
  Possible defeaters, and some defence against those defeaters obtaining.

  Really important thing from these \illu{1} is that no particular assumptions about reasoning.
  \illu{3} all relied on absence of reasoning.
  So, although somewhat strong, still plausibly weak.
  Mentioned at many times things that seem sufficient.
  However, did not rely on these.

  So, claiming support is this odd thing.
  We will argue for additional proposition.
  \nI{}.
  Again, this will not rely on assumptions about reasoning.
\end{note}

\section{Summary of assumptions}

\begin{note}
  Claiming support.

  Two key ideas:

  \begin{enumerate}
  \item From \nfcs{}, always possible.
  \item From \eiS{}, doesn't depend.
  \end{enumerate}
  Second in part motivated by the first.

  Intuitively, stronger than belief, but weaker than knowledge.

  {
    \color{red}
    Claiming support is strong in the sense that it requires the agent's reasoning to hold up even if things are not how the agent thinks.
    However, strength is mitigated as bar for reasoning about a \requ{} may be set low.
  }

  Consequence of the first is way of establishing that reasoning does not result in claiming support.
  These assumptions are important.
  Argument relies on these assumptions.

  May be that it is possible to revise, but seem to capture something sufficiently interesting.
\end{note}

\begin{note}
  Well, it's a little more complex.
  What the argument really depends on is \ESU{} and \nI{}.
  Specifically \nI{}.

  It's not clear to me that these assumptions are strictly speaking required for \nI{}.
  And, some motivation of \nI{} independently of these.
  Still, this is as far as I got with \nI{}.

  Just so happens that these two assumptions also offer a nice `functional' characterisation.
  Therefore, appeal to these in order to set the stage.
\end{note}

\section{Closing focus on claimed support}

\begin{note}[Closing support]
  To summarise, claim of support.
  Certain kind of independence.
  Only interested in support, and not how this relates to attitudes.
  Somewhat intuitive, but no claims that this is the only understanding of support.

  For the moment, this provides clarity for understanding of support.
  Below, use to argue for failure to claim support.
\end{note}

\begin{note}[Something to emphasise]
  \color{red}
  Something to emphasise here is that this means that there's a way for an agent to claim support without being certain that \(\phi\) is the case.
  I don't have any answers for what this is.
  However, I do take this to be highly intuitive.
\end{note}


\begin{note}[Adequate]
  Kind of reasoning that we, the folk, do.
  Distinction for claiming support is that this is different from whether the agent has support, and we may set issues about whether the agent has support.

  Our interest is what is required for an agent to \emph{claim} support for (premises and) steps of reasoning, rather than what is required for an agent to \emph{have} support for (premises and) steps of reasoning.

  Use support as opposed to justification.
  Initial focus is on epistemic/doxastic attitudes.
  However, practical reasoning.
  For example, means-end.
  Support considered quite general to also include this.
\end{note}

\begin{note}
  Highlight again \phantref{dogmatism-wrt-nI}{below}.
\end{note}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End: