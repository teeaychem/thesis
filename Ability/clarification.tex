\chapter{Clarification}
\label{cha:clarification}

\begin{note}
  The role of this chapter is to refine important things about concluding.

  What it is about concluding we're interested in.
  This is support.
  Leads to a refinement of why? and how?
\end{note}

\begin{note}
  The goal here is to refine understanding of key question.
  And, to introduce type of \scen{} of interest.
\end{note}

\section{Support and reasoning}
\label{sec:clarification:support-reasoning}

\subsection{Concluding and support}
\label{sec:clarification:support}

\begin{note}
  \color{red}
  Purpose of concluding is to motivate relation of support as important.
  Here, strong relation between premises and conclusion.
  However, argument doesn't really rely on this.
\end{note}

\begin{note}
  Our interest is with the process of an agent concluding some proposition-value pair from some pool of premises.

  Concluding is an event --- concluding is something that happens.
  And, in particular, concluding is an act --- an agent concludes.%
  \footnote{
    \color{red}
    This passive construction is to avoid characterising an act as something brought about by an agent.
    Of course, agent being involved doesn't make an act.
    Involvement of agent, exist, but not an act.
    On the other hand, waking up.
    {
      \color{red}
      Also, Freud's example with adjourning a meeting.
      No intention, but perhaps conclusion.
    }
    {
      \color{red} This line of inquiry doesn't really matter.
    }
  }

  Two important assumptions were implicit in \autoref{cha:introduction}.

  \begin{assumption}
    \label{assu:concluding:pvp}
    What an agent concludes is always some proposition-value pair.
  \end{assumption}

  \begin{assumption}
    \label{assu:concluding:pools}
    An agent always concludes some proposition-value pair from some pool of premises, where a pool of premises is some collection of proposition-value pairs.
  \end{assumption}
\end{note}

\begin{note}
  I take \autoref{assu:concluding:pvp} to be fairly straightforward.
  In natural language, \emph{that} clauses.
  Default interpretation, true.

  However, propositions describe some state of affairs, and values are how the agent evaluates a state of affairs.

  True, false, desirable, etc.%
  \footnote{
    Nothing in particular hangs on the distinction between different values.
    If you prefer, you may expand the proposition (\world{}) to include additional factors, and consider only the values `true' and `false'.
    For example, the proposition that \emph{I desire the bath to be warm} is false, as opposed me assigned the proposition that \emph{the bath is warm} the value `undesirable'.
  }

  In terms of reasoning, understanding of concluding includes both theoretical and practical, and if you think this division is non-exhaustive, then some long as the result of the type of reasoning is the agent's evaluation of some situation, \autoref{assu:concluding:pvp} is designed, at least, to not rule out the culmination of the type of reasoning as an instance of concluding.%
  \footnote{
    Though, concluding may be stronger.
  }
\end{note}

\begin{note}
  \autoref{assu:concluding:pools} may be a little less straightforward.

  Not so clear that concluding always involves premises.

  Indeed, have seen in \autoref{cha:introduction} some difficulty in stating what premises would be involved in concluding via understanding of arithmetic.

    Robinson or Peano arithmetic together with the two numbers joined by an operator.
  Though, I doubt this.

  For a clear example, consider the rule for conditional introduction a Fitch-style rule for propositional logic.%
  \footnote{
    \citeauthor[cf.][206]{Barwise:1999tu}
  }

  \begin{quote}
    \fitchctx{
     \subproof{\pline{P}}{
         \ellipsesline\\
         \pline{Q}
     }
     \pline{P \lif Q}
   }
  \end{quote}

  {
    \color{red}
    The rule states that at any point in a proof, assume \formula{P}, then, after deriving \formula{Q} from \formula{P} discharge assumption of \formula{P} and introduce \formula{P \lif Q}.
  }

  Start with an assumption , derive proposition-value pair.
  Conclude if X then Y.
  Indeed,~\citeauthor{Ramsey:1929tf} test for conditionals.%
  \footnote{
    See, for example,~\textcite{Read:1995wf}.
  }

  No premises.

  Parallel, pool of premises may be empty.

  Rather than being motivated by some pre-theoretical understanding of concluding, \autoref{assu:concluding:pools} is primarily a matter of convenience.
  Far easier to talk about concluding proposition-value pair from some pool of premises, than to cover distinct cases.

  What it means to say an agent concluded from empty pool of premises, set aside.

  Indeed, taking in terms of proposition-value-premises pairings will be key for our statement of \autoref{idea:support}, a key idea concerning concluding.
\end{note}

\begin{note}
  \begin{idea}[Support I]
    \label{idea:support}
    \emph{If:}
    \begin{itemize}
    \item
      An agent has concluded some proposition \(\phi\) has some value \(v\) from some pool of premises \(\Phi\).
    \end{itemize}
    \emph{Then:}
    \begin{itemize}
    \item
      A \emph{relation of support} holds between \(\Phi\) and \(\phi\) having value \(v\), when concluding \(\phi\) has value \(v\) from \(\Phi\), from the agent's perspective.
    \end{itemize}
    \vspace{-\baselineskip}
  \end{idea}

  Primary role of \autoref{idea:support} is to distinguish concluding from other acts.
\end{note}

\begin{note}
  As we will shortly see, links to reasons.
  However, support is distinct from reasons.

  Relation of support holds between conclusion and pool of premises.
  Between some proposition-value pair and a collection of proposition-value pairs.

  Explanatory reason holds between something which explains and an action.

  Support involved in providing explanatory reason.
\end{note}

\begin{note}
  \begin{idea}[Support II]
    \label{idea:support:possible}
    It is possible for there to be a relation of support between \(\phi\) having value \(v\) and \(\Phi\) without \vAgent{} having concluded \(\pv{\phi}{v}\) from \(\Phi\), from \vAgent{}' perspective.
  \end{idea}

  Note, \autoref{idea:support:possible} does not state:

  \begin{quote}
    It is possible for there to be a relation of support between \(\phi\) having value \(v\) and \(\Phi\) without \vAgent{} having concluded \(\pv{\phi}{v}\) from \(\Phi\) \emph{from \vAgent{}' perspective}, from \vAgent{}' perspective.
  \end{quote}

  So, relation of support, but it doesn't follow from this that we get this from the agent's perspective.
\end{note}

\begin{note}
  \autoref{idea:support:possible}, motivation from the distinction between propositional and doxastic justification.

  Here, this clearly holds.

  Whether agent gets that they have propositional justification without doxastic justification is somewhat difficult.

  Various cases, fails.

  For example, look at Sudoku.
  Now, in a sense propositional justification for whether or not number is in square.
  Good understanding of rules, and easy to do.

  Now, suppose filled in with some clues.
  Here, justification for which numbers are not possible.
  Doxastic justification, via testimony.
  However, seems also get that you have propositional justification from understanding of Sudoku.

  However, from that have propositional justification, don't get doxastic justification.
  For this, would need to go from understanding of Sudoku to rejection of number.
  Going from A to B is built in to understanding of doxastic justification.
\end{note}

\begin{note}
  This proposition, idea is that allow support to be arbitrarily strong, under constraint that no witnessing.

  So, witnessing isn't necessary for relation of support.
  However, it may still be the case that witnessing is necessary to determine whether relation of support, from agent's perspective.

  Strictly speaking, though, this isn't too important.

  Consider against propositional and doxastic justification.
  Similar issue, it seems plausible that in order to get that propositional justification for square via rules, first need to get doxastic justification via testimony.
  Only after doxastic justification do you get propositional justification.

  So, same holds for concluding.

  Indeed, could go through all of this with propositional and doxastic justification.
  Though, a little less clear.
  Propositional justification is in part answer to why without doxastic justification.
  Difficulty is arguing for this.
  For, depends on theory.
  Well, in particular, what grants propositional justification.
  In example, easy to get.

  Concluding, deny this.
  Indeed, seems to be intuitive thing about reasoning.
\end{note}

\subsection{The agent's perspective}
\label{cha:introduction:sec:agents-perspective}

\begin{note}
  Before continuing.
  The agent's perspective.

  Mentioned before, but make this clear.
\end{note}

\begin{note}
  Talk about what an agent believes, knows, desires, etc.

  Agent believes \(\phi\) has value \(v\), stating how things are.

  From the agent's perspective, \(\phi\) has value \(v\).

  So, shift.

  Continue to talk of what the agent believes, etc.

  However, prefer to talk about the agent's perspective.

  Basic so that \(\phi\) has value \(v\).

  Whether this is belief or not.%
  \footnote{
    \label{fn:belief-is-difficult}
    I don't think belief is really so straightforward.

    Consider the Jeremy Goodman's example of three-horse race from~\textcite{Hawthorne:2016wv}:
    \begin{quote}
      Assume that horse A is more likely to win than horse B which in turn is more likely to win then horse C (so the probabilities of winning could be known to be 45, 28, 27\%).
      In this case it seems Ô¨Åne to say `I think horse A will win' or `I believe horse A will win'.%
      \mbox{ }\hfill\mbox{(\citeyear[1440]{Hawthorne:2016wv})}
    \end{quote}
    As \citeauthor{Hawthorne:2016wv} observe: ``[I]t is awful to say, in this case, `I think horse A will win but I don't believe it will'.''
    (\citeyear[1440, fn.17]{Hawthorne:2016wv})
  }
\end{note}

\begin{note}
  Express the idea using familiar ideas from modal logic.

  World \(w\).
  Say whether something is true or not \(w \vDash \phi\).

  Now, say whether or not an agent believes something \(w \vDash B\phi\).

  Now, semantics of belief.
  Some collection of epistemically plausible worlds.

  \(\mathcal{B}\).

  \(\mathcal{B} \vDash \phi\).

  So, here, on this understanding, agent's perspective from belief.

  But, technical use of belief.
  So, again, agent's perspective.
\end{note}

\begin{note}
  Perspective, so agent may be wrong.
\end{note}

\paragraph{Motivation for support I}

\begin{note}
  For example, \citeauthor{Boghossian:2014aa}'s Taking Condition:%
  \footnote{
    There are various objections to the taking condition.

    See, for example,~\textcite{Hlobil:2014tq}, \textcite{McHugh:2016vp}, and~\textcite{Wright:2014tt}.

    \citeauthor{Hlobil:2014tq} argues against the Taking Condition as it distracts from what accounts of reasoning out to explain, rather than arguing against the Taking Condition directly.

    \citeauthor{McHugh:2016vp} summarise various objects to the taking condition, and present district arguments against against (distinct) ideas in favour of the taking condition.
    In particular,~\autoref{idea:support} is closer to what \citeauthor{McHugh:2016vp} term the `Consequence Condition' (\citeyear[cf.][316]{McHugh:2016vp}), which \citeauthor{McHugh:2016vp} also (indirectly) argue against.
    However, \citeauthor{McHugh:2016vp} does not consider an alternative account of what distinguishes concluding from any other action, and as~\autoref{idea:support} is designed to capture this distinction, it is unclear to me whether \citeauthor{McHugh:2016vp}'s arguments apply to~\autoref{idea:support} (if, indeed, they are sound).

    \citeauthor{Wright:2014tt} denies that reasoning must involve a state which connects premises to conclusions. (\citeyear[Cf.][33-34]{Wright:2014tt})
    Note,~\autoref{idea:support} is compatible with \citeauthor{Wright:2014tt}'s objection.
  }

  \begin{quote}
    (Taking Condition):
    Inferring necessarily involves the thinker \emph{taking} his premises to support his conclusion and drawing his conclusion because of that fact.%
    \mbox{}\hfill\mbox{(\citeyear[5]{Boghossian:2014aa})}
  \end{quote}

  \begin{quote}
    The intuition behind the Taking Condition is that no causal process counts as inference, unless it consists in an attempt to arrive at a belief by figuring out what, in some suitably broad sense, is supported by other things one believes.%
    \mbox{}\hfill\mbox{(\citeyear[5]{Boghossian:2014aa})}
  \end{quote}

  Inference --- and hence reasoning with beliefs --- rather than reasoning more broadly (\citeyear[cf][2]{Boghossian:2014aa}).

  \citeauthor{Boghossian:2014aa}, `taking'.
  Taking is required for support to explain.
  No explanation without taking.
\end{note}

\begin{note}
  \citeauthor{Broome:2002aa}'s `jogging account' of reasoning:

  \begin{quote}
    [I]n reasoning you call to mind some of the premises, and doing so jogs into operation an automatic process that causes you to acquire a conclusion-attitude.%
    \mbox{}\hfill\mbox{(\citeyear[226]{Broome:2002aa})}
  \end{quote}

  {
    \color{red}
    We will talk about reasoning later.
    For the moment, substitute in concluding.
    }

  \citeauthor{Broome:2002aa} argues some things which satisfy jogging are clearly not reasoning.
  For example, \citeauthor{Broome:2002aa} considers
  {
    \color{red}
    Suppose you believe that it is raining and that if it is raining the snow will melt. Suppose these beliefs are conscious, and suppose they cause you to believe you hear trumpets.
  }
  (\citeyear[225,226--227]{Broome:2002aa})%
  \footnote{
    Does not rule out concluding (\citeyear[231,233]{Broome:2002aa}).
  }

  \citeauthor{Broome:2002aa} endorses rule following.

  \begin{quote}
    Active reasoning is a particular sort of process by which conscious premise-attitudes cause you to acquire a conclusion-attitude.
    The process is that you operate on the contents of your premise-attitudes following a rule, to construct the conclusion, which is the content of a new attitude of yours that you acquire in the process.\newline
    \mbox{ }\hfill\mbox{(\citeyear[234]{Broome:2002aa})}
  \end{quote}

  Understand support of \autoref{idea:support} in terms of having followed a rule.
\end{note}

\begin{note}
  Present purposes, assume relation of support is involved in providing explanatory reasons for concluding.
\end{note}

\begin{note}
  Key assumption regarding concluding.
  Further assumptions detailed in~\autoref{chapter:concluding}.
\end{note}

\subsubsection{Support and why}

\begin{note}
  Assumption about support.
  Distinguishes from concluding.

  Relation of support also \emph{why}.

  \begin{restatable}[Proposition-value-premises pairing only if support]{idea}{ideaWhySupport}
    \label{assu:why:pvpp:support}
    \emph{If:}
    \begin{itemize}
    \item
      Some proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\) is, in part, an answer to why an agent concludes \(\phi\) has value \(v\) from some pool of premises \(\Phi\).
    \end{itemize}
    \emph{Then:}
    \begin{itemize}
    \item
      The relation of support holding between \(\Psi\) and \(\psi\) having value \(v'\) is, in part, an answer to why the agent concluded \(\phi\) has value \(v\) from \(\Phi\).
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  Interest in support is with respect to why an agent concluded.

  Support captures relation between proposition-value pair and pool of premises from perspective of agent when concluding.
  If relation between proposition-value pair and pool of premises explains, in part, why, then so does relation of support.
\end{note}

\paragraph{Examples}

\begin{note}
  For example, from agent's point of view, support between testimony of calculator and sum.

  Other examples \dots
\end{note}


\paragraph{Subtle}

\begin{note}
  Somewhat subtle, however.

  Antecedent, then answer to \qWhy{}.
  And, motivated constraint between \qWhy{} and \qHow{}.

  Important that consequent is not necessarily an answer to \qHow{}.

  This is obtained because \qWhy{} and \qHow{} only consider proposition-value-premises pairings.

  So, \autoref{assu:why:pvpp:support} does not require that relation of support is, in part, an answer to \qHow{}.

  Of course, on a theory like \citeauthor{Boghossian:2014aa}'s, support does have a role in how, as the taking condition requires the agent takes conclusion.
  Here, relevant that relation of support, taking is then evaluation, and this does not need to be intentional.%
  \footnote{
    Problems of rule following.
  }

  In some respects, plausible.
  Given \autoref{idea:support}, support is key to characterising some act as concluding.
  From the agent's perspective, \(\Phi\) support \(\pv{\phi}{v}\).
  However, this is a state of affairs.
  Does not follow that relation of support from the agent's perspective is also part of that state of affairs.

  Consider, for example, \citeauthor{Wright:2014tt}'s `Simple Proposal':
  \begin{quote}
    But consider instead the proposal, not that the status of the transition as inferential depends on the thinker's judgments about his reasons, but that it depends on \emph{what his reasons are}.
    We want his acceptance of the premises to supply his \emph{actual} reasons for accepting the conclusion.

    \mbox{}\hfill\(\vdots\)\hfill\mbox{}

    Call this the Simple Proposal.
    It says that a thinker infers q from p\(_{1}\) \(\cdots\) p\(_{\text{n}}\) when he accepts each of p\(_{1}\) \(\cdots\) p\(_{\text{n}}\), moves to accept q, and does so for the reason that he accepts p\(_{1}\) \(\cdots\) p\(_{\text{n}}\).\newline
    \mbox{}\hfill\mbox{(\citeyear[33]{Wright:2014tt})}
  \end{quote}

  Relation of support from accepting pool of premises and then accepting conclusion.
  However, from agent's perspective, relation between pool of premises and conclusion is not part of why agent moves to accept conclusion, pool of premises alone is sufficient.

  Still, from our perspective, still an account of why.
  Rejected here is that relation should be part of how.
\end{note}

\begin{note}
  So, \autoref{assu:why:pvpp:support} links support to \qWhy{}, but in a cautious way.
  Explanatory, but only for why from our perspective.
  Does not necessarily relate to \qHow{}.
\end{note}

\paragraph{Additional notes}

\begin{note}
  Understanding of support is generic.

  From agent's perspective.
  Perhaps the calculator is faulty, or the agent has an a unsteady grip on arithmetic.
  Still, conclusion from somewhere.
  Something account for why the agent holds.
\end{note}

\begin{note}[Support \emph{from the agent's perspective}]
    \begin{illustration}[A box of flan(nels)]
    \label{illu:flan-nels}
    Suppose `flan' is written on the side of a container.
    I may claim support that the container contains flan.
    And, it may be that the writing on the side of the container is support for the box containing flan.
    However, the straps ensuring the container remains closed is unfortunately placed, and if moved would reveal the side of the container reads `flannels'.
  \end{illustration}

  The unfortunate placing of the straps does not seem to prevent concluding, but I'm not sure whether it is right to say that the writing on the side of the box (straps in place) hence support.

  However, from an employee of the factory, no concluding, no support.
\end{note}

\begin{note}
  \phantlabel{mention:concluding-non-factive}
  In this respect, doesn't matter whether premises have values, or whether conclusion has value.
  Provide an \illu{0} of this in~\autoref{chapter:concluding}.%
  \footnote{
    \color{red}
    On page~\pageref{concluding:not-factive}.
  }
\end{note}

\begin{note}
  {
    \color{red}
    Not assuming that concluding involves belief.
  }
\end{note}

\subsection{Reasoning}
\label{sec:overview:reasoning}

\begin{note}
  \begin{idea}
    \label{assu:C-culmination-of-R}
    If concluded \(\pv{\phi}{v}\) from \(\Phi\), then reasoned from \(\Phi\) to \(\pv{\phi}{v}\).
  \end{idea}

  In other words, conclude \(\pv{\phi}{v}\) then reasoned from some pool of premises to \(\Phi\).
\end{note}

\begin{note}[No constraints]
  No constraints placed on reasoning.

  In line with, for example, \citeauthor{Broome:2013aa}.

  \begin{quote}
    Following this rule would lead you to believe you hear trumpets when you believe it is raining and believe that if it is raining the snow will melt. If you did this, should we count you as reasoning?

    I think we should. If you derive this conclusion by operating on the premises, following the rule, we should count you as reasoning.

    \mbox{}\hfill\(\vdots\)\hfill\mbox{}

    I think we should not impose a limit on rules.%
    \mbox{}\hfill\mbox{(\citeyear[233]{Broome:2013aa})}
  \end{quote}
\end{note}

\begin{note}
  Plausibly contrasts with an account of reasoning such as \citeauthor{Wedgwood:2006ui}'s (\citeyear{Wedgwood:2006ui}) account of reasoning.

  \begin{quote}
    % So, the disposition that one must manifest in forming a belief in \emph{p} by means of reasoning must be one that can be specified by means of a function that, for \emph{any} proposition \emph{q} within the relevant range, maps the stimulus event-type \emph{coming to be in some mental states or other that rationalize forming a belief in q} onto the response event-type \emph{forming a belief in q}.
    [T]he disposition that one must manifest in reasoning is a disposition that responds to the fact that one is in some mental states or other that rationalize one's forming the belief or intention in question.\newline
    \mbox{ }\hfill\mbox{(\citeyear[672]{Wedgwood:2006ui})}
  \end{quote}

  Where:

  \begin{quote}
    If a set of antecedent mental states makes it rational for one to form a new belief or intention, then those antecedent mental states are surely of a suitable type and content so that it is \emph{intelligible} that they could represent one's reason for forming that belief or intention.\newline
    \mbox{ }\hfill\mbox{(\citeyear[662]{Wedgwood:2006ui})}
  \end{quote}

  Of course, this is only sufficient condition, but \citeauthor{Wedgwood:2006ui}'s account of reasoning is developed under the assumption the condition is also necessary.%
  \footnote{
    So, here, problem with fallacious reasoning that \citeauthor{Wedgwood:2006ui} notes.
    Following brief discussion:
    \begin{quote}
      I shall proceed on the idealizing assumption that the only way in which a set of antecedent mental states can rationalize the formation of a belief or intention is by making that new belief or intention a \emph{rational} belief or intention to form.\newline
      \mbox{ }\hfill\mbox{(\citeyear[662]{Wedgwood:2006ui})}
    \end{quote}
    However, it's not clear to me that fallacious reasoning is a pressing problem for an account such as \citeauthor{Wedgwood:2006ui}'s.
    For, fallacious reasoning may be reasoning in the same way that a fake water pistol is a water pistol.
    I.e.\ fallacious reasoning need not be reasoning proper.
  }
\end{note}

\begin{note}
  So, allow reasoning to be broad.
  Hence, concluding also.
  Still, compatible with account such as \citeauthor{Wedgwood:2006ui}'s.

  No constraints means that we do not place constraints, it does not mean that we assume there are no constraints on reasoning.
\end{note}

\begin{note}
  Here, with \citeauthor{Wedgwood:2006ui}, antecedent mental states rationalise.
  Understand this in terms of \qWhy{}.
  So, this motivates.
  The mental states rationalise, hence, it seems, full account of why agent concludes in terms of the reasoning the agent does.

  There is also the disposition.
  \citeauthor{Wedgwood:2006ui} doesn't explicit include this in terms of rationalising.
  Though, I think this should plausibly be the case.%
  \footnote{
    See discussion regarding \citeauthor{Turri:2010aa}'s (\citeyear{Turri:2010aa}) account of doxastic justification in~\autoref{cha:fcs:sec:dox-just} (on~\autopageref{cha:fcs:sec:dox-just}).

    In short, \(p\) and \emph{if} \(p\) then \(q\) rationalise concluding \(q\).
    However, disposition.

    Tighten \citeauthor{Wedgwood:2006ui}'s account some disposition \emph{only} responds to rationalising mental states.
    Though, have no constrained the disposition.
    And, that the disposition is so constrained is, in part, why.
  }
\end{note}

\subsubsection[Reasoning-to vs.\ concluding]{Distinction between reasoning-to and concluding \hfill (Optional)}

\begin{note}
  Reasoning that concludes \(\phi\) has value \(v\) is distinct from reasoning:
  \begin{enumerate}[label=\Alph*., ref=(\Alph*)]
  \item
    \label{CS:delicacy:O}
    Whose conclusion is (merely) \emph{about} \(\phi\) having value \(v\), and does not `require' \(\phi\) has value \(v\).
  \item
    \label{CS:delicacy:A}
    That concludes \(\phi\) has value \(v\) \emph{assuming} \dots\space --- where `\emph{assuming} \dots\space' is expanded to include some proposition-value pair \(\pv{\chi}{v}\) such that they agent has \emph{not} concluded \(\pv{\chi}{v}\).
  \end{enumerate}
\end{note}

\begin{note}[Epistemic operator]
  The statement of \ref{CS:delicacy:O} is loose, but the underlying idea is straightforward.

  we typically express the conclusion of the agent's reasoning which is (merely) about \(\phi\) having value \(v\) with some adjective.
  For example:

  \begin{quote}
    \vAgent{} \(\{ \text{hopes}, \text{imagines}, \text{desires}, \text{thinks}, \dots \}\) \(\phi\) is true.%
    \footnote{
      More generally, has value \(v\).
    }
  \end{quote}
  Each candidate adjective may be read in a way which is compatible with past, present, or future reasoning which concludes \(\phi\) does not have value `true'.
  In this sense, the reasoning is (merely) \emph{about} \(\phi\) being true, and does not require \(\phi\) is true.

  However, the relevant adjective may also be read as an evaluation of the relevant situation.
  It may be \(\phi\) \emph{is} hoped for, imagined, desired, thought, and so on.
  In this sense, the reasoning concludes \(\phi\) has some value \(v\), where the value is some value distinct from `true'.

  For the most part, `true' will be the relevant value \(v\) when discussing instances of reasoning.
  And, you may (unless there is clear tension) substitute mention or use of `\(\phi\) having value \(v\)' for `\(\phi\) being true'.
  Still, we do not require that `true' is the unique value of interest, and on occasion we will observe how various different valuations interact with observations made.
\end{note}

\begin{note}[Suppositions]
  \ref{CS:delicacy:A} is more straightforward.
  Contrast the instances of reasoning in~\autoref{fig:Rover}.
  \begin{figure}[h!]
    \mbox{}\hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item
        \label{fig:Rover:CS:1}
        Rover is tired.
      \item
        \label{fig:Rover:CS:2}
        Rover will fall asleep soon.
      \end{enumerate}
      \caption{}
      \label{fig:Rover:CS}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}[label=\arabic*\('\).,ref=(\arabic*\('\))]
      \item
        \label{fig:Rover:nCS:1}
        \emph{Supposing} Rover is tired.
      \item
        \label{fig:Rover:nCS:2}
        Rover will fall asleep soon.
      \end{enumerate}
      \caption{}
      \label{fig:Rover:nCS}
    \end{subfigure}
    \hfill\mbox{}
    \caption{Two instance of reasoning}
    \label{fig:Rover}
  \end{figure}

  \ref{fig:Rover:CS} and \ref{fig:Rover:nCS} are distinguishing by whether or not the premise that Rover is tired is a supposition (\ref{fig:Rover:nCS}) or not (\ref{fig:Rover:CS}).

  It may be the case that Rover would fall asleep soon if Rover were tired, but as \ref{fig:Rover:nCS:1} does not concern the actual state of Rover, \ref{fig:Rover:nCS:2} need not concern the actual state of Rover.

  By contrast,~\ref{fig:Rover:CS} is an instance of reasoning about how things are.
  The agent is holding that it is the case that Rover is tired, and therefore it is the case that Rover will fall asleep soon.

  I take this distinction to be straightforward.
  Though, it is not always immediately clear how the distinction applies to some conclusion of reasoning when stated independently of the preceding reasoning.
  Consider the conclusion:

  \begin{quote}
    That Rover is asleep is likely.
  \end{quote}

  Following the distinction, there are two broad ways of interpreting the conclusion:
  \begin{enumerate}
  \item
    The agent has made some plausible assumptions and granting those assumptions, Rover is asleep.
  \item
    For every proposition-value pair \(\chi_{i}\) having value \(v_{i}\) the agent has appealed to, the agent hold it to be the case \(\chi_{i}\) has value \(v_{i}\).
    However, the agent only concludes from \(\chi_{i}\) having values \(v_{i}\) that there is some (objective or subjective) chance that Rover is asleep.
  \end{enumerate}
  So, though claiming support is for some proposition \(\phi\) having some value \(v\), it is not clearly the case that claiming support is restricted to certain proposition-value combinations.
\end{note}

\begin{note}[Analogue]
  Analogue of concluding for conditional.
  Here, bundle into \(\phi\).
  More generally, not much need for conditional stuff.
\end{note}

\paragraph{Why concluding}
\label{concluding-consistency}

\begin{note}
  In simple terms, focus on concluding because bad to \emph{conclude} \(\phi\) has value \(v\) and \(\phi\) has value \(\overline{v}\).
  Though, it's not so bad to reason to this, at least generally speaking.
\end{note}

\subsubsection{Summary}
\label{sec:clarification:support-reasoning:summary}

\begin{note}[What we've seen]
  Support and reasoning.
\end{note}

\begin{note}[Role in expanding]
  Following section, use support and reasoning to expand on \qWhy{}, \qHow{}, and \issueInclusion{}.
\end{note}

\begin{note}[Motivation]
  Handful of additional theories that motivate positive resolution to \issueInclusion{}.
\end{note}

\subsection{Section summary}
\label{sec:section-summary}

\begin{note}
  Support and reasoning.

  Three ideas regarding support.

  The agent's perspective.

  Reasoning.
\end{note}

\section{\qWhy{}, \qHow{}, and \issueInclusion{}, expanded}
\label{sec:support-why-how}

\begin{note}[Goal]
  Goal is to refine understanding of these questions and relation.

  In particular, connecting \qWhy{} to relations of support.

  Also, \qHow{} to reasoning.
\end{note}

\begin{note}[Division]
  Three sections.

  First two sections focus on \qWhy{} and \qHow{}, respectively.
  Introduce an idea, expand on question, and present variant question given introduced idea.

  \qWhy{}, support, converse.
  \qHow{}, witnessing.

  Third section, bring the expansions together.
  Present variant of main issue.
  This variant will be our focus for the document.

  \begin{itemize}
  \item
    \autoref{sec:clar:expand:qWhy}.
  \item
    \autoref{sec:clar:expand:qHow}.
  \item
    \autoref{sec:clar:expand:issue}
  \end{itemize}
\end{note}

\subsection{\qWhy{}}
\label{sec:clar:expand:qWhy}

\begin{note}[Introduction]
  We now turn to \qWhy{}:
  \vspace{-\baselineskip}
  \begin{quote}
    \questionWhyBasic*
  \end{quote}
  Example, pairing of \(23 \times 15 = 345\) and the testimony of the calculator that \(23 \times 15 = 345\) answers, in part, why the agent concluded \(23 \times 15 = 345\) in \autoref{illu:gist:calc}.
  Slightly more natural to say `the testimony of the calculator that \(23 \times 15 = 345\)', but \emph{paring}.

  Observed that, intuitively, pairing of \(23 \times 15 = 345\) and whatever pool of premises would be associated with the agent applying their understanding of arithmetic does not answer, in part, why the agent concluded \(23 \times 15 = 345\).
\end{note}

\begin{note}
  Intuition.

  Theoretical motivation for this via \issueInclusion{}.
  Understanding of arithmetic intuitively not part of how.
\end{note}

\begin{note}
  Present section, stronger link between relation of support and \qWhy{}.
  From \autoref{assu:why:pvpp:support}, relation of support between testimony and \(23 \times 15 = 345\) explains why.

  Converse.

  Given positive resolution to \issueInclusion{}, relation of support is not answer why.

  More generally, equivalence between relation of support and proposition-value-premises pairings.


  However, possible relation of support also explains why.
  Rule this out.
\end{note}

\paragraph{Idea}
\label{sec:clar:expand:qWhy:idea}

\begin{note}
  Have~\autoref{assu:why:pvpp:support}.

  \autoref{assu:why:pvpp:support} links answers to \qWhy{} to support.
  However, does not link explanatory role of support to \qWhy{}.
  For this, converse.
\end{note}

\begin{note}
  \begin{restatable}[Support only if proposition-value-premises pairing]{idea}{ideaSupportWhy}
    \label{assu:why:support:pvpp}
    \emph{If:}
    \begin{itemize}
    \item
      A relation of support holding, from the perspective of the agent's epistemic state, between \(\Psi\) and \(\psi\) having value \(v'\) is, in part, an answer to why the agent concluded \(\phi\) has value \(v\) from from some pool of premises \(\Phi\).
    \end{itemize}
    \emph{Then:}
    \begin{itemize}
    \item
      The proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\) is, in part, an answer to why the agent concluded \(\phi\) has value \(v\) from \(\Phi\).
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  So, if support answers why, then the related proposition-value pair and pool of premises, in part, answer why.

  Take this to be fairly straightforward.
\end{note}

\begin{note}
  General picture.

  Support, why.
  So, proposition-value-premises pairing why.
  So, if positive resolution to issue, then proposition-value-premises pairing how.

  In other words, if positive resolution to issue, then account of how is going to constraint whether some relation of support answers why.

  We haven't learnt much about what support is.
  However, we have abstracted.
  Our perspective, linked with what happens in the agent.
  If positive answer, constrained by what happens in the agent.

  Way we're talking about support, somehow links to what the agent does when they conclude.
  Clear on this.
  But, figuring out this link is task for a theory.
  We're not providing a theory.
  \textbf{Understanding of support is fairly theory neutral.}
\end{note}

\begin{note}
  Difficulty.
  Testimony, then support, but then, \qWhy{}, and so \qHow{}.
  However, motivated relation in terms of causal theories.
  Pairing between \(\pv{\phi}{v}\) and \(\Phi\) is, intuitively, not how.
  Paired only in terms of support.

  Here, need to be careful about how support is involved.
  Not \emph{just} from relation between \(\pv{\phi}{v}\) and \(\Phi\).
  That partner testified.

  Need it to be the case that \(\Phi\) alone.
  And, this is not the case.

  So, this idea isn't going to give rise to this problem.
\end{note}

\paragraph{Variant of \qWhy{}}
\label{sec:clar:expand:qWhy:variant}

\begin{note}[The variant]
  Given role of support, and ideas, variant of \qWhy{}:

  \begin{question}[\qWhyV{}]
    \label{q:why:v}
    \emph{Which} proposition-value-premises pairings are such that support between involved in why agent concludes?
  \end{question}

  \begin{proposition}
    \label{prop:qWhy-and-qWhyV}
    For any proposition-value-premises pairing \(\pvp{\phi}{v}{\Phi}\):

    \(\pvp{\phi}{v}{\Phi}\) is, in part, an answer to \qWhyV{} \emph{if and only if} \(\pvp{\phi}{v}{\Phi}\) is, in part, an answer to \qWhy{}.
  \end{proposition}

  \begin{argument}
    \autoref{prop:qWhy-and-qWhyV} is immediate given \autoref{assu:why:pvpp:support} and \autoref{assu:why:support:pvpp}.

    relation of support answers this, then proposition-value-premises pairing answers \qWhy{}.

    proposition-value-premises pairing answer \qWhy{}, then relation of support.
  \end{argument}
\end{note}

\begin{note}
  \emph{Here}, note that we're not dealing with pairing of a proposition-value pair and a collection of proposition-value pairs.
  Instead, conclusion-premises pairing.
\end{note}

\begin{note}
  Note, we have stated `why?' and `how?' from theoretical perspective.

  \autoref{assu:why:pvpp:support} is also from this theoretical perspective.
\end{note}

\begin{note}
  From the perspective of the agent's (present) epistemic state, rather than the agent's point of view.

  Some flexibility.
\end{note}

\begin{note}
  Understanding of `why'.

  From the perspective of the agent.
  `The calculator', etc.
\end{note}

\begin{note}
  \issueInclusion{} distinguishes classes of theories.
  A positive resolution to \issueInclusion{} will not directly provide general answer to \qWhy{}.
  Though, a positive answer will rule out certain answers.

  For example, wrt.~\autoref{illu:gist:calc}.

  Indeed, accounts for the intuitions noted.
  Testimony of the calculator, but not agent's understanding of arithmetic.

  As we will see below, many accounts of concluding seem to fall in line with this.
\end{note}

\subsubsection{Reasons (Optional)}

\begin{note}

\end{note}

\begin{note}
  Variant of the more general issue with which \citeauthor{Davidson:1963aa} opens \citetitle{Davidson:1963aa}:

  \begin{quote}
    What is the relation between a reason and an action when the reason explains the action by giving the agent‚Äôs reason for doing what he did?%
    \mbox{}\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}

  \citeauthor{Davidson:1963aa}'s question is more general as covers all action.
  Our interest is specifically with concluding.

  Possible answers to \qWhy{}, lots.
\end{note}

\begin{note}
  \begin{quote}
    Cl. R is a primary reason why an agent performed the action A under the description d only if R consists of a pro attitude of the agent toward actions with a certain property, and a belief of the agent that A, under the description d, has that property.
  \end{quote}
  Now, primary reason is not from the agent's perspective.
  Pro attitude, we state something about the agent's perspective.

  Still, primary reason for every step of reasoning.
  Here, we get a causal trace.
  No need to look for any relation of support other than premises of reasoning.
\end{note}

\begin{note}
  Alternative may be to talk in terms of reasons.
  Concluding is an action.
  Reasons for action.
  Concludes from premises.
  Hence, premises are part of agent's reasons for action.

  With a little more care, we make further distinguish between normative and explanatory reasons.%
  \footnote{
    Normative: `reasons which show a given action, attitude, activity or outcome good, right, appropriate or called for'
    Explanatory: `the reasons why things happen, or why things are the way they are'
    \citeyear[410]{Hieronymi:2011aa}

    \citeauthor{Hieronymi:2011aa} also distinguishes `motivating' reasons,

    Motivating: `psychological facts which explain action'
    (\citeyear[411--412]{Hieronymi:2011aa})

    This way of dividing reasons is difficult.
    \citeauthor{Hieronymi:2011aa}'s account of motivating reasons follows~\textcite{Smith:1994wo}, but~\citeauthor{Smith:1994wo} distinguishes motivating reasons from normative reasons.

    \begin{quote}
      The distinctive feature of a motivating reason to \(\phi\) is that, in virtue of having such a reason, an agent is in a state that is \emph{explanatory} of her \(\phi\)-ing, at least other things being equal --- other things must be equal because an agent may have a motivating reason to \(\phi\) without that reason's being overriding.%
      \mbox{}\hfill\mbox{(\citeyear{Smith:1994wo})}
    \end{quote}

    See also \citeauthor{Broome:2013aa}:
    \begin{quote}
      Sometimes the explanation of why a person does something has a particular character:
      roughly, it involves the person's rationality in a distinctive way that I shall not try to describe.
      Then we say the person does what she does for a reason.
      We might say ‚ÄòThe reason for which Hannibal used elephants was to terrorize the Romans'.
      The reason for which a person does something is called a ‚Äòmotivating reason'.
      In general, a motivating reason is whatever explains or helps to explain what a person does in the distinctive way that involves her rationality.

      \mbox{}\hfill\(\vdots\)\hfill\mbox{}

      Whereas motivating reasons explain or help to explain why a person does something, normative reasons explain or help to explain why a person ought to do something, or to believe something, or to hope for something, or to like something, or in general to F, where ‚ÄòF' stands for a verb phrase.%
      \mbox{}\hfill\mbox{(\citeyear[46--47]{Broome:2013aa})}
    \end{quote}
  }

  In this way of looking at things, relation of support concerns explanatory reasons.
\end{note}

\begin{note}
  \citeauthor{Davidson:1963aa} resolution, in the \citeyear{Davidson:1963aa} paper at least, causal.
  Identifying \emph{something}%
  \footnote{
    \textcite{Hieronymi:2011aa} for a general overview.
  }
\end{note}

\begin{note}
  This is delicate.
  On my understanding of \citeauthor{Davidson:1963aa}, there's a tight link between then content of some state and the causal relations that arise from the state.

  So, go from content to state, and then proceed from here.

  This, I think, is correct.
  And, the problem of deviant causal chains highlights this.
  For, \citeauthor{Davidson:1963aa} recognises there's a problem with the link between content and the causal relations which hold between the states.

  \begin{quote}
    Beliefs and desires that would rationalize an action if they caused it in the right way‚Äîthrough a course of practical reasoning, as we might try saying---may cause it in other ways.%
    \mbox{ }\hfill\mbox{(\citeyear[79]{Davidson:1973vd})}
  \end{quote}
\end{note}

\begin{note}
  Note, however, causal deviance is not an issue for the argument suggested here.
  For, concluding, assume that no deviant causal chains, basically.

  Of course, if deviance is a problem, then there may be no cases of concluding, but this is a very distinct worry.
\end{note}

\subsection{\qHow{}}
\label{sec:clar:expand:qHow}

\begin{note}[Introduction]
  We now turn to \qHow{}:
  \vspace{-\baselineskip}
  \begin{quote}
    \questionHowBasic*
  \end{quote}
  Example, pairing of \(23 \times 15 = 345\) and the testimony of the calculator that \(23 \times 15 = 345\) answers, in part, how the agent concluded \(23 \times 15 = 345\) in \autoref{illu:gist:calc}.
  Slightly more natural to say `the testimony of the calculator that \(23 \times 15 = 345\)', but \emph{paring}.

  Observed that, intuitively, pairing of \(23 \times 15 = 345\) and whatever pool of premises would be associated with the agent applying their understanding of arithmetic does not answer, in part, how the agent concluded \(23 \times 15 = 345\).
\end{note}

\begin{note}[Theoretical motivation]
  Broader theoretical support from something like \citeauthor{Davidson:1963aa}'s causal theory of action.
  Also, now, \citeauthor{Boghossian:2014aa} and \citeauthor{Broome:2013aa}.
  And, \citeauthor{Wright:2014tt}.
\end{note}

\begin{note}
  In this section we expand via a necessary condition on how.
  In short, the agent has witnessed reasoning.

  The primary purpose of this expansion is to clarify the way in which, for present purposes, answers to how may be fairly weak.

  Two important things.

  No constraints placed on reasoning.
  Has, and so temporal component.
\end{note}

\begin{note}
  Two parts.

  Ideas, and discussion.

  Variant of \qHow{} given ideas.
\end{note}

\paragraph{Ideas}
\label{sec:clar:expand:qHow:ideas}

\begin{note}
  \begin{definition}[Witnessing]
    An agent has \emph{witnessed} reasoning from \(\Phi\) to \(\pv{\phi}{v}\) \emph{just in case} at some point in the past, the agent has reasoned from \(\Phi\) to \(\pv{\phi}{v}\).
  \end{definition}

  Term `witnessing' to make it clear that the agent has reasoned.
  The agent hasn't (merely), for example, entertained or forbidden reasoning from \(\Phi\) to \(\pv{\phi}{v}\).

  This introduces reasoning.
  Performed some act.
  Moved, somehow, from pools of proposition-value pairs to other pools of proposition-value pairs.

  Do not assume that result of reasoning is concluding.
  However, as we will see, concluding only if reasoning.
\end{note}

\begin{note}
  \begin{idea}[\ideaWitness{}]
    \label{idea:how-witnessing}
    For any proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\):
    \begin{itemize}
    \item
      \(\pvp{\psi}{v'}{\Psi}\) is, in part, an answer \qHow{}.
    \end{itemize}
    \emph{Only if:}
    \begin{itemize}
    \item
      The agent has \emph{witnessed} reasoning from \(\Psi\) to \(\psi\) having value \(v'\).
    \end{itemize}
  \end{idea}

  \autoref{idea:how-witnessing} links concluding and broad understanding of reasoning.

  Understanding of reasoning is broad, so that in general, whatever understanding is of how, if proposition-value-premises pairing answers how, then reasoning from \(\Phi\) to \(\pv{\phi}{v}\).

  The statement of~\autoref{idea:how-witnessing} is fairly straightforward.
\end{note}

\begin{note}[Basic case]
  \qHow{} is always stated with respect to the proposition-value-premises pairing \(\pv{\phi}{v}\) --- i.e.\ how did the agent conclude \(\phi\) has value \(v\).
  And, we assume that an agent always concludes \(\pv{\phi}{v}\) from some pool of premises.
  So, assuming the pairing of \(\pv{\phi}{v}\) and \(\Phi\), in part, answer how the agent concluded \(\pv{\phi}{v}\), it follows from \autoref{idea:how-witnessing} that the agent has witnessed reasoning from \(\Phi\) to \(\pv{\phi}{v}\).

  In this basic case, \autoref{idea:how-witnessing} may seem trivial, so long as no constraints are placed on what counts as reasoning.
  And, in this basic case, \autoref{idea:how-witnessing} is designed to be trivial.
  As mentioned, we place no constraints on what counts as reasoning.

  Hence, \autoref{idea:how-witnessing} states that if the paring of \(\pv{\phi}{v}\) and \(\Phi\) is, in part, how the agent concluded \(\pv{\phi}{v}\) then the agent has witnessed reasoning from \(\Phi\) to \(\pv{\phi}{v}\).
\end{note}

\begin{note}[Converse]
  \begin{quote}
    If the agent has \emph{not} witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\), then \(\pvp{\psi}{v'}{\Psi}\) is \emph{not}, in part, an answer \qHow{}.
  \end{quote}
  Given the weak interpretation of reasoning, if the agent has not transitioned from \(\Psi\) to \(\pv{\psi}{v'}\), then the pairing \(\pvp{\psi}{v'}{\Psi}\) is not relevant to the agent concluding.

  This is clearly violated in the case of \(\pvp{\phi}{v}{\Phi}\).
\end{note}

\begin{note}[Complex case]
  More generally, complex case.
\end{note}

\begin{note}[Weak]
  However, also designed to be fairly weak.
  Key qualifier is \emph{witnessed}.
  Do not require that the reasoning from \(\Psi\) to \(\pv{\psi}{v'}\) is part of the agent's present reasoning.
\end{note}

\begin{note}[Illustration]
  To illustrate, consider an agent working on some mathematical problem.

  As part of their work on the problem the agent concludes the hypotenuse of some right-angled triangle is \(\sqrt{74}\text{cm}\) by use of the Pythagorean theorem.

  Further, the agent has, at some point in the past proved the Pythagorean theorem from more basic principles.

  Now, generally speaking, it seems to me it may be the case that the agent concludes the hypotenuse of the triangle is \(\sqrt{74}\text{cm}\), in part, from those more basic principles.
  For example, the agent may have just completed their proof of the Pythagorean theorem and the reasoning from the more basic principles to the hypotenuse of the triangle may be considered a single unified instances of reasoning, with an intermediary conclusion.

  Still, suppose the agent proved the Pythagorean theorem some years ago.

  Perhaps the agent's reasoning from more basic principles continues to provide, in part, an answer to how the agent concluded the hypotenuse of the triangle is \(\sqrt{74}\text{cm}\).
  There may be a gap of some years, but it may be the case that the agent uses the Pythagorean theorem (in some sense of the word) \emph{because} they concluded the theorem from more basic principles.

  On the other hand, one may be inclined to hold that the more basic principles the agent proved the Pythagorean theorem from have no role in explaining how the agent concluded the hypotenuse of the triangle is \(\sqrt{74}\text{cm}\) in the present.
  Rather, the Pythagorean theorem is a more-or-less fundamental premise of the agent's present reasoning.

  At best, the agent's memory of reasoning from more basic principles to the Pythagorean theorem may, in part, answer how the agent concluded hypotenuse of the triangle is \(\sqrt{74}\text{cm}\).
  The reasoning from the more basic principles, given that it happened so long ago, is irrelevant.

  \autoref{idea:how-witnessing} is designed to allow either opinion on the agent's conclusion.
\end{note}

\begin{note}[Stronger idea]
  Note, \autoref{idea:how-witnessing} is a one-way conditional, and is therefore compatible with some idea restricting reasoning to the present.

  For example, one may hold:
  \begin{quote}
    \(\pvp{\psi}{v'}{\Psi}\) is, in part, an answer \qHow{}
    \emph{only if}
    the agent concluded \(\pv{\phi}{v}\), in part, by witnessing reasoning from \(\Psi\) to \(\psi\) having value \(v'\).
  \end{quote}
  For, it remains the case that the agent has witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\).
  A strong idea such as the one presented only limits \emph{when} the agent witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\).
\end{note}

\begin{note}
  Argue against positive resolution to \issueInclusion{}.
  Stronger idea, then in principle, easier counterexamples.

  For example, argue that more basic principles really are involved in explaining why.
  But, not how given stronger idea.

  With \autoref{idea:how-witnessing}, in order to motivate a negative resolution, \emph{no witnessing}.%
  \footnote{
    Further, won't rely on an agent having witnessed.
    Though, will not explore this.
    Have that paper on testimony, though.
  }
\end{note}


\begin{note}
  The point now is that I expand on a necessary condition to how.
  For, this is still somewhat intuitive.

  So, proposition-value-premises pairing is, in part, and answer to \qHow{} only if the agent has \emph{witnessed} reasoning from pool of premises to conclusion.

  Then, add in, that it's unclear to me exactly how well this fares with causal theories.
  \emph{However}, necessary rather than sufficient, and if stronger, then still relation.
  This, I already have an argument for.
\end{note}


\paragraph{Variant of \qHow{}}
\label{sec:clar:expand:qHow:variant}

\begin{note}
  Our interest is with answers to \qWhy{}, rather than providing an answer to \qWhy{}.
  For, answers to \emph{why} an agent concluded may be constrained by \emph{how} an agent concluded.
  In other words, answers to \qWhy{} may be constrained by answers to \qHow{}:

  \begin{question}[\qHowV{}]
    \label{q:how:v}
    Which proposition-value-premises pairing are such that the agent has witnessed reasoning in involved in explaining how the agent concluded \(\phi\) has value \(v\)?
  \end{question}

  What information was appealed to by the agent to conclude \(\phi\) has value \(v\)?

  Which premises did the agent use, which conclusions did the agent draw from those premises?

  For example, \autoref{illu:gist:calc}, agent concluded \(23 \times 15 = 345\) from the testimony of the calculator.
\end{note}

\begin{note}
  \begin{proposition}
    \label{prop:qHow-and-qHowV}
    For any conclusion-premises pairing \(\pvp{\phi}{v}{\Phi}\):

    \emph{If} \(\pvp{\phi}{v}{\Phi}\) is, in part, an answer to \qHow{} \emph{then} \(\pvp{\phi}{v}{\Phi}\) is, in part, an answer to \qHowV{}.
  \end{proposition}

  \begin{argument}
    So, this comes from lack of specification about what \qHow{} amounts to.
  \end{argument}

  \autoref{prop:qHow-and-qHowV} contrasts with~\autoref{prop:qWhy-and-qWhyV}.
  \qHowV{} and \qHow{} are not equivalent.
\end{note}

\begin{note}
    In contrast to \issueInclusion{}, \issueConstraint{} does not require a relation of support which answers \qWhy{} to involve a pool of premises drawn from the agent's present reasoning.
  Instead, so long as the agent has --- either through their present reasoning or in some past reasoning --- witnessed reasoning from the pool of premises to the conclusion, the relevant relation of support may answer \qWhy{}.
\end{note}

\paragraph{Summary}

\begin{note}
  So, necessary condition.
  Doesn't commit to witnessing as answer to how.

  Provide some suggestion of how this may work in \autoref{chap:twoc}.

  Primary motivation for this revision is that, as witnessing is necessary, \qHowV{} is weaker than \qHow{}.
\end{note}

\subsection{\issueInclusion{}}
\label{sec:clar:expand:issue}

\begin{note}
  \autoref{sec:clar:expand:qWhy} refined \qWhy{} in terms of support.
  \autoref{sec:clar:expand:qHow} refined, or perhaps weakened, \qHow{} in terms of witnessing.

  Interest in \qWhy{} and \qHow{} in terms of whether a constraint holds.

  \begin{quote}
    \vspace{-\baselineskip}
    \issueInclusionFirst*
  \end{quote}

  Introduced in~\autoref{cha:introduction}.
  Provided some intuitive motivation via \autoref{illu:gist:calc}.
  And, theoretical motivation via \citeauthor{Davidson:1963aa}' causal theory of action.
  In addition, \citeauthor{Boghossian:2014aa} when discussing support.

  Purpose of the present section is to bring refinements to questions together to provide refinement to \issueInclusion{}.

  The refined issue will be the focus.
\end{note}

\paragraph{Linking}

\begin{note}
  \begin{proposition}
    \label{prop:support-and-witnessing}
    Grating a positive resolution to \issueInclusion{}, and given \autoref{assu:why:support:pvpp} and \autoref{idea:how-witnessing}:
    \begin{itemize}
    \item
      A relation of support between \(\pv{\psi}{v'}\) and \(\Psi\) is, in part, an answer to why an agent concluded \(\pv{\phi}{v}\) from \(\Phi\).
    \end{itemize}
    \emph{Only if:}
    \begin{itemize}
    \item
      The agent has witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\).
    \end{itemize}
  \end{proposition}

  \autoref{prop:support-and-witnessing} is straightforward.
  A visual representation is given in~\autoref{fig:relations-between-whys-and-hows}.
\end{note}

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \tikzset{ansStyle/.style={
        draw=gray,
        text width=.45\textwidth,
        rounded corners=2pt,
      }
    }
    %
    \node[ansStyle] (whyO) at (0,0) %
    {\qWhyV{} is answered by support between \(\pv{\psi}{v'}\) and \(\Psi\).};
    %
    \node[ansStyle] (whyA) at (2,-1.5) %
    {\qWhy{} is answered by \(\pvp{\psi}{v'}{\Psi}\).};
    %
    \node[ansStyle] (howA) at (4,-3) %
    {\qHow{} is answered by \(\pvp{\psi}{v'}{\Psi}\).};
    %
    \node[ansStyle] (witA) at (6,-4.5) %
    {\qHowV{} is answered by witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\).};
    %
    \path[->] ($(whyO.south)!0.9!(whyO.south west)$) edge [out=270, in=180] (whyA);
    \path[->] ($(whyA.south)!0.9!(whyA.south west)$) edge [out=270, in=180] (howA);
    \path[->] ($(howA.south)!0.9!(howA.south west)$) edge [out=270, in=180] (witA);
    %
    \node[text width=.5\textwidth] (1) at (1,-.8) %
    {Via \autoref{assu:why:support:pvpp}.};
    %
    \node[text width=.75\textwidth] (2) at (4.5,-2.25) %
    {Via a positive resolution to \issueInclusion{}.};
    %
    \node[text width=.5\textwidth] (3) at (5,-3.625) %
    {Via \autoref{idea:how-witnessing}.};
    %
    \draw[->, gray] ($(whyA.north)!0.9!(whyA.north east)$) to [out=90, in=0] ($(whyO.east)$);
    %
    \node[text width=.5\textwidth, text=gray] (1p) at (8,-.8) %
    {Via \autoref{assu:why:pvpp:support}.};
  \end{tikzpicture}%
  \caption{Relation between positive answers to questions.}
  \label{fig:relations-between-whys-and-hows}
\end{figure}

\begin{note}
  \begin{idea}[Witnessing constraints support]
    A relation of support between \(\psi\) having value \(v'\) and some pool of premises \(\Psi\) is, in part, an answer to, why an agent concluded \(\phi\) has value \(v\) \emph{only if} the agent has witnessed reasoning from \(\Psi\) to \(\psi\) having value \(v'\).
  \end{idea}
\end{note}

\begin{note}
  Witnessing as a constraint on relations of support being, in part, an answer to why an agent concluded.
\end{note}

\paragraph{Variant of \issueInclusion{}}
\label{sec:clar:expand:issue:variant}

\begin{note}
  \begin{restatable}[\issueConstraint{}]{issue}{rIssueConstraint}
    \label{issue:has-witnessed}
    Is it the case that:

    A relation of support between \(\psi\) having value \(v'\) and some pool of premises \(\Psi\) is, in part, an answer to, why an agent concluded \(\phi\) has value \(v\) \emph{only if} the agent has witnessed reasoning from \(\Psi\) to \(\psi\) having value \(v'\).
  \end{restatable}

  {
    \color{red}
    \issueConstraint{} generalises \issueInclusion{} in two ways.
    \begin{itemize}
    \item
      Current reasoning.
    \item
      Other support relations.
    \end{itemize}
  }

\end{note}

\begin{note}
  Difficulty with all of this is that the accounts seem to be consistent, but do not explicitly motivate this constraint.
\end{note}

\begin{note}
  An additional example, \citeauthor{Hieronymi:2011aa}
  \begin{quote}
    The proposal starts with this simple thought: whenever an agent acts for reasons, the agent, in some sense, takes certain considerations to settle the question of whether so to act, therein intends so to act, and executes that intention in action.

    If this much is uncontroversial (and, under some interpretation, I believe it must be), we can use it as a form for filling out.
    I propose, then, that we explain an event that is an action done for reasons by appealing to the fact that the agent took certain considerations to settle the question of whether to act in some way, therein intended so to act, and successfully executed that intention in action.
    I suggest that \emph{this} complex fact, \dots is the reason that rationalizes the action---that explains the action by giving the agent‚Äôs reason for acting.%
    \mbox{ }\hfill\mbox{(\citeyear[431]{Hieronymi:2011aa})}
  \end{quote}

  From the deliberation.

  So, reason is the complex fact.
  Complex fact gives the reason the agent acted, and so content of constituent considerations from agent's point of view.
\end{note}

\paragraph{Negative resolution}

\begin{note}
  Converse, then either reject ideas or negative resolution to \issueInclusion{}.
\end{note}

\begin{note}
  Argument here that the break should be with positive resolution.

  How and witnessing link, nothing to this.

  So, either support and why or why and how.

  Support and why, fairly straightforward.
\end{note}


\paragraph*{Quick argument}

\begin{note}
  More generally, a quick argument for witnessing is that conclusion needs to come from somewhere.
\end{note}

\begin{note}[The general pre-theoretic argument]
  At least, the positive resolution is not straightforward without placing some constraints on \emph{which} premises an agent may appeal to when reasoning, and we will motivate the positive resolution without such constraints.

  For, without constraints on which premises an agent may appeal to when reasoning, one may argue as follows:
  \begin{enumerate}
  \item
    Any instance of reasoning is some process with start and end points and intermediary steps.
  \item
    If an agent has concluded \(\phi\) has value \(v\) by some reasoning, then the reasoning has start points and intermediary steps.
  \item
    Hence, the agent has concluded \(\phi\) has value \(v\) by witnessing some reasoning from some start points via some intermediary steps.
  \item
    In other words, the agent has concluded \(\phi\) has value \(v\) by witnessing some reasoning from some premises.
  \end{enumerate}

  In short, so long as an agent has concluded \(\phi\) has value \(v\), the agent has always witnessed reasoning from some premises.

  \begin{enumerate}[resume]
  \item
    So, either the start points are the premises of interest mentioned in the issue, or the agent has concluded \(\phi\) has value \(v\) from a distinct set of premises.
  \end{enumerate}

  In other words, either the agent has witnessed reasoning from the premises of interest, or the premises of interest (and any reasoning from them) are not required to conclude \(\phi\) has value \(v\).
\end{note}

\begin{note}[More on the quick argument]
  The quick argument does not directly lead to a negative resolution to the issue.
  Still, the quick argument does suggest that any appeal to premises \emph{without} witnessing reasoning from those premises is redundant.

  Now, perhaps redundancy isn't so bad.
  I only need a single key to ensure I have the option of unlocking a door, but a second key is useful if the first is lost.

  Still, I take it to be the case that redundancy provides leverage for a wide range of arguments motivating a negative resolution in the case of reasoning.

  For, if appeal to some premises is redundant, then any argument that requires witnessing need only observe that a counterargument must find some role for something which is not needed.

  Reasoning is an event, and distinct way of concluding \(\phi\) has value \(v\) may be useful, it is unclear why the distinct way of concluding \(\phi\) has value \(v\) is of use when concluding \(\phi\) has value \(v\) from present premises.
  To push the analogy, a second key may have various uses, but the second key is irrelevant in the event of unlocking the door with the first key.
  That the second key is would unlock the door if the first was lost has no role in the event of unlocking the door with the first key.

  From a different perspective, if appeal to certain premises without witnessing reasoning from those premises is redundant, then it seems any positive role given to appeal to those premises may be redistributed to the premises of the reasoning the agent did witness.

  More concretely, even if I were to show that there was some benefit for concluding \(\phi\) has value \(v\) via unwitnessed reasoning with respect to some particular account of reasoning, it seems at least plausible that the account of reasoning may be reformulated to derive the same benefit from the premises of the reasoning the agent witnessed.

  More generally, it may seem (and I suspect it does seem) intuitive that the issue should be resolved negatively.
  Reasoning just is obtaining a conclusion by witnessing reasoning from premises.
  And, if the quick argument succeeds, then there surely is some way to preserve the intuition.
\end{note}

\begin{note}
  So, part of the task is to show that the quick argument fails.
  Concluding \(\phi\) has value \(v\) from certain premises without witnessing reasoning that concludes \(\phi\) has value \(v\) from those premises has some role.
  Or, rather, that the quick argument is not without cost.
  Perhaps the issue really should be resolved in the negative, but this will require giving up some at least equally (I think) intuitive ideas.

  The result will be motivation for a positive resolution to the issue.
  However, the motivation will be somewhat narrow.
  To escape the tension, the positive resolution need only hold for a restricted pattern of reasoning.
  Still, with the existential motivated, I hope future work may expand the positive resolution to other patterns of reasoning.
  And, while such expansions may still need to argue that concluding \(\phi\) has value \(v\) from unwitnessed reasoning is makes sense with respect to the specific topic at hand, observing that the broad idea of concluding \(\phi\) has value \(v\) from unwitnessed reasoning may not be dismissed without cost may be an option.
\end{note}

\paragraph*{Summarising}

\begin{note}[Pre-theoretical constraint]
  Issue captures intuitive constraint of no account of why without an account of how.
  Witnessing a pre-theoretical constraint.

  Broader than causation.
\end{note}

\begin{note}
  `Use'.

  Negative resolution, some pool of premises, why.
  Yet, agent does not have a specific account of how.
\end{note}

\subsection{Summary}
\label{sec:clar:expand:issue:summary}

\begin{note}
  Three key things.

  Support.
  Witnessing.
  Issue.
\end{note}

\begin{note}
  Focus on \issueConstraint{}.
  \vspace{-\baselineskip}
  \begin{quote}
    \rIssueConstraint*
  \end{quote}
  Sufficient clarity on both `why?' and `how?'.
  Link we have argued for.
  And, further, independently of argument, it seems to me that a positive resolution to \issueConstraint{} is equally compelling as positive resolution to \issueInclusion{}.
\end{note}

\begin{note}
  This is the important thing, and in this respect it doesn't matter whether past or present.
  Whether a relation of support holds only if witnessed.
  Whether resolution to \qWhy{} only if the agent has witnessed.
\end{note}

\section{The type of \scen{0} we will focus on}
\label{sec:clar:type-of-scen}

\begin{note}
  In this section, type of \scen{0} we will focus on.
  \begin{itemize}
  \item
    Instance of \scen{0}.
  \item
    General characterisation of type of \scen{0}.
  \item
    Comparison, highlighting key features.
  \item
    Additional examples.
  \end{itemize}
\end{note}

\subsection{An example of the type of \scen{0}}

\begin{note}
  \begin{scenario}[Quadratic roots]
    \label{illu:gist:roots}
    An agent is given the following statement:

    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item
      \label{illu:gist:roots:eq}
      For some \(x \in \mathbb{R}\), \(2x^{2} - x - 1 = 0\).
    \end{enumerate}

    The agent reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume, itemsep=.125em]
    \item
      \label{illu:gist:roots:qf}
      The quadratic formula is \(x = \frac{-b \pm \sqrt{b^{2} - 4ac}}{2a}\) \hfill Memory
    \item
      \label{illu:gist:roots:subs}
      \(a = 2\), \(b = -1\), \(c = -1\) \hfill \ref{illu:gist:roots:eq}, How to use \ref{illu:gist:roots:qf}%
      \footnote{
        \(a\) is the coefficient of the \(x^{2}\) term, \(b\) is the coefficient of the x term, and \(c\) is the constant.
      }
    \item
      \label{illu:gist:roots:qf-subs}
      \(x = \frac{-(-1) \pm \sqrt{(-1)^{2} - 4(2)(-1)}}{2(2)}\) \hfill \ref{illu:gist:roots:qf}, \ref{illu:gist:roots:subs}, Substitution
    \item
      \label{illu:gist:roots:qf:1}
      \(x = \sfrac{(1 \pm 3)}{4}\) \hfill \ref{illu:gist:roots:qf-subs}, Simplification
    % \item
    %   \label{illu:gist:roots:qf:3}
    %   \(x = \sfrac{(1 + 3)}{4}\) or \(x = \sfrac{(1 - 3)}{4}\) \hfill \ref{illu:gist:roots:qf:1}, Expansion
    \item
      \label{illu:gist:roots:qf:done}
      \(x = 1\) or \(x = -\sfrac{1}{2}\) \hfill \ref{illu:gist:roots:qf:1}, Expansion, Simplification
    \end{enumerate}
    Hence, the agent concludes: if \(2x^{2} - x - 1 = 0\), \(x = 1\) or \(x = -\sfrac{1}{2}\).

    \mbox{ }

    Still, prior to concluding \(x = 1\) or \(x = -\sfrac{1}{2}\), the agent observed that \emph{if} \(x = 1\) or \(x = -\sfrac{1}{2}\), then they would also be able to observe this via factorisation.
  \end{scenario}

  The particular details of \autoref{illu:gist:roots} are present primarily to present a clear instance of reasoning.
  For present purposes, our interest is with steps \ref{illu:gist:roots:qf}, \ref{illu:gist:roots:subs}, and \ref{illu:gist:roots:qf-subs}.

  Intuitively, the agent concludes `\(x = 1\) or \(x = -\sfrac{1}{2}\) if \(2x^{2} - x - 1 = 0\)' in part from their understanding of arithmetic.
  And, in particular, from their understanding of the quadratic formula and how to use it.

  Further, as the agent does not derive the quadratic formula from more basic principles, the quadratic formula is, intuitively, a premise of the agent's reasoning.
\end{note}

\begin{note}
  Now, in the same way the agent may have calculated \(23 \times 15 = 345\) without the aid of a calculator in \autoref{illu:gist:calc}, the agent may have concluded \(x = 1\) or \(x = -\sfrac{1}{2}\) if \(2x^{2} - x - 1 = 0\) without the aid of the quadratic formula in~\autoref{illu:gist:roots}.

  For example, consider the following variant steps:
  \begin{quote}
    \begin{enumerate}[label=\arabic*\('\)., ref=(\arabic*\('\)), itemsep=.125em]
      \setcounter{enumi}{1}
    \item
      \label{illu:gist:roots:factor}
      \((2x + 1)(x - 1) = 0\) \hfill \ref{illu:gist:roots:eq}, Factoring
    \item
      \label{illu:gist:roots:zero}
      Either \((2x + 1) = 0\) or \((x - 1) = 0\) \hfill \ref{illu:gist:roots:factor}, Arithmetic
    \item
      \label{illu:gist:roots:case:a}
      If \((x - 1) = 0\), then \(x = 1\) \hfill \ref{illu:gist:roots:factor}, \ref{illu:gist:roots:zero}, Arithmetic
    \item
      \label{illu:gist:roots:case:b}
      If \((2x + 1) = 0\), then \(x = -\sfrac{1}{2}\) \hfill \ref{illu:gist:roots:factor}, \ref{illu:gist:roots:zero}, Arithmetic
    \item
      \label{illu:gist:roots:factor:done}
      Either \(x = 1\) or \(x = -\sfrac{1}{2}\). \hfill \ref{illu:gist:roots:zero}, \ref{illu:gist:roots:case:a}, \ref{illu:gist:roots:case:b}, Replacement
    \end{enumerate}
  \end{quote}

  Steps~\ref{illu:gist:roots:factor} to~\ref{illu:gist:roots:factor:done} yield the same results as steps~\ref{illu:gist:roots:qf} to~\ref{illu:gist:roots:qf:done}, but do not involve the quadratic formula.
\end{note}

\begin{note}
  Intuitively, did not conclude from a pool of premises which does not include the quadratic formula.
\end{note}

\begin{note}
  \scen{3}~\ref{illu:gist:calc} and~\ref{illu:gist:roots} are similar.
  Broadly, both involve an agent concluding \(\phi\) has value \(v\) from some pool of premises \(\Phi\) and an option for the agent to conclude \(\phi\) has value \(v\) from some distinct set of premises \(\Phi'\).

  The key difference between \scen{1}~\ref{illu:gist:calc} and~\ref{illu:gist:roots} is how concluding \(\phi\) has value \(v\) from \(\Phi'\) relates to the agent's conclusion of \(\phi\) having value \(v\) from \(\Phi\).
  Roughly, in \scen{0}~\ref{illu:gist:calc} the alternative reasoning relates to the premises \(\Phi\), while in \scen{0}~\ref{illu:gist:roots} the alternative reasoning relates to the reasoning from \(\Phi\) to \(\phi\) having value \(v\).

  This, noted.

  Argue this type of \scen{0} motivates negative resolution to \issueConstraint{}, and, by extension, \issueInclusion{}.

  Intuitions are difficult.
  Motivation will focus on:
  \begin{itemize}
  \item
    Conditional
  \item
    \fc{0}
  \end{itemize}

  Turn to sketching the general argument.

  Still, while we are here, abstract form of \scen{1}, a few additional examples, and a handful of contrasting examples.
\end{note}

\subsection[General characterisation]{A general characterisation of the type of \scen{0}}

\begin{note}
  Strictly, the key properties of the type of \scen{0} we are interested in concern an agent's epistemic state just prior to the agent concluding some proposition-value pair from some pool of premises.
\end{note}

\begin{note}
  \begin{scenarioType}[(Partial) check on reasoning-scenarios \hfill \cScen{1}]
    \label{scenType:CoR}
    \mbox{ }

    An agent \vAgent{} has concluded some proposition \(\phi\) has some value \(v\) from some pool of premises \(\Phi\).

    And, \emph{prior} to concluding \(\phi\) has value \(v\) from \(\Phi\), it was the case that:
    \begin{itemize}
    \item
      From \vAgent{}' perspective, if \(\phi\) has value \(v\) then:
      \begin{itemize}
      \item
        There is some proposition-value pair \(\psi\) having value \(v'\) and pool of premises \(\Psi\) such that:
        \begin{itemize}
        \item
          If the \vAgent{} were to fail to conclude that \(\psi\) has value \(v'\) from \(\Psi\) prior to concluding, \vAgent{} would not conclude \(\phi\) has value \(v\) from \(\Phi\).
        \end{itemize}
      \end{itemize}
    \end{itemize}
    \vspace{-\baselineskip}
  \end{scenarioType}

  {
    \color{red}
    Slight variation on \citeauthor{Tolliver:1982us}'s Pendulum Case.%
    \footnote{
      Understood \citeauthor{Tolliver:1982us}'s case only after.
    }
    Similar to \citeauthor{Tolliver:1982us}, though a difference.
  For, here, not lacking information.
  With the pendulum, didn't have the option of concluding from period, as didn't have information about period.
  }

  For ease of reference, we term scenarios of this type `\cScen{1}', where `CoRe' stands for `check on reasoning', or more carefully `partial check on reasoning'.

  The key feature of \cScen{1} is that prior to concluding \(\phi\) has value \(v\) from \(\Phi\), the agent has the option of reasoning about some other proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\), such that, from the agent's perspective, failure to conclude \(\psi\) has value \(v'\) from \(\Psi\), the agent would not conclude \(\phi\) has value \(v\) from \(\Phi\).

  In this respect, the agent reasoning about whether \(\psi\) has value \(v'\) is a partial check on whether it makes sense for the agent, from their present perspective, to conclude \(\phi\) has value \(v\) from \(\Phi\) given the reasoning they have performed.

  In other words, the proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\) is a partial check on the agent's reasoning from \(\Phi\) to \(\phi\) having value \(v\).

  We expand on this in three steps.
  First, why \(\pvp{\psi}{v'}{\Psi}\) is a \emph{check}.
  Second, why \(\pvp{\psi}{v'}{\Psi}\) is a check \emph{on reasoning}.
  And, finally, why \(\pvp{\psi}{v'}{\Psi}\) is a \emph{partial} check on reasoning.
\end{note}

\begin{note}[Check]
  Agent has the option.
  Something went wrong with the reasoning from premises to conclusion.
\end{note}

\subsection{Contrast to inital \scen{0}}

\begin{note}
  \color{blue}
  The important contrast is whether the conditional holds.
  This is not at all clear in first \scen{}.
  Though, if, for example, building the calculator, it may.

  Right, as noted below, then it's not clear the agent gets the equation via testimony.

  There's also observation about conflict with premises.
  However, I don't think this can be right.

  Really, the important thing is that the reasoning is `internal'.
  Could test the calculator, but this isn't just about the agent's reasoning.
\end{note}

\begin{note}
  On the agent's reasoning.

  The key contrast here is between \scen{1}~\ref{illu:gist:roots} and~\ref{illu:gist:calc}.

  Difference is how failure relates to the premise.

  With \autoref{illu:gist:calc}, testimony.
  It seems, if testimony, then it is not possible to satisfy the conditional.
  In other words, if the conditional holds, then it seems the agent doesn't have \(23 \times 15 = 345\) by testimony.

  With \autoref{illu:gist:roots}, quadratic formula.
  Fail to conclude from factorising, but this would not involve revising premise.
  Rather, reasoning from premises.
  For example, application of quadratic formula to the quadratic equation.
  Or, reduction of the quadratic equation.

  Reasoning from premises, rather than premises.

  Way this is captured, concluding \(\phi\) has value \(v\) from \(\Phi\).
  Agent would not conclude, because revise either testimony or understanding of arithmetic.
  However, remains the case that \emph{given} testimony, agent would conclude.

  The conditional focuses on the relation between premises and conclusion.
\end{note}

\begin{note}
  In addition, relative to \(\phi\) having value \(v\).
  Checking that the conclusion does indeed follow from the premises.

  This property is shared in both examples.
  However, narrows things down.

  Case in which agent could reason about premises further.
\end{note}

\begin{note}
  Partial.
  Failure to conclude \(\psi\) has value \(v'\) from \(\Psi\).
  Nothing about successfully concluding \(\psi\) has value \(v'\) from \(\Psi\).
  In general, other considerations against concluding \(\phi\) has value \(v\) from \(\Phi\).
  With respect to \cScen{1}, other proposition-value-premises pairings for which the same holds.
\end{note}

\begin{note}
  \color{red}
  Though we observed a slight contrast between \scen{1}~\ref{illu:gist:roots} and~\ref{illu:gist:calc} given the differing roles of the testimony of the calculator and the quadratic formula in the agent's reasoning, these variant steps highlight a key parallel.

  For, in~\autoref{illu:gist:calc} we noted the agent may have concluded \(23 \times 15 = 345\) without the testimony of the calculator.
  And, so long as the agent understands factorisation, a parallel statement holds for~\ref{illu:gist:roots}:
  The agent may have concluded \(x = 1\) or \(x = -\sfrac{1}{2}\) if \(2x^{2} - x - 1 = 0\) without the aid of the quadratic formula in~\autoref{illu:gist:roots}.
\end{note}

\begin{note}
  \scen{3} \ref{illu:gist:calc} and \ref{illu:gist:roots} both fit this pattern of a partial check.

  \autoref{illu:gist:calc}, agent's understanding of arithmetic, whether to trust the calculator.

  \autoref{illu:gist:roots}, factorising instead of applying the quadratic formula.

  In both these cases, \(\phi\) and \(\psi\) are the same proposition, and \(v\) and \(v'\) are the same value.
  Difference is the pools of premises.
\end{note}

\subsection{Additional examples}

\subsubsection{\cScen{3}}

\begin{note}[Propositional logic]
  \begin{scenario}
    \label{illu:sketch:prop-logic}
    Suppose an agent has a good grasp of propositional logic.
    In particular:
    \begin{itemize}
    \item
      The agent has a good understanding of some formal proof system.
      For example, some Fitch-style system.
    \item
      The agent has a good understanding of some method to construct semantic proofs.
      For example, by constructing truth tables, or reasoning about valuation functions.
    \item
      The agent understands the proof system is sound and complete.
      That is to say, the agent understands there exists a proof of some sentence \(A\) \emph{if and only if} \(A\) is true given an arbitrary valuation.
    \end{itemize}
    The agent constructs a proof of \(A\).

    Given the agent's understanding of propositional logic, the agent observes:
    \begin{quote}
      The construction is a proof of \(A\) \emph{only if} \(A\) is true given an arbitrary valuation.
    \end{quote}
  \end{scenario}

  Intuitively, if the agent were to reason about whether \(A\) is true given an arbitrary valuation and failed to conclude \(A\) is true given an arbitrary valuation, then the agent would not conclude the construction is a proof of \(A\).

  If were to go for semantic, then by soundness, works out.
\end{note}

\begin{note}[Interest]
  Delicate, the equivalence result is not in question.
  What's at issue is one's reasoning.
  The result tells me that if reasoning is fine for syntax, then also semantics and vice-versa.
\end{note}

\begin{note}[Programming]
  \begin{scenario}
    \label{illu:programming}
    Writing a program to automate some reasoning/processing of data.
  \end{scenario}
  Various test cases.
  In these, possible to do the reasoning oneself.
  Therefore, no appeal to program for these simple cases, at least.
  This is quite similar to the logic illustration in this sense.

  However, interest here as interdependence breaks down in interesting ways.
  For, may break down due to resource constraints.
  E.g.\ available time or complexity of inputs.

  And, after enough time with the program, failure to obtain the same result is not clearly going to indicate a problem with the program.
  Rather, one's reasoning.
  Though, in turn, this may be reversed after enough checking of the reasoning.
\end{note}

\begin{note}
  Three examples which follow basic pattern.
  All these involve reasoning which is both deductive and formal.
  Contingent feature.
  Straightforward to identify related proposition-value-premises pairings and motivate the option of reasoning with the related pairing.%
  \footnote{
    Note, in particular, non-deductive reasoning is fine.
    For, present epistemic state.
    May be the case that some novel information would overturn conclusion.
    However, novel information would require a revised epistemic State.
  }

  Favour these features in \scen{1} and examples as fairly general.
  Particular constants chosen are easily replaced.
  And, easy to find similar.%
  \footnote{
    For example, consider calculating exponents.
    One may calculated \(x^{n} \times x^{m}\) directly, or appeal to \(x^{n} \times x^{m} = x^{n + m}\).
 
    Also relatively simple, but there are a wealth of more complex examples.

    For example:
    See~\textcite{Fine:1997vc} for three distinct proofs of the fundamental theorem of algebra (i.e.\ any complex polynomial must have a complex root).
    Likewise, \textcite{Ribenboim:2012ts} contains eight proofs that their exist infinitely many prime numbers.
    And, \textcite{Wagon:1987vm} details fourteen proofs of a result about tiling a rectangle (specifically, whenever a rectangle is tiled by rectangles each of which has at least one integer side, then the tiled rectangle has at least one integer side).
  }
\end{note}

\begin{note}
  Simplify~\ref{illu:gist:roots} as a slight variation on~\ref{illu:gist:calc}.

  \begin{restatable}[\(\times\) and \(\div\)]{scenario}{scenarioClacMulDiv}
    \label{illu:sketch:math}
    An agent calculates \(345 \div 15 = 23\) via their understanding of arithmetic.

    \mbox{ }

    Given the agent's understanding of arithmetic, the agent observes:
    \begin{quote}
      \(345 \div 15 = 23\) \emph{only if} \(23 \times 15 = 345\).
    \end{quote}
    And, \emph{if} \(345 \div 15 = 23\), then they would not fail to conclude \(23 \times 15 = 345\).

    \mbox{ }

    The agent concludes \(345 \div 15 = 23\).
  \end{restatable}
\end{note}

\subsubsection{Non-\cScen{1}}

\begin{note}[Serial number]
  \begin{scenario}
    \label{illu:number-check}
    Handed a credit card.
    Conclude, will be able to bill after repairs are done.
  \end{scenario}

  Fairly straightforward partial check on whether the credit card is usable by applying the Luhn algorithm to check whether the credit card number is valid.
  Applying the Luhn algorithm requires only basic addition and multiplication.%
  \footnote{
    To illustrate.
    Credit card number is:
    \(4676\) \(2250\) \(1000\) \(0626\).
    Array:
    \([4,6,7,6,2,2,5,0,1,0,0,0,0,6,2]\)
    For every even index of the array (index from \(0\)), multiply the number by two, and add the resulting digits together if the results is greater than ten.
    \([8,6,5,6,4,2,1,0,1,0,0,0,0,6,4]\)
    Add elements of the array together with the check digit.
    Valid only if the result is equal to a multiple of ten.
  }
  However, if the agent is not aware of that the Lund algorithm may be applied to check whether the credit card number is valid, the agent will not have the option of checking given their present epistemic state.
\end{note}

\begin{note}[Calculator B]
  \begin{scenario}[Calculator B]
    \mbox{}
    \vspace{-\baselineskip}
    \begin{itemize}
    \item
      Calculation
    \item
      Only if calculator.
    \end{itemize}
  \end{scenario}

  Problem, not by reasoning alone.

  Here, reverse of original scenario.
  Problem is, using the calculator is not the agent's own reasoning.

  Interesting, and is a check in the same way.
  But, falls outside scope of interest.

  Similar, any instance of looking at solutions.
  So, for example, textbook with worked solutions.

  Taking a photo with a disposable camera.
  Only if, conclude negative is present on reel.
\end{note}

\section{Summary}

\paragraph*{Interest}

\begin{note}
  As seen from \illu{1}~\ref{illu:gist:calc} and \ref{illu:gist:roots}, there is an intuitive sense in which an agent concluding some proposition \(\phi\) has some value \(v\) involves certain pools of premises and does not involve other pools of premises.

  Calculator, understanding of arithmetic.
  Quadratic formula, factorisation.

  I am somewhat unsure about the intuitions expressed with respect to \scen{1} like~\autoref{illu:gist:calc}.
  However, I quite unsure about the intuitions expressed with respect to \scen{1} like~\autoref{illu:gist:roots}.
\end{note}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
