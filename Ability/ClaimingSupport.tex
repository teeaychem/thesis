\chapter{\support{2} and claiming support}
\label{cha:claiming-support}

\begin{note}
  \color{red}
  Note somewhere that the step doesn't have to be deductive.
\end{note}

\paragraph*{Overview}

\begin{note}
  The present chapter is about claiming support.
  Or, more precisely, claiming support and claimed support --- we are interested in both an activity and the result of that activity.

  The purpose of the following discussion of claiming support with respect to the {\color{red} overall project} is as follows:

  Reasoning with ability, obtaining some conclusion.
  Incompatible with intuitive understanding of part of such reasoning and, in particular, an common idea appealed to in various arguments.

  In order to make such an argument we require some background constraints on such reasoning.
  Hence, in this chapter we work though those background constraints.

  This then provides sufficiently precise context for {\color{red} ???} in which we state in detail what we arguing against, and what we are arguing for.
  And, provide background for~\autoref{part:tension} in which we argue for a principle restricting claiming support (specifically \autoref{sec:second-conditional}).

  And, as part of providing sufficiently precise context will include a rough template of the considerations which motivate argument.

  In other words, context, and also preview.
\end{note}

\begin{note}
  Two things to keep in mind.

  \begin{enumerate}
  \item These constraints are partial.
  \item Consequence of constraints that matters.
  \end{enumerate}

  Enough to identify certain ways in which an agent may fail to perform the reasoning of interest.

  Benefit of not building in `too much'.

  However, also possible to endorse additional constraints.
  In particular, rule out alternative.
  If so, also a problem.
  We will not give much attention to this.
  Argument rests on plausibility when applied to particular case.
  If agree with constraints and agree with particular case, then this is an indirect argument against stronger constraints.
\end{note}

\section{Epistemic states}
\label{sec:epistemic-states}

\begin{note}
  What an epistemic state is.
\end{note}

\begin{note}
  \begin{restatable}[An epistemic state]{definition}{defEState}
    An epistemic state is a collection of \world{1}, with:
    \begin{enumerate}
    \item \epVW{3}
    \item \epPW{3}
    \end{enumerate}
    Where,
    \begin{itemize}
    \item \epVW{3} are candidates for the actual \world{}.
    \item \epPW{3} are candidates for the actual \world{}, if the actual world is not an \epVW{0}.
    \end{itemize}
  \end{restatable}
\end{note}

\begin{note}
  \world{3}, plausibility ordering.
  Here,
  However, binary ordering.
  And:
  allow that ordering may be world dependent.
  do not require that the actual world is among the most plausible.
\end{note}

\paragraph{\epPN{3} and \epVN{1}}

\begin{note}
  In these examples, \PAd{0} rather than possible.
  \PAd{2} does not mean `likely'.

  This is a somewhat imprecise distinction, but it helps to narrow focus.
  It is possible, but not \PAd{0}, that there is no external world.
  It is possible, but not \PAd{0}, that the moon does not exist.
  It is possible, but not \PAd{0}, that the clock on my phone is incorrect.

  And so on.

  Move from extreme to less extreme.

  Plausibility is somewhat arbitrary, conspiracy theories, etc.
  Nothing in the paper rests on this distinction.
  However, clarify focus.
\end{note}

\begin{note}
  Not interested in sceptical scenarios.
\end{note}

\section{`Claiming'}
\label{sec:claiming}

\begin{note}[Introducing support]
  Initial clarification is with respect to claiming support.
  Emphasis on `\emph{claim}'.

  The thesis is not about when and why an agent has \emph{support}.

  There are three primary reasons why we focus on claimed support.

  First, neutral for main thread of argument on what support amounts to.
  Interest is with structure of claim, and background assumption that if success in claiming then structure of support follows structure of claim.

  Second, whether or not an agent has support often seems secondary.
  It may be that any claimed support for a proposition is support for that proposition, but perhaps not.
  \begin{illustration}[A box of flan(nels)]
    \label{illu:flan-nels}
    Suppose `flan' is written on the side of a container.
    I may claim support that the container contains flan.
    And, it may be that the writing on the side of the container is support for the box containing flan.
    However, the straps ensuring the container remains closed is unfortunately placed, and if moved would reveal the side of the container reads `flannels'.
  \end{illustration}

  The unfortunate placing of the straps does not seem to prevent \emph{claiming} support, but I'm not sure whether it is right to say that the writing on the side of the box (straps in place) \emph{does} provide support that the box containing flan.
  So, speaking in terms of claiming support leaves open whether what is claimed reflects on whether an agent has support.\nolinebreak
  \footnote{
    In particular, claiming allows focus on internal constrains, while remaining silent on whether having support is (in part) determined by external factors.
  }
  \(^{,}\)\nolinebreak
  \footnote{
    Distinction between propositional and doxastic support.
    Propositional, support agent has whether or not made a claim.
    Doxastic is successful claim and propositional support.
    So, both require that the agent has support.
    Claimed support is the agentive component of doxastic support.
    Not interested in whether the agent also has propositional support, though more or less assume.
  }
  \(^{,}\)\nolinebreak
  \footnote{
    {
      \color{red}
      English is somewhat difficult.
      It is somewhat unfortunate that `an agent has claimed support for \(\phi\)' may be read `there is support which the agent has claimed for \(\phi\)'.
      Still, this seems to follow more easily from `support claimed'.
      So, `claimed support' emphasises the claim, while `support claimed' emphasises support.
    }
  }

  Third, and following from the second, focusing on claimed support allows us to make no assumption about the relationship between claimed support and support.
  To elaborate, consider enthymematic inferences.
  One may hold that an agent may claim support for some conclusion via enthymematic inference, but hold that the support the agent has is understood from the perspective of the (corresponding) complete inference.\nolinebreak
  \footnote{
    Cf.\ \textcite{Moretti:2019wx}.
  }
  Alternatively, one may hold that the enthymematic argument is an adequate support relation (at least with respect to context in which the inference was made).

  Hence, one may question whether the structure of claimed support follows the structure of support.

  An important consequence of this final point is that we will only be interested in why (and when) an agent claims support for and from ability rather than why (or when) an agent \emph{has} an ability.
\end{note}

\section{Basic assumptions}
\label{sec:basic-assumptions}

\begin{note}
  Overview of basic assumptions.
\end{note}

\subsection{Culmination of reasoning}
\label{sec:basic-assumptions:culmination-of-reasoning}


\paragraph{Simplifying}

\begin{assumption}[Simplifying assumption]
  \label{assu:simplifying:epPAlways}
  ???
\end{assumption}

\begin{note}
  Say more below.
  If an agent concludes \(\phi\) has value \(v\), we hold that constrains \epVW{1} to \(\phi\) having value \(v\).
  We assume, for simplicity, that concluding \(\phi\) has value \(v\) will only lead to any incompatible proposition-value pair being relegated to \epPAd{}.
  Nothing in principle hangs on this, only adding additional qualifications to the relevant ideas, notions, assumptions, and definitions.
\end{note}

\section{Ideas regarding support, and claiming support}
\label{sec:two-ideas}

\begin{note}
    In \autoref{sec:basic-assumptions} we made three assumptions regarding the kind of thing claiming support it.
  In the present section we introduce two ideas to narrow down the type of thing claiming support is.
\end{note}

\begin{note}
  From \autoref{assu:CSVP}, claiming support is an instance of reasoning that concludes that some proposition \(\phi\) has some value \(v\).
  Again, the conclusion of an instance of claiming support is \emph{unqualified}.
  If an agent concludes that the grass is wet, then the agent has claimed support that the grass is wet.
  The agent has not (merely) concluded that the grass is wet so long as it rained last night, or that the sun is not to warm, etc.\

  Still, \autoref{assu:CSVP} only places a restriction on how an instance of reasoning concludes.
  To illustrate, it is compatible with \autoref{assu:CSVP} that an agent concludes that the grass is wet arbitrarily.
  Consider:
  \begin{enumerate}
  \item\label{ex:assu:CSVP:lim:1} Birds are singing, so the grass is wet.
  \item\label{ex:assu:CSVP:lim:2} I dreamt of rain, so the grass is wet.
  \end{enumerate}
  It is not clear how birds signing or dreams of rain relate to the grass being wet, but \autoref{assu:CSVP} is satisfied given that the conclusion of both~\ref{ex:assu:CSVP:lim:1} and~\ref{ex:assu:CSVP:lim:2} is that the grass is wet.
\end{note}

\begin{note}[Support]
  To narrow claiming support further start with \support{}.
  \ideaS{} states a necessary condition for an agent having support for some proposition-value pair.
  Roughly, an agent has \support{} for \(\phi\) having value \(v\) \emph{only if} the agent would conclude \(\phi\) has value \(v\) were the agent to reason from any \epPW{0}.

  \hozline

  This is a substantial idea, but the constraint it places should not be overestimated.
  First, this idea does not require that an agent has support for \(\phi\) having value \(v\) only if \(\phi\) has value \(v\).
  Second, this idea does not constrain how or why the agent would conclude \(\phi\) has value \(v\) from any \epPW{0}.

  Still our interest is with what \ideaS{} rules out, rather than with what \ideaS{} permits.
  And, \ideaS{} rules out claiming support if some \epPW{} such that the agent would not conclude \(\phi\) has value \(v\).

  Whether or not an agent has \support{} for conclusions of the (seemingly) arbitrary instances of reasoning \ref{ex:assu:CSVP:lim:1} and \ref{ex:assu:CSVP:lim:1} is, in general, independent of the particular way in which the agent has reasoned to the conclusion.
  For, it may be that the agent only needs to reflect that they are standing barefoot on the lawn, and their feet are wet.
\end{note}

\begin{note}[Claiming support]
  Indeed, we will have no interest in whether an agent \emph{has} \support{0} for any particular proposition-value pair.
  Rather, the role of \ideaS{} is to motivate a necessary condition on \emph{claiming} support.

  \hozline

  Though, strictly speaking, they are compatible.
  It may be the case that the agent would conclude that the grass is wet from bird song \emph{even if} the grass is not wet.
  And, perhaps, the agent may hold that their dreams of rain do distinguish between wet and dry grass.
\end{note}

\section{\ideaS{0}}
\label{sec:ideaS}

\begin{note}[Overview of \ideaS{}]
  Above we paraphrased \ideaS{} as holding that that an instance of reasoning that concludes \(\phi\) has value \(v\) is an instance of claiming support for \(\phi\) having value \(v\) \emph{only if} the agent would conclude \(\phi\) has value \(v\) were it to be the case that the actual \world{} is some \epPW{}.
\end{note}


\begin{note}
  The present section will be divided as follows:
  \begin{itemize}
  \item \autoref{sec:ideaS:statement}, state \ideaS{}, and \sink{}.
  \item \autoref{sec:ideaS:intuition}, intuition.
  \item \autoref{sec:ideaS:illus}, provide some \illu{1}.
  \item \autoref{sec:ideaS:contrast} contrasts to safety and sensitivity.
  \item \autoref{sec:ideaS:closing} additional observations.
  \end{itemize}
\end{note}

\paragraph{Statement of \ideaS{}}
\label{sec:ideaS:statement}

\begin{note}[Statement of \ideaS{} and \sink{0}]
  \begin{restatable}[\ideaS{0} --- \ideaS{}]{idea}{iCSA}
    \label{idea:defs-for-CS}
    \label{idea:S}
    An agent \vAgent{} has support for \(\phi\) having value \(v\) \emph{only if}
    \begin{enumerate}
    \item
      \label{idea:S:phi}
      \vAgent{} has concluded \(\phi\) has value \(v\).
    \item
      \label{idea:S:sink}
    \(\phi\) having value \(v\) is a \sink{} with respect to the agent's current epistemic state.
  \end{enumerate}
  \vspace{-\baselineskip}
\end{restatable}

  Where:

  \begin{restatable}[A \sink{0}]{notion}{defSink}
    \label{def:sink}
    \(\phi\) having value \(v\) is a \emph{\sink{}} with respect to an agent \vAgent{}' epistemic state \(\eState{\vAgent{}}\) just in case:
    \begin{enumerate}[label=\alph*., ref=(\(\odot\)1\alph*)]
    \item
      \label{def:sink:base}
      If \vAgent{} were reason about whether \(\phi\) has value \(v\) from \(\eState{\vAgent{}}\), \vAgent{} would conclude \(\phi\) has value \(v\).
    \item
      For any \epPAd{} proposition \(\psi\) having value \(v'\) with respect to \(\eState{\vAgent{}}\).
      \begin{enumerate}[label=\alph*., ref=(\(\odot\)2\alph*)]
      \item
        \label{def:sink:restrict}
        If \vAgent{} were to relax \(\eState{\vAgent{}}\) to \(\eState{\vAgent{}}[']\) such that \(\psi\) having value \(v'\) is \epVAd{} with respect to \(\eState{\vAgent{}}[']\) then:
        \begin{enumerate}[label=\alph*., ref=(\(\odot\)2\alph*)]
          \setcounter{enumiii}{1}
        \item
          For any proposition-value pair \(\chi\) having value \(v''\) such that \vAgent{} would conclude \(\chi\) has value \(v''\) from \(\eState{\vAgent{}}[']\):
          \begin{enumerate}[label=\alph*., ref=(\(\odot\)2\alph*)]
            \setcounter{enumiv}{2}
          \item
            \(\phi\) having value \(v\) is a \sink{} with respect to \(\eState{\vAgent{}}['']\), where \(\eState{\vAgent{}}['']\) is the result of concluding \(\chi\) has value \(v''\) from \(\eState{\vAgent{}}[']\).
          \end{enumerate}
        \end{enumerate}
      \end{enumerate}
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  Whether an agent has support for some proposition-value pair \(\langle \phi,v \rangle\) then, primary reduces to~\ref{idea:S:sink}:
  Whether \(\phi\) having value \(v\) is a \sink{} with respect to the agent's current epistemic state.

  Hence, our focus will be on clarifying the notion of a \sink{}.

  Our goal, however, is to not provide complete clarity.
  For, out interest with \support{} is limited to motivating an assumption with respect to \emph{claiming} \support{}, \ideaCS{}.
  And, with respect to motivating \ideaCS{}, difficulties with the details of how to evaluate whether some proposition-value pair is a \sink{} will be mitigated by focusing on specific steps of reasoning with respect to what an agent considers \epVAd{}.

  Still, as \(\phi\) having value \(v\) being a \sink{} does not guarantee that the agent has concluded \(\phi\) has value \(v\),~\ref{idea:S:phi} ensures the agent has concluded \(\phi\) has value \(v\).
  Though, this is both a technical and conceptual distinction.
  The notion of a \sink{} concerns subjunctive considerations about whether it is possible for an agent to conclude \(\phi\) has value \(v\) given what the agent considers \epPAd{} from their current epistemic state, while the agent having concluded \(\phi\) has value \(v\) is a property that need only hold of the agent's current epistemic state, and may not be preserved under the relevant subjunctive considerations.
\end{note}

\paragraph{Intuition}
\label{sec:ideaS:intuition}

\begin{note}[Structure]
  Whether \(\phi\) having value \(v\) is a \sink{} with respect to some epistemic state is an instance of generative recursion.
  We start with some base property \ref{def:sink:base}, and then expand the property to variant epistemic states generated from the relevant epistemic state under consideration.

  In particular,~\ref{def:sink:restrict} combines of a `forwards' and a `backwards' condition.
  The key question is whether the agent may fail to conclude, or failed to have concluded, \(\phi\) has value \(v\) given the alternative conclusions the agent may make, or may have made.

  We start with the forwards condition, and then expand to the backwards condition.
\end{note}

\begin{note}[Forwards]
  The \emph{forwards} condition considers the agent's present epistemic state with respect to the trivial `relaxation' of the epistemic state, and requires that for any proposition-value pair \(\chi\) having value \(v''\) such that the agent would conclude \(\chi\) has value \(v''\), \(\phi\) having value \(v\) remains an \sink{} \emph{after} the agent has concluded \(\chi\) has value \(v''\).

  In other words, not only would the agent conclude \(\phi\) has value \(v\) if the agent were to reason about whether \(\phi\) has value \(v\), but further:
  If the agent were to reason about some other proposition-value pair from the present epistemic state, the agent would continue to conclude \(\phi\) has value \(v\) if they were to reason about whether \(\phi\) has value \(v\).

  The key point is this:
  The agent would conclude \(\phi\) has value \(v\), and there is no other proposition-value pair \(\langle \chi, v'' \rangle\) such that if the agent were to first conclude \(\chi\) has value \(v''\) then the agent would no longer conclude \(\phi\) has value \(v\).

  Loosely, not only would the agent conclude \(\phi\) has value \(v\), but from the agent's perspective there are no considerations that could intervene to prevent the agent from concluding \(\phi\) has value \(v\).

  Still, in the case of \ideaS{}, an agent has already concluded \(\phi\) has value \(v\), hence the primary role of the forwards condition is with respect to the backwards condition.
\end{note}

\begin{note}[Backwards]
  The \emph{backwards} condition applies in non-trivial `relaxations' to the agent's present epistemic state, and requires that the forward condition holds with respect to any such `relaxation'.

  Intuitively, if the agent were to cancel some previous instance of reasoning such that what the agent considers \epVAd{} is not longer restricted to the conclusion of that instance of reasoning, it remains the case that the agent would conclude \(\phi\) has value \(v\) and there are no considerations that could intervene with respect to the `relaxed' epistemic state to prevent the agent from concluding \(\phi\) has value \(v\).\nolinebreak
  \footnote{
    Strictly, the backwards condition also requires that the backwards condition holds with respect to any `relaxation', though this is only of interest if what the agent considers \epPAd{} may change.
    We will ignore this possibility.
  }
  The key idea of the backwards, condition, then, is to ensure that some proposition-value pair \(\phi\) having value \(v\) being a \sink{} is that for any \epPN{} that the agent may entertain, the agent both has some way of concluding \(\phi\) has value \(v\), and would conclude \(\phi\) has value \(v\) if the agent were to initially conclude some other proposition-value pair from the epistemic state.

  Loosely, the agent the agent would conclude \(\phi\) has value \(v\) even if\dots\space --- where the ellipses indicate some \epPN{}.
\end{note}

\begin{note}[The task]
  Showing that some proposition-value pair is a \sink{} with respect to an agent's epistemic state may be an intractable task.
  For, there may be no clear bounds on what an agent considers \epPAd{}, nor on how an agent may reason about any given proposition-value pair and one must cover all possibilities.

  However, showing that some proposition-value pair \(\langle \phi,v \rangle\) is \emph{not} a \sink{} with respect to an agent's epistemic state is more straightforward.

  If the agent has not yet concluded \(\phi\) has value \(v\), then one only needs to find some proposition-value pair \(\langle \chi,v'' \rangle\) such that the agent would conclude \(\chi\) has value \(v''\) and would not conclude \(\phi\) has value \(v\) \emph{after} concluding \(\chi\) has value \(v''\).

  And, if the agent has conclude \(\phi\) has value \(v\), the one only needs to find some proposition-value pair \(\langle \psi,v' \rangle\), such that the agent considers \(\psi\) having value \(v'\) \epPAd{} and would not conclude \(\phi\) has value \(v\) if the agent were to revise their epistemic state so \(\psi\) having value \(v'\) is \epVAd{}.
\end{note}

\begin{note}
  Two small points.
  First, on relaxing, second on the relation between an agent having \support{} and particular instances of reasoning.
\end{note}

\begin{note}[`Relaxing']
  Throughout, `relaxing' an epistemic state has been left undeveloped.
  I expect the terminology is sufficient indicative to provide some intuition as to what this operation amounts to.
  Still, without a clear statement, the \emph{notion} of a \sink{} falls far short of a \emph{definition}.
  And, though attempts were made, a clear statement of the operation remains elusive.
  Now, while this leaves the notion of a \sink{}, and hence \ideaS{} somewhat unclear, the significance of this lack of clarity will be mitigated when we turn to claiming \support{}.
  For, the assumption we make regarding \emph{claiming} \support{} will not invoke the operation of relaxing an agent's epistemic state.
\end{note}

\begin{note}
  You may note that \ideaS{} concerns whether an agent \emph{has} \support{} for some proposition-value pair, as opposed to whether an agent has \support{} for some proposition-value pair \emph{relative to} some prior reasoning.
  Indeed, you may observe that there is no connexion between the reasoning from which the agent concluded \(\phi\) has value \(v\) from \ref{idea:S:phi}, and the reasoning relevant to whether \(\phi\) having value \(v\) is a \sink{} with respect to the agent's epistemic state from \ref{idea:S:sink}.

  Abstractly, an agent may have concluded \(\phi\) has value \(v\) from some reasoning, but the reasoning relies on particulars of the agent's prior epistemic state, and given some further relaxation of the agent's prior epistemic state, the agent may have concluded \(\phi\) has value \(v\) from a quite distinct line of reasoning.

  Again, \ideaS{} states only a necessary condition on whether an agent has \support{} for some proposition-value pair, allowing the property of having \support{} to be tied closer to the reasoning the agent has witnessed.
  I avoid doing so for two reasons.
  First, to keep the notion of a \sink{} relatively simple.
  Second, I have no clear intuition regarding the issue.
  A detective may conclude that someone is innocent on a hunch, but have \support{} for the conclusion given the evidence they would bring to mind were they to consider the matter more carefully.
  What to say is unclear.
  Certain restrictions will be placed on whether the detective may \emph{claim} \support{}, but these will be postponed to \autoref{sec:ideaCS}.
\end{note}

\paragraph{\illu{3}}
\label{sec:ideaS:illus}

\begin{note}
  \begin{itemize}
  \item Start with simile.
  \item Question.
  \item Clock.
  \item Simple instances.
  \item Final illustration in following section, distinguish concluding \(\phi\) has value \(v\) from whether \(\phi\) has value \(v\).
\end{itemize}
\end{note}

\begin{note}
  \begin{illustration}[Lost keys]
    Lost keys, searched everywhere.
    However, \epVAd{} that place haven't looked.
    And, hence \epVAd{} that they keys are there.
  \end{illustration}
  So, that one has lost their keys is not a \sink{}, no matter how tempting.

  Indeed, if I may be granted a simile, question of whether an agent has \support{} for some proposition-value pair \(\langle \phi, v \rangle\) seems like a pair of lost keys.
  For, at issue is whether there is some line of reasoning from a relaxation of the agent's epistemic state which would prevent them from concluding \(\phi\) has value \(v\).
  Without exhausting all possible locations, or lines of reasoning, the keys may turn up, or one may find fault in the reasoning that led them to their current epistemic state.
\end{note}

\begin{note}[Gifts]
  \begin{illustration}
    \label{illu:S:gifts}
    \begin{enumerate}
    \item S knows me very well.
    \item Whatever S has gifted me satisfies some desire I have.
    \end{enumerate}
  \end{illustration}
  Perhaps wishful thinking.
  Suppose not knowing very well is \epPAd{}.
  `Relax', no consider previous gifts.
  Some of these were quite bad.
  Might not satisfy some desire.

  On the other hand, even if \epPAd{}, the previous gifts may have been ideal.
  So, even after `relaxing', would arrive at the same conclusion.

  The same basic idea underlying~\autoref{illu:S:gifts} extends to various other premise-conclusion instances.
  Consider, for example:
  \begin{enumerate}
  \item The newspaper reported \(S\) said that \(p\).
  \item \(S\) said that \(p\).
  \end{enumerate}
  It seems plausible that the reasoning from premise to conclusion assumes that the paper has a history of accurate reporting.
  And, and if available to the agent are various premises which suggest that the paper does not have such a history, then the agent may refrain from concluding \(S\) said that \(p\) from the report.
  Still, even if the agent were to relax their epistemic state so that the newspaper lacking such a history is \epVAd{}, the agent may still have sufficient premises to conclude that the newspaper does have the history, those premises may resist questioning, and so on.
  Hence, whether or not an agent has \support{} for the conclusion broadly depends on the agent's epistemic state.
  Further, the agent may also have some other premise from which to conclude \(S\) said that \(p\).
  For example, by having been in the room when \(S\) said that \(p\).
\end{note}

    \begin{note}
  \begin{illustration}
    Suppose the check engine light of the agent's car has come on.
    As a result the agent has concluded that their is some fault with their car's engine.

    Of course, the agent is aware that it is possible for the check engine light to be on with no fault in the engine.
    Still, even if the agent were to consider the possibility that their is no fault in the engine, the presence of the check engine light would lead the agent to conclude that there is some fault in the engine.
  \end{illustration}

  The agent's reasoning is non-deductive, and the agent recognises that by moving from the check engine light to a problem with the engine that they may conclude that there is a problem with the engine when there is none, but as the agent would reason regardless,~{\color{red} ???} is satisfied.
\end{note}

\begin{note}
  \begin{illustration}
    \label{ideaS:illu:clock}
    Suppose an agent considers it \epPAd{} that the clock is not functioning, and has reasoned as follows:
    \begin{enumerate}
    \item The clock is in the centre of the library, and has been seen by many people.
    \item The clock is functioning.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{illustration}

  Hence, to entertain the relevant \epPN{1}, the conclusion that the clock is functioning would need to be relaxed.
  However, a non-functioning clock may still be in the centre of the library and seen by many people.
  And, as it is plausible that someone would have noticed that the clock is not functioning, it seems the agent may still conclude that the clock is functioning.

  Likewise, expand \autoref{ideaS:illu:clock} suppose the agent considers it \epPAd{} that the clock is not functioning and no-one has noticed that the clock is broken.
  In such a case, the agent's relaxed epistemic state will not include that the clock has been seen by many people.
  Still, the agent may observe that:
  \begin{enumerate}
    \setcounter{enumi}{-1}
  \item It is exam week so the library is busy and many students will be sensitive to what time it is.
  \end{enumerate}
  Hence, it seems the agent may conclude that the clock has been seen by many people, and with this intermediary proposition-value pair in hand then conclude that the clock is functioning.
\end{note}

\begin{note}
  Pair of trivial instances.
  Inspection immediately grants.
  \begin{illustration}
    \begin{figure}[h!]
    \mbox{}\hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item That persons' eyes have been closed for a long time and their breathing is slow.
      \item That person is asleep.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item The die has rolled even in \(5251\) of \(6000\) samples.
      \item The die is biased.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill\mbox{}
    \caption{}
    \label{fig:ideaS:basic-examples}
  \end{figure}
\end{illustration}
\end{note}

\addtocontents{toc}{\protect\setcounter{tocdepth}{2}} % Skip subsubsections

\subsubsection{Contrasting constraints}
\label{sec:ideaS:contrast}

\begin{note}[Independence of support]
  An important for emphasis, though inessential for practice, feature of \ideaS{} is that whether an agent has claimed support for \(\phi\) having value \(v\) is independent of whether \(\phi\) (actually) has value \(v\).

  For, \ideaS{} requires the agent would reason to \(\phi\) having value \(v\) were the agent to entertain any \epPW{} as a candidate for the actual \world{}.
  Hence the agent would conclude \(\phi\) (actually) has value \(v\).
  However, no requirement is placed on the agent \emph{concluding} \(\phi\) has value \(v\) and \(\phi\) having value \(v\).

  In this respect, \ideaS{} is distinct, though compatible with, variants of safety and sensitivity applied to claiming support.
\end{note}

\begin{note}[Safety and sensitivity]
  We borrow the following definitions from~\citeauthor{Zalabardo:2017td}:

  \begin{quote}
    S's belief that p is \emph{safe} just in case, if S believed p, p would be true.\newline
    \mbox{}\hfill\mbox{(\citeyear[1]{Zalabardo:2017td})}
  \end{quote}

  \begin{quote}
    S's belief that p is \emph{sensitive} just in case, if p were false, S wouldn't believe p.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[2]{Zalabardo:2017td})}
  \end{quote}

  In both definitions, `S's \support{} for p (being true)' may be substituted for `S's belief that p'.

  Further, both definitions consist of a subjunctive conditional which concerns the value that p has.
  In the case of safety, p has the value true, and in the case of sensitivity, p is false.
  And, indeed, it follows from either definition that if S believes that p then p is true.\nolinebreak
  \footnote{
    In the case of safety, this is immediate.
    In the case of sensitivity, if S believes that p and p is false, then it follows by sensitivity that S doesn't believe p.
    Hence, either S believes that p and p is true, or S does not believe that p.

    Note, however, that while both safety and sensitivity ensure that S believes that p only if p is true, the two conditions are distinguished by which possibilities the relevant subjunctive antecedent quantifiers over.
  }

  So, given that the definition of a \sink{} is compatible with the agent concluding that p is true when p is (actually) false and safety and sensitivity rule out such a possibility, \ideaS{} does not follow from either safety or sensitivity, and conversely, neither safety nor sensitivity follow from \ideaS{}.
\end{note}

\begin{note}
  \color{red} The point is that these notions are about two quite different things.
  When relaxing an agent's epistemic state, this doesn't require any change to `base level' proposition-value pairs.
  However, that is what safety and sensitivity require.
\end{note}

\begin{note}
  Still, as the definition of a \sink{} is \emph{merely} compatible with the agent concluding that p is true when p is (actually) false, there is no restriction on placing either safety, sensitivity, or some other condition on claiming support in conjunction with \ideaS{}.

  Indeed, \ideaS{} is stated as a necessary condition to allow for additional restrictions.
  However, the importance of the foregoing observation is that without additional constraints, and evaluation of whether an agent has claimed support may be separated from how things actually are.
  Even if \(\phi\) does not have value \(v\), it may be the case that an agent would reason to \(\phi\) having value \(v\).
  What matters, rather, is that there is no \epPN{} for which the agent would not reason to \(\phi\) having value \(v\).
\end{note}

\begin{note}[An extreme example]
  We have already seen the independence of an agent having \support{} for \(\phi\) having value \(v\) from whether \(\phi\) (actually) has value \(v\), with respect to instances of non-deductive reasoning.
  Still, to clarify this point we offer a final, somewhat outlandish, illustration.

  \begin{illustration}
    It is compatible with \ideaS{} that an agent has \support{} for \(0.999\dots \ne 1\), where the agent holds themselves to have a conventional understanding of real numbers.
  \end{illustration}
  The qualification is important, there are various interpretations under which \(0.999\dots \ne 1\), but it is convention that the Archimedean property holds for real numbers.

  Still, an agent may reason that even if \(0.999\dots = 1\), there must be \emph{some} difference between \(0.999\dots\) and \(1\) --- no matter how small --- and some difference between to things is sufficient to establish that they are not equal.

  Expanding: \(0.9 = (1 - 0.1)\), \(0.99 = (1 - 0.01)\), and so \(0.999\dots = (1 - 0.000\dots 1)\), hence \(1 = (0.999\dots + 0.000\dots 1)\), and because \(0.999\dots\) refers to some quantity, \(0.000\dots 1\) likewise refers to some quantity.

  In other worlds, an agent need not consider it \epPAd{} that the Archimedean property does not hold for real numbers.
  Of course, including either safety or sensitivity as additional constraints on \support{} would rule out this illustration, we do not require such constraints.
\end{note}

\subsubsection{Closing \ideaS{}}
\label{sec:ideaS:closing}

\begin{note}[Summary of \ideaS{}]
  The core intuition regarding \support{} takes the form of the `even if\dots' test.
  An agent has \support{} for some proposition \(\phi\) having some value \(v\) just in case the agent would conclude \(\phi\) has value \(v\) \emph{even if} \(\phi\) does not have value \(v\).

  In most cases, an agent will not merely have \support{} for \(\phi\) having value \(v\), but it will also be the case that \(\phi\) has value \(v\).
  And, it is compatible with \ideaS{} that \(\phi\) having value \(v\) is also a necessary condition on an agent having \support{}.
  Still, to the extent that the `even if\dots' test is independent of the way things actually are, \ideaS{} is limited to requiring that an agent has \support{} for \(\phi\) having value \(v\) only if \(\phi\) having value \(v\) is a \sink{} with respect to the agent's epistemic state.

  Though we have developed the notion of a \sink{} in some detail, the central role of (nested) subjunctive conditionals leaves evaluating whether a proposition-value pair is a \sink{} somewhat unclear.
  For, without a detailed account of what it is for an agent to relax an epistemic state, and a detail account of reasoning about whether some proposition has some value, we lack a way to verify that any given proposition-value pair is a \sink{} with respect to an agent's epistemic state.

  Still, \ideaS{} is an idea, and further the idea may be restricted to being an ideal.
  We will appeal to \ideaS{} to motivate an idea constraining \emph{claiming} \support{}.
  What will matter is whether certain instances of reasoning, and in particular \emph{steps} of reasoning are compatible obtaining support for some proposition-value pair.

  In particular, the idea constraining claiming support will focus only on \epVW{1}.
  Hence, satisfying the constraint on claiming support will not suggest that an agent has, or succeeds in obtaining \support{}.
  Indeed, an upshot of focusing on claiming with respect to \epVW{1} is that we will avoid the presence subjunctive considerations and issues regarding relaxing an epistemic state.

  So, it is to an idea about claiming \support{} to which we now turn.
\end{note}

\addtocontents{toc}{\protect\setcounter{tocdepth}{3}} % Include subsubsections

\section{\ideaCS{0}}
\label{sec:ideaCS}

\begin{note}[Introducing \ideaCS{}]
  \ideaS{} provided a general constraint on \support{}.
  We now turn our attention to \emph{claiming} support.
  As with \ideaS{}, \ideaCS{} is a necessary condition.
\end{note}

\subsection{Statement of \ideaCS{}}
\label{sec:ideaCS:statement}

\begin{note}[Statement: \ideaCS{}]
  \begin{restatable}[\ideaCS{0} --- \ideaCS{}]{assumption}{ideaEIS}
    \label{idea:CS:B}
    \label{assumption:CS}
    For an agent \vAgent{}, and some instance of reasoning:

    The instance of reasoning is an instance of claiming \support{} only if:
    \begin{enumerate}
    \item
      \label{idea:CS:B:step}
      For any step \(\delta\), which moves from premises \(\chi_{i}\) having values \(v_{i}\) to the conclusion that \(\phi\) has value \(v\):
      \begin{enumerate}[label=\alph*., ref=(\alph*)]
      \item
        \vAgent{} has satisfied any \requ{} of the reasoning.
    %     \begin{itemize}
    %     \item
    %       Such that:
    %       \begin{enumerate}[label=\alph*., ref=(\alph*)]
    %       \item
    %         \label{idea:CS:B:step:requ}
    %         \(\psi\) having value \(v'\) is a \emph{\requ{}} of \(\delta\).
    %       \end{enumerate}
    %     \end{itemize}
    %   \end{enumerate}
    % \item
    %   Then:
    %   \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    %   \item
    %     The instance of reasoning is an instance of claiming support \emph{only if}:
    %     \begin{enumerate}[label=\alph*., ref=(\alph*)]
    %       \setcounter{enumii}{1}
    %     \item
    %       \label{idea:CS:B:prior-reasoning}
    %       The agent, independent of making \(\delta\), has witnessed some reasoning which \indicateV{1} \(\psi\) has value \(v'\) with respect to the agent's epistemic state (prior to making \(\delta\)).\nolinebreak
    %       \footnote{
    %         This clause is non-committal about the reasoning which \indicateV{1} \(\psi\) has value \(v'\).
    %         In particular:
    %         With respect to \ESU{}, the reasoning may include the reasoning of some other agent.
    %         And, with respect to \EAS{}, the reasoning may itself involve appeal to some unwitnessed reasoning.
    %       }
    %     \end{enumerate}
      \item
        Or, for any \requ{}, the step itself is sufficient to deal with the \requ{}. {\color{red} The problem here is \(\phi \land \psi\). Either alone is a \requ{}. However, it seems the step really deals with both.}
        E.g.\ the dog is big and happy.
        Strictly, big, happy.

        Perhaps also, simultaneously.
        I mean, if \(\phi \land \psi\) needs to come via a step, then already for \(\phi\) and for \(\psi\).
      \end{enumerate}
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}[Notion: \requ{2}]
  As with \ideaS{} and the notion of a \emph{\sink{}}, a significant component of \ideaCS{} is concealed by a piece of technical vocabulary --- that of \(\psi\) having value \(v'\) being a \emph{\requ{}} of a step of reasoning.

  We begin with the intuitive notion of a \requ{}.
  We will then work through a handful of \illu{1}, and introduce two notions:
  First, the notion of a \crequ{}, and second the notion of a \prequ{}.
  Following, in~\autoref{sec:ideaCS:requ:details}, we will further refine the two intuitive notions in to (still somewhat rough) definitions.

  \begin{restatable}[A \requ{0} --- \named{\dag \Re}]{notion}{notionRequisite}
    \label{notion:requ}
    \(\psi\) having value \(v'\) is a \requ{} of concluding that \(\phi\) has value \(v\) with respect to an agent's epistemic state, just in case:

    \begin{itemize}
    \item From the perspective of the agent's epistemic state:
    \begin{itemize}
    \item If \(\phi\) has value \(v\) then:
      \begin{itemize}
      \item There are premises \(\rho_{1},\dots,\rho_{k}\) with values \(v_{1},\dots,v_{k}\) such that,
      \item there is a potential witnessing event in which the agent concludes \(\psi\) has value \(v'\) from \(\rho_{1},\dots,\rho_{k}\) having values \(v_{1},\dots,v_{k}\),
      \item where \(\phi\) having value \(v\) is neither a premise, nor an intermediary conclusion of the potential witnessing event.
      \end{itemize}
    \end{itemize}
  \end{itemize}
  \vspace{-\baselineskip}
  \end{restatable}

  {
    \color{red}
    \begin{enumerate}[label=\arabic*., ref=\named{\dag \Re:\arabic*}]
    \item
      \label{notion:requ:structure}
      The structure of the agent's epistemic state is such that:
      \begin{enumerate}[label=\alph*., ref=\named{\dag \Re:1\alph*}]
      \item
        \label{notion:requ:structure:psi}
        \requNotionEpVAd{}.
      \item
        \label{notion:requ:structure:need-psi}
        \requNotionSubset{}.
      \end{enumerate}
    \item
      \label{notion:requ:possible-psi}
      \requNotionReasoningUC{}.
    \end{enumerate}
  }
\end{note}

\begin{note}
  As noted, we will shortly replace this notion with a definition covering two specific types of \requ{}.
  First, however, we will consider the intuition underlying the notion of a \requ{}.

  Roughly, \(\psi\) having value \(v'\) is a \requ{} of some step of reasoning just in case the agent has the option of concluding \(\psi\) has value \(v\) as an antecedent check on whether the agent would conclude \(\phi\) has value \(v\) regardless of the reasoning the agent may perform from their current epistemic state.
\end{note}

\begin{note}[Expanding]
  Let us expand by noting how the clauses of the notion of a \requ{} interact.
  To keep things short, we consider only the case where~\ref{notion:requ:structure:need-psi} is satisfied because it is not \epVAd{} for \(\phi\) to have value \(v\) and for \(\psi\) to not have value \(v'\).\nolinebreak
  \footnote{
    Analogous reasoning holds in the \(\chi_{1},\dots,\chi_{k}\) having values \(v_{1},\dots,v_{k}\) case.
  }
\end{note}

\begin{note}[\ref{notion:requ:structure:psi}]
  First,~\ref{notion:requ:structure:psi} holds that the agent, given their current epistemic state has not (yet, at least) concluded \(\psi\) has value \(v'\).\nolinebreak
  \footnote{
    More strictly, either the agent has not yet concluded \(\psi\) has value \(v'\) \emph{or} the agent has voided some previous instance of reasoning which concluded \(\psi\) has value \(v'\).
    Even more strictly, though not explicitly stated, the above but with respect to any instance of reasoning whose conclusion \indicateV{} \(\psi\) has value \(v'\).
  }
  For, if the agent had concluded \(\psi\) has value \(v\), then \(\psi\) not having value \(v'\) would not be \epVAd{}.

  Still, from the first part of~\ref{notion:requ:possible-psi}, the agent think they have the option of concluding \(\psi\) has value \(v'\).

  In this respect, that \(\psi\) has value \(v'\) may be described as a hunch, suspicion, feeling in one's bones, conjecture, and so on from the perspective of the agent.
  However, that \(\psi\) has value \(v'\) is no \emph{mere} hunch.
  For, concluding \(\psi\) has value \(v'\) is quite strong:
  If the agent were to conclude \(\psi\) has value \(v'\), then the agent would rule out (from their perspective) any \world{} in which \(\psi\) does not have value \(v'\) as a candidate for the actual \world{}.
  Hence, if the agent thinks that they have the option of concluding \(\psi\) has value \(v'\), the agent is \emph{almost} committed to \(\psi\) having value \(v'\).
  The limiting factor is that the agent only \emph{thinks} they have the option of concluding \(\psi\) has value \(v'\), and allows that they may fail to conclude \(\psi\) has value \(v'\) if they were to reason.

  Generally, any number of proposition-value pairs may satisfy the above description:
  I think I have the option of concluding that my passport is up to date, though perhaps if I checked I would notice (unlikely though I think it would be) that it recently expired.
  Likewise, I think I have the option of concluding that my bicycle tyres are more-or-less fully inflated, though perhaps they have deflated due to a slow puncture.
  And, I think that I will enjoy reading \emph{Bleeding Edge}, though perhaps it will turn out to be a disaster.

  The role of the second part of~\ref{notion:requ:possible-psi}, combined with~\ref{notion:requ:structure:need-psi}, is to tie the perceived option of concluding \(\psi\) has value \(v'\) to a particular step of reasoning.
  Let us fix a certain step of reasoning, and assume it concludes \(\phi\) has value \(v\).

  From the second part of~\ref{notion:requ:possible-psi}, the agent may conclude \(\psi\) has value \(v'\) without making the relevant step of reasoning, and more generally without concluding \(\phi\) has value \(v\).
  Hence, the agent thinks they have the option of concluding \(\psi\) has value \(v'\) prior to concluding \(\phi\) has value \(v\).
  Concluding \(\psi\) having value \(v'\), then, weaker (from the agent's perspective) than concluding \(\phi\) has value \(v\).\nolinebreak
  \footnote{
    Though, this is not to say that concluding \(\psi\) has value \(v'\) is necessarily easier than concluding \(\phi\) has value \(v\).
  }

  And, from~\ref{notion:requ:structure:need-psi}, it is not possible for the agent to conclude \(\phi\) has value \(v\) without the conclusion \indicateV{} \(\psi\) has value \(v'\).
  Hence, if the agent were to conclude \(\phi\) has value \(v\), then in doing so the agent would rule out any \world{} in which \(\psi\) does not have value \(v'\) as a candidate for the actual \world{}.
  Now, if the agent were to have concluded \(\psi\) has value \(v'\) prior to concluding \(\phi\) has value \(v\), then this feature of concluding \(\phi\) has value \(v\) would be unremarkable --- the agent would have already ruled out any \world{} in which \(\psi\) does not have value \(v'\) as a candidate for the actual \world{}.
  However, if the agent has not yet concluded \(\psi\) has value \(v'\), there is potential for trouble.

  There are two cases to consider:
\end{note}

\begin{note}[First case]
  First, the agent may conclude \(\psi\) does not have value \(v'\).
  As a result, \(\psi\) having value \(v'\) would not be \epVAd{}, and by \ref{notion:requ:structure:need-psi}, \(\phi\) having value \(v\) would not be \epVAd{}.
  For, if the agent has concluded \(\psi\) does not have value \(v'\) and concluding \(\phi\) has value \(v\) \indicateV{0} \(\psi\) has value \(v'\), then the agent would be committed to \(\psi\) having value \(v'\) \emph{and} \(\psi\) not having value \(v'\).\nolinebreak
  \footnote{
    This does not strictly exclude the possibility that an agent may conclude \(\psi\) has value \(v'\) and that \(\psi\) has value \(v'^{'}\).
    However, I will assume that if an agent concludes \(\psi\) has value \(v'\), then this amounts to concluding \(\psi\) does not have value \(v'^{'}\), as nothing in particular will hang on merging or separating the distinction.
  }
  In this respect, the agent certainly would not have \emph{clearly} have \support{} for \(\phi\) having value \(v\), were they to conclude.
  For, suppose the agent concluded \(\phi\) has value \(v\).
  Then, after concluding \(\phi\) having value \(v\) it remains true that with respect to the agent's epistemic state \emph{prior} to the conclusion that the agent may have concluded \(\psi\) does not have value \(v'\), blocking a conclusion to \(\phi\) having value \(v\).

  Now, whether or not an agent \emph{has} \support{} is a distinct matter.
  If the agent had concluded \(\psi\) does not have value \(v'\), then some further reasoning may have lead the agent to retract the conclusion in favour of \(\phi\) having value \(v\).

  At issue, though, is whether the agent may \emph{claim} \support{}.
  And, so long as the above possibility it present, it is by no means clear that the agent would have \support{} for \(\phi\) having value \(v\) if they were to conclude \(\phi\) has value \(v\).
  Not merely in the general sense where deciding whether an agent has \support{} for some proposition-value pair seems an intractable notion, but in a specific sense.
  Specifically, from the agent's current epistemic state (prior to concluding \(\phi\) has value \(v\)), the agent has no guarantee that they would conclude \(\phi\) has value \(v\) were they to first reason about whether \(\psi\) has value \(v'\).
\end{note}

\begin{note}[Second case]
  The second case is a little more complex.
  \ref{notion:requ:possible-psi} only states that it is \epVAd{} for the agent to conclude \(\psi\) has value \(v'\) prior to concluding \(\phi\) has value \(v\).
  This does not require that the agent would decide whether \(\psi\) has value \(v'\) prior to concluding \(\phi\) has value \(v\).

  For example, I may think I have the option to conclude that a store has inventory in stock before concluding that it is worthwhile to place an order.
  However, the `check stock' button may do nothing, or return an error --- either remains compatible with the store having inventory.

  In contrast to concluding \(\psi\) does not have value \(v'\), the issue here is less pronounced, but still sufficient for trouble.

  For, by \ref{notion:requ:possible-psi}, it is \epVAd{} for the agent to conclude \(\psi\) has value \(v'\).
  Hence, failing to conclude \(\psi\) has value \(v'\) would lead to a revision of what the agent considers \epVAd{}.
  And, without further information there is no guarantee that the agent would still conclude \(\phi\) has value \(v\) from the revised epistemic state (after failing to conclude \(\psi\) has value \(v'\)).\nolinebreak
  \footnote{
    If the `check stock' button does nothing, then I may conclude the store is not sufficiently trustworthy, and hence refrain from concluding that it is worthwhile to place a order.
  }
  Hence, again, the agent has no guarantee that they would conclude \(\phi\) has value \(v\) were they to first reason about whether \(\psi\) has value \(v'\).
\end{note}

\begin{note}[Summary]
  To summarise, and link back to \ideaCS{}:

  If \(\psi\) having value \(v'\) is a \requ{} of some step of reasoning which concludes \(\phi\) has value \(v\), then there is (form the agent's perspective) the possibility that the agent would not conclude \(\phi\) has value \(v\) if they were to first reason about whether \(\psi\) has value \(v'\), relative to their current epistemic state.

  Hence, \ideaCS{} holds that an instance of reasoning is an instance of claiming \support{} \emph{only if} no step of the instance of reasoning has an associated \requ{}.

  In particular, for any would be \requ{}, \(\psi\) having value \(v'\), of the step of reasoning, the agent will have already witnessed reasoning which concluded (or \indicateVed{}) \(\psi\) has value \(v'\).

  And, in order to show that an agent has failed to claim \support{} by some instance of reasoning, one needs only identify a \requ{} of some step of the instance of reasoning.

  In this respect, when \(\psi\) having value \(v'\) is a \requ{} of some step of reasoning, then the agent \emph{first} concluding \(\psi\) has value \(v'\) prior to making the step of reasoning functions as an antecedent check on whether it makes sense for the agent to make the relevant step given their current epistemic state.
\end{note}


\paragraph{\illu{3}}

\begin{note}
  A pair of \illu{1} to highlight the two specific type of \requ{1} that we will be interested in.
\end{note}

\paragraph*{The conclusion of a step}

\begin{note}[Wally]
  \begin{illustration}[Where's Wally]
    \label{illu:CS:wheres-wally}
    \nagent{15} has a book containing numerous drawings of bustling scenes in which various characters are doing a variety of things.
    And, somewhere in each scene is a character called `Wally', identifiable by a collection of individually necessary and jointly sufficient distinguishing features.
    These features include a red and white striped jumper, blue trousers, short brown wavy hair, and so on.

    \nagent{15} has searched through one particular scene, and has identified a character with a variety of the features.
    Before concluding that the character is Wally, \nagent{15} remembers that there is a picture of Wally On the cover of the book, with all the identifying features present.

    Wally is always wearing a pair of round glasses, but this was not a feature \nagent{15} kept in mind when searching for Wally, and it is \epVAd{} for \nagent{15} that the character they identified is not wearing round glasses  --- \nagent{15} only recalls the features they identified.
  \end{illustration}

  Our interest is, generally, in whether \nagent{15} may conclude from the variety of features identified that the character is Wally.

  Descriptively, of course, there seems no barrier.
  An agent may reason to an arbitrary conclusion to arbitrary premises.

  So, specifically, our interest is in whether \nagent{15} would claim support that the character is Wally by concluding that the character is Wally from the variety of features identified.

  The difficulty for \nagent{15} is that so long as they consider it \epVAd{} that the character is not wearing round glasses, then there a clear check on whether \nagent{15} may reason to a different conclusion.
  For, if \nagent{15} were to check whether the character is wearing a pair of round glasses, and the character is not wearing a pair of round glasses, then \nagent{15} would conclude that the character is not Wally.
\end{note}

\begin{note}
  Well, missing premise.
  However, not so clear more generally.
\end{note}

\begin{note}
  \begin{illustration}
    For the agent it is \epVAd{} that the library uses one of a number of different indexing systems.
    E.g.\ LCC or DDC indexing.
    \begin{enumerate}
    \item A search for `H61 .R593' returned no results.
    \item The library does not have a copy of `Measurement Theory'.
    \end{enumerate}
  \end{illustration}

  Holding that a library does not have a copy of a book because a search for the book under a particular indexing system would be a mistake.
  For, if the library does not use the particular indexing system then a search using that indexing system will always fail, regardless of whether or not the library has a copy of the book.

  In turn, a failed search for an LCC index in the library's database does not seems sufficient for an agent to claim that the library does not have a copy of the book unless the agent is in a position to claim support that the library uses LCC indexing.
  Following, it seems the failed response to the `Even if\dots' test may be supplemented by noting that the library is a research library, and therefore likely uses LCC indexing, etc.\
\end{note}

\begin{note}
  Similar issue, though so long as background, then it's not clear why this would need to be explicit premise.

  Hence, broader idea of a \requ{}.
\end{note}

\begin{note}
  Of interest.
  The collection of properties might be very strong.
  It may be that there is really little chance that the agent is not Wally.
  However, of interest is that there is some reasoning that the agent may witness.
\end{note}

\paragraph*{The premise(s) of a step}

\begin{note}[\prequ{3}]
  \begin{illustration}
    Suppose \nagent{13} is interested in concluding that they're set to have coffee before travelling to work from the premises that they have the time and resources to make a cup of coffee.
    And, the additional premise that they have milk.
    (For, the milk will cool the coffee quickly enough for \nagent{13} to drink before leaving.)

    Still, \nagent{13} is unsure about whether the milk is safe to drink.
    The milk smells okay-ish and \nagent{13} is fairly sure that they bought it fairly recently.

    \nagent{13} holds that if the milk is past it's expiry date, then it is not safe to drink.
    But, if the milk is within it's expiry date, then as it smells okay-ish, \nagent{13} would conclude that the milk is safe to drink.
  \end{illustration}
  \epVAd{} that the milk is not safe to drink.
  It is not \epVAd{} for \nagent{13} to conclude conclusion from premises if the milk is not safe to drink.
  \nagent{13} is holding the milk, so trivial to check the expiry date.

  It seems intuitive, at least to me, that \nagent{13} should check the expiry date.

  For present purposes, this intuition is accounted for by there being an antecedent check on whether it makes sense for the agent to conclude.
  The expiry date.

  More broadly, \support{}.
  If \support{}, then no matter what is plausible, conclude.
  Well, that the milk is not safe.
  But, some reasoning that \emph{may} prevent conclusion.
  As \nagent{13} has not reasoned about expiry date, it does not follow that the milk is either past or within.
  However, from the epistemic state of \nagent{13}, there is the possibility that they would fail to conclude.
\end{note}

\begin{note}
  \ideaCS{}, then, requires that any agent has witnessed some reasoning which \indicateV{0} that any \requ{} of a step of reasoning is the case prior to making the step of reasoning, so long as the reasoning relies on the relevant step.

  Though, strictly, \ideaCS{}
\end{note}

\paragraph{Limitations}

\begin{note}
  Does not show that there's no hope for the agent.
  Only that the reasoning fails.

  Two possibilities:
  \begin{itemize}
  \item Different approach to claiming support.
  \item Reasoning that indicates \crequ{}.
  \end{itemize}

  So, \ideaCS{} is a limitation, but not a particularly strong limitation.
\end{note}

\subsection{\requ{3}: Definitions and details}
\label{sec:requ3}
\label{sec:ideaCS:requ:details}


\begin{note}[Definition: \requ{2}]
  To be precise, we refine the notion of a \requ{} into a partial definition which covers two ways in which a proposition-value pair may be a \requ{} of some step of reasoning.

  \begin{restatable}[A \requ{0} --- \named{\ddag\Re}]{definition}{defRequisite}
    \label{def:requ}
    Let \(\delta\) be a step of reasoning from premises \(\chi_{1},\dots,\chi_{k}\) with values \(v_{1},\dots,v_{k}\) to \(\phi\) having value \(v\).

    \(\psi\) having value \(v'\) is a \emph{\requ{}} of \(\delta\) with respect to an agent \vAgent{}' epistemic state \emph{if} either:
    \begin{itemize}
    \item \(\psi\) having value \(v'\) is a \emph{\crequ{}} of \(\delta\)
    \item \(\psi\) having value \(v'\) is a \emph{\prequ{}} of \(\delta\)
    \item \dots
    \end{itemize}
  \end{restatable}
\end{note}

\begin{note}[Structure of \autoref{def:requ}]
  Structurally,~\autoref{def:requ} provides two conditions sufficient for some proposition-value pair being a \requ{} of some step of reasoning.
  These two conditions, are termed `\prequ{}' and `\crequ{}' and will reduce to a collection of necessary and sufficient conditions.

  In other words, we provide necessary and sufficient conditions for two specific ways in which a proposition-value pair is a \requ{}, but we do not hold that these two ways in which a proposition-value pair may be a \requ{} exhaust the intuitive notion of a \requ{}.

  Still, for the purposes of this document we will only be \emph{directly} interested in \crequ{1}, with \prequ{1} being a contrast.
  Hence, \autoref{def:requ} may be strengthened to a necessary condition, so long as the strengthened definition is not taken to capture the intuitive notion of a \requ{}.
\end{note}

\begin{note}
  Further still, the core argument of this document will focus only on the issue of whether some proposition-value pair is a \crequ{1}.
  Indeed, the purpose of defining a \prequ{} is to provide a an explanatory partner for the definition of a \crequ{} --- we will use the definition of a \prequ{} to help clarify the definition of a \crequ{}.
\end{note}

\subsubsection{\crequ{3}}

\paragraph*{Outline}

\begin{note}
  In the present section we develop what it is for some proposition-value pair to be a \crequ{} for some step of reasoning.

  Whether a particular kind of proposition-value pair is \crequ{} with a specific type of step will be of crucial importance to the overall argument of this document.
  However, for the moment we detail and motivate \crequ{1} in general.
  The specific \crequ{1} of interest will be detailed in~{\color{red} ???}, and then applied in~{\color{red} ???}.
\end{note}

\begin{note}
  Structure
  \begin{itemize}
  \item Definition
  \item Details of definition
  \end{itemize}
\end{note}

\paragraph{Definition of a \crequ{}}

\begin{note}
  The definition of a \crequ{} largely follows the notion of a \requ{}.
  The key difference between a \crequ{} and a \requ{} is that we focus only considerations regarding what would follow from having made the relevant step of reasoning.

  In this respect,~\ref{notion:requ:structure} and~\ref{notion:requ:possible-psi} are tightened to consider on the relation between the conclusion of the step of reasoning and some proposition-value pair.
  Still, the definition of a \crequ{} expands on the relevant parts of the notion of a \requ{} in order to cover various edge cases.
\end{note}

\begin{note}
  \begin{restatable}[A \crequ{0} --- \named{\ddag C\Re}]{definition}{defCRequisite}
    \label{def:requ:crequ}
    Let \(\delta\) be a step of reasoning from premises \(\chi_{1},\dots,\chi_{k}\) with values \(v_{1},\dots,v_{k}\) to \(\phi\) having value \(v\).

    \(\psi\) having value \(v'\) is a \emph{\crequ{}} of \(\delta\) \emph{if and only if} the following conditions jointly hold:
    \begin{enumerate}[label=\arabic*., ref=\named{\ddag C\(\Re\):\arabic*}]
    \item
      \label{def:requ:crequ:strcture}
      The structure of the \vAgent{}' epistemic state is such that:
      \begin{enumerate}[label=\alph*., ref=\named{\ddag C\(\Re\):1\alph*}]
      \item
        \label{def:requ:crequ:strcture:psi-not-v}
        There is some \epVW{} such that:
        \begin{itemize}
        \item
          \(\psi\) does not have value \(v'\).
        \end{itemize}
      \item
        \label{def:requ:crequ:strcture:subset}
        There are no \epVW{1} such that:
        \begin{itemize}
        \item \(\phi\) has value \(v\) and \(\psi\) does not have value \(v'\).
        \end{itemize}
      \item
        \label{def:requ:crequ:strcture:propersubset}
        There is some \epVW{} such that:
        \begin{itemize}
        \item \(\psi\) has value \(v'\) and \(\phi\) does not have value \(v\).
        \end{itemize}
      \end{enumerate}
    \item
      \label{def:requ:crequ:no-revision}
      It is not the case that the agent would revise their epistemic state so that \ref{def:requ:crequ:strcture:propersubset} does not hold, in order to conclude \(\phi\) has value \(v\) from \(\delta\).
    \item
      \label{def:requ:crequ:possible-reason}
      For all \epVW{} in which \(\phi\) has value \(v\), there is some temporal extension of the \world{} in which \vAgent{} witnesses reasoning which concludes \(\psi\) has value \(v'\) (without first concluding \(\phi\) has value \(v\)).
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\subparagraph{Expanding on the definition of a \crequ{}}

\begin{note}
  Expand on the definition.
  Start with structure.
  Leads to \ref{def:requ:crequ:no-revision}.
  Agent centric.
  Then, the core of the definition, \ref{def:requ:crequ:possible-reason}.
\end{note}

\subsubparagraph{The structure of the agent's epistemic state}

\begin{note}
  \ref{def:requ:crequ:strcture} describes the relevant structure of the agent's epistemic state.
  In short:
  \begin{itemize}
  \item
    From \ref{def:requ:crequ:strcture:psi-not-v} there is some \epVAd{} in which \(\psi\) does not have value \(v'\) \emph{and}
  \item
    not only does \(\phi\) have value \(v\) only if \(\psi\) has value \(v'\) from \ref{def:requ:crequ:strcture:subset}, but
  \item
    \(\psi\) having value \(v'\) is strictly weaker than \(\phi\) having value \(v\) from \ref{def:requ:crequ:strcture:propersubset}.
  \end{itemize}
  Where, the notion of some proposition being strictly weaker than another is stated in terms of inclusion.
  \autoref{fig:crequ:intuition} (specifically~\autoref{fig:crequ:psi} and~\autoref{fig:crequ:subset}) provides an example depiction of such structure.
\end{note}

\begin{figure}[h!]
  \mbox{ }\hfill
  \begin{subfigure}{0.3\linewidth}
    \begin{tikzpicture}[scale=.85]
      \coordinate (epVC) at (0,0);
      \coordinate (epV) at (4,5);
      \coordinate (epVLL) at ($(epVC)-0.5*(epV)$);
      \coordinate (epVUR) at ($(epVC)+0.5*(epV)$);
      \draw[thick, rounded corners] (epVLL) rectangle (epVUR);

      \filldraw (0.5*-3,0.5*-4) node {\(\psi\)};
      \coordinate (psiC) at (-.2,-.2);
      \coordinate (psi) at (3,4);
      \coordinate (psiLL) at ($(psiC)-0.5*(psi)$);
      \coordinate (psiUR) at ($(psiC)+0.5*(psi)$);
      \draw[dashed, rounded corners] (psiLL) rectangle (psiUR);
    \end{tikzpicture}
    \caption{\ref{def:requ:crequ:strcture:psi-not-v}}
    \label{fig:crequ:psi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.3\linewidth}
    \begin{tikzpicture}[scale=.85]
      \coordinate (epVC) at (0,0);
      \coordinate (epV) at (4,5);
      \coordinate (epVLL) at ($(epVC)-0.5*(epV)$);
      \coordinate (epVUR) at ($(epVC)+0.5*(epV)$);
      \draw[thick, rounded corners] (epVLL) rectangle (epVUR);

      \filldraw (0,0) node {\(\phi\)};
      \coordinate (phiC) at (-.25,-.25);
      \coordinate (phi) at (2,3);
      \coordinate (phiLL) at ($(phiC)-0.5*(phi)$);
      \coordinate (phiUR) at ($(phiC)+0.5*(psi)$);
      \draw[dashdotted, rounded corners] (phiLL) rectangle (phiUR);

      \filldraw (0.5*-3,0.5*-4) node {\(\psi\)};
      \coordinate (psiC) at (-.2,-.2);
      \coordinate (psi) at (3,4);
      \coordinate (psiLL) at ($(psiC)-0.5*(psi)$);
      \coordinate (psiUR) at ($(psiC)+0.5*(psi)$);
      \draw[dashed, rounded corners] (psiLL) rectangle (psiUR);
    \end{tikzpicture}
    \caption{\ref{def:requ:crequ:strcture:subset} \& \ref{def:requ:crequ:strcture:propersubset}}
    \label{fig:crequ:subset}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.3\linewidth}
    \begin{tikzpicture}[scale=.85]
      \coordinate (epVC) at (0,0);
      \coordinate (epV) at (4,5);
      \coordinate (epVLL) at ($(epVC)-0.5*(epV)$);
      \coordinate (epVUR) at ($(epVC)+0.5*(epV)$);
      \draw[thick, rounded corners] (epVLL) rectangle (epVUR);

      \filldraw (0.5*2.9,0.5*4) node {\(\chi\)};
      \coordinate (chiC) at (-.1,-.1);
      \coordinate (chi) at (3.5,4.7);
      \coordinate (chiLL) at ($(chiC)-0.5*(chi)$);
      \coordinate (chiUR) at ($(chiC)+0.5*(chi)$);
      \draw[rounded corners] (chiLL) rectangle (chiUR);

      \filldraw (0.5*-3,0.5*-4) node {\(\psi\)};
      \coordinate (psiC) at (-.2,-.2);
      \coordinate (psi) at (3,4);
      \coordinate (psiLL) at ($(psiC)-0.5*(psi)$);
      \coordinate (psiUR) at ($(psiC)+0.5*(psi)$);
      \draw[dashed, rounded corners] (psiLL) rectangle (psiUR);

      \filldraw (0,0) node {\(\phi\)};
      \coordinate (phiC) at (-.25,-.25);
      \coordinate (phi) at (2,3);
      \coordinate (phiLL) at ($(phiC)-0.5*(phi)$);
      \coordinate (phiUR) at ($(phiC)+0.5*(psi)$);
      \draw[dashdotted, rounded corners] (phiLL) rectangle (phiUR);
    \end{tikzpicture}
    \caption{Example premise(s)}
    \label{fig:crequ:intuition:prem-ex}
  \end{subfigure}
  \hfill\mbox{ }
  \caption{\crequ{}}
  \label{fig:crequ:intuition}
\end{figure}

\begin{note}[Weaker]
  That \(\psi\) having value \(v'\) is strictly weaker than \(\phi\) having value \(v\) captures an intuitive sense in which whether \(\psi\) has value \(v'\) is an antecedent check on concluding \(\phi\) has value \(v\) from \(\delta\).

  Further, \(\psi\) having value \(v'\) is strictly weaker than \(\phi\) having value \(v\) ensures that the definition of a \crequ{} is compatible with granting that concluding any proposition-value pair also \indicateV{} any weaker proposition-value pair.

  For, if \(\phi\) were to have value \(v\) in every \epVW{} for which \(\psi\) has value \(v'\) it would not be possible for the agent to conclude \(\psi\) has value \(v'\) without the conclusion also \indicateV{} \(\phi\) has value \(v\).\nolinebreak
  \footnote{
    Note, \ref{def:requ:crequ:strcture:psi-not-v} does not place any constraints on how the premises of the step of reasoning relate to \(\psi\) having value \(v'\) (or \(\phi\) having value \(v\)).
    \autoref{fig:crequ:intuition:prem-ex} depicts a possibility, but in general the agent may entertain arbitrary proposition-value pairs as premises.

    Hence, satisfying the definition of a \crequ{} will not ensure that the step is `reasonable'.
    For example, be that there is no \epVW{} where \(\chi_{1},\dots,\chi_{k}\) all have values \(v_{1},\dots,v_{k}\), and hence the agent would, if they were to conclude \(\phi\) has value \(v\), reason from premise proposition-value pairs that the agent do not consider \epVAd{}.

    Still, \ideaCS{} is only a necessary condition on claiming support, and in turn a \requ{}, and specifically a \crequ{}, need not capture every way in which a step of reasoning may be problematic (with respect to claiming support).

    And, as we will observe, the partner definition of a \prequ{} will place some constraints on when an agent may appeal to some premises to claim support for some conclusion.
  }

  It also follows from both \(\psi\) having value \(v'\) is strictly weaker than \(\phi\) having value \(v\) and the \epVN{} of \(\psi\) not having value \(v'\), that there is some \epVW{} in which \(\phi\) does not have value \(v\).
  In this respect, the definition of a \crequ{} is restricted to non-deductive steps of reasoning.\nolinebreak
  \footnote{
    This is not to deny that the definition of a \requ{} may be extended to cover cases of deductive reasoning.
    Still, it is unclear to me (at least) how the intuitive idea of a \crequ{} \emph{could} be extended to deductive steps.
    For, at issue is whether the agent may have first witnessed some other reasoning which would prevent the agent from concluding \(\phi\) has value \(v\), but if \(\phi\) having value \(v\) follows deductively, then no other reasoning is possible without the agent having concluded that some proposition has multiple incompatible values, or the agent revising their current epistemic state.

    Still, this is not to deny that an agent may make a non-deductive step of reasoning by appeal to a deductive step.
    For example, the agent may fail to note a key restriction on a theorem before applying it to a specific case.
    However, the distinction between whether a step of reasoning is deductive or non-deductive is made independently of the agent's perspective.
  }
\end{note}


\begin{note}[\ref{def:requ:prequ:no-revision}]
  However, \ref{def:requ:prequ:no-revision} captures an important subtlety regarding the agent's epistemic state that does not reduce to the present relation between various proposition-value pairs.
  For, it may be that the extant relation between \(\phi\) having value \(v\) and \(\psi\) having value \(v'\) is unimportant to the agent.

  Consider a familiar situation from \citeauthor{Harman:1986ux}:

  \begin{quote}
    Mary believes, prior to looking in the cupboard, that if she looks in the cupboard, then she will see a box of Cheerios.
    Mary then looks in the cupboard and does not see a box of Cheerios.
    Hence, Mary abandons her belief about what she would see if she looks in the cupboard.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[Cf.][Chs.1\&2]{Harman:1986ux})}
  \end{quote}

  In a similar way, an agent may abandon any relation between the premises of some step and \(\psi\) having value \(v'\) rather than hold that so long as the premises have their respective values then \(\psi\) has value \(v'\).
  For example, an agent may hold that the fire alarm will active whenever there is a fire.
  Though, allow for the possibility that the fire alarm may active when there is no fire.
  However, given the presence of fire with an the appearance of no alarm, the agent may abandon that the fire alarm will active whenever there is fire in order to conclude that someone is in danger, rather than investigating when the alarm really is active.

  In this respect, clause \ref{notion:requ:structure:need-psi} of \autoref{notion:requ} would not be satisfied --- it is \epVAd{} for the agent to conclude that someone is in danger from the presence of fire without being \committed{} to the fire alarm being active.

  While both \ref{def:requ:prequ:strcture} and \ref{def:requ:prequ:no-revision} relate to the same intuitive point, these are separated in the definition of a \prequ{} as \ref{def:requ:prequ:strcture} concerns the structure of the agent's current epistemic state, while \ref{def:requ:prequ:no-revision} concerns a subjunctive property of the present structure.
\end{note}

\subsubparagraph{Relevance}

\begin{note}[Relevance]
  By relativising the core of the constraint to the agent's perspective we ensure that whether or not \(\psi\) has value \(v'\) is relevant to the agent's own reasoning.
  In particular, we ensure that whether or not \(\psi\) having value \(v'\) matters to whether or not \(\chi_{i}\) have values \(v_{i}\) by the agent's own lights, so to speak.

  Variations on the idea of a \prequ{} may take into account the epistemic states of other agents. For example if the agent were engaged in not merely reasoning to, but arguing for, some conclusion.
  Still, for present purposes we only identifying \(\psi\) having value \(v'\) as a \prequ{} if the agent considers it \epVAd{} to `check' their appeal to some premises prior to making a step of reasoning.

  This observation will be important for motivating \ideaCS{} via \ideaS{}.

  For now, observe:

  If \ref{def:requ:prequ:possible-reason} is satisfied, and the agent were to fail to conclude \(\psi\) has value \(v'\), then the agent would be unable to distinguish an \epVW{} in which \(\psi\) has value \(v'\) and \(\chi_{i}\) have values \(v_{i}\) from an \epVW{} in which \(\psi\) does not have value \(v'\) and \(\chi_{i}\) does not have values \(v_{i}\).
  Hence, it would seem that from the agent's perspective that they have no basis for concluding \(\phi\) has value \(v\) by appeal to \(\chi_{i}\) having values \(v_{i}\).
\end{note}

\subsubparagraph{The possibility of reasoning}

\begin{note}
  \ref{prequ:int:reasoning} is primarily captured by \ref{def:requ:prequ:possible-reason}.
  However, \ref{def:requ:prequ:possible-reason} is significantly more complex than \ref{prequ:int:reasoning}.

  In order to clarify \ref{def:requ:prequ:possible-reason}, we break down the clause in to three important components, and will discuss each component in turn.
  The three important components are:
  \begin{itemize}
  \item
    First, the core of the constraint concerning reasoning.
  \item
    Second, a relativisation of the core of the constraint to what is \epVAd{} for the agent.
  \item
    Third, a restriction on the scope of the core of the constraint relative to what is \epVAd{} for the agent to \epVW{1} in which the premises are true.
  \end{itemize}
\end{note}

\subsubparagraph{The core constraint}

\begin{note}[Constraint]
  The constraint:
  \begin{quote}
    There is some temporal extension of any relevant \epVW{} in which the agent witnesses reasoning which concludes \(\psi\) has value \(v'\).
  \end{quote}

  Recall, any (relevant) \epVW{} is a candidate for the actual \world{}.
  And, by temporal extension we mean the progression of a \world{} up to some future point in time.

  So, at core, the constraint specifies that the agent has the opportunity to reason about whether \(\psi\) has value \(v'\), and if the agent were to reason about whether \(\psi\) has value \(v'\), the agent would conclude \(\psi\) has value \(v'\).

  Note, the core of the constraint only requires that there is \emph{some} temporal extension of any given \epVW{}.
  Hence, the core of the constraint does not require that the agent \emph{will} conclude \(\psi\) has value \(v'\).
\end{note}

\begin{note}[Delicacy]
  On the one hand it is simple to fail the core of the constraint.
  For, the core of constraint requires that the agent would not fail to conclude \(\psi\) has value \(v'\).
  On the other hand, it is difficult to fail the core constraint.
  For, the core constraint requires only that there is at least one instance in which the agent would not fail to conclude \(\psi\) has value \(v'\).

  To illustrate, consider two different kinds of uncertainty.

  On the one hand, and agent may be uncertain about whether they would conclude \(\psi\) has value \(v'\) due to, say, requiring some information that they may or may not be in a position to acquire.
  If so, then the agent will be unsure about whether there \emph{is} a temporal extension of the relevant \world{}.
  For, the existence of the required temporal extension will depend on whether the agent acquires the required information.
  Hence the core of the constraint will not be satisfied.

  Note, the relevant sense of the copula `is' concerns existence, rather than possibility, however the notion of existence is understood for temporal extensions.

  On the other hand, an agent may be uncertain about whether they really do have the opportunity to conclude \(\psi\) has value \(v'\) as any instance of reasoning may be interrupted.
  However, so long as there is no guarantee that the agent's reasoning would be interrupted, then the core of the constraint will be satisfied, even if it is highly unlikely that the agent would conclude the relevant reasoning.

  Somewhere between these two extremes is a more nuanced constraint.
  Still, in order to keep the complexity of the constraint (relatively) low, we will not add further conditions.
  In cases where the constraint is to simple to fail, then the definition of a \requ{} may be added to, as \(\psi\) having value \(v'\) being a \prequ{} is only a sufficient condition for \(\psi\) having value \(v'\) being a \requ{}.
  And, we will avoid applying the definition of \prequ{} in cases where the definition exceeds intuition.
\end{note}

\paragraph{Temporal extension}

\begin{note}
  \color{red}
  Need to say more about this.
\end{note}

\begin{note}
  Receiving a letter.
  Unmarked, okay, it's for me.
  Marked, check the address.
\end{note}

\begin{note}[Illustration, testimony]
  To illustrate, consider expert testimony to a layperson.
  Suppose you, the expert, have testified to me, the layperson, that there are exactly five intermediate logics that have the interpolation property.\nolinebreak
  \footnote{Cf.\ \textcite{Maksimova:1977un}}
  From this it follows that there is an intermediate logics that has the interpolation property.

  However, I am quite confident that I would not be in a position to claim support for the latter proposition without your testimony.
  So, given that I do not have the expertise involved, any failure by me to claim support that there is a intermediate logic with the interpolation property is uninformative.
\end{note}

\begin{note}
  Still, an issue arises if we are both experts.

  To illustrate, suppose you and I are both experts.
  You claim to have developed a sound and complete proof system for an logic and presented me with a paper containing the system and a proof.
  Given that I have the paper and the expertise, I am confident that I would be mistaken or misled by your testimony if I am not in a position to claim support that the system is sound and complete by working through the paper.\nolinebreak
  \footnote{
    Here, complexity of understanding of having resources shows.
    For, it may be that the reader learns something new, a lemma etc.\ which could be considered a new resource.
    Likewise, one may think that it's fine to continue to follow testimony given a problematic proof as one is confident that the prover has the resources to revise the proof.
    If so, not clear whether conditional holds, and will depend having resources.
    If proof synthesises resources, then may still hold.
    If proof introduces new information, then conditional does not hold.

    No clear answer for these cases.
    Intend to be compatible with your understanding of resources.
    Will only take a stance on this when applying.
  }
\end{note}

\begin{note}
  Even more difficult

  Coworker.
  Rely on colleague, as the agent doesn't have access to the file.
  But, access is granted quickly after hearing from the colleague.
\end{note}

\begin{note}
  These cases are harder within the broader context of \ideaCS{}.
  Issue is that in both cases, result may seem excessive.

  Well, first thing to do is to check that the agent really is claiming support.
  Fine, it seems, for the agent to stop at claiming support for the other agent, and not going any further.
  See no reason to hold that the agent must \csN{}.

  Second, whether it holds with respect to the agent's current epistemic state.
  With the coworker.
  No.
  With the experts, yes.

  Though, this is not entirely satisfactory.
  For, it seems that motivation behind \ideaCS{} suggests \csVed{} does not `persist'.
  If update epistemic state, then may lose property of having \csVed{}.

  Consider variation of the expert case.
  It isn't obvious that one gets to claim support for the stuff learnt as a layperson when one develops expertise.

  So, question.
  However, beyond scope of document.
\end{note}

\begin{note}[Uninspiring]
  These responses aren't particularly inspiring.

  However, let's look at this from a different angle.
  What's going to follow from insensitivity to context?
  End up with claiming support that does not depend on whether or not the agent is in a position to deal with defeaters.

  Well, the first option is that these never matter.

  Some kind of built in support.
  This comes up with ~\citeauthor{Pryor:2012tq}'s dogmatism (\cite{Pryor:2000tl,Pryor:2012tq}) and various ideas about entitlement (Wright, Burge, etc.)
  For example, Pryor's dogmatism for perception, just having the experience is good enough.
  Question about these kinds of defeaters.
  Reads to me that these kinds of things mean that {\color{red} inclusion} will never hold.

  Question is whether this extends to all cases, so that \nI{} is trivial, but before pressing this seems too strong.
  Problems in various cases.
  The red room, but in the corner is a switch, flipped to off, but says it's broken.

  Context makes a difference.
  So, to this extent, looks as though there's going to be difficult cases.
\end{note}

\begin{note}[Following doesn't depend on difficult cases]
  Of course, this isn't a general defence of the clauses.
  Rather, that such difficulties can't be avoided.
  Upshot here is that we aren't really interested in such difficult cases.
\end{note}

\subsubparagraph{The role of the agent}

\begin{note}
  Our discussion of the core of the constraint focused on there being some temporal extension of the \world{} in which \vAgent{} witnesses reasoning which concludes \(\psi\) has value \(v'\).

  In general, whether or not the core of the constraint is satisfied by be evaluated independently of the agent's perspective on how the actual \world{} is.
  Still, we relativise the core of the constraint to the agent's perspective.

  The motivation is simple and has two (related) parts.
  \begin{itemize}
  \item
    First, we ensure \(\psi\) having value \(v'\) is relevant to the agent's reasoning.
  \item
    Second, we reduce latent issues concerning whether there is some temporal extension of a \world{} to an single source --- the agent.
  \end{itemize}
  We expand on both points in turn.
\end{note}

\subsubparagraph{Latent issues}

\begin{note}
  The upshot of resolving the relevant sense of possibility to the agent's epistemic state is that we avoid questions about whether it is possible for an agent to recognise that it is possible for them to conclude \(\psi\) has value \(v'\).
  For, if it is \epVAd{} for the agent to witness reasoning which concludes \(\psi\) has value \(v'\), then the agent holds that for every candidate for the actual \world{}, there is some extension of the candidate \world{} in which the agent witnesses the relevant reasoning.\nolinebreak
  \footnote{
    Note, this does not guarantee that the agent would witness reasoning which concludes \(\psi\) has value \(v'\) if the agent were to try, as we do not require that the actual \world{} is always an \epVW{}.
  }

  For example, it may be `possible' for the agent to conclude that the liquid in a glass is not poisoned prior to appealing to it being safe to drink in order to conclude that they should drink the liquid.

  In order to resolve whether it really is possible the agent to conclude that the liquid in a glass is not poisoned, we need only consider whether the agent considers it \epVAd{} that they may witness such reasoning.
  And, the answer may be negative as the agent expects dehydration to set in before concluding any such reasoning.
\end{note}

\begin{note}
  The upshot comes with a corresponding downshot.
  For, it may be possible (in the relevant intuitive sense) for the agent to witness reasoning which concludes \(\psi\) has value \(v'\) without the agent holding that it is \epVAd{} for them to so reason.

  For example, it may be possible (and quite straightforward) for an agent to check the boiler for a simple fault before appealing to the premises that it is broken in order to conclude that they should call for a repair.
  Yet, so long as the agent does not consider it \epVAd{} for them to check the boiler, any proposition-value pair captured a simple fault will not be a \prequ{}.
\end{note}

\subsubparagraph{Quantification}

\begin{note}
  Finally we turn restricting the scope of the core of the constraint to \epVW{1} in which all of the premises that the agent would appeal to when making the step of reasoning have the appropriate values.

  Key here is that the core of the constraint requires that there is some temporal extension of the relevant \epVW{1} in which the agent witnesses reasoning which concludes \(\psi\) \emph{has} value \(v'\).

  This gives rise to the following problem:
\end{note}

\begin{note}[Problem]
  In order for \(\psi\) having value \(v'\) to be a \crequ{} the agent must consider it \epVAd{} \(\psi\) does not have value \(v'\).
  Yet, if \(\psi\) does not have value \(v'\), then it may be the case that the agent would fail to conclude \(\psi\) has value \(v'\).\nolinebreak
  \footnote{
    In particular, whether \(\psi\) has value \(v'\) may be straightforwardly decidable for the agent, and hence if the agent were to reason about whether \(\psi\) has value \(v'\) and \(\psi\) does not have value \(v'\), then they agent would conclude \(\psi\) does not have value \(v'\).
  }
  In which case, the core of the constraint will fail to be satisfied.
\end{note}

\begin{note}[Solution]
  \color{red}
  Still, quantifying over \epVW{1} in which \(\phi\) has value \(v\) provides a motivated solution.

  For, we are only interested in the idea \(\psi\) having value \(v'\) being \crequ{} as a check on whether it would make sense for an agent to conclude \(\phi\) has value \(v\) from a collection of premises.
  Hence, in order for the \crequ{} to be a check of the relevant kind, we are only interested in cases where the agent would (`successfully') make the step.

  In other words, the agent is moving to \(\phi\), and so long as this would make sense, it says something about what the agent can do.
  It does not need to follow that the agent can reason to \(\psi\) in general.

  Therefore, we may restrict the interest in the possibility of concluding \(\psi\) has value \(v'\) to those \epVW{1} in which \(\phi\) has value \(v\).
\end{note}

\begin{note}[Illustration]
  To illustrate.

  \begin{illustration}
    Suppose an agent wishes to conclude that a parcel has gone missing from the premise that they are not (yet, at least) in possession of the parcel.

    If the parcel has gone missing, then no delivery attempt will have been made, and no note will be on their front door.
    Still, if the parcel has \emph{not} gone missing, then a delivery may have been attempted, and a note left on the agent's front door.
    And, the agent considers it \epVAd{} that a delivery was attempted earlier in the day, and that a note was left on their front door.
  \end{illustration}

  Premise, that the agent is not in possession of the parcel.
  Conclusion, the parcel has gone missing.

  However, check.
  That no delivery has been made.

  If the parcel is missing, then no note.

  So, satisfy the core of the constraint in the case of missing.

  However, if the parcel has not gone missing, there may be a note.
  So, failure to satisfy the core of the constraint in the case of not missing.
\end{note}

\begin{note}
  Key is that if not, then expect failure.
\end{note}

\paragraph{Motivation from \support{}}

\begin{note}
  We now turn to motivating \ideaCS{} with respect to \prequ{1}.
\end{note}

\begin{note}
  If the agent has not concluded for each of the premises, then it's at least necessary that conclude for \(\psi\).
  For, if not, then if were to reason about \(\psi\), then might go to \(\lnot\psi\).
  Hence, that the premises do not jointly hold.
  Therefore, the premises are not a \sink{}, and \(\phi\) is not a \sink{}.
\end{note}

\begin{note}
  There are two exceptions.

  First, that it is not possible for the agent to reason.
  Without this, then no failure of being a \sink{}.

  Second, giving up whatever leads to \(\psi\) being a \prequ{}.
  This is because the definition of a \prequ{} does not rely on the agent recognising \(\psi\) is a \prequ{}.
  Hence, possibility that agent may revise their epistemic state to avoid \(\psi\) being a \prequ{}.
  Simply done by abandoning any link.
\end{note}

\begin{note}[\prequ{}]
  \prequ{}.
  Then, premises of \(\delta\) do not hold with respect to all \epVW{1}.
  And, there is some way for the agent to reason.
  Problem here is quite clear.
  Question is whether something stronger.
  This depends on possibility of reasoning.
  If general, then simplifies.
  Reasoning for anything by required by premises.
  If not, then \(\psi\) falls outside of our interest.
  \support{2} is just about reasoning.
\end{note}



\paragraph{\illu{3} of \crequ{1}}

\begin{note}
  Key is to find a series of necessary conditions for some conclusion.
\end{note}

\subparagraph{Where's Wally}

\begin{note}
  Back to initial \illu{0}.
\end{note}

\begin{note}
  Problem.
  \requ{}.
  Agent didn't notice, so possibility.
  And, agent is appealing to it being Wally.
  Not merely that they identified as Wally.

  It's not clear need to give up claimed support, but does not extend to having a cane.

  In contrast to \ref{illu:CS:spot-the-diff}, does not seem there is anything weaker to fall back on.
  However, no strong claim here.
  Rely on stronger principles about claiming support.
\end{note}

\subparagraph{Spot the difference}

\begin{note}[Spot the difference]
  \begin{illustration}[Spot the difference]
    \label{illu:CS:spot-the-diff}
    The agent has been working through a spot-the-difference to pass some time.

    Though the time is not completely passed, the agent examined the two images with what seems sufficient care to claim support that they have found all the differences.
    However, the agent did not keep track of the number of differences.

    The agent announces `I have found all the differences' and their companion responds `All fifteen?'.

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*)]
      \setcounter{enumi}{-1}
    \item
      \label{illu:CS:spot-the-diff:info}
      If I have found all the differences, I have found fifteen differences.
    \end{enumerate}

    The agent then reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*), resume]
    \item Exhaustive search.
    \item
      \label{illu:CS:spot-the-diff:all}
      I found all the differences.
    % \item\label{illu:CS:spot-the-diff:info} My companion has testified that there are fifteen differences.
    % \item\label{illu:CS:spot-the-diff:cond} If I have found all the differences, I have found fifteen differences.
    \item
      \label{illu:CS:spot-the-diff:fif}
      So, I have found fifteen differences. \hfill (From \ref{illu:CS:spot-the-diff:info} and \ref{illu:CS:spot-the-diff:all})
    \end{enumerate}
  \end{illustration}

  Before going further, structure of this.

  The agent performed some reasoning, and concluded that they found all the differences.
  However, that reasoning is mentioned but not stated in the \illu{0}.
  Rather, present is distinct instance of reasoning after being provided with information.
  ``If not 15, then problem''.
  Present reasoning appeals to past reasoning, and draws out consequence of this given new information.
  Important: the present reasoning does not consider possibility that the agent did not find all 15 differences.
  Instead, consequence of conclusion of previous instance of reasoning.
  Still, epistemically possible that the agent did not find 15 differences.
\end{note}

\begin{note}
    Providing additional information about what the agent has claimed support for.
  Recall, \autoref{assu:CSVP}, information rather than \world{}.
  \nolinebreak
  \footnote{
    Still slight issue.
    Offering a redescription.
    You met Clark Kent, so you met Superman.
    In this case, rather than claiming support for meeting Superman, provided information is seen as an equivalent formulation.
    It is possible to read \autoref{illu:CS:spot-the-diff} in this way, and this might be the most natural interpretation.
    However, it is not the interpretation under which see the problem.
    Rather, problem is where the conditional is explicit.
    Unlike Superman case, proper conditional.
  }
\end{note}

\begin{note}
  Information leads to \requ{}.

  Possibility of not fifteen.
  And, not merely that the agent performed the reasoning, but that the reasoning identified all.
  If not fifteen, then not all, so would involve appeal to something that is not the case.

  And, present reasoning does not include reasoning about \requ{}.
\end{note}

\begin{note}[Avoiding the problem]
  This doesn't rule out some additional reasoning.
  \begin{enumerate}
  \item Exhausted search.
  \end{enumerate}
  Difference here is that the agent is not only appealing to having found.
  In addition, what they recall about reasoning.
  What matters is not that found all but rather that exhaustivity of search.
  This is not specific to 15.
  Up to some \(k\) such that agent is still confident that they performed an exhaustive search.

  Whether you think this is enough is up to you.
  On the one hand, intuitive that this does enough.\nolinebreak
  \footnote{
    Indeed, reasoning framed with all as I think it is much less clear here.
  }

  On the other hand, the agent did not keep track of the number of differences.
  So, may hold that they should go back and count.\nolinebreak
  \footnote{
    Looking ahead, \nI{}.
    Difficulty here is that don't need to go to \(\phi\).
    Indeed, note somewhere that \nI{} really only clearly takes hold when need some sort of factivity in play.
    We'll return to this.
  }

  {
    \color{red} As observed in the footnote above, the trick here is that the agent doesn't really `need' to go to having found all the differences.

    Alternatively, not enough to show that the reasoning is bad.
    E.g.\ then I would have been deceived, some trick, etc.
    Something \emph{I} wouldn't count as a difference.
  }
\end{note}

\begin{note}
  Argued above against circularity.
  Here, additional consideration.

  If the agent were to have had the information first time, then plausibly an instance of circularity.
  And, may think that this is also circularity as must also all must amount to fifteen.
\end{note}


\subparagraph{Zebra}

\begin{note}
  This is somewhat tentative.
  If you think that you would succeed in checking, then go for it.
\end{note}

\paragraph{Conditionals}

\begin{note}
  \color{red}
  The point of this section should be to note how \ideaCS{} relates to conditionals.
  In the case of truth-functional conditionals, things are quite straightforward.
  In the case of non-truth-function conditionals, not so much.
\end{note}

\begin{note}
  \(\phi \rightarrow \psi\), \(\lnot\psi \rightarrow \lnot\phi\), \(\psi \not\rightarrow \phi\).
  These are the key things.
  Does not extend to probability, because then don't get the overlapping relations.
\end{note}

\subsubparagraph{Closing}

\begin{note}
  Now, taxing.
  Very many things that could be checked.
  But whether an agent has claimed \support{} is not (necessarily) transparent.
  Rather, whether there's a clear problem.
\end{note}

\hozline


\subsubsection{\crequ{3}???}

\begin{note}
    \color{red}
    Note, focus on what the actual world is is important for the second clause.
    If it doesn't matter what the actual world is, then it's hard to see why this would matter.

    `Possible' should be restricted in some way.
    This is also why recursive in the case of \support{} is useful.
    Though, also should state that it's reasoning, with no further information.

    \requ{} is split into two cases.

    \ref{def:requ:crequ} observes that the result of making the step is a conclusion that \(\phi\) has value \(v\) only if \(\psi\) has value \(v'\).
    Alternatively, a conclusion that \(\phi\) has value \(v\) \emph{given} that \(\psi\) has value \(v'\).

    \ref{def:requ:prequ} observes that the premises appealed to cover all \epVW{1} only if \(\psi\) has value \(v'\).
\end{note}

\begin{note}[Intuition for \ideaCS{}]
  \ideaCS{}.
  The notion of a \requ{} specifies how \(\psi\) not having value \(v'\) is involved with step.
  Required in order to make step.
  Then, the problem is that the step will only conclude \(\phi\) has value \(v\) with respect to a restriction of \world{1} which are \epVAd{} for the agent.
  The agent may conclude that \emph{if} \(\psi\) has value \(v'\), \emph{then} \(\phi\), but as \(\psi\) may not have value \(v'\), the agent may not conclude \(\phi\) has value \(v\) alone.

  In other words, if an agent is \committed{} to it being that case that some step of reasoning in informative about the actual \world{} \emph{just in case} some proposition \(\psi\) has value \(v\), then unless the agent has witnessed some reasoning which \indicateV{1} \(\psi\) has value \(v'\), then the step only applies to a restricted collection of \epVW{1}.
\end{note}

\begin{note}[Dynamics]
  Stated in this way, \ideaCS{} is perhaps intuitive.

  The delicate part of \ideaCS{} is dynamics.
  In the cases of interest, the agent has concluded \(\chi_{i}\) have values \(v_{i}''\) from some prior reasoning, which have satisfied claiming support.
  However, between concluding \(\chi_{i}\) have values \(v_{i}''\) and reasoning from \(\chi_{i}\) have values \(v_{i}''\) to \(\phi\) having value \(v\), \(\psi\) (not) having value \(v'\) is introduced as an \epVN{}.

  This is where \ideaCS{} will do significant work.
\end{note}

\begin{note}[Relying]
  First, a subtle, but important, distinction is that the reasoning must \emph{rely} on the relevant step.
  Intuitively, some instance of reasoning which concludes \(\phi\) has value \(v\) relies on a step of reasoning just in case the reasoning requires both the premises and conclusion of the step to actually have their respective values in order to conclude \(\phi\) has value \(v\).

  In other words, \ideaCS{} does not extend to steps made where the step is part of some hypothetical reasoning, such as reasoning by cases.
\end{note}

\begin{note}[Intuition for \requ{}]
  Key is \(\psi\) having value \(v'\) is required to make the step.

  ??, ensures \(\psi\) not having value \(v'\) is relevant to making the step.
  There is not requirement that agent reasons about arbitrary \epVAd{} propositions.
  With respect to \ideaCS{}, keep things simple.
  Though, when defining a \requ{} in ???, strengthen somewhat.

  ??, reduces issues concerning the step to premises and conclusion of the step.

  ??, expands with respect to the agent's epistemic state.
  The use of the term `\committed{}' is to surpass any form of recognition.
\end{note}

\begin{note}
  Of course, it may be that the agent has \support{}.
  However, the reasoning would performed would not be suitable.
  Hence, failure of \emph{claiming} \support{}.

  Following \ideaS{}, \(\phi\) having value \(v\) is not a \sink{} with respect to \epVW{1}.
  Alternatively, it is not clear that the agent concludes \(\phi\) has value \(v\).
\end{note}

\paragraph{\illu{3}}

\begin{note}
  Some \illu{1}.
  Three \illu{1}.
  In each, reasoning which fails to satisfy \ideaCS{}, then suggested reasoning that would satisfy.
\end{note}

\begin{note}
  Observe, however, that the intuitive problem is not that the agent has any reason(ing) to think that \nagent{11} is \emph{not} trustworthy when speaking on matters regarding their personal character.

  Rather, the intuitive problem is that the agent does not have any reason(ing) to think that \nagent{11} \emph{is} trustworthy when speaking on matters regarding their personal character.

  In particular, that that \nagent{11} is not trustworthy when speaking on matters regarding their personal character is simply a possibility.
  It may be the case that \nagent{11} is trustworthy.\nolinebreak
  \footnote{
    \color{red}
    It's not like this suggests that they are not trustworthy.
    Asking for directions.
    These are fine, but addition is not.
  }
\end{note}

\subsection{Limitations}
\label{sec:limitations}

\begin{note}
  Goal of this section is to argue that \ideaCS{} does not over-generate.
\end{note}

\begin{note}
  The basic point is that while \(\psi\) is a consequence of \(\phi\), it's also the case that \(\phi\) is stronger.
  And, that the agent doesn't need to establish something so strong.
\end{note}

\begin{note}
  The bag contains green balls.
  The bag does not contain any red balls.

  Well, possible to empty the bag.

  However, \crequ{} doesn't cover this case, because the latter is not strictly weaker than the former.
\end{note}

\begin{note}
  X has at least \(\$100\).
  Well, then, X has at least \(\$1\), etc.

  Here, something nested.
  Where, it's always possible to check something weaker.

  It's hard to think of a compelling case.
  Still, the structure should be clear.

  Now, this does not mean that it is not possible for an agent to conclude some intermediary without previous.
  For, what the agent appeals to for an intermediary may also cover previous.
  Saw with \(\$50\), and this \indicateV{} \(\$50 - x\).

  What matters is that there's some jump, and an antecedent check on whether that jump makes sense that the agent hasn't considered.
  Yet \(\$50\) clearly works for all previous checks.
\end{note}

\subsection{\prequ{3}}
\label{sec:prequ3}

\begin{note}
  Definition of a \requ{} focused on particular structure.
  However, only a sufficient condition.
  Here, we consider \prequ{}.
  Observe this places further constraints.
  However, stronger.
  Any \prequ{} is a \crequ{}.
  Note, however, vice-versa.
\end{note}

\paragraph{Definition}

\begin{definition}
  \label{def:requ:prequ}
  \(\psi\) having value \(v'\) is a \emph{\prequ{}} of \(\delta\) \emph{if and only if} the following conditions jointly hold:
  \begin{enumerate}[label=\arabic*., ref=\named{P\(\Re\):\arabic*}]
  \item
    \label{def:requ:prequ:strcture}
    The structure of the \vAgent{}' epistemic state is such that:
    \begin{enumerate}[label=\alph*., ref=\named{P\(\Re\):1\alph*}]
    \item
      \label{def:requ:prequ:strcture:psi-not-v}
      There is some \epVW{} such that:
      \begin{itemize}
      \item
        \(\psi\) does not have value \(v'\).
      \end{itemize}
    \item
      \label{def:requ:prequ:strcture:chi-subset-psi}
      There is no \epVW{} such that:
      \begin{itemize}
      \item
        \(\chi_{i}\) have value \(v_{i}\) and \(\psi\) does not have value \(v'\)
      \end{itemize}
    \item
      \label{def:requ:prequ:strcture:chi-propersubset-psi}
      There is some \epVW{} such that:
      \begin{itemize}
      \item
        \(\psi\) has value \(v'\) and some \(\chi_{i}\) does not have value \(v_{i}\).
      \end{itemize}
    \end{enumerate}
  \item
    \label{def:requ:prequ:no-revision}
    It is not the case that the agent would revise their epistemic state so that \ref{def:requ:prequ:strcture:chi-subset-psi} does not hold (in order to conclude \(\phi\) has value \(v\) from \(\delta\)).
  \item
    \label{def:requ:prequ:possible-reason}
    For all \epVW{} in which \(\chi_{i}\) have values \(v_{i}\), there is some temporal extension of the \world{} in which \vAgent{} witnesses reasoning which concludes \(\psi\) has value \(v'\).
  \end{enumerate}
\end{definition}

\paragraph{Idea}

\begin{note}
  Intuitively, \(\psi\) having value \(v'\) is a \prequ{} of some step of reasoning just in case:
  \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
  \item
    \label{prequ:int:structure}
    \(\psi\) not having value \(v'\) is \epVAd{} and the relevant \emph{premise} proposition-value pairs of the step are paired only if \(\psi\) has value \(v'\), and
  \item
    \label{prequ:int:reasoning}
    It is possible, given the agent's epistemic state, for the agent to conclude \(\psi\) has value \(v'\) prior to making the step of reasoning.
  \end{enumerate}
\end{note}

\paragraph{The structure}

\begin{note}
  \ref{prequ:int:structure} is primarily captured by \ref{def:requ:prequ:strcture}, where:

  \ref{def:requ:prequ:strcture:psi-not-v} ensures that \(\psi\) may not have value \(v'\).
  And, \ref{def:requ:prequ:strcture:chi-subset-psi} together with \ref{def:requ:prequ:strcture:chi-propersubset-psi} ensure that the \world{1} in which the premise proposition-value pairs holds are a subset (from \ref{def:requ:prequ:strcture:chi-subset-psi}) and moreover a \emph{proper} subset (from \ref{def:requ:prequ:strcture:chi-propersubset-psi}) of the \world{1} in which \(\psi\) has value \(v'\).

  \begin{figure}
    \mbox{ }\hfill
    \begin{subfigure}{0.3\linewidth}
      \begin{tikzpicture}[scale=.85]
        \coordinate (epVC) at (0,0);
        \coordinate (epV) at (4,5);
        \coordinate (epVLL) at ($(epVC)-0.5*(epV)$);
        \coordinate (epVUR) at ($(epVC)+0.5*(epV)$);
        \draw[thick, rounded corners] (epVLL) rectangle (epVUR);

        \filldraw (0.5*2.9,0.5*4) node {\(\psi\)};
        \coordinate (psiC) at (-.1,-.1);
        \coordinate (psi) at (3.5,4.7);
        \coordinate (psiLL) at ($(psiC)-0.5*(psi)$);
        \coordinate (psiUR) at ($(psiC)+0.5*(psi)$);
        \draw[dashed, rounded corners] (psiLL) rectangle (psiUR);
      \end{tikzpicture}
      \caption{\ref{def:requ:prequ:strcture:psi-not-v}}
      \label{fig:prequ:intuition:psi-not-v}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\linewidth}
      \begin{tikzpicture}[scale=.85]
        \coordinate (epVC) at (0,0);
        \coordinate (epV) at (4,5);
        \coordinate (epVLL) at ($(epVC)-0.5*(epV)$);
        \coordinate (epVUR) at ($(epVC)+0.5*(epV)$);
        \draw[thick, rounded corners] (epVLL) rectangle (epVUR);

        \filldraw (0.5*2.9,0.5*4) node {\(\psi\)};
        \coordinate (psiC) at (-.1,-.1);
        \coordinate (psi) at (3.5,4.7);
        \coordinate (psiLL) at ($(psiC)-0.5*(psi)$);
        \coordinate (psiUR) at ($(psiC)+0.5*(psi)$);
        \draw[dashed, rounded corners] (psiLL) rectangle (psiUR);

        \filldraw (0.5*-3,0.5*-4) node {\(\chi\)};
        \coordinate (chiC) at (-.2,-.2);
        \coordinate (chi) at (3,4);
        \coordinate (chiLL) at ($(chiC)-0.5*(chi)$);
        \coordinate (chiUR) at ($(chiC)+0.5*(chi)$);
        \draw[rounded corners] (chiLL) rectangle (chiUR);
      \end{tikzpicture}
      \caption{\ref{def:requ:prequ:strcture:chi-subset-psi} \& \ref{def:requ:prequ:strcture:chi-propersubset-psi}}
      \label{fig:prequ:intuition:subset}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\linewidth}
      \begin{tikzpicture}[scale=.85]
        \coordinate (epVC) at (0,0);
        \coordinate (epV) at (4,5);
        \coordinate (epVLL) at ($(epVC)-0.5*(epV)$);
        \coordinate (epVUR) at ($(epVC)+0.5*(epV)$);
        \draw[thick, rounded corners] (epVLL) rectangle (epVUR);

        \filldraw (0.5*2.9,0.5*4) node {\(\psi\)};
        \coordinate (psiC) at (-.1,-.1);
        \coordinate (psi) at (3.5,4.7);
        \coordinate (psiLL) at ($(psiC)-0.5*(psi)$);
        \coordinate (psiUR) at ($(psiC)+0.5*(psi)$);
        \draw[dashed, rounded corners] (psiLL) rectangle (psiUR);

        \filldraw (0.5*-3,0.5*-4) node {\(\chi\)};
        \coordinate (chiC) at (-.2,-.2);
        \coordinate (chi) at (3,4);
        \coordinate (chiLL) at ($(chiC)-0.5*(chi)$);
        \coordinate (chiUR) at ($(chiC)+0.5*(chi)$);
        \draw[rounded corners] (chiLL) rectangle (chiUR);

        \filldraw (0,0) node {\(\phi\)};
        \coordinate (phiC) at (-.25,-.25);
        \coordinate (phi) at (2,3);
        \coordinate (phiLL) at ($(phiC)-0.5*(phi)$);
        \coordinate (phiUR) at ($(phiC)+0.5*(chi)$);
        \draw[dashdotted, rounded corners] (phiLL) rectangle (phiUR);
      \end{tikzpicture}
      \caption{Prospective conclusion}
      \label{fig:prequ:intuition:conclusion}
    \end{subfigure}
    \hfill\mbox{ }
    \caption{
      The structure of an agent's epistemic state with respect to \epVW{} when \ref{def:requ:prequ:strcture} is satisfied.
    }
    \label{fig:prequ:intuition}
  \end{figure}
  This structure is depicted in \autoref{fig:prequ:intuition}:

  \begin{itemize}
  \item
    \autoref{fig:prequ:intuition:psi-not-v} represents the agent's epistemic state (the bold rectangle) being such that there are some \world{1} such that \(\psi\) has value \(v'\) (those within the dashed rectangle), and that there are some \world{1} such that \(\psi\) does not have value \(v'\) (those outside the dashed rectangle).
  \item
    \autoref{fig:prequ:intuition:subset} represents the \world{1} in which the collection of premises \(\chi_{i}\) all have respective values \(v_{i}\) are a proper subset of the \world{1} such that \(\psi\) has value \(v'\).
  \item
    \autoref{fig:prequ:intuition:conclusion} represents a prospective conclusion, in which \(\phi\) having value \(v\) is obtained via a non-deductive step of reasoning from \(\chi_{i}\) having values \(v_{i}\), though the relevant step may also be deductive.
  \end{itemize}
\end{note}

\paragraph{\illu{3}}



\begin{note}
  \begin{illustration}
    Computer, not turning on.
    Broken.
    Check that it's plugged in.
  \end{illustration}
\end{note}

\begin{note}
  \begin{illustration}
    Sent documents.
    Up to date.
    Revised at the end of financial year, past that.
    Well, at least check the year of the document.
  \end{illustration}
\end{note}

\begin{note}
  Given the constraints, we mostly get variations on this kind of case.
  The purpose of a \prequ{} is just clarify how to refine the notion of a \requ{}.
  In particular, some of the limitations.
\end{note}

\paragraph{Not completely trivial}

\begin{note}
  Trivially satisfied if the agent has concluded for each of the premises.
  For, given that \(\psi\) is strictly weaker than the premises, any reasoning for the premises is going to \indicateV{} \(\psi\).

  In this respect, fault is local to the reasoning, and again motivation for broadening to subjunctive considerations regarding relaxing and agent's epistemic state.

  Final: Not completely trivial.
  For, it may be the case that it is not possible for the agent to reason to one of the premises, but that \(\psi\) is still a condition that they could reason to.
\end{note}

\begin{note}
  \begin{illustration}
    The clock is working.
    Without any other source for the time, there's nothing to be done.
    However, it should definitely be ticking.
    Therefore, at the very least check this.
  \end{illustration}
  Or, that it's not clearly daylight outside.

  Not here that it's not clear that the clock would be particularly good.
  However, with respect to constraints, it's fine.
\end{note}

\newpage

\subsection{Contrasts}
\label{sec:contrasts}

\paragraph{Circularity}

\begin{note}
  \ideaCS{} is not about circular reasoning in the sense that the term `circularity' suggests that the reasoner has taken the conclusion of the reasoning for granted.

  There's nothing in \ideaCS{} that appeals to getting \(\psi\) having value \(v'\) from \(\phi\) having value \(v\).

  However, does identify a problem in the sense that would prevent the agent from getting \(\psi\) having value \(v'\) from \(\phi\) having value \(v\).
\end{note}

\begin{note}[Testimony 1]
  \begin{illustration}[Testimony 1]
    \label{illu:CS:test:basic}
    \mbox{}
    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item
      \label{ex:eiS:t:basic:test}
      \nagent{11} stated that they are trustworthy when speaking on matters regarding their personal character.
    \item
      \label{ex:eiS:t:basic:ok}
      \nagent{11} is trustworthy when speaking on matters regarding their personal character.
    \end{enumerate}
  \end{illustration}
  This kind of case is intuitively problematic.
  It seems that already need trustworthy.
  However, in order for \csN{} to apply, need for it to be the case that one has some check on whether \nagent{11} is trustworthy.
  And, by reasoning.

  This need not be the case.
  Of course, this does not mean that an agent need \csN{}.
  May be other necessary conditions.
\end{note}

\paragraph{Sgaravatti}

\begin{note}
  For example, consider what \citeauthor{Sgaravatti:2013wu} terms the `Justification Account' of circularity.\nolinebreak
  \footnote{
    As \citeauthor{Sgaravatti:2013wu} notes, the Justification Account of circularity is a rewriting of the third type of `epistemic dependence' considered by \citeauthor{Pryor:2004ws}~(\citeyear[359]{Pryor:2004ws}).
    Neither \citeauthor{Pryor:2004ws} nor \citeauthor{Sgaravatti:2013wu} endorse the Justification Account, but I take the spirit of the account to sufficient for interest.
    Still, the considerations which follow also apply to distinguish the {\color{red} problem identified} from \citeauthor{Sgaravatti:2013wu}'s favoured account (\Citeyear[\S3]{Sgaravatti:2013wu}) and the fifth type of `epistemic dependence' considered by \citeauthor{Pryor:2004ws}~(\citeyear[359]{Pryor:2004ws}).
  }

  \begin{quote}
    \begin{enumerate}[label=(JA), ref=(JA)]
    \item\label{sg:JA} An argument is circular if and only if for you to have justification to believe the premisses, it is necessary that you have justification to believe the conclusion.\nolinebreak
      \mbox{}\hfill\mbox{(\Citeyear[754]{Sgaravatti:2013wu})}
    \end{enumerate}
  \end{quote}
  Where `justification to believe' is to be read as in terms of having formed the belief in an epistemically appropriate way as opposed to (merely) possessing sufficient resources to form formed the belief in an epistemically appropriate way.\nolinebreak
  \footnote{
    Or, however you prefer to characterise \citeauthor{Firth:1978vi}'s (\Citeyear{Firth:1978vi}) distinction between doxastic and propositional justification (or warrant).
    See also \citeauthor{Silva:2020aa} (\Citeyear{Silva:2020aa}) --- esp.\ fn.\ 1.
  }
  (\citeauthor[Cf.][754--755]{Sgaravatti:2013wu})
\end{note}

\begin{note}
  First, reliance on something like justification.

  With \support{}, we arguably have something distinct.
  Have not placed constraints on reasoning.
  Hence, \ideaCS{} applies even when no justification (or any other epistemic attribute) is found.

  Indeed, to the extent that the value \(v\) need not be truth, \ideaS{} and \ideaCS{} are broader.

  Point extends to relation between the premises and the conclusion of a step of reasoning.
  There's some issue with whether there's a clear reduction to premises.

  Now, both these points may be addressed by linking justification to steps of reasoning.
  However, it still remains that get this kind of circularity by placing a constraint on permissible steps of reasoning.
\end{note}

\paragraph{Pryor}

\begin{note}[\citeauthor{Pryor:2004ws}'s Type 4]
  An instance of a limitation arising from assuming that the possibility obtains is the fourth type of dependence between premise and conclusion considered by \citeauthor{Pryor:2004ws}.

  \begin{quote}
    [Type 4] dependence between premise and conclusion is that the conclusion be such that evidence \emph{against it} would (to at least some degree) undermine the kind of justification you purport to have for the premises.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[359]{Pryor:2004ws})}
  \end{quote}

  Again, plausible.\nolinebreak
  \footnote{
    A variant of \citeauthor{Pryor:2004ws}'s Type 4 dependence is~\citeauthor{Jackson:1984vk}'s account of circularity.
    \begin{quote}
      [I]t may be that a given argument to a given conclusion is such that anyone --- or anyone sane --- who doubted the conclusion would have background beliefs relative to which the evidence for the premises would be no evidence.\space \dots

      Such an argument could be of no use in convincing doubters, and is most properly said to beg the question.\nolinebreak
      \mbox{}\hfill\mbox{(\Citeyear[111-12]{Jackson:1984vk})}
    \end{quote}
    Still, in contrast to \citeauthor{Pryor:2004ws}'s Type 4, \citeauthor{Jackson:1984vk}'s account of circularity is dialectical.
    Indeed, on \citeauthor{Jackson:1984vk}'s account (without additional constraints on when an agent has justification or evidence) it need not be the case that the agent's own justification would be undermined by someone doubting the conclusion.
    In this respect, \ideaCS{} is further distinguished from a proposal such as \citeauthor{Jackson:1984vk}'s as \ideaCS{} makes mention only of the relevant agent's epistemic state and reasoning.
  }
  Further, weaken from justification to any reasoning.
  In this respect, motivated by \ideaS{}, plausibly.
  However, much stronger.
  \ideaS{} is just about entertaining.
  Subjunctive with stronger is less clear.

  Issue:
  \begin{enumerate}
  \item Evidence undermines the kind of justification the agent purports to have for the premises.
  \end{enumerate}

  And, as \citeauthor{Pryor:2004ws} notes, \emph{kind} is important.
  However, it seems kind is not the only problem.
\end{note}

\begin{note}
  \citeauthor{Pryor:2004ws}'s argument that type 4 over-generates is somewhat interesting.
  Details are in the following footnote.\footnote{
  Compatible with \citeauthor{Pryor:2004ws}'s objection to type 4 dependence.

  % \begin{illustration}
    % \mbox{}
    % \vspace{-\baselineskip}
    \begin{quote}
      Suppose you're watching a cat stalk a mouse. Your visual experiences justify you in believing:

      \begin{enumerate}[label=(\arabic*), ref=(\arabic*)]
        \setcounter{enumi}{10}
      \item
        \label{illu:Pryor:cat:1}
        The cat sees the mouse.
      \end{enumerate}

      You reason:

      \begin{enumerate}[label=(\arabic*), ref=(\arabic*), resume]
      \item
        \label{illu:Pryor:cat:2}
        If the cat sees the mouse, then there are some cases of seeing.
      \item
        \label{illu:Pryor:cat:3}
        So there are some cases of seeing.\nolinebreak
        \mbox{}\hfill\mbox{(\citeyear[361]{Pryor:2004ws})}
      \end{enumerate}
    \end{quote}
  % \end{illustration}

  Setting aside whether this is fine.

  Following \citeauthor{Pryor:2004ws}:

  Bad, given proposal, as if no cases of seeing, then the cat is not seeing. (\citeyear[361]{Pryor:2004ws})

  \citeauthor{Pryor:2004ws}'s position is as follows:

  \begin{quote}
    I don't think you need antecedent justification to believe \ref{illu:Pryor:cat:3}, before your experiences can give you justification to believe \ref{illu:Pryor:cat:1}.
    I also think it's plausible that your perceptual justification to believe \ref{illu:Pryor:cat:1} contributes to the credibility of \ref{illu:Pryor:cat:3}.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[361]{Pryor:2004ws})}
  \end{quote}

  This may be compatible with \ideaS{} and \ideaCS{}.
  With \ideaCS{}, somewhat trivial, if \ref{illu:Pryor:cat:3} holds throughout \epVW{1}.

  More generally, weaker proposition.
  Hence, it seems \indicateV{1}.
  So there's no issue with the reasoning.
  However, `contributes to the credibility\dots'.
  }
\end{note}

\begin{note}[Issue]
  Somewhat similar to above.
  Here, however, role of novel information is of interest.
  Hence, dynamic.
  And, \csN{} is, in this respect, static.
\end{note}


\paragraph{Others}

\begin{note}
  This also extends to \citeauthor{Wright:2011wn}.
  For, \citeauthor{Wright:2011wn} relies on the idea of doubt.

  The issue here is what is required in order to doubt.
  One may need to revise one's epistemic state.

  Of course, if idea of claiming support is taken generally, then it should be the case that for any \epPW{}, it is possible for the agent to conclude from reasoning that \(\phi\) having value \(v\) holds for any \epVAd{} \world{}.

  So, if satisfy claiming support, then may satisfy doubt idea.
  However, ideal.
  Pointing out the issue here does not require such a general thing as doubt.
\end{note}

\begin{note}
  Instead, as \(\psi\) not having value \(v'\) is an \ep{}, it is possible that \(\psi\) does not have value \(v'\).
  And, if \(\psi\) does not have value \(v'\), then step \(\delta'\) does not apply to how things are.
  Hence, observing that \(\psi\) having value \(v'\) follows in turn from the conclusion of step \(\delta'\) (together with other premises) is uninformative about how things are.
\end{note}

\subsubsection{Motivation}
\label{sec:motivation}

\begin{note}
  Provided clarification and some intuition.
  Seen some \illu{1}.
  Turn to motivation.

  Recap \ideaS{}, \support{}.
  Show how \ideaCS{} is motivated by \ideaS{}.
  Suggest that \ideaCS{} also motivates \ideaS{}.
\end{note}

\begin{note}
  First, this idea of claiming support is for how things are.
  If \epVW{}, then not for how things are.

  The difficulty is that we have no placed any constraints on reasoning.
  Specifically, steps of reasoning.
  Without preventing certain steps of reasoning, there is no problem with agent arbitrarily concluding that some proposition \(\phi\) has some value \(v\).

  Hence, \ideaS{} provided a partial constraint on the result of reasoning.
  We noted that this may still allow arbitrary reasoning, but \ideaS{} places some limits.
  Secures the conclusion with respect to the agent's epistemic state.
  What it is, in part, for the agent's reasoning to conclude something about how things are.
  Even if things were some other way, the agent would still reason to the relevant conclusion.
\end{note}

\begin{note}[Getting \ideaCS{} from \ideaS{}]
  Key property from \ideaS{} is that if an agent would not reason, then no \support{}.
  This is what matters.
  If agent fails to satisfy necessary condition of \ideaCS{}, then the reasoning would not be an instance of reasoning suitable for \support{}.

  For, suppose antecedent conditions.
  But, no reasoning.

  Then, given this, need \(\psi\) to have value \(v'\), but no reasoning which concludes \(\psi\) has value \(v'\).

  Now, this leaves open the possibility that if the agent were to reason about whether \(\psi\) has value \(v'\), then the agent would conclude \(\psi\) does not have value \(v'\).
  Indeed, \(\psi\) not having value \(v'\) may be a \sink{} with respect to the agent's epistemic state.
  Recall, the idea is that if the agent were to reason about\dots

  So, this means that the agent has no guarantee \(\phi\) having value \(v\) is a sink.

  Hence, lacking that the agent would reason even if \(\psi\) does not have value \(v'\).

  Indeed, the key part of \ideaS{} is reasoning about \epVAd{} proposition-value pairs.
  Our interest with relaxing with respect to \ideaS{} was to provide somewhat clear account of why the agent's reasoning concludes.
  Still, relaxing is important because it means that even after making the step, the agent would not necessarily have \support{}.

  Of course, still problem of whether the agent has \support{} for current epistemic state.
  However, only a necessary condition.

  Still, so long as agent satisfies \ideaCS{} for all reasoning, then plausible support.
  This is the converse.
\end{note}

\begin{note}
  From empty epistemic state.
  Satisfy \ideaCS{}.
  Then, plausibly support.
  As, reasoning about any \requ{}.
  So, if the agent were to relax, they would repeat same reasoning.
  Nothing would be `overlooked'.
\end{note}

\begin{note}
  \color{red}
  For, the underlying issue is that if no motivation for \(\psi\) having value \(v'\), then no account of why the step of reasoning is about how things actually are, rather than what follows from a restriction of how things actually are.
  \(\psi\) not having value \(v'\) remains a candidate, and so long as this is the case, then concluding \(\xi\) has value \(v''\) is not a conclusion about what is the case.

  Hence, if every step of reasoning satisfies \ideaCS{} from \epPAd{} \world{}, and the reasoning for \(\psi\) having value \(v'\) is sufficient, then it seems \ideaS{} will also be satisfied.
\end{note}

\subsection{\FCS{}}
\label{sec:fcs-2}

\begin{note}
  \color{red}
  Here, clarify how \ideaCS{} is going to work with respect to the broader argument.
\end{note}

\begin{note}
  \begin{restatable}[\FCS{0}  --- \FCS{}]{proposition}{propFCS}
    \label{prop:fcs}
    Suppose:

    \begin{enumerate}
    \item
      \(\psi\) having value \(v'\) is a \crequ{} of step \(\delta\) to \(\phi\) having value \(v\).
    \item
      \vAgent{} requires \(\phi\) having value \(v\) from step \(\delta\)
      in order for some instance of reasoning (other than mentioned) to \indicateN{} that reasoning for \(\psi\) having value \(v'\) without doing the reasoning.
    \end{enumerate}

    Then:
    \begin{enumerate}[resume]
    \item
      It is not possible for \vAgent{} to claim support for \(\phi\) having value \(v\) without witnessing the reasoning which concludes \(\psi\) has value \(v'\).
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{restatable}

  Hence, so long as \(\phi\) having \(v\) persists, further reasoning that appeals to \(\phi\) having value \(v'\) as a premise is (also) not an instance of claiming support without witnessing reasoning mentioned in {\color{red} inclusion}.

  {
    \color{red}
    Interest will be in how agent witnesses such reasoning.
  }
\end{note}

\begin{note}[Witnessing the reasoning?]
  {
    \color{red} Relation to overall argument.
  }
  Core question about whether there's a generalisation of \ideaCS{}.

  In particular, one might think that there's a requirement for the agent to witness the relevant reasoning in certain cases.
  I mean, that's the core of \ideaCS{}.
  In some cases, the agent doesn't have the option of skipping this by appealing to claimed support for something.

  However, the difficulty is in finding an expansion which doesn't also prevent the agent from claiming support when they do witness.
  In all cases, it's clear that one may get things wrong.

  The way that \adB{} avoids this is by avoiding strong claims to the specific ability.
  Indeed, principle is the same as witnessing.
  So, there's no plausible way to expand \ideaCS{} to cover the proposals without also denying the relevant instance of witnessing.

  Rather, objections here comes from supporting \ESU{}.
  That this isn't a way to claim support.
\end{note}

\paragraph{Testimony}

\begin{note}[Summary, and testimony]
  Final case to summarise:
  Knowledge via testimony.
  This condition doesn't necessarily apply, as agent may not be in position to claim support for what follows from knowledge claim.

  Agent may not be in a position to check.
\end{note}


\subsection{Notes}
\label{sec:notes}

\paragraph{Quick notes}
\begin{note}
  Two quick notes.
\end{note}

\begin{note}[First point to stress]
  First, \LCS{} outlines sufficient conditions for a particular type of proposition-value pair to be a \crequ{}.
  In turn, \FCS{} observes a constraint that this places given \ideaCS{}.

  Still, \ideaCS{} only outlines a necessary condition on an agent having claimed support.
  There may be other constraints on claiming support.

  For example, \ESU{} implies a limitation of claiming support --- an agent may not claim support by appeal to some premises or step of reasoning that they have not used.

  Similarly, there may be other limitations on claiming support with obtain.
\end{note}

\begin{note}[Second point to stress]
  Second~\FCS{} does not rule out that the agent may claim support.
  Indeed, conclude that it is possible for the agent to conclude \(\psi\) has value \(v'\).

  So, \nI{} does not imply that the agent is not in a position to claim support for \(\psi\) having value \(v'\).

  \color{red}
  Indeed, I take the primary upshot of \nI{} to be a demand for understanding alternative ways of claiming support when each clause of \nI{} holds and it seems that the agent may claim support for \(\psi\) having value \(v'\).
  And, after arguing for \nI{} our attention will turn to examining how an agent may claim support by \EAS{}.
\end{note}

\subsection{Cleaning up}
\label{sec:cleaning-up}

\paragraph{\ideaCS{}}

\begin{note}
  Handful of important points.
  \begin{itemize}
  \item I need to be careful not to suggest that the agent \emph{regonises} \(\psi\) does(n't) have value \(v'\).
    Though, this may be relaxed.
  \item Explicit premises and conclusion are candidates.
  Hence, {\color{red} idea:CS:B:step:requ} constrains the reasoning in general.
  \end{itemize}
\end{note}

\subsubsection{The agent's own reasoning}
\label{sec:agents-own-reasoning}

\begin{note}
  So, the set up for the problem is.
  Look, there's no guarantee that the agent has the possibility of reasoning to \(\psi\) if \(\phi\) does not have value \(v\).
  So, in order to appeal to the possibility, it seems that the agent tacitly assumes \(\phi\) has value \(v\).
  I think this worry only really applies with respect to \LCS{}.

  And, this does look somewhat difficult.
  For, it is not clear that the agent would get to reason if \(\phi\) is not the case.

  The response here is that so long as the agent is confidence with respect to the inductive support is that they have all the basics, then the only issue is whether they would actually be successful.
  This means that the agent thinks that they'd be good to reason, and the only issue would be whether they really do have the ability.

  The problem still remains.
  The task for the agent is to establish why the would not come to some other conclusion regarding \(\psi\).
  The issue is not with some relation between proposition-value pairs in the abstract, but with the agent's reasoning.

  Doesn't the agent's reasoning already \indicateN{}?
  Well, not necessarily.
  For, there may be some \epPW{} such that the general does not extend to the specific.
  The point with this distinction is just to mark when something is a not, intuitively, a \emph{consequence}.
  Hence, this seems okay.

  And, even if it does \indicateV{}, there's still a question of why it \indicateV{}.
  So long as think possible \(\phi\) and not \(\psi\), then there's an issue.

  \(\psi\) having value \(v'\) is a \requ{} for getting \(\phi\) from \(\delta\).
  So, the agent has first got \(\psi\) having value \(v'\).
  And, now has moved to \(\phi\) having value \(v\).

  Now, the problem is,
  \(\phi\) having value \(v\) is stronger than \(\psi\) having value \(v'\).
  So, if \(\phi\) does not have value \(v\), then it may still be the case that \(\psi\) has value \(v'\), but only in cases where \(\phi\) does not have value \(v\).
  Hence, it may seem that in order to move from \(\psi\) to \(\phi\), the agent has \(\phi\) has a premise.
  If \(\phi\) then \(\psi\).
  If \(\lnot\phi\) then \(\psi\).

  There is a distinction between

  seeing \(\psi\) would not have value \(v'\) if \(\phi\) does not have value \(v\)

  and

  appealing to \(\phi\) having value \(v\) in order to get that \(\psi\) has value \(v'\).


  Note that the reasoning for \(\phi\) having value \(v\) would do no more to secure that \(\psi\) has value \(v'\), nor, for that matter, that \(\phi\) has value \(v\).
  In general, this is kind of an insane constraint on reasoning.
\end{note}

% \subsubsection{Weakening}
% \label{sec:weakening}

% \begin{note}
%   With a \requ{} we have that \(\psi\) is strictly weaker.
%   However, may also think anything equal.
%   Consider the following \illu{1}:

%   \begin{illustration}
%     \label{illu:requ:import-export}
%     Suppose we have some \emph{non-deductive} conditional `\(\Rightarrow\)' and some either deductive or non-deductive conditional \(\rightarrow\) such that:
%     \begin{quote}
%       \(\phi \Rightarrow (\psi \rightarrow \xi)\) if and only if \((\phi \text{ and } \psi) \Rightarrow \xi\)
%     \end{quote}
%     And, suppose an agent's reasoning has the structure:
%     \begin{enumerate}
%     \item \(\phi\)
%     \item \(\phi \Rightarrow (\psi \Rightarrow \xi)\)
%     \item \(\psi \Rightarrow \xi\)
%     \end{enumerate}
%     Such that possible \(\phi \rightarrow (\psi \rightarrow \xi)\) is not the case.
%   \end{illustration}

%   Here, \((\phi \text{ and } \psi) \Rightarrow \xi\) is a \prequ{} of the step from 2 to 3.
%   For, if \(\phi \Rightarrow (\psi \Rightarrow \xi)\) then also \((\phi \text{ and } \psi) \Rightarrow \xi\).
%   Hence, if \((\phi \text{ and } \psi) \rightarrow \xi\) is not the case, then \(\phi \Rightarrow (\psi \Rightarrow \xi)\) is also not the case.
% \end{note}

% \begin{note}
%   In other words, the non-deductive conditional admits of import-export.\nolinebreak
%     \footnote{
%       For example, the material conditional, but not necessarily the natural language conditional expressed in certain `if \dots then \dots' constructions {\color{red}~\cite{McGee:1985tz}}.
%     }
%     Consider the following pair of conditionals from~\citeauthor{McGee:1985tz}:
%     \begin{quote}
%       \begin{enumerate}
%       \item
%         \label{McGee:1}
%         If Uncle Otto hadn't found gold but he had struck it rich, it would have been by finding silver.
%       \item
%         \label{McGee:2}
%         If Uncle Otto hadn't found gold, then if he had struck it rich, it would have been by finding silver.\nolinebreak
%         \mbox{}\hfill\mbox{(\citeyear[467]{McGee:1985tz})}
%       \end{enumerate}
%     \end{quote}

%     If the main conditional of both statements admits of import-export, then~\ref{McGee:1} and~\ref{McGee:2} share the value true, or share the value false.

%     Still, even if an agent is \committed{} to import-export, it is perhaps not so clear that they would conclude that \ref{McGee:1} is true if and only if they would conclude that \ref{McGee:2} is true.
%     Counterfactuals are

%     Well, different things to evaluate.
%     So, gold was the last chance, hence the latter is trivial.
%     However, the former, need to do some work to allow for this possibility, so Otto would have had to have given up the efforts early, and so it's not clear that it would have been silver.

%     Well, maybe IE doesn't hold.
%     On the other hand, if committed, then this suggests that one is bad.
%     The second, plausibly, as reasoned about a restricted set of possibilities.
%     Or, the former, because you really shouldn't be revising so much.\nolinebreak
%     \footnote{
%       It seems~\textcite{Mandelkern:2020tc} makes some suggestions along these lines\dots
%     }
% \end{note}

% \begin{note}[The difficulty]
%   This I think is really quite plausible.
%   The difficulty is that I appeal to \indicateV{}.
%   In this sense, there's no difference between two proposition-value pairs of equal strength.
%   So, in order to have this, we would need to relax this simplifying assumption.

%   Intuitively, a distinction between trivial and non-trivial.
%   Suggestion is that different reasoning for showing for or against.
%   But making this precise is somewhat difficult.
% \end{note}

% \hozline

\paragraph{Other \illu{1}}

\begin{note}[Treasure --- failure of interdependence]
  \begin{illustration}
    Claimed treasure only if learnt secret.
  \end{illustration}
  A little more interesting, as here, agent is going to have done something to learn secret when claiming support for treasure, but may not recognise that they've learnt the information.

  Of course, may be wrong treasure.

  However, there's too little information here to establish interdependence.
  That's the key point.

  Useful, as earlier examples may seem to rely on easy checks, but putting pieces together to reveal secret may be quite difficult.
\end{note}

\subparagraph{Theorem \illu{1}}

\begin{note}[A few illustrations]
  Let us now turn to a few illustrations before discussing \nI{} in further detail.

  We'll begin with a somewhat detailed illustration.
  \nI{} identifies a particular way in which an agent may fail to claim support, and the primary goal of the initial demonstration is to highlight why the agent would fail to claim support.
  Hence, the illustration treads a fine line between highlighting a problematic method, but not necessarily a problematic result.
  This is by design.
  And, I will continue to stress that \nI{} concerns a way of claiming support for some proposition, rather than the possibility of claiming support for some proposition.

  Following two illustrations will be variations on the initial.

  Still, it may be helpful to observe how \nI{} relates to an intuitively problematic result.
  Therefore, we will provide an additional, simple, illustration of a failure to claim support.

  The final illustration in the trio will complement the initial par of illustrations by highlighting an instance where~\nI{} does not apply.

  \phantlabel{dogmatism-wrt-nI}
  The reader may note structural similarities between these illustrations and \citeauthor{Kripke:2011wv}'s Dogmatism paradox.
  We will discuss the relation after the illustrations.
\end{note}

\paragraph{First}

\begin{note}[Brief illustration of \nI{}]
  The first illustration considers theories and counterexamples.

  \begin{illustration}
    \label{ill:CE:main}
    Suppose a researcher have constructed a theory of some general phenomenon.

    The theory seems to capture the phenomenon, and the researcher has claimed (inductive) support that the theory is adequate by applying it to various instances of the general phenomenon.
    Even if the theory isn't adequate, the theory has been (seemingly) successful applied to sufficient specific instances of the phenomenon.
    Hence, even if \mom{}.

    However, as the phenomenon is a \emph{general} phenomenon it also makes various predictions about what must happen in all other instances to which the researcher has not (yet, at least) applied the theory to.

    Hence, there is a possible counterexample to the theory associated with each instance the researcher has not (yet) applied the theory to.
    If some particular instance does not conform to the theory, the theory is inadequate.
    Conversely, if the theory is adequate, every particular instance of the phenomenon conforms the theory.
    In other words, if the theory is adequate, then there are no counterexamples to the theory.

    Of course, it may be simple to revise the theory is a counterexample exists, and the fundamental ideas of the theory may remain sound (\cite[Cf.][]{Bonevac:2011tz}).
    And, the theory may have sufficient resources to explain why any apparent counterexample is not a counterexample.
    Yet, it remains the case that the theory would need to be revised in light of a counterexample.

    Now, to summarise, the researcher may claim support for two propositions allow the agent to claim support that there are no counterexamples.

    \begin{enumerate}
    \item The theory is adequate, and
    \item If the theory is adequate, then there are no counterexamples.
    \end{enumerate}

    At issue is whether the researcher may claim support that there are no counterexamples to the theory from the claimed support for the two propositions in the following way:

    \begin{enumerate}
    \item I have claimed support that the theory is adequate.
    \item So, given the claimed support, theory is adequate.
    \item Therefore, as the theory is adequate, given the claimed support, it follows that there are no counterexamples.
    \item Hence, I claim support that there are no counterexamples to the theory.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{illustration}
\end{note}

\begin{note}[Seems problematic]
  Seems problematic.
  Claimed support that the theory is adequate is qualified by the possibility of counterexamples.
  {
    \color{red}
    Note, agent is, here, only claiming support that there are no counterexamples.
    And, claiming support may be \mom{}.
    So, it does not follow that the agent is ruling out the possibility of counterexamples to the theory.
    Plausible that the agent \emph{may} claim support.
    Problem is the way in which the agent goes about this.
  }

  {
    Even if not convinced about support, this way of claiming support seems problematic.
    Relying on theory being adequate.
    However, if this is the case, then no possible counterexamples.
    Issue is that such counterexamples are possible given the state of your claimed support.
    Hence, claiming support in this way seems to take for granted that there are no counterexamples.
  }

  Problem is that the reasoning only works if there are no counterexamples.
  If there are counterexamples, misled.
  Hence, problem to go from the theory is adequate.
  However, without this step, researcher doesn't get to no counterexamples.
\end{note}

\begin{note}
  So, relation between theory and counterexample \emph{undercuts} using way of using theory to get no counterexample.

  Now, given that the researcher has claimed support that the theory is adequate, the researcher may \emph{expect} that there are no counterexamples to the theory.
  And, it doesn't follow that the researcher may not claim support.
  Plausible that details of the theory provide some way of claiming support.

  Indeed, it seems the researcher is require to take the alternative path --- to show that the proposed counterexample is accounted for by the contents of the theory, regardless of whether the theory is true.

  Fault here is with respect to \ideaCS{}.
  {
    \color{red}
    Here, conditions of~{\color{red} inclusion} are satisfied, but we did not explicitly appeal to them.
    Purpose of~{\color{red} inclusion} is conditions sufficient for this kind of problem to arise.
    So, to do in argument for \nI{} is to develop is why~{\color{red} inclusion} does something similar.
    Upshot is that \nI{} is general.

    In the third illustration, we'll see why the way of claiming support is okay in some cases.
  }
  Difficult part is to account for why~{\color{red} inclusion} sets things up and ensures that things don't go too far.
\end{note}

\paragraph{Second}

\begin{note}[Idea main part of \nI{} works]
  As noted above, it is unclear whether or not there may be some way for the researcher to claim that there are no counterexamples to the theory.

  In other words, one may be wondering whether \ideaCS{} is a plausible constraint on claiming support.
  We gave a general argument for \ideaCS{} in~\autoref{cha:claiming-support}.
  However, it may help to see how the issue highlighted relates to an intuitively problematic instance of reasoning, regardless of how support is claimed.

  \begin{illustration}\label{ill:CE:colleague}
    Suppose a colleague has studied the researcher's theory, and they (the colleague) thinks they have found a counterexample.

    The colleague has informed the researcher that they think they have observed a counterexample.

    However, the colleague has not provided the researcher with any further details about the counterexample.

    Now, the conditional of interest may be made more precise:
    \begin{enumerate}
    \item If the theory is adequate, then the colleague has failed to identify a counterexample to the theory.
    \end{enumerate}

    Now, let's replicate the way of claiming support from before.

    \begin{enumerate}
    \item I have claimed support that the theory is adequate.
    \item So, given the claimed support, theory is adequate.
    \item Therefore, as the theory is adequate, given the claimed support, it follows that the colleague has failed to identify a counterexample to the theory.
    \item Hence, I claim support that the colleague has failed to identify a counterexample to the theory.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{illustration}

  I take this illustration to be intuitively problematic.
  In short, if claim support, then doesn't need to examine counterexample to claim support that it is not a counterexample.

  Possible response is that researcher does claim support, but information colleague impacts claimed support for theory.
  However, this is also puzzling.
  Researcher has no information.
  Hence, if retain confidence, then equally against counterexample.
  And, if does not retain confidence, then down the theory in a way that seems implausible.

  Seems, instead, that claimed support for theory persists, but that this doesn't extend to counterexample.\nolinebreak
  \footnote{
    Inclined to apply this to previous illustration.

    However, there's a difference between two illustrations.
    Here, someone (the colleague) has reason to think there is a counterexample, and this seems a sufficiently important difference to draw any quick conclusions.
    And, as we don't require a resolution to this issue, I won't explore further.
  }

  Perhaps more detail is needed.
  I have some doubts that claiming support is always bad.
  However, clearer that developed in a way such that problem remains.

  Now, seems that the researcher doesn't get to claim support because if counterexample, then theory is bad.
  Hence, requires that counterexample is not true in order to progress.
  But, then, doesn't make the move regardless of whether or not there is a counterexample.

  So, it seems \ideaCS{} does the work.
\end{note}


\begin{note}
  ``Undercuts using \(\phi\) for \(\psi\).''
  Same problem, failure of \ideaCS{}.

  For, the agent has already `assumed' that they may reason.

  Problem is that the agent doesn't get to claim support for \(\psi\) because fail the \ideaCS{} thing.
  If \(\psi\) isn't really the case, then reasoning collapses.
  Key thing about our understanding of claimed support is that it holds up even if the agent is \mom{} about the value of the proposition.

  {
    \color{red}
    Note:
    There's possible tension here.
    It seems that if the first illustration is okay, then this (second) illustration should also be okay.
    Maybe.
    But, this is too quick.
    Additional information here.

    Now, still some difficulty, as I think \EAS{} might apply to the first.
    So, shouldn't it apply to this?
    Well, no.
    For, \EAS{} only suggests possibility in some cases.
    Fine to think of this additional information as constraint on appeal via ability.
    For, if the colleague thinks they've found a counterexample, then this suggests a problem with the agent's ability.
  }
\end{note}

\paragraph{Third}

\begin{note}[Variation where \nI{} does not apply]
  \begin{illustration}\label{ill:CE:testimony}
    Suppose the researcher has published a paper containing the details of the theory.

    Our attention now turns to a novice who has read far enough into the paper to understand, at least, the general phenomenon that the theory applies to and that the researcher has claimed inductive support for the theory.
    We'll also assume that the novice does not possess the expertise required to apply the theory.\nolinebreak
    \footnote{
      Though I don't think this assumption is important.
    }

    The novice is thinking about instances of the general phenomenon, and identifies one.

    The conditional of interest is:
    \begin{enumerate}
    \item If theory is adequate, it accounts for this instance of the phenomenon.
    \end{enumerate}

    Of course, the novice also recognises that the theory is inadequate if it  does not account for the particular instance of the phenomenon.
    Still, the novice claims support in the familiar manner.

    \begin{enumerate}
    \item I have claimed support that the theory is adequate (this time by reading a published paper).
    \item So, given the claimed support, the theory is adequate.
    \item Therefore, as the theory is adequate, given the claimed support, it follows that the theory accounts for this instance of the phenomenon.
    \item Hence, I claim support that the theory accounts for this instance of the phenomenon.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{illustration}

  In contrast to the previous illustrations, it seems the novice may claim support in such a way.

  Possibility of being either \mom{} remains.
  Still, not in position to reason through theory and phenomena.
  Hence, claiming support from something like status of peer review --- or testimony.
  And, not accounting would not show peer review is bad.
\end{note}

\paragraph{Summary of illustration and variations}

\begin{note}
  These three illustrations.
  First, kind of scenario that's the main interest.
  Where claiming support in a certain way seems problematic, even if it not clear that the agent may claim support in some other way.

  To stress the problem, considered a cleaner case, where it seems agent may not claim support, and argued that same problem is a plausible account of why.

  Third illustration, way of claiming support is okay.
  As all instances of \nI{}, and hence the previous two illustrations, focus on particular way of claiming support illustrated that it's okay.
\end{note}

\begin{note}[Intuition]
  In short, \nI{} captures a limitation: An agent is not in a position to claim support for some proposition \(\psi\) when circumstances are such that the claimed support requires (from agent's point of view) that the agent is already in position to claim support for \(\psi\).

  No claiming support for\(\psi\) if failure to establish support for \(\psi\) independently of the value of \(\phi\) would reveal problem with the support claim for \(\phi\).

  Hence, \nI{} focuses on when an agent may claim support for some proposition by noting that (from the agent's perspective) that the value of the proposition is determined by further propositions the agent has claimed support for.

  Some other way of claiming support for \(\psi\).
  However, not merely an alternative path, but an alternative path that must be possible given claimed support for \(\phi\).

  Issue is that given {\color{red} background} and~{\color{red} inclusion}, agent expect that they have the resources, and hence expects \(\psi\) is the case.

  So, that \(\phi\) has value \(v\).
  In doing so, resources to claim support for \(\psi\) has value \(v'\).
  Hence, \(\psi\) has value \(v'\).
  So, \(\psi\) having value \(v'\) is a requirement on claimed support for \(\phi\) being any good.
  However, no support claimed for \(\psi\) having value \(v'\).

  In cases of reasoning with a conditional, such as the illustrations given, that value of \(\phi\) constrains value of \(\psi\) is in general helpful information, but in these specific cases it does not help the agent claim support for \(\psi\) having value \(v'\) because if \(\psi\) isn't already so constrained, then no appeal to \(\phi\) having value \(v\).

  Similar to other principles, failure because establishing something that needs to be the case in order to be in a position to establish.
\end{note}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End: