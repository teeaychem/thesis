\chapter{Introduction}
\label{cha:introduction}

\begin{note}
  \begin{itemize}
  \item
    Initial \scen{0}, intuitions, questions, relation between answers, motivation for positive answer.
  \end{itemize}
\end{note}

\section{Concluding: Why? and How?}
\label{sec:overview:issue}

\subsection{Initial \scen{0}}

\begin{note}
  \begin{scenario}[Multiplication]
    \label{illu:gist:calc}
    An agent enters `\(23 \times 15\)' into a calculator and presses the button marked `\(=\)'.
    The calculator displays `\(345\)'.

    \mbox{ }

    The agent observes they have the option to calculate \(23 \times 15\) via their understanding of arithmetic.
    And, \emph{if} the calculator is trustworthy, then they would not fail to conclude \(23 \times 15 = 345\) via their understanding of arithmetic.

    \mbox{ }

    The agent concludes \(23 \times 15 = 345\).
  \end{scenario}

  Intuitively, the agent concluded \(23 \times 15 = 345\) from the calculator.
  Personifying a little, we may say the agent has concluded \(23 \times 15 = 345\) from the testimony of the calculator.%
  \footnote{
    Indeed, for our purposes \autoref{illu:gist:calc} may be recast in terms of an agent asking another agent to solve `\(23 \times 15\)', but using a calculator is more natural.
  }

  Still, as noted by the agent, they had the option of concluding \(23 \times 15 = 345\) through their own understanding of arithmetic, and hence without the use of the calculator.

  Still, it is intuitive that an agent concludes some proposition has some value%
  \footnote{In \scen{0} the proposition is `\(23 \times 15 = 345\)' and the value is `true'.
    In isolation, `\(23 \times 15 = 345\)' describes some possible state of affairs, and assigning the value `true' indicates the possible state of affairs is the actual state of affairs.
    Still, the agent may have concluded `\(23 \times 15 = 345\)' is `desired', `impossible', `probable', and so on.
    When speaking generally, we will keep explicit which value a proposition is paired with, though when describing specific \scen{0} or examples, we will leave the associated value implicit.
  }
  from some pool of premises only if the agent reasoned from those premises to the proposition-value pair.

  In other words, the agent may have concluded \(23 \times 15 = 345\) via their understanding of arithmetic, but as the agent did not calculate \(23 \times 15\) themselves, they did not conclude \(23 \times 15 = 345\) from whatever premises would be involved when reasoning via their understanding of arithmetic.

  Indeed, given the agent's understanding of arithmetic, it seems clear that prior to using the calculator the agent knew \emph{whether} \(23 \times 15 = 345\).
  Though, knowing whether \(23 \times 15 = 345\) is not knowing \(23 \times 15 = 345\).
  For example, I expect --- though one of the following equalities does not hold --- you know whether \(345 \times 11 = 3,795\), whether \(3,795 \div 5 = 760\), and whether \(760 \div 8 = 95\).

  Rephrasing things a little, and keeping track of truth, we may say \(23 \times 15 = 345\) was a \fc{} for the agent in \autoref{illu:gist:calc}.
  And, for you, \(345 \times 11 = 3,795\), \(3,795 \div 5 \ne 760\), and \(760 \div 8 = 95\) are \fc{1}.

  Instead, it seems the agent concluded \(23 \times 15 = 345\) by use of the calculator, regardless of whether \(23 \times 15 = 345\) was a \fc{1}.
  And, likewise, if you have concluded \(3,795 \div 5 \ne 760\) from the paragraph above, it was due to my testimony, and not your understanding of arithmetic.
\end{note}

\begin{note}[Summary of basic intuitions]
  So, intuitively, in \autoref{illu:gist:calc} the agent concluded \(23 \times 15 = 345\) from the testimony of the calculator.
  And, intuitively, \(23 \times 15 = 345\) being a \fc{0} had no significant role in the agent concluding \(23 \times 15 = 345\) from the testimony of the calculator.
\end{note}

\subsection{Two questions: Why? and How?}

\begin{note}[Not just concluding]
  So far we have spoken about intuitions of the basic form:

  \begin{itemize}
  \item
    Agent \(A\) concluded some proposition \(\phi\) has some value \(v\) from some pool of premises \(\Phi\).
  \end{itemize}

  I take intuitions of this basic form to be readily available in a variety of \scen{1}, and I also take those intuitions expressed in regards to \autoref{illu:gist:calc} to be fairly clear.

  \phantlabel{how-and-why-first-mention}
  Still, concluding is something an agent does, and in this respect there are (at least) two distinct questions intuitions of the above form may answer:%

  \begin{restatable}[\qWhy{}]{question}{questionWhyBasic}
    \label{q:why}
    Which proposition-value-premises pairings an involved in explaining \emph{why} the agent concluded \(\phi\) has value \(v\)?
  \end{restatable}

  \begin{restatable}[\qHow{}]{question}{questionHowBasic}
    \label{q:how}
    Which proposition-value-premises pairings an involved in explaining \emph{how} the agent concluded \(\phi\) has value \(v\)?
  \end{restatable}

  In basic form, focus is on what the agent did, or alternatively whether some action way performed.
  Did the agent conclude \(\phi\) has value \(v\)?
  Or, did the agent conclude \(\phi\) has value \(v\) from the pool of premises \(\Phi\)?
  Or, perhaps, did the agent fail to conclude \(\phi\) has value \(v\)?

  `How?' and `why?' by contrast, take for granted the agent concluded \(\phi\) has value \(v\) and consider, respectively, how and why this action was performed.

  How do intuitions regarding whether or not an agent performed an action relation to how and why the agent performed the action?
\end{note}

\begin{note}
  \color{red}
  Designed to allow intermediate conclusions.
\end{note}

\begin{note}
  \qWhy{} and \qHow{} are distinct questions.
  Particular instances of broader `why?' and `how?'.
  And, generally speaking, `why?' and `how?' may have distinct answers.

  For example, consider asking why and how some agent arrived at some location.
  `By bicycle' answers how the agent arrived at the post office, but does not answer why the agent arrived at the post office.
  Likewise, `to post a letter' intuitively answers why the agent arrived at the post office, but does not answer how the agent arrived at the post office.%
  \footnote{
    Of course, things get complex.
    Action, motivating reason, belief-desire pair.
    Hence, desire to post a letter is part of how.

    Preface with `intuitively'.
    The point is that may refine intuition regarding the agent concluding \(23 \times 15 = 345\).
  }

  So, the intuitions expressed with respect to \autoref{illu:gist:calc} may answer `how?' but not `why?', or `why?' but not `how?'.

  Still, I suspect this is not the case.
  In the case of \autoref{illu:gist:calc} both have the same rough answer:

  \begin{itemize}
  \item
    The pairing of testimony of the calculator with \(23 \times 15 = 345\), is, in part, \emph{both} how \emph{and} why the agent concluded \(23 \times 15 = 345\).
  \end{itemize}
  That premises associated with the agent's understanding of arithmetic do not answer either `how?' or `why?' is implicit by omission.

  Again, the agent used the testimony of the calculator to conclude \(23 \times 15 = 345\), and the agent appealed to the testimony of the calculator to conclude \(23 \times 15 = 345\).
  The agent did not use their understanding of arithmetic to conclude \(23 \times 15 = 345\), and the agent did not appeal to their understanding of arithmetic to conclude \(23 \times 15 = 345\).
\end{note}

\subsection{Relationship between \qWhy{} and \qHow{}}

\begin{note}
  Our observation that the testimony of the calculator seems to answer both `why?' and `how?' the agent concluded \(23 \times 15 = 345\) suggests, even if --- as a single \scen{0} --- only slightly, the following basic idea:%
  \footnote{
    The observation also suggests the converse holds --- an answer, in part, to `how?' is also, in part, an answer to `why?' --- though I think the converse faces some immediate difficulties.
    For, it seems answers to `how?' may include details that are irrelevant to `why?'.
    For example, typing digits and operators into the calculator answers, in part, how the agent concluded \(23 \times 15 = 345\) but these actions seems irrelevant to why the agent concluded \(23 \times 15 = 345\).
    Rather, an answer to `why?' seems to be limited to the calculator providing testimony that \(23 \times 15 = 345\), regardless of whether it was the agent who used the calculator, or whether the agent observed someone else using the calculator.
  }

  \phantlabel{how-and-why-relation-first-mention}
  \begin{restatable}[\issueInclusion{}]{issue}{issueInclusionFirst}
    \label{issue:why-inc-in-how}
    Some proposition-value-premises pairing is, in part, an answer to \qWhy{} only if that proposition-value-premises pairing is (also), in part, an answer to \qHow{}.
  \end{restatable}

  In other words, in order for premise to, in part, answer \emph{why} an agent concluded \(\phi\) has value \(v\), that premise must also, in part, answer \emph{how} the agent concluded \(\phi\) has value \(v\).

  With respect to \autoref{illu:gist:calc}, the testimony of the calculator satisfies the constraint imposed by the idea, while the agent's understanding of arithmetic does not.
  Specifically, the testimony of the calculator was part of how the agent concluded \(23 \times 15 = 345\), and so the testimony of the calculator may be, in part, an answer to why the agent concluded \(23 \times 15 = 345\).
  However, the agent's understanding of arithmetic was \emph{not} part of how the agent concluded \(23 \times 15 = 345\), and so the agent's understanding of arithmetic \emph{may not}, in part, an answer to why the agent concluded \(23 \times 15 = 345\).

  In addition, the basic idea may be taken to capture some explanatory significance and we may even say:
  The agent's understanding of arithmetic is not, in part, an answer to why the agent concluded \(23 \times 15 = 345\) \emph{because} the agent's understanding of arithmetic was \emph{not} part of how the agent concluded \(23 \times 15 = 345\).
\end{note}

\subsection{Motivation from \citeauthor{Davidson:1963aa}}

\begin{note}
  The basic idea, rather than intuitions regarding specific \scen{1} is our interest.
  Roughly, at least.%
  \footnote{
    We will shortly refine our understanding of `why?' and `how?' to focus on support between premises and conclusions, and will motivate a slightly weaker idea with respect to support.
  }

  Additional \scen{1} may provide additional motivation for the basic idea.
  Though, I think the basic idea is sufficiently intuitive independently of individual \scen{1}.
  Instead, observe the basic idea may be motivated not only by \scen{1}, but also by theories.
  Perhaps the most prominent is \citeauthor{Davidson:1963aa}' causal theory of action.

  \citeauthor{Davidson:1963aa} opens \textcite{Davidson:1963aa} with the following question:

  \begin{quote}
    What is the relation between a reason and an action when the reason explains the action by giving the agent's reason for doing what he did?
    We may call such explanations \emph{rationalizations}, and say that the reason \emph{rationalizes} the action.%
    \mbox{}\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}

  As noted, concluding is an action, and hence \qWhy{} is a particular instance of \citeauthor{Davidson:1963aa}' question.
  And, answers to \qWhy{} will be reasons that rationalise the agent concluding \(\phi\) has value \(v\).

  \citeauthor{Davidson:1963aa} argues, in short, for the following answer to the relation between a reason and the rationalisation of an action:

  \begin{quote}
    \begin{enumerate}[label=\arabic*]
      [R]ationalization is a species of ordinary causal explanation.\newline
      \mbox{ }\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
    \end{enumerate}
  \end{quote}

  Following \citeauthor{Davidson:1963aa}, an answer to \qWhy{} is a rationalisation, rationalisation is an instance of ordinary causal explanation.
  So, the answer to why an agent concluded \(\phi\) has value \(v\) will, in part, by a cause of the agent concluding \(\phi\) has value \(v\).
  Therefore, an answer to why an agent concluded \(\phi\) has value \(v\) is, in part, an answer to how the agent concluded \(\phi\) has value \(v\).

  Implicit in this quick argument is the idea that a causal explanation answers `how?'.
  Note, however, that we did not appeal to the converse.
  Causal theories of action seem to motivate the basic idea, though I do not think the basic idea (directly, at least) motivates causal theories of action (or, specifically, concluding).
  In other words, for our purposes, answers to `how?' need not be causal explanations, though they may be.

  More broadly, I take the basic idea to capture a pre-theoretical constraint on classes of theories.
  There are theories that agree with the basic idea, such as \citeauthor{Davidson:1963aa}' causal theory of action (when the action is concluding) and there \emph{may be} theories which do not agree with the basic idea --- though I do not know of any specific theories that are explicitly of this kind.
\end{note}

\subsection{Questioning the intuitive relationship}

\begin{note}
  The basic idea is more-or-less the basic issue of this document.

  Both intuitions, such as those regarding \autoref{illu:gist:calc}, and theories, such as \citeauthor{Davidson:1963aa} causal theory of action, provide motivation for the basic issue.

  Our goal is to motivate the following, basic, contrary idea:

  \begin{itemize}
  \item
    There are cases in which something is, in part, an answer to `why?' and that something is \emph{not} (also), in part, an answer to `how?'.
  \end{itemize}

  The basic contrary idea is the negation of the basic idea.
  For, the basic idea states, roughly, answers to `why?' are always included in answers to `how?' while the basic contrary idea states that there are cases in which something that answers `why?' does not also answer `how?'.

  The basic contrary idea, then, has the form of an existential.
  We will not motivate the idea that there is always something which answers `why?' but does not also answer `how?'.
  And, in particular, it may be the case that the intuitions observed with respect to \autoref{illu:gist:calc} are correct.
\end{note}

\begin{note}
  Now, all this has been said without giving attention to the conditional observed by the agent in \autoref{illu:gist:calc}:

  \begin{itemize}
  \item
    If the calculator is trustworthy, then the agent would not fail to conclude \(23 \times 15 = 345\) via their understanding of arithmetic.
  \end{itemize}

  Both natural, and somewhat surprising.

  Consider the contraposition.

  \begin{itemize}
  \item
    If the agent were to fail to conclude \(23 \times 15 = 345\) via their understanding of arithmetic, then the calculator is not trustworthy.
  \end{itemize}

  \begin{itemize}
  \item
    Is it possible, from the agent's perspective, fail to conclude \(23 \times 15 = 345\) via their understanding of arithmetic?
  \end{itemize}

  If possible, then difficulty.
  For, testimony, so must be, but at the same time, possible that it is not.
  If not possible, then it doesn't seem that observing \(23 \times 15 = 345\) via the testimony of the calculator is sufficient.
  For, by the previous observation, difficulty with the testimony of the calculator.

  \begin{itemize}
  \item
    Testimony of the calculator \emph{only if} \(23 \times 15 = 345\) is a \fc{0} given the agent's understanding of arithmetic.
  \end{itemize}
\end{note}

\begin{note}
  The only if, interesting.

  Calculator provides information about what is a \fc{}.
  Agent's understanding of arithmetic is why it is a \fc{}.

  So, if being a \fc{0} is involved in concluding, then it may be that understanding of arithmetic is, in part, an answer to `why?'.
  And, as the agent has not concluded, not, in part, an answer to `how?'.
\end{note}

\begin{note}
  Important:

  Multiple ways to conclude.
  So, have a check.

  Differs to, for example, concluding {\color{red} ???} from a scientific calculator.
  {\color{red} ???} goes beyond typical understanding of arithmetic.
  Parallel pair of conditionals does not hold.

  Or, alternatively, testimony that {\color{red} ???}.
  Beyond understanding.
\end{note}

\begin{note}
  I am not sure what to make of \ref{illu:gist:calc}.
  Understanding of arithmetic is a partial check.
  However, testimony.

  Unsure because status of a premise.

  Basic contrary idea only requires some instances.

  Argument against this intuition.
  Type of cases, premises are fixed.
  Check on own reasoning.

  First, expand on intuition.
  Then, introduce type of \scen{0} of interest.
\end{note}

\subsection{Key things going forward}

\begin{note}
  Three things of interest.

  \begin{enumerate}
  \item
    \scen{1} like \autoref{illu:gist:calc} in which an agent concludes some proposition has some value.
  \item
    Relation between Why and how and agent concludes.
    Basic idea, and basic contrary idea.
  \item
    Idea of a \fc{} and how \fc{1} may be involved in concluding.
  \end{enumerate}


  Chapter will be split into three parts
  In \autoref{cha:clarification}, we will clarify what is of interest.
  In particular, \autoref{cha:clarification} will be split into two subsections.

  In~\autoref{sec:clarification:support} we will clarify why we are interested in intuitions regarding \scen{1} such as \autoref{illu:gist:calc}.


  First, clarify what is of interest.
  Two things in particular.
  1. What it is about concluding.
  2. Scenarios of interest.
  \autoref{illu:gist:calc} is similar to the type of \scen{0} that will be the focus on this document.
  However, the argument we provide will not directly apply to \scen{1} like \autoref{illu:gist:calc}.

  In \autoref{sec:clar:type-of-scen} we present the type of \scen{0} we will present an instance of the type of \scen{0} interested in, provide a general description of the \scen{0} type.
  Further, we will provide a detailed contrast between the type of \scen{0} we are interested in and \autoref{illu:gist:calc}.%
  \footnote{
    Roughly, if it were the agent failed to conclude \(23 \times 15 = 345\) in \autoref{illu:gist:calc}, then there would be conflict between the agent's understanding of arithmetic and the testimony of the calculator.
    Expressed differently, there would be conflict between the agent's failure to conclude \(23 \times 15 = 345\) by their understanding of arithmetic, and a premises involved in concluding \(23 \times 15 = 345\) via the calculator.
    I.e. supposing the agent concludes \(23 \times 15 \ne 345\), then from the agent's perspective the calculator is not a source of testimony.
    In the \scen{1} of interest, this hypothetical --- or in some cases possible --- conflict will strictly be between the agent's reasoning from pools of premises to conclusions.
  }

  Generally speaking, I am unsure about the intuitions expressed with respect to~\autoref{illu:gist:calc}.
  \Autoref{illu:gist:calc} shares an important feature with the type of \scen{0} that we will explore in detail.
  Yet, \dots

  I am inclined to think intuitions are fine.
  variation of scenario, what the difference is, and why focus.
  Second, sketch general argument of the paper, and role of \fc{1}.
\end{note}

\chapter{Clarification}
\label{cha:clarification}

\begin{note}
  The role of this chapter is to refine important things about concluding.

  What it is about concluding we're interested in.
  This is support.
  Leads to a refinement of why? and how?
\end{note}

\begin{note}
  The goal here is to refine understanding of key question.
  And, to introduce type of \scen{} of interest.
\end{note}

\section{Support and reasoning}
\label{sec:clarification:support-reasoning}

\subsection{Concluding and support}
\label{sec:clarification:support}

\begin{note}
  \color{red}
  Purpose of concluding is to motivate relation of support as important.
  Here, strong relation between premises and conclusion.
  However, argument doesn't really rely on this.
\end{note}

\begin{note}
  Our interest is with the process of an agent concluding some proposition-value pair from some pool of premises.

  Concluding is an event --- concluding is something that happens.
  And, in particular, concluding is an act --- an agent concludes.%
  \footnote{
    \color{red}
    This passive construction is to avoid characterising an act as something brought about by an agent.
    Of course, agent being involved doesn't make an act.
    Involvement of agent, exist, but not an act.
    On the other hand, waking up.
    {
      \color{red}
      Also, Freud's example with adjourning a meeting.
      No intention, but perhaps conclusion.
    }
    {
      \color{red} This line of inquiry doesn't really matter.
    }
  }

  Two important assumptions were implicit in \autoref{cha:introduction}.

  \begin{assumption}
    \label{assu:concluding:pvp}
    What an agent concludes is always some proposition-value pair.
  \end{assumption}

  \begin{assumption}
    \label{assu:concluding:pools}
    An agent always concludes some proposition-value pair from some pool of premises, where a pool of premises is some collection of proposition-value pairs.
  \end{assumption}
\end{note}

\begin{note}
  I take \autoref{assu:concluding:pvp} to be fairly straightforward.
  In natural language, \emph{that} clauses.
  Default interpretation, true.

  However, propositions describe some state of affairs, and values are how the agent evaluates a state of affairs.

  True, false, desirable, etc.%
  \footnote{
    Nothing in particular hangs on the distinction between different values.
    If you prefer, you may expand the proposition (\world{}) to include additional factors, and consider only the values `true' and `false'.
    For example, the proposition that \emph{I desire the bath to be warm} is false, as opposed me assigned the proposition that \emph{the bath is warm} the value `undesirable'.
  }

  In terms of reasoning, understanding of concluding includes both theoretical and practical, and if you think this division is non-exhaustive, then some long as the result of the type of reasoning is the agent's evaluation of some situation, \autoref{assu:concluding:pvp} is designed, at least, to not rule out the culmination of the type of reasoning as an instance of concluding.%
  \footnote{
    Though, concluding may be stronger.
  }
\end{note}

\begin{note}
  \autoref{assu:concluding:pools} may be a little less straightforward.

  Not so clear that concluding always involves premises.

  Indeed, have seen in \autoref{cha:introduction} some difficulty in stating what premises would be involved in concluding via understanding of arithmetic.

    Robinson or Peano arithmetic together with the two numbers joined by an operator.
  Though, I doubt this.

  For a clear example, consider the rule for conditional introduction a Fitch-style rule for propositional logic.%
  \footnote{
    \citeauthor[cf.][206]{Barwise:1999tu}
  }

  \begin{quote}
    \fitchctx{
     \subproof{\pline{P}}{
         \ellipsesline\\
         \pline{Q}
     }
     \pline{P \lif Q}
   }
  \end{quote}

  {
    \color{red}
    The rule states that at any point in a proof, assume \formula{P}, then, after deriving \formula{Q} from \formula{P} discharge assumption of \formula{P} and introduce \formula{P \lif Q}.
  }

  Start with an assumption , derive proposition-value pair.
  Conclude if X then Y.
  Indeed,~\citeauthor{Ramsey:1929tf} test for conditionals.%
  \footnote{
    See, for example,~\textcite{Read:1995wf}.
  }

  No premises.

  Parallel, pool of premises may be empty.

  Rather than being motivated by some pre-theoretical understanding of concluding, \autoref{assu:concluding:pools} is primarily a matter of convenience.
  Far easier to talk about concluding proposition-value pair from some pool of premises, than to cover distinct cases.

  What it means to say an agent concluded from empty pool of premises, set aside.

  Indeed, taking in terms of proposition-value-premises pairings will be key for our statement of \autoref{idea:support}, a key idea concerning concluding.
\end{note}

\begin{note}
  \begin{idea}[Support]
    \label{idea:support}
    \emph{If:}
    \begin{itemize}
    \item
      An agent has concluded some proposition \(\phi\) has some value \(v\) from some pool of premises \(\Phi\).
    \end{itemize}
    \emph{Then:}
    \begin{itemize}
    \item
      From the perspective of the agent's epistemic state when concluding \(\phi\) has value \(v\) from \(\Phi\), a \emph{relation of support} holds between \(\Phi\) and \(\phi\) having value \(v\).
    \end{itemize}
    \vspace{-\baselineskip}
  \end{idea}

  Role of \autoref{idea:support} is to distinguish concluding from other acts.
\end{note}

\begin{note}
  As we will shortly see, links to reasons.
  However, support is distinct from reasons.

  Relation of support holds between conclusion and pool of premises.
  Between some proposition-value pair and a collection of proposition-value pairs.

  Explanatory reason holds between something which explains and an action.

  Support involved in providing explanatory reason.
\end{note}

\subsection{The agent's perspective}
\label{cha:introduction:sec:agents-perspective}

\begin{note}
  Before continuing.
  The agent's perspective.

  Mentioned before, but make this clear.
\end{note}

\begin{note}
  Talk about what an agent believes, knows, desires, etc.

  Agent believes \(\phi\) has value \(v\), stating how things are.

  From the agent's perspective, \(\phi\) has value \(v\).

  So, shift.

  Continue to talk of what the agent believes, etc.

  However, prefer to talk about the agent's perspective.

  Basic so that \(\phi\) has value \(v\).

  Whether this is belief or not.%
  \footnote{
    \label{fn:belief-is-difficult}
    I don't think belief is really so straightforward.

    Consider the Jeremy Goodman's example of three-horse race from~\textcite{Hawthorne:2016wv}:
    \begin{quote}
      Assume that horse A is more likely to win than horse B which in turn is more likely to win then horse C (so the probabilities of winning could be known to be 45, 28, 27\%).
      In this case it seems ﬁne to say `I think horse A will win' or `I believe horse A will win'.%
      \mbox{ }\hfill\mbox{(\citeyear[1440]{Hawthorne:2016wv})}
    \end{quote}
    As \citeauthor{Hawthorne:2016wv} observe: ``[I]t is awful to say, in this case, `I think horse A will win but I don't believe it will'.''
    (\citeyear[1440, fn.17]{Hawthorne:2016wv})
  }
\end{note}

\begin{note}
  Express the idea using familiar ideas from modal logic.

  World \(w\).
  Say whether something is true or not \(w \vDash \phi\).

  Now, say whether or not an agent believes something \(w \vDash B\phi\).

  Now, semantics of belief.
  Some collection of epistemically plausible worlds.

  \(\mathcal{B}\).

  \(\mathcal{B} \vDash \phi\).

  So, here, on this understanding, agent's perspective from belief.

  But, technical use of belief.
  So, again, agent's perspective.
\end{note}

\begin{note}
  Perspective, so agent may be wrong.
\end{note}

\paragraph{Motivation for support}

\begin{note}
  For example, \citeauthor{Boghossian:2014aa}'s Taking Condition:%
  \footnote{
    There are various objections to the taking condition.

    See, for example,~\textcite{Hlobil:2014tq}, \textcite{McHugh:2016vp}, and~\textcite{Wright:2014tt}.

    \citeauthor{Hlobil:2014tq} argues against the Taking Condition as it distracts from what accounts of reasoning out to explain, rather than arguing against the Taking Condition directly.

    \citeauthor{McHugh:2016vp} summarise various objects to the taking condition, and present district arguments against against (distinct) ideas in favour of the taking condition.
    In particular,~\autoref{idea:support} is closer to what \citeauthor{McHugh:2016vp} term the `Consequence Condition' (\citeyear[cf.][316]{McHugh:2016vp}), which \citeauthor{McHugh:2016vp} also (indirectly) argue against.
    However, \citeauthor{McHugh:2016vp} does not consider an alternative account of what distinguishes concluding from any other action, and as~\autoref{idea:support} is designed to capture this distinction, it is unclear to me whether \citeauthor{McHugh:2016vp}'s arguments apply to~\autoref{idea:support} (if, indeed, they are sound).

    \citeauthor{Wright:2014tt} denies that reasoning must involve a state which connects premises to conclusions. (\citeyear[Cf.][33-34]{Wright:2014tt})
    Note,~\autoref{idea:support} is compatible with \citeauthor{Wright:2014tt}'s objection.
  }

  \begin{quote}
    (Taking Condition):
    Inferring necessarily involves the thinker \emph{taking} his premises to support his conclusion and drawing his conclusion because of that fact.%
    \mbox{}\hfill\mbox{(\citeyear[5]{Boghossian:2014aa})}
  \end{quote}

  \begin{quote}
    The intuition behind the Taking Condition is that no causal process counts as inference, unless it consists in an attempt to arrive at a belief by figuring out what, in some suitably broad sense, is supported by other things one believes.%
    \mbox{}\hfill\mbox{(\citeyear[5]{Boghossian:2014aa})}
  \end{quote}

  Inference --- and hence reasoning with beliefs --- rather than reasoning more broadly (\citeyear[cf][2]{Boghossian:2014aa}).

  \citeauthor{Boghossian:2014aa}, `taking'.
  Taking is required for support to explain.
  No explanation without taking.
\end{note}

\begin{note}
  \citeauthor{Broome:2002aa}'s `jogging account' of reasoning:

  \begin{quote}
    [I]n reasoning you call to mind some of the premises, and doing so jogs into operation an automatic process that causes you to acquire a conclusion-attitude.%
    \mbox{}\hfill\mbox{(\citeyear[226]{Broome:2002aa})}
  \end{quote}

  {
    \color{red}
    We will talk about reasoning later.
    For the moment, substitute in concluding.
    }

  \citeauthor{Broome:2002aa} argues some things which satisfy jogging are clearly not reasoning.
  For example, \citeauthor{Broome:2002aa} considers
  {
    \color{red}
    Suppose you believe that it is raining and that if it is raining the snow will melt. Suppose these beliefs are conscious, and suppose they cause you to believe you hear trumpets.
  }
  (\citeyear[225,226--227]{Broome:2002aa})%
  \footnote{
    Does not rule out concluding (\citeyear[231,233]{Broome:2002aa}).
  }

  \citeauthor{Broome:2002aa} endorses rule following.

  \begin{quote}
    Active reasoning is a particular sort of process by which conscious premise-attitudes cause you to acquire a conclusion-attitude.
    The process is that you operate on the contents of your premise-attitudes following a rule, to construct the conclusion, which is the content of a new attitude of yours that you acquire in the process.\newline
    \mbox{ }\hfill\mbox{(\citeyear[234]{Broome:2002aa})}
  \end{quote}

  Understand support of \autoref{idea:support} in terms of having followed a rule.
\end{note}

\begin{note}
  Present purposes, assume relation of support is involved in providing explanatory reasons for concluding.
\end{note}

\begin{note}
  Key assumption regarding concluding.
  Further assumptions detailed in~\autoref{chapter:concluding}.
\end{note}

\paragraph{Support and why}

\begin{note}
  Assumption about support.
  Distinguishes from concluding.

  Relation of support also \emph{why}.

  \begin{restatable}[Proposition-value-premises pairing only if support]{idea}{ideaWhySupport}
    \label{assu:why:pvpp:support}
    \emph{If:}
    \begin{itemize}
    \item
      Some proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\) is, in part, an answer to why an agent concludes \(\phi\) has value \(v\) from some pool of premises \(\Phi\).
    \end{itemize}
    \emph{Then:}
    \begin{itemize}
    \item
      The relation of support holding between \(\Psi\) and \(\psi\) having value \(v'\) is, in part, an answer to why the agent concluded \(\phi\) has value \(v\) from \(\Phi\).
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  Interest in support is with respect to why an agent concluded.

  Support captures relation between proposition-value pair and pool of premises from perspective of agent when concluding.
  If relation between proposition-value pair and pool of premises explains, in part, why, then so does relation of support.
\end{note}

\paragraph{Examples}

\begin{note}
  For example, from agent's point of view, support between testimony of calculator and sum.

  Other examples \dots
\end{note}


\paragraph{Subtle}

\begin{note}
  Somewhat subtle, however.

  Antecedent, then answer to \qWhy{}.
  And, motivated constraint between \qWhy{} and \qHow{}.

  Important that consequent is not necessarily an answer to \qHow{}.

  This is obtained because \qWhy{} and \qHow{} only consider proposition-value-premises pairings.

  So, \autoref{assu:why:pvpp:support} does not require that relation of support is, in part, an answer to \qHow{}.

  Of course, on a theory like \citeauthor{Boghossian:2014aa}'s, support does have a role in how, as the taking condition requires the agent takes conclusion.
  Here, relevant that relation of support, taking is then evaluation, and this does not need to be intentional.%
  \footnote{
    Problems of rule following.
  }

  In some respects, plausible.
  Given \autoref{idea:support}, support is key to characterising some act as concluding.
  From the agent's perspective, \(\Phi\) support \(\pv{\phi}{v}\).
  However, this is a state of affairs.
  Does not follow that relation of support from the agent's perspective is also part of that state of affairs.

  Consider, for example, \citeauthor{Wright:2014tt}'s `Simple Proposal':
  \begin{quote}
    But consider instead the proposal, not that the status of the transition as inferential depends on the thinker's judgments about his reasons, but that it depends on \emph{what his reasons are}.
    We want his acceptance of the premises to supply his \emph{actual} reasons for accepting the conclusion.

    \mbox{}\hfill\(\vdots\)\hfill\mbox{}

    Call this the Simple Proposal.
    It says that a thinker infers q from p\(_{1}\) \(\cdots\) p\(_{\text{n}}\) when he accepts each of p\(_{1}\) \(\cdots\) p\(_{\text{n}}\), moves to accept q, and does so for the reason that he accepts p\(_{1}\) \(\cdots\) p\(_{\text{n}}\).\newline
    \mbox{}\hfill\mbox{(\citeyear[33]{Wright:2014tt})}
  \end{quote}

  Relation of support from accepting pool of premises and then accepting conclusion.
  However, from agent's perspective, relation between pool of premises and conclusion is not part of why agent moves to accept conclusion, pool of premises alone is sufficient.

  Still, from our perspective, still an account of why.
  Rejected here is that relation should be part of how.
\end{note}

\begin{note}
  So, \autoref{assu:why:pvpp:support} links support to \qWhy{}, but in a cautious way.
  Explanatory, but only for why from our perspective.
  Does not necessarily relate to \qHow{}.
\end{note}

\paragraph{Additional notes}

\begin{note}
  Understanding of support is generic.

  From agent's perspective.
  Perhaps the calculator is faulty, or the agent has an a unsteady grip on arithmetic.
  Still, conclusion from somewhere.
  Something account for why the agent holds.
\end{note}

\begin{note}[Support \emph{from the agent's perspective}]
    \begin{illustration}[A box of flan(nels)]
    \label{illu:flan-nels}
    Suppose `flan' is written on the side of a container.
    I may claim support that the container contains flan.
    And, it may be that the writing on the side of the container is support for the box containing flan.
    However, the straps ensuring the container remains closed is unfortunately placed, and if moved would reveal the side of the container reads `flannels'.
  \end{illustration}

  The unfortunate placing of the straps does not seem to prevent concluding, but I'm not sure whether it is right to say that the writing on the side of the box (straps in place) hence support.

  However, from an employee of the factory, no concluding, no support.
\end{note}

\begin{note}
  \phantlabel{mention:concluding-non-factive}
  In this respect, doesn't matter whether premises have values, or whether conclusion has value.
  Provide an \illu{0} of this in~\autoref{chapter:concluding}.%
  \footnote{
    \color{red}
    On page~\pageref{concluding:not-factive}.
  }
\end{note}

\begin{note}
  {
    \color{red}
    Not assuming that concluding involves belief.
  }
\end{note}

\subsection{Reasoning}
\label{sec:overview:reasoning}

\begin{note}
  \begin{idea}
    \label{assu:C-culmination-of-R}
    If concluded \(\pv{\phi}{v}\) from \(\Phi\), then reasoned from \(\Phi\) to \(\pv{\phi}{v}\).
  \end{idea}

  In other words, conclude \(\pv{\phi}{v}\) then reasoned from some pool of premises to \(\Phi\).
\end{note}

\begin{note}[No constraints]
  No constraints placed on reasoning.

  In line with, for example, \citeauthor{Broome:2013aa}.

  \begin{quote}
    Following this rule would lead you to believe you hear trumpets when you believe it is raining and believe that if it is raining the snow will melt. If you did this, should we count you as reasoning?

    I think we should. If you derive this conclusion by operating on the premises, following the rule, we should count you as reasoning.

    \mbox{}\hfill\(\vdots\)\hfill\mbox{}

    I think we should not impose a limit on rules.%
    \mbox{}\hfill\mbox{(\citeyear[233]{Broome:2013aa})}
  \end{quote}
\end{note}

\begin{note}
  Plausibly contrasts with an account of reasoning such as \citeauthor{Wedgwood:2006ui}'s (\citeyear{Wedgwood:2006ui}) account of reasoning.

  \begin{quote}
    % So, the disposition that one must manifest in forming a belief in \emph{p} by means of reasoning must be one that can be specified by means of a function that, for \emph{any} proposition \emph{q} within the relevant range, maps the stimulus event-type \emph{coming to be in some mental states or other that rationalize forming a belief in q} onto the response event-type \emph{forming a belief in q}.
    [T]he disposition that one must manifest in reasoning is a disposition that responds to the fact that one is in some mental states or other that rationalize one's forming the belief or intention in question.\newline
    \mbox{ }\hfill\mbox{(\citeyear[672]{Wedgwood:2006ui})}
  \end{quote}

  Where:

  \begin{quote}
    If a set of antecedent mental states makes it rational for one to form a new belief or intention, then those antecedent mental states are surely of a suitable type and content so that it is \emph{intelligible} that they could represent one's reason for forming that belief or intention.\newline
    \mbox{ }\hfill\mbox{(\citeyear[662]{Wedgwood:2006ui})}
  \end{quote}

  Of course, this is only sufficient condition, but \citeauthor{Wedgwood:2006ui}'s account of reasoning is developed under the assumption the condition is also necessary.%
  \footnote{
    So, here, problem with fallacious reasoning that \citeauthor{Wedgwood:2006ui} notes.
    Following brief discussion:
    \begin{quote}
      I shall proceed on the idealizing assumption that the only way in which a set of antecedent mental states can rationalize the formation of a belief or intention is by making that new belief or intention a \emph{rational} belief or intention to form.\newline
      \mbox{ }\hfill\mbox{(\citeyear[662]{Wedgwood:2006ui})}
    \end{quote}
    However, it's not clear to me that fallacious reasoning is a pressing problem for an account such as \citeauthor{Wedgwood:2006ui}'s.
    For, fallacious reasoning may be reasoning in the same way that a fake water pistol is a water pistol.
    I.e.\ fallacious reasoning need not be reasoning proper.
  }
\end{note}

\begin{note}
  So, allow reasoning to be broad.
  Hence, concluding also.
  Still, compatible with account such as \citeauthor{Wedgwood:2006ui}'s.

  No constraints means that we do not place constraints, it does not mean that we assume there are no constraints on reasoning.
\end{note}

\begin{note}
  Here, with \citeauthor{Wedgwood:2006ui}, antecedent mental states rationalise.
  Understand this in terms of \qWhy{}.
  So, this motivates.
  The mental states rationalise, hence, it seems, full account of why agent concludes in terms of the reasoning the agent does.

  There is also the disposition.
  \citeauthor{Wedgwood:2006ui} doesn't explicit include this in terms of rationalising.
  Though, I think this should plausibly be the case.%
  \footnote{
    See discussion regarding \citeauthor{Turri:2010aa}'s (\citeyear{Turri:2010aa}) account of doxastic justification in~\autoref{cha:fcs:sec:dox-just} (on~\autopageref{cha:fcs:sec:dox-just}).

    In short, \(p\) and \emph{if} \(p\) then \(q\) rationalise concluding \(q\).
    However, disposition.

    Tighten \citeauthor{Wedgwood:2006ui}'s account some disposition \emph{only} responds to rationalising mental states.
    Though, have no constrained the disposition.
    And, that the disposition is so constrained is, in part, why.
  }
\end{note}

\paragraph[Reasoning-to vs.\ concluding]{Distinction between reasoning-to and concluding \hfill (Optional)}

\begin{note}
  Reasoning that concludes \(\phi\) has value \(v\) is distinct from reasoning:
  \begin{enumerate}[label=\Alph*., ref=(\Alph*)]
  \item
    \label{CS:delicacy:O}
    Whose conclusion is (merely) \emph{about} \(\phi\) having value \(v\), and does not `require' \(\phi\) has value \(v\).
  \item
    \label{CS:delicacy:A}
    That concludes \(\phi\) has value \(v\) \emph{assuming} \dots\space --- where `\emph{assuming} \dots\space' is expanded to include some proposition-value pair \(\pv{\chi}{v}\) such that they agent has \emph{not} concluded \(\pv{\chi}{v}\).
  \end{enumerate}
\end{note}

\begin{note}[Epistemic operator]
  The statement of \ref{CS:delicacy:O} is loose, but the underlying idea is straightforward.

  we typically express the conclusion of the agent's reasoning which is (merely) about \(\phi\) having value \(v\) with some adjective.
  For example:

  \begin{quote}
    \vAgent{} \(\{ \text{hopes}, \text{imagines}, \text{desires}, \text{thinks}, \dots \}\) \(\phi\) is true.%
    \footnote{
      More generally, has value \(v\).
    }
  \end{quote}
  Each candidate adjective may be read in a way which is compatible with past, present, or future reasoning which concludes \(\phi\) is not true.
  In this sense, the reasoning is (merely) \emph{about} \(\phi\) being true, and does not require \(\phi\) is true.

  However, the relevant adjective may also be read as an evaluation of the relevant situation.
  It may be \(\phi\) \emph{is} hoped for, imagined, desired, thought, and so on.
  In this sense, the reasoning concludes \(\phi\) has some value \(v\), where the value is some value distinct from `true'.

  For the most part, `true' will be the relevant value \(v\) when discussing instances of reasoning.
  And, you may (unless there is clear tension) substitute mention or use of `\(\phi\) having value \(v\)' for `\(\phi\) being true'.
  Still, we do not require that `true' is the unique value of interest, and on occasion we will observe how various different valuations interact with observations made.
\end{note}

\begin{note}[Suppositions]
  \ref{CS:delicacy:A} is more straightforward.
  Contrast the instances of reasoning in~\autoref{fig:Rover}.
  \begin{figure}[h!]
    \mbox{}\hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item
        \label{fig:Rover:CS:1}
        Rover is tired.
      \item
        \label{fig:Rover:CS:2}
        Rover will fall asleep soon.
      \end{enumerate}
      \caption{}
      \label{fig:Rover:CS}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}[label=\arabic*\('\).,ref=(\arabic*\('\))]
      \item
        \label{fig:Rover:nCS:1}
        \emph{Supposing} Rover is tired.
      \item
        \label{fig:Rover:nCS:2}
        Rover will fall asleep soon.
      \end{enumerate}
      \caption{}
      \label{fig:Rover:nCS}
    \end{subfigure}
    \hfill\mbox{}
    \caption{Two instance of reasoning}
    \label{fig:Rover}
  \end{figure}

  \ref{fig:Rover:CS} and \ref{fig:Rover:nCS} are distinguishing by whether or not the premise that Rover is tired is a supposition (\ref{fig:Rover:nCS}) or not (\ref{fig:Rover:CS}).

  It may be the case that Rover would fall asleep soon if Rover were tired, but as \ref{fig:Rover:nCS:1} does not concern the actual state of Rover, \ref{fig:Rover:nCS:2} need not concern the actual state of Rover.

  By contrast,~\ref{fig:Rover:CS} is an instance of reasoning about how things are.
  The agent is holding that it is the case that Rover is tired, and therefore it is the case that Rover will fall asleep soon.

  I take this distinction to be straightforward.
  Though, it is not always immediately clear how the distinction applies to some conclusion of reasoning when stated independently of the preceding reasoning.
  Consider the conclusion:

  \begin{quote}
    That Rover is asleep is likely.
  \end{quote}

  Following the distinction, there are two broad ways of interpreting the conclusion:
  \begin{enumerate}
  \item
    The agent has made some plausible assumptions and granting those assumptions, Rover is asleep.
  \item
    For every proposition-value pair \(\chi_{i}\) having value \(v_{i}\) the agent has appealed to, the agent hold it to be the case \(\chi_{i}\) has value \(v_{i}\).
    However, the agent only concludes from \(\chi_{i}\) having values \(v_{i}\) that there is some (objective or subjective) chance that Rover is asleep.
  \end{enumerate}
  So, though claiming support is for some proposition \(\phi\) having some value \(v\), it is not clearly the case that claiming support is restricted to certain proposition-value combinations.
\end{note}

\begin{note}[Analogue]
  Analogue of concluding for conditional.
  Here, bundle into \(\phi\).
  More generally, not much need for conditional stuff.
\end{note}

\paragraph{Why concluding}
\label{concluding-consistency}

\begin{note}
  In simple terms, focus on concluding because bad to \emph{conclude} \(\phi\) has value \(v\) and \(\phi\) has value \(\overline{v}\).
  Though, it's not so bad to reason to this, at least generally speaking.
\end{note}

\subsubsection{Summary}
\label{sec:clarification:support-reasoning:summary}

\begin{note}[What we've seen]
  Support and reasoning.
\end{note}

\begin{note}[Role in expanding]
  Following section, use support and reasoning to expand on \qWhy{}, \qHow{}, and \issueInclusion{}.
\end{note}

\begin{note}[Motivation]
  Handful of additional theories that motivate positive resolution to \issueInclusion{}.
\end{note}

\section{\qWhy{}, \qHow{}, and \issueInclusion{}, expanded}
\label{sec:support-why-how}

\begin{note}[Goal]
  Goal is to refine understanding of these questions and relation.

  In particular, connecting \qWhy{} to relations of support.

  Also, \qHow{} to reasoning.
\end{note}

\begin{note}[Division]
  Three sections.

  First two sections focus on \qWhy{} and \qHow{}, respectively.
  Introduce an idea, expand on question, and present variant question given introduced idea.

  \qWhy{}, support, converse.
  \qHow{}, witnessing.

  Third section, bring the expansions together.
  Present variant of main issue.
  This variant will be our focus for the document.

  \begin{itemize}
  \item
    \autoref{sec:clar:expand:qWhy}.
  \item
    \autoref{sec:clar:expand:qHow}.
  \item
    \autoref{sec:clar:expand:issue}
  \end{itemize}
\end{note}

\subsection{\qWhy{}}
\label{sec:clar:expand:qWhy}

\begin{note}[Introduction]
  We now turn to \qWhy{}:
  \vspace{-\baselineskip}
  \begin{quote}
    \questionWhyBasic*
  \end{quote}
  Example, pairing of \(23 \times 15 = 345\) and the testimony of the calculator that \(23 \times 15 = 345\) answers, in part, why the agent concluded \(23 \times 15 = 345\) in \autoref{illu:gist:calc}.
  Slightly more natural to say `the testimony of the calculator that \(23 \times 15 = 345\)', but \emph{paring}.

  Observed that, intuitively, pairing of \(23 \times 15 = 345\) and whatever pool of premises would be associated with the agent applying their understanding of arithmetic does not answer, in part, why the agent concluded \(23 \times 15 = 345\).
\end{note}

\begin{note}
  Intuition.

  Theoretical motivation for this via \issueInclusion{}.
  Understanding of arithmetic intuitively not part of how.
\end{note}

\begin{note}
  Present section, stronger link between relation of support and \qWhy{}.
  From \autoref{assu:why:pvpp:support}, relation of support between testimony and \(23 \times 15 = 345\) explains why.

  Converse.

  Given positive resolution to \issueInclusion{}, relation of support is not answer why.

  More generally, equivalence between relation of support and proposition-value-premises pairings.


  However, possible relation of support also explains why.
  Rule this out.
\end{note}

\paragraph{Idea}
\label{sec:clar:expand:qWhy:idea}

\begin{note}
  Have~\autoref{assu:why:pvpp:support}.

  \autoref{assu:why:pvpp:support} links answers to \qWhy{} to support.
  However, does not link explanatory role of support to \qWhy{}.
  For this, converse.
\end{note}

\begin{note}
  \begin{restatable}[Support only if proposition-value-premises pairing]{idea}{ideaSupportWhy}
    \label{assu:why:support:pvpp}
    \emph{If:}
    \begin{itemize}
    \item
      A relation of support holding, from the perspective of the agent's epistemic state, between \(\Psi\) and \(\psi\) having value \(v'\) is, in part, an answer to why the agent concluded \(\phi\) has value \(v\) from from some pool of premises \(\Phi\).
    \end{itemize}
    \emph{Then:}
    \begin{itemize}
    \item
      The proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\) is, in part, an answer to why the agent concluded \(\phi\) has value \(v\) from \(\Phi\).
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  So, if support answers why, then the related proposition-value pair and pool of premises, in part, answer why.

  Take this to be fairly straightforward.
\end{note}

\begin{note}
  General picture.

  Support, why.
  So, proposition-value-premises pairing why.
  So, if positive resolution to issue, then proposition-value-premises pairing how.

  In other words, if positive resolution to issue, then account of how is going to constraint whether some relation of support answers why.

  We haven't learnt much about what support is.
  However, we have abstracted.
  Our perspective, linked with what happens in the agent.
  If positive answer, constrained by what happens in the agent.

  Way we're talking about support, somehow links to what the agent does when they conclude.
  Clear on this.
  But, figuring out this link is task for a theory.
  We're not providing a theory.
  \textbf{Understanding of support is fairly theory neutral.}
\end{note}

\begin{note}
  Difficulty.
  Testimony, then support, but then, \qWhy{}, and so \qHow{}.
  However, motivated relation in terms of causal theories.
  Pairing between \(\pv{\phi}{v}\) and \(\Phi\) is, intuitively, not how.
  Paired only in terms of support.

  Here, need to be careful about how support is involved.
  Not \emph{just} from relation between \(\pv{\phi}{v}\) and \(\Phi\).
  That partner testified.

  Need it to be the case that \(\Phi\) alone.
  And, this is not the case.

  So, this idea isn't going to give rise to this problem.
\end{note}

\paragraph{Variant of \qWhy{}}
\label{sec:clar:expand:qWhy:variant}

\begin{note}[The variant]
  Given role of support, and ideas, variant of \qWhy{}:

  \begin{question}[\qWhyV{}]
    \label{q:why:v}
    \emph{Which} proposition-value-premises pairings are such that support between involved in why agent concludes?
  \end{question}

  \begin{proposition}
    \label{prop:qWhy-and-qWhyV}
    For any conclusion-premises pairing \(\pvp{\phi}{v}{\Phi}\):

    \(\pvp{\phi}{v}{\Phi}\) is, in part, an answer to \qWhyV{} \emph{if and only if} \(\pvp{\phi}{v}{\Phi}\) is, in part, an answer to \qWhy{}.
  \end{proposition}

  \begin{argument}
    \autoref{prop:qWhy-and-qWhyV} is immediate given \autoref{assu:why:pvpp:support} and \autoref{assu:why:support:pvpp}.

    relation of support answers this, then proposition-value-premises pairing answers \qWhy{}.

    proposition-value-premises pairing answer \qWhy{}, then relation of support.
  \end{argument}
\end{note}

\begin{note}
  \emph{Here}, note that we're not dealing with pairing of a proposition-value pair and a collection of proposition-value pairs.
  Instead, conclusion-premises pairing.
\end{note}

\begin{note}
  Note, we have stated `why?' and `how?' from theoretical perspective.

  \autoref{assu:why:pvpp:support} is also from this theoretical perspective.
\end{note}

\begin{note}
  From the perspective of the agent's (present) epistemic state, rather than the agent's point of view.

  Some flexibility.
\end{note}

\begin{note}
  Understanding of `why'.

  From the perspective of the agent.
  `The calculator', etc.
\end{note}

\begin{note}
  \issueInclusion{} distinguishes classes of theories.
  A positive resolution to \issueInclusion{} will not directly provide general answer to \qWhy{}.
  Though, a positive answer will rule out certain answers.

  For example, wrt.~\autoref{illu:gist:calc}.

  Indeed, accounts for the intuitions noted.
  Testimony of the calculator, but not agent's understanding of arithmetic.

  As we will see below, many accounts of concluding seem to fall in line with this.
\end{note}

\subsubsection{Reasons (Optional)}

\begin{note}

\end{note}

\begin{note}
  Variant of the more general issue with which \citeauthor{Davidson:1963aa} opens \citetitle{Davidson:1963aa}:

  \begin{quote}
    What is the relation between a reason and an action when the reason explains the action by giving the agent’s reason for doing what he did?%
    \mbox{}\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}

  \citeauthor{Davidson:1963aa}'s question is more general as covers all action.
  Our interest is specifically with concluding.

  Possible answers to \qWhy{}, lots.
\end{note}

\begin{note}
  Alternative may be to talk in terms of reasons.
  Concluding is an action.
  Reasons for action.
  Concludes from premises.
  Hence, premises are part of agent's reasons for action.

  With a little more care, we make further distinguish between normative and explanatory reasons.%
  \footnote{
    Normative: `reasons which show a given action, attitude, activity or outcome good, right, appropriate or called for'
    Explanatory: `the reasons why things happen, or why things are the way they are'
    \citeyear[410]{Hieronymi:2011aa}

    \citeauthor{Hieronymi:2011aa} also distinguishes `motivating' reasons,

    Motivating: `psychological facts which explain action'
    \citeyear[411--412]{Hieronymi:2011aa}

    This way of dividing reasons is difficult.
    \citeauthor{Hieronymi:2011aa}'s account of motivating reasons follows~\textcite{Smith:1994wo}, but~\citeauthor{Smith:1994wo} distinguishes motivating reasons from normative reasons.

    \begin{quote}
      The distinctive feature of a motivating reason to \(\phi\) is that, in virtue of having such a reason, an agent is in a state that is \emph{explanatory} of her \(\phi\)-ing, at least other things being equal --- other things must be equal because an agent may have a motivating reason to \(\phi\) without that reason's being overriding.%
      \mbox{}\hfill\mbox{(\citeyear{Smith:1994wo})}
    \end{quote}

    See also \citeauthor{Broome:2013aa}:
    \begin{quote}
      Sometimes the explanation of why a person does something has a particular character:
      roughly, it involves the person's rationality in a distinctive way that I shall not try to describe.
      Then we say the person does what she does for a reason.
      We might say ‘The reason for which Hannibal used elephants was to terrorize the Romans'.
      The reason for which a person does something is called a ‘motivating reason'.
      In general, a motivating reason is whatever explains or helps to explain what a person does in the distinctive way that involves her rationality.

      \mbox{}\hfill\(\vdots\)\hfill\mbox{}

      Whereas motivating reasons explain or help to explain why a person does something, normative reasons explain or help to explain why a person ought to do something, or to believe something, or to hope for something, or to like something, or in general to F, where ‘F' stands for a verb phrase.%
      \mbox{}\hfill\mbox{(\citeyear[46--47]{Broome:2013aa})}
    \end{quote}
  }

  In this way of looking at things, relation of support concerns explanatory reasons.
\end{note}

\begin{note}
  \citeauthor{Davidson:1963aa} resolution, in the \citeyear{Davidson:1963aa} paper at least, causal.
  Identifying \emph{something}%
  \footnote{
    \textcite{Hieronymi:2011aa} for a general overview.
  }
\end{note}

\subsection{\qHow{}}
\label{sec:clar:expand:qHow}

\begin{note}[Introduction]
  We now turn to \qHow{}:
  \vspace{-\baselineskip}
  \begin{quote}
    \questionHowBasic*
  \end{quote}
  Example, pairing of \(23 \times 15 = 345\) and the testimony of the calculator that \(23 \times 15 = 345\) answers, in part, how the agent concluded \(23 \times 15 = 345\) in \autoref{illu:gist:calc}.
  Slightly more natural to say `the testimony of the calculator that \(23 \times 15 = 345\)', but \emph{paring}.

  Observed that, intuitively, pairing of \(23 \times 15 = 345\) and whatever pool of premises would be associated with the agent applying their understanding of arithmetic does not answer, in part, how the agent concluded \(23 \times 15 = 345\).
\end{note}

\begin{note}[Theoretical motivation]
  Broader theoretical support from something like \citeauthor{Davidson:1963aa}'s causal theory of action.
  Also, now, \citeauthor{Boghossian:2014aa} and \citeauthor{Broome:2013aa}.
  And, \citeauthor{Wright:2014tt}.
\end{note}

\begin{note}
  In this section we expand via a necessary condition on how.
  In short, the agent has witnessed reasoning.

  The primary purpose of this expansion is to clarify the way in which, for present purposes, answers to how may be fairly weak.

  Two important things.

  No constraints placed on reasoning.
  Has, and so temporal component.
\end{note}

\begin{note}
  Two parts.

  Ideas, and discussion.

  Variant of \qHow{} given ideas.
\end{note}

\paragraph{Ideas}
\label{sec:clar:expand:qHow:ideas}

\begin{note}
  \begin{definition}[Witnessing]
    An agent has \emph{witnessed} reasoning from \(\Phi\) to \(\pv{\phi}{v}\) \emph{just in case} at some point in the past, the agent has reasoned from \(\Phi\) to \(\pv{\phi}{v}\).
  \end{definition}

  Term `witnessing' to make it clear that the agent has reasoned.
  The agent hasn't (merely), for example, entertained or forbidden reasoning from \(\Phi\) to \(\pv{\phi}{v}\).

  This introduces reasoning.
  Performed some act.
  Moved, somehow, from pools of proposition-value pairs to other pools of proposition-value pairs.

  Do not assume that result of reasoning is concluding.
  However, as we will see, concluding only if reasoning.
\end{note}

\begin{note}
  \begin{idea}[\ideaWitness{}]
    \label{idea:how-witnessing}
    For any proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\):
    \begin{itemize}
    \item
      \(\pvp{\psi}{v'}{\Psi}\) is, in part, an answer \qHow{}.
    \end{itemize}
    \emph{Only if:}
    \begin{itemize}
    \item
      The agent has \emph{witnessed} reasoning from \(\Psi\) to \(\psi\) having value \(v'\).
    \end{itemize}
  \end{idea}

  \autoref{idea:how-witnessing} links concluding and broad understanding of reasoning.

  Understanding of reasoning is broad, so that in general, whatever understanding is of how, if proposition-value-premises pairing answers how, then reasoning from \(\Phi\) to \(\pv{\phi}{v}\).

  The statement of~\autoref{idea:how-witnessing} is fairly straightforward.
\end{note}

\begin{note}[Basic case]
  \qHow{} is always stated with respect to the proposition-value-premises pairing \(\pv{\phi}{v}\) --- i.e.\ how did the agent conclude \(\phi\) has value \(v\).
  And, we assume that an agent always concludes \(\pv{\phi}{v}\) from some pool of premises.
  So, assuming the pairing of \(\pv{\phi}{v}\) and \(\Phi\), in part, answer how the agent concluded \(\pv{\phi}{v}\), it follows from \autoref{idea:how-witnessing} that the agent has witnessed reasoning from \(\Phi\) to \(\pv{\phi}{v}\).

  In this basic case, \autoref{idea:how-witnessing} may seem trivial, so long as no constraints are placed on what counts as reasoning.
  And, in this basic case, \autoref{idea:how-witnessing} is designed to be trivial.
  As mentioned, we place no constraints on what counts as reasoning.

  Hence, \autoref{idea:how-witnessing} states that if the paring of \(\pv{\phi}{v}\) and \(\Phi\) is, in part, how the agent concluded \(\pv{\phi}{v}\) then the agent has witnessed reasoning from \(\Phi\) to \(\pv{\phi}{v}\).
\end{note}

\begin{note}[Converse]
  \begin{quote}
    If the agent has \emph{not} witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\), then \(\pvp{\psi}{v'}{\Psi}\) is \emph{not}, in part, an answer \qHow{}.
  \end{quote}
  Given the weak interpretation of reasoning, if the agent has not transitioned from \(\Psi\) to \(\pv{\psi}{v'}\), then the pairing \(\pvp{\psi}{v'}{\Psi}\) is not relevant to the agent concluding.

  This is clearly violated in the case of \(\pvp{\phi}{v}{\Phi}\).
\end{note}

\begin{note}[Complex case]
  More generally, complex case.
\end{note}

\begin{note}[Weak]
  However, also designed to be fairly weak.
  Key qualifier is \emph{witnessed}.
  Do not require that the reasoning from \(\Psi\) to \(\pv{\psi}{v'}\) is part of the agent's present reasoning.
\end{note}

\begin{note}[Illustration]
  To illustrate, consider an agent working on some mathematical problem.

  As part of their work on the problem the agent concludes the hypotenuse of some right-angled triangle is \(\sqrt{74}\text{cm}\) by use of the Pythagorean theorem.

  Further, the agent has, at some point in the past proved the Pythagorean theorem from more basic principles.

  Now, generally speaking, it seems to me it may be the case that the agent concludes the hypotenuse of the triangle is \(\sqrt{74}\text{cm}\), in part, from those more basic principles.
  For example, the agent may have just completed their proof of the Pythagorean theorem and the reasoning from the more basic principles to the hypotenuse of the triangle may be considered a single unified instances of reasoning, with an intermediary conclusion.

  Still, suppose the agent proved the Pythagorean theorem some years ago.

  Perhaps the agent's reasoning from more basic principles continues to provide, in part, an answer to how the agent concluded the hypotenuse of the triangle is \(\sqrt{74}\text{cm}\).
  There may be a gap of some years, but it may be the case that the agent uses the Pythagorean theorem (in some sense of the word) \emph{because} they concluded the theorem from more basic principles.

  On the other hand, one may be inclined to hold that the more basic principles the agent proved the Pythagorean theorem from have no role in explaining how the agent concluded the hypotenuse of the triangle is \(\sqrt{74}\text{cm}\) in the present.
  Rather, the Pythagorean theorem is a more-or-less fundamental premise of the agent's present reasoning.

  At best, the agent's memory of reasoning from more basic principles to the Pythagorean theorem may, in part, answer how the agent concluded hypotenuse of the triangle is \(\sqrt{74}\text{cm}\).
  The reasoning from the more basic principles, given that it happened so long ago, is irrelevant.

  \autoref{idea:how-witnessing} is designed to allow either opinion on the agent's conclusion.
\end{note}

\begin{note}[Stronger idea]
  Note, \autoref{idea:how-witnessing} is a one-way conditional, and is therefore compatible with some idea restricting reasoning to the present.

  For example, one may hold:
  \begin{quote}
    \(\pvp{\psi}{v'}{\Psi}\) is, in part, an answer \qHow{}
    \emph{only if}
    the agent concluded \(\pv{\phi}{v}\), in part, by witnessing reasoning from \(\Psi\) to \(\psi\) having value \(v'\).
  \end{quote}
  For, it remains the case that the agent has witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\).
  A strong idea such as the one presented only limits \emph{when} the agent witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\).
\end{note}

\begin{note}
  Argue against positive resolution to \issueInclusion{}.
  Stronger idea, then in principle, easier counterexamples.

  For example, argue that more basic principles really are involved in explaining why.
  But, not how given stronger idea.

  With \autoref{idea:how-witnessing}, in order to motivate a negative resolution, \emph{no witnessing}.%
  \footnote{
    Further, won't rely on an agent having witnessed.
    Though, will not explore this.
    Have that paper on testimony, though.
  }
\end{note}


\begin{note}
  The point now is that I expand on a necessary condition to how.
  For, this is still somewhat intuitive.

  So, proposition-value-premises pairing is, in part, and answer to \qHow{} only if the agent has \emph{witnessed} reasoning from pool of premises to conclusion.

  Then, add in, that it's unclear to me exactly how well this fares with causal theories.
  \emph{However}, necessary rather than sufficient, and if stronger, then still relation.
  This, I already have an argument for.
\end{note}


\paragraph{Variant of \qHow{}}
\label{sec:clar:expand:qHow:variant}

\begin{note}
  Our interest is with answers to \qWhy{}, rather than providing an answer to \qWhy{}.
  For, answers to \emph{why} an agent concluded may be constrained by \emph{how} an agent concluded.
  In other words, answers to \qWhy{} may be constrained by answers to \qHow{}:

  \begin{question}[\qHowV{}]
    \label{q:how:v}
    Which proposition-value-premises pairing are such that the agent has witnessed reasoning in involved in explaining how the agent concluded \(\phi\) has value \(v\)?
  \end{question}

  What information was appealed to by the agent to conclude \(\phi\) has value \(v\)?

  Which premises did the agent use, which conclusions did the agent draw from those premises?

  For example, \autoref{illu:gist:calc}, agent concluded \(23 \times 15 = 345\) from the testimony of the calculator.
\end{note}

\begin{note}
  \begin{proposition}
    \label{prop:qHow-and-qHowV}
    For any conclusion-premises pairing \(\pvp{\phi}{v}{\Phi}\):

    \emph{If} \(\pvp{\phi}{v}{\Phi}\) is, in part, an answer to \qHow{} \emph{then} \(\pvp{\phi}{v}{\Phi}\) is, in part, an answer to \qHowV{}.
  \end{proposition}

  \begin{argument}
    So, this comes from lack of specification about what \qHow{} amounts to.
  \end{argument}

  \autoref{prop:qHow-and-qHowV} contrasts with~\autoref{prop:qWhy-and-qWhyV}.
  \qHowV{} and \qHow{} are not equivalent.
\end{note}

\begin{note}
    In contrast to \issueInclusion{}, \issueConstraint{} does not require a relation of support which answers \qWhy{} to involve a pool of premises drawn from the agent's present reasoning.
  Instead, so long as the agent has --- either through their present reasoning or in some past reasoning --- witnessed reasoning from the pool of premises to the conclusion, the relevant relation of support may answer \qWhy{}.
\end{note}

\paragraph{Summary}

\begin{note}
  So, necessary condition.
  Doesn't commit to witnessing as answer to how.

  Provide some suggestion of how this may work in \autoref{chap:twoc}.

  Primary motivation for this revision is that, as witnessing is necessary, \qHowV{} is weaker than \qHow{}.
\end{note}

\subsection{\issueInclusion{}}
\label{sec:clar:expand:issue}

\begin{note}
  \autoref{sec:clar:expand:qWhy} refined \qWhy{} in terms of support.
  \autoref{sec:clar:expand:qHow} refined, or perhaps weakened, \qHow{} in terms of witnessing.

  Interest in \qWhy{} and \qHow{} in terms of whether a constraint holds.

  \begin{quote}
    \vspace{-\baselineskip}
    \issueInclusionFirst*
  \end{quote}

  Introduced in~\autoref{cha:introduction}.
  Provided some intuitive motivation via \autoref{illu:gist:calc}.
  And, theoretical motivation via \citeauthor{Davidson:1963aa}' causal theory of action.
  In addition, \citeauthor{Boghossian:2014aa} when discussing support.

  Purpose of the present section is to bring refinements to questions together to provide refinement to \issueInclusion{}.

  The refined issue will be the focus.
\end{note}

\paragraph{Linking}

\begin{note}
  \begin{proposition}
    \label{prop:support-and-witnessing}
    Grating a positive resolution to \issueInclusion{}, and given \autoref{assu:why:support:pvpp} and \autoref{idea:how-witnessing}:
    \begin{itemize}
    \item
      A relation of support between \(\pv{\psi}{v'}\) and \(\Psi\) is, in part, an answer to why an agent concluded \(\pv{\phi}{v}\) from \(\Phi\).
    \end{itemize}
    \emph{Only if:}
    \begin{itemize}
    \item
      The agent has witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\).
    \end{itemize}
  \end{proposition}

  \autoref{prop:support-and-witnessing} is straightforward.
  A visual representation is given in~\autoref{fig:relations-between-whys-and-hows}.
\end{note}

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \tikzset{ansStyle/.style={
        draw=gray,
        text width=.45\textwidth,
        rounded corners=2pt,
      }
    }
    %
    \node[ansStyle] (whyO) at (0,0) %
    {\qWhyV{} is answered by support between \(\pv{\psi}{v'}\) and \(\Psi\).};
    %
    \node[ansStyle] (whyA) at (2,-1.5) %
    {\qWhy{} is answered by \(\pvp{\psi}{v'}{\Psi}\).};
    %
    \node[ansStyle] (howA) at (4,-3) %
    {\qHow{} is answered by \(\pvp{\psi}{v'}{\Psi}\).};
    %
    \node[ansStyle] (witA) at (6,-4.5) %
    {\qHowV{} is answered by witnessed reasoning from \(\Psi\) to \(\pv{\psi}{v'}\).};
    %
    \path[->] ($(whyO.south)!0.9!(whyO.south west)$) edge [out=270, in=180] (whyA);
    \path[->] ($(whyA.south)!0.9!(whyA.south west)$) edge [out=270, in=180] (howA);
    \path[->] ($(howA.south)!0.9!(howA.south west)$) edge [out=270, in=180] (witA);
    %
    \node[text width=.5\textwidth] (1) at (1,-.8) %
    {Via \autoref{assu:why:support:pvpp}.};
    %
    \node[text width=.75\textwidth] (2) at (4.5,-2.25) %
    {Via a positive resolution to \issueInclusion{}.};
    %
    \node[text width=.5\textwidth] (3) at (5,-3.625) %
    {Via \autoref{idea:how-witnessing}.};
    %
    \draw[->, gray] ($(whyA.north)!0.9!(whyA.north east)$) to [out=90, in=0] ($(whyO.east)$);
    %
    \node[text width=.5\textwidth, text=gray] (1p) at (8,-.8) %
    {Via \autoref{assu:why:pvpp:support}.};
  \end{tikzpicture}%
  \caption{Relation between positive answers to questions.}
  \label{fig:relations-between-whys-and-hows}
\end{figure}

\begin{note}
  \begin{idea}[Witnessing constraints support]
    A relation of support between \(\psi\) having value \(v'\) and some pool of premises \(\Psi\) is, in part, an answer to, why an agent concluded \(\phi\) has value \(v\) \emph{only if} the agent has witnessed reasoning from \(\Psi\) to \(\psi\) having value \(v'\).
  \end{idea}
\end{note}

\begin{note}
  Witnessing as a constraint on relations of support being, in part, an answer to why an agent concluded.
\end{note}

\paragraph{Variant of \issueInclusion{}}
\label{sec:clar:expand:issue:variant}

\begin{note}
  \begin{restatable}[\issueConstraint{}]{issue}{rIssueConstraint}
    \label{issue:has-witnessed}
    Is it the case that:

    A relation of support between \(\psi\) having value \(v'\) and some pool of premises \(\Psi\) is, in part, an answer to, why an agent concluded \(\phi\) has value \(v\) \emph{only if} the agent has witnessed reasoning from \(\Psi\) to \(\psi\) having value \(v'\).
  \end{restatable}

  {
    \color{red}
    \issueConstraint{} generalises \issueInclusion{} in two ways.
    \begin{itemize}
    \item
      Current reasoning.
    \item
      Other support relations.
    \end{itemize}
  }

\end{note}

\begin{note}
  Difficulty with all of this is that the accounts seem to be consistent, but do not explicitly motivate this constraint.
\end{note}

\begin{note}
  An additional example, \citeauthor{Hieronymi:2011aa}
  \begin{quote}
    The proposal starts with this simple thought: whenever an agent acts for reasons, the agent, in some sense, takes certain considerations to settle the question of whether so to act, therein intends so to act, and executes that intention in action.

    If this much is uncontroversial (and, under some interpretation, I believe it must be), we can use it as a form for filling out.
    I propose, then, that we explain an event that is an action done for reasons by appealing to the fact that the agent took certain considerations to settle the question of whether to act in some way, therein intended so to act, and successfully executed that intention in action.
    I suggest that \emph{this} complex fact, \dots is the reason that rationalizes the action---that explains the action by giving the agent’s reason for acting.%
    \mbox{ }\hfill\mbox{(\citeyear[431]{Hieronymi:2011aa})}
  \end{quote}

  From the deliberation.

  So, reason is the complex fact.
  Complex fact gives the reason the agent acted, and so content of constituent considerations from agent's point of view.
\end{note}

\paragraph{Negative resolution}

\begin{note}
  Converse, then either reject ideas or negative resolution to \issueInclusion{}.
\end{note}

\begin{note}
  Argument here that the break should be with positive resolution.

  How and witnessing link, nothing to this.

  So, either support and why or why and how.

  Support and why, fairly straightforward.
\end{note}


\paragraph*{Quick argument}

\begin{note}
  More generally, a quick argument for witnessing is that conclusion needs to come from somewhere.
\end{note}

\begin{note}[The general pre-theoretic argument]
  At least, the positive resolution is not straightforward without placing some constraints on \emph{which} premises an agent may appeal to when reasoning, and we will motivate the positive resolution without such constraints.

  For, without constraints on which premises an agent may appeal to when reasoning, one may argue as follows:
  \begin{enumerate}
  \item
    Any instance of reasoning is some process with start and end points and intermediary steps.
  \item
    If an agent has concluded \(\phi\) has value \(v\) by some reasoning, then the reasoning has start points and intermediary steps.
  \item
    Hence, the agent has concluded \(\phi\) has value \(v\) by witnessing some reasoning from some start points via some intermediary steps.
  \item
    In other words, the agent has concluded \(\phi\) has value \(v\) by witnessing some reasoning from some premises.
  \end{enumerate}

  In short, so long as an agent has concluded \(\phi\) has value \(v\), the agent has always witnessed reasoning from some premises.

  \begin{enumerate}[resume]
  \item
    So, either the start points are the premises of interest mentioned in the issue, or the agent has concluded \(\phi\) has value \(v\) from a distinct set of premises.
  \end{enumerate}

  In other words, either the agent has witnessed reasoning from the premises of interest, or the premises of interest (and any reasoning from them) are not required to conclude \(\phi\) has value \(v\).
\end{note}

\begin{note}[More on the quick argument]
  The quick argument does not directly lead to a negative resolution to the issue.
  Still, the quick argument does suggest that any appeal to premises \emph{without} witnessing reasoning from those premises is redundant.

  Now, perhaps redundancy isn't so bad.
  I only need a single key to ensure I have the option of unlocking a door, but a second key is useful if the first is lost.

  Still, I take it to be the case that redundancy provides leverage for a wide range of arguments motivating a negative resolution in the case of reasoning.

  For, if appeal to some premises is redundant, then any argument that requires witnessing need only observe that a counterargument must find some role for something which is not needed.

  Reasoning is an event, and distinct way of concluding \(\phi\) has value \(v\) may be useful, it is unclear why the distinct way of concluding \(\phi\) has value \(v\) is of use when concluding \(\phi\) has value \(v\) from present premises.
  To push the analogy, a second key may have various uses, but the second key is irrelevant in the event of unlocking the door with the first key.
  That the second key is would unlock the door if the first was lost has no role in the event of unlocking the door with the first key.

  From a different perspective, if appeal to certain premises without witnessing reasoning from those premises is redundant, then it seems any positive role given to appeal to those premises may be redistributed to the premises of the reasoning the agent did witness.

  More concretely, even if I were to show that there was some benefit for concluding \(\phi\) has value \(v\) via unwitnessed reasoning with respect to some particular account of reasoning, it seems at least plausible that the account of reasoning may be reformulated to derive the same benefit from the premises of the reasoning the agent witnessed.

  More generally, it may seem (and I suspect it does seem) intuitive that the issue should be resolved negatively.
  Reasoning just is obtaining a conclusion by witnessing reasoning from premises.
  And, if the quick argument succeeds, then there surely is some way to preserve the intuition.
\end{note}

\begin{note}
  So, part of the task is to show that the quick argument fails.
  Concluding \(\phi\) has value \(v\) from certain premises without witnessing reasoning that concludes \(\phi\) has value \(v\) from those premises has some role.
  Or, rather, that the quick argument is not without cost.
  Perhaps the issue really should be resolved in the negative, but this will require giving up some at least equally (I think) intuitive ideas.

  The result will be motivation for a positive resolution to the issue.
  However, the motivation will be somewhat narrow.
  To escape the tension, the positive resolution need only hold for a restricted pattern of reasoning.
  Still, with the existential motivated, I hope future work may expand the positive resolution to other patterns of reasoning.
  And, while such expansions may still need to argue that concluding \(\phi\) has value \(v\) from unwitnessed reasoning is makes sense with respect to the specific topic at hand, observing that the broad idea of concluding \(\phi\) has value \(v\) from unwitnessed reasoning may not be dismissed without cost may be an option.
\end{note}

\paragraph*{Summarising}

\begin{note}[Pre-theoretical constraint]
  Issue captures intuitive constraint of no account of why without an account of how.
  Witnessing a pre-theoretical constraint.

  Broader than causation.
\end{note}

\begin{note}
  `Use'.

  Negative resolution, some pool of premises, why.
  Yet, agent does not have a specific account of how.
\end{note}

\subsection{Summary}
\label{sec:clar:expand:issue:summary}

\begin{note}
  Three key things.

  Support.
  Witnessing.
  Issue.
\end{note}

\begin{note}
  Focus on \issueConstraint{}.
  \vspace{-\baselineskip}
  \begin{quote}
    \rIssueConstraint*
  \end{quote}
  Sufficient clarity on both `why?' and `how?'.
  Link we have argued for.
  And, further, independently of argument, it seems to me that a positive resolution to \issueConstraint{} is equally compelling as positive resolution to \issueInclusion{}.
\end{note}

\begin{note}
  This is the important thing, and in this respect it doesn't matter whether past or present.
  Whether a relation of support holds only if witnessed.
  Whether resolution to \qWhy{} only if the agent has witnessed.
\end{note}

\section{The type of \scen{0} we will focus on}
\label{sec:clar:type-of-scen}

\begin{note}
  In this section, type of \scen{0} we will focus on.
  \begin{itemize}
  \item
    Instance of \scen{0}.
  \item
    General characterisation of type of \scen{0}.
  \item
    Comparison, highlighting key features.
  \item
    Additional examples.
  \end{itemize}
\end{note}

\subsection{An example of the type of \scen{0}}

\begin{note}
  \begin{scenario}[Quadratic roots]
    \label{illu:gist:roots}
    An agent is given the following statement:

    \begin{enumerate}[label=\arabic*., ref=(\arabic*)]
    \item
      \label{illu:gist:roots:eq}
      For some \(x \in \mathbb{R}\), \(2x^{2} - x - 1 = 0\).
    \end{enumerate}

    The agent reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(\arabic*), resume, itemsep=.125em]
    \item
      \label{illu:gist:roots:qf}
      The quadratic formula is \(x = \frac{-b \pm \sqrt{b^{2} - 4ac}}{2a}\) \hfill Memory
    \item
      \label{illu:gist:roots:subs}
      \(a = 2\), \(b = -1\), \(c = -1\) \hfill \ref{illu:gist:roots:eq}, How to use \ref{illu:gist:roots:qf}%
      \footnote{
        \(a\) is the coefficient of the \(x^{2}\) term, \(b\) is the coefficient of the x term, and \(c\) is the constant.
      }
    \item
      \label{illu:gist:roots:qf-subs}
      \(x = \frac{-(-1) \pm \sqrt{(-1)^{2} - 4(2)(-1)}}{2(2)}\) \hfill \ref{illu:gist:roots:qf}, \ref{illu:gist:roots:subs}, Substitution
    \item
      \label{illu:gist:roots:qf:1}
      \(x = \sfrac{(1 \pm 3)}{4}\) \hfill \ref{illu:gist:roots:qf-subs}, Simplification
    % \item
    %   \label{illu:gist:roots:qf:3}
    %   \(x = \sfrac{(1 + 3)}{4}\) or \(x = \sfrac{(1 - 3)}{4}\) \hfill \ref{illu:gist:roots:qf:1}, Expansion
    \item
      \label{illu:gist:roots:qf:done}
      \(x = 1\) or \(x = -\sfrac{1}{2}\) \hfill \ref{illu:gist:roots:qf:1}, Expansion, Simplification
    \end{enumerate}
    Hence, the agent concludes: if \(2x^{2} - x - 1 = 0\), \(x = 1\) or \(x = -\sfrac{1}{2}\).

    \mbox{ }

    Still, prior to concluding \(x = 1\) or \(x = -\sfrac{1}{2}\), the agent observed that \emph{if} \(x = 1\) or \(x = -\sfrac{1}{2}\), then they would also be able to observe this via factorisation.
  \end{scenario}

  The particular details of \autoref{illu:gist:roots} are present primarily to present a clear instance of reasoning.
  For present purposes, our interest is with steps \ref{illu:gist:roots:qf}, \ref{illu:gist:roots:subs}, and \ref{illu:gist:roots:qf-subs}.

  Intuitively, the agent concludes `\(x = 1\) or \(x = -\sfrac{1}{2}\) if \(2x^{2} - x - 1 = 0\)' in part from their understanding of arithmetic.
  And, in particular, from their understanding of the quadratic formula and how to use it.

  Further, as the agent does not derive the quadratic formula from more basic principles, the quadratic formula is, intuitively, a premise of the agent's reasoning.
\end{note}

\begin{note}
  Now, in the same way the agent may have calculated \(23 \times 15 = 345\) without the aid of a calculator in \autoref{illu:gist:calc}, the agent may have concluded \(x = 1\) or \(x = -\sfrac{1}{2}\) if \(2x^{2} - x - 1 = 0\) without the aid of the quadratic formula in~\autoref{illu:gist:roots}.

  For example, consider the following variant steps:
  \begin{quote}
    \begin{enumerate}[label=\arabic*\('\)., ref=(\arabic*\('\)), itemsep=.125em]
      \setcounter{enumi}{1}
    \item
      \label{illu:gist:roots:factor}
      \((2x + 1)(x - 1) = 0\) \hfill \ref{illu:gist:roots:eq}, Factoring
    \item
      \label{illu:gist:roots:zero}
      Either \((2x + 1) = 0\) or \((x - 1) = 0\) \hfill \ref{illu:gist:roots:factor}, Arithmetic
    \item
      \label{illu:gist:roots:case:a}
      If \((x - 1) = 0\), then \(x = 1\) \hfill \ref{illu:gist:roots:factor}, \ref{illu:gist:roots:zero}, Arithmetic
    \item
      \label{illu:gist:roots:case:b}
      If \((2x + 1) = 0\), then \(x = -\sfrac{1}{2}\) \hfill \ref{illu:gist:roots:factor}, \ref{illu:gist:roots:zero}, Arithmetic
    \item
      \label{illu:gist:roots:factor:done}
      Either \(x = 1\) or \(x = -\sfrac{1}{2}\). \hfill \ref{illu:gist:roots:zero}, \ref{illu:gist:roots:case:a}, \ref{illu:gist:roots:case:b}, Replacement
    \end{enumerate}
  \end{quote}

  Steps~\ref{illu:gist:roots:factor} to~\ref{illu:gist:roots:factor:done} yield the same results as steps~\ref{illu:gist:roots:qf} to~\ref{illu:gist:roots:qf:done}, but do not involve the quadratic formula.
\end{note}

\begin{note}
  Intuitively, did not conclude from a pool of premises which does not include the quadratic formula.
\end{note}

\begin{note}
  \scen{3}~\ref{illu:gist:calc} and~\ref{illu:gist:roots} are similar.
  Broadly, both involve an agent concluding \(\phi\) has value \(v\) from some pool of premises \(\Phi\) and an option for the agent to conclude \(\phi\) has value \(v\) from some distinct set of premises \(\Phi'\).

  The key difference between \scen{1}~\ref{illu:gist:calc} and~\ref{illu:gist:roots} is how concluding \(\phi\) has value \(v\) from \(\Phi'\) relates to the agent's conclusion of \(\phi\) having value \(v\) from \(\Phi\).
  Roughly, in \scen{0}~\ref{illu:gist:calc} the alternative reasoning relates to the premises \(\Phi\), while in \scen{0}~\ref{illu:gist:roots} the alternative reasoning relates to the reasoning from \(\Phi\) to \(\phi\) having value \(v\).

  This, noted.

  Argue this type of \scen{0} motivates negative resolution to \issueConstraint{}, and, by extension, \issueInclusion{}.

  Intuitions are difficult.
  Motivation will focus on:
  \begin{itemize}
  \item
    Conditional
  \item
    \fc{0}
  \end{itemize}

  Turn to sketching the general argument.

  Still, while we are here, abstract form of \scen{1}, a few additional examples, and a handful of contrasting examples.
\end{note}

\subsection[General characterisation]{A general characterisation of the type of \scen{0}}

\begin{note}
  Strictly, the key properties of the type of \scen{0} we are interested in concern an agent's epistemic state just prior to the agent concluding some proposition-value pair from some pool of premises.
\end{note}

\begin{note}
  \begin{scenarioType}[(Partial) check on reasoning-scenarios \hfill \cScen{1}]
    \label{scenType:CoR}
    \mbox{ }

    An agent \vAgent{} has concluded some proposition \(\phi\) has some value \(v\) from some pool of premises \(\Phi\).

    And, \emph{prior} to concluding \(\phi\) has value \(v\) from \(\Phi\), it was the case that:
    \begin{itemize}
    \item
      From \vAgent{}' perspective, if \(\phi\) has value \(v\) then:
      \begin{itemize}
      \item
        There is some proposition-value pair \(\psi\) having value \(v'\) and pool of premises \(\Psi\) such that:
        \begin{itemize}
        \item
          If the \vAgent{} were to fail to conclude that \(\psi\) has value \(v'\) from \(\Psi\) prior to concluding, \vAgent{} would not conclude \(\phi\) has value \(v\) from \(\Phi\).
        \end{itemize}
      \end{itemize}
    \end{itemize}
    \vspace{-\baselineskip}
  \end{scenarioType}

  {
    \color{red}
    Slight variation on \citeauthor{Tolliver:1982us}'s Pendulum Case.%
    \footnote{
      Understood \citeauthor{Tolliver:1982us}'s case only after.
    }
    Similar to \citeauthor{Tolliver:1982us}, though a difference.
  For, here, not lacking information.
  With the pendulum, didn't have the option of concluding from period, as didn't have information about period.
  }

  For ease of reference, we term scenarios of this type `\cScen{1}', where `CoRe' stands for `check on reasoning', or more carefully `partial check on reasoning'.

  The key feature of \cScen{1} is that prior to concluding \(\phi\) has value \(v\) from \(\Phi\), the agent has the option of reasoning about some other proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\), such that, from the agent's perspective, failure to conclude \(\psi\) has value \(v'\) from \(\Psi\), the agent would not conclude \(\phi\) has value \(v\) from \(\Phi\).

  In this respect, the agent reasoning about whether \(\psi\) has value \(v'\) is a partial check on whether it makes sense for the agent, from their present perspective, to conclude \(\phi\) has value \(v\) from \(\Phi\) given the reasoning they have performed.

  In other words, the proposition-value-premises pairing \(\pvp{\psi}{v'}{\Psi}\) is a partial check on the agent's reasoning from \(\Phi\) to \(\phi\) having value \(v\).

  We expand on this in three steps.
  First, why \(\pvp{\psi}{v'}{\Psi}\) is a \emph{check}.
  Second, why \(\pvp{\psi}{v'}{\Psi}\) is a check \emph{on reasoning}.
  And, finally, why \(\pvp{\psi}{v'}{\Psi}\) is a \emph{partial} check on reasoning.
\end{note}

\begin{note}[Check]
  Agent has the option.
  Something went wrong with the reasoning from premises to conclusion.
\end{note}

\subsection{Contrast to inital \scen{0}}

\begin{note}
  \color{blue}
  The important contrast is whether the conditional holds.
  This is not at all clear in first \scen{}.
  Though, if, for example, building the calculator, it may.

  Right, as noted below, then it's not clear the agent gets the equation via testimony.

  There's also observation about conflict with premises.
  However, I don't think this can be right.

  Really, the important thing is that the reasoning is `internal'.
  Could test the calculator, but this isn't just about the agent's reasoning.
\end{note}

\begin{note}
  On the agent's reasoning.

  The key contrast here is between \scen{1}~\ref{illu:gist:roots} and~\ref{illu:gist:calc}.

  Difference is how failure relates to the premise.

  With \autoref{illu:gist:calc}, testimony.
  It seems, if testimony, then it is not possible to satisfy the conditional.
  In other words, if the conditional holds, then it seems the agent doesn't have \(23 \times 15 = 345\) by testimony.

  With \autoref{illu:gist:roots}, quadratic formula.
  Fail to conclude from factorising, but this would not involve revising premise.
  Rather, reasoning from premises.
  For example, application of quadratic formula to the quadratic equation.
  Or, reduction of the quadratic equation.

  Reasoning from premises, rather than premises.

  Way this is captured, concluding \(\phi\) has value \(v\) from \(\Phi\).
  Agent would not conclude, because revise either testimony or understanding of arithmetic.
  However, remains the case that \emph{given} testimony, agent would conclude.

  The conditional focuses on the relation between premises and conclusion.
\end{note}

\begin{note}
  In addition, relative to \(\phi\) having value \(v\).
  Checking that the conclusion does indeed follow from the premises.

  This property is shared in both examples.
  However, narrows things down.

  Case in which agent could reason about premises further.
\end{note}

\begin{note}
  Partial.
  Failure to conclude \(\psi\) has value \(v'\) from \(\Psi\).
  Nothing about successfully concluding \(\psi\) has value \(v'\) from \(\Psi\).
  In general, other considerations against concluding \(\phi\) has value \(v\) from \(\Phi\).
  With respect to \cScen{1}, other proposition-value-premises pairings for which the same holds.
\end{note}

\begin{note}
  \color{red}
  Though we observed a slight contrast between \scen{1}~\ref{illu:gist:roots} and~\ref{illu:gist:calc} given the differing roles of the testimony of the calculator and the quadratic formula in the agent's reasoning, these variant steps highlight a key parallel.

  For, in~\autoref{illu:gist:calc} we noted the agent may have concluded \(23 \times 15 = 345\) without the testimony of the calculator.
  And, so long as the agent understands factorisation, a parallel statement holds for~\ref{illu:gist:roots}:
  The agent may have concluded \(x = 1\) or \(x = -\sfrac{1}{2}\) if \(2x^{2} - x - 1 = 0\) without the aid of the quadratic formula in~\autoref{illu:gist:roots}.
\end{note}

\begin{note}
  \scen{3} \ref{illu:gist:calc} and \ref{illu:gist:roots} both fit this pattern of a partial check.

  \autoref{illu:gist:calc}, agent's understanding of arithmetic, whether to trust the calculator.

  \autoref{illu:gist:roots}, factorising instead of applying the quadratic formula.

  In both these cases, \(\phi\) and \(\psi\) are the same proposition, and \(v\) and \(v'\) are the same value.
  Difference is the pools of premises.
\end{note}

\subsection{Additional examples}

\subsubsection{\cScen{3}}

\begin{note}[Propositional logic]
  \begin{scenario}
    \label{illu:sketch:prop-logic}
    Suppose an agent has a good grasp of propositional logic.
    In particular:
    \begin{itemize}
    \item
      The agent has a good understanding of some formal proof system.
      For example, some Fitch-style system.
    \item
      The agent has a good understanding of some method to construct semantic proofs.
      For example, by constructing truth tables, or reasoning about valuation functions.
    \item
      The agent understands the proof system is sound and complete.
      That is to say, the agent understands there exists a proof of some sentence \(A\) \emph{if and only if} \(A\) is true given an arbitrary valuation.
    \end{itemize}
    The agent constructs a proof of \(A\).

    Given the agent's understanding of propositional logic, the agent observes:
    \begin{quote}
      The construction is a proof of \(A\) \emph{only if} \(A\) is true given an arbitrary valuation.
    \end{quote}
  \end{scenario}

  Intuitively, if the agent were to reason about whether \(A\) is true given an arbitrary valuation and failed to conclude \(A\) is true given an arbitrary valuation, then the agent would not conclude the construction is a proof of \(A\).

  If were to go for semantic, then by soundness, works out.
\end{note}

\begin{note}[Interest]
  Delicate, the equivalence result is not in question.
  What's at issue is one's reasoning.
  The result tells me that if reasoning is fine for syntax, then also semantics and vice-versa.
\end{note}

\begin{note}[Programming]
  \begin{scenario}
    \label{illu:programming}
    Writing a program to automate some reasoning/processing of data.
  \end{scenario}
  Various test cases.
  In these, possible to do the reasoning oneself.
  Therefore, no appeal to program for these simple cases, at least.
  This is quite similar to the logic illustration in this sense.

  However, interest here as interdependence breaks down in interesting ways.
  For, may break down due to resource constraints.
  E.g.\ available time or complexity of inputs.

  And, after enough time with the program, failure to obtain the same result is not clearly going to indicate a problem with the program.
  Rather, one's reasoning.
  Though, in turn, this may be reversed after enough checking of the reasoning.
\end{note}

\begin{note}
  Three examples which follow basic pattern.
  All these involve reasoning which is both deductive and formal.
  Contingent feature.
  Straightforward to identify related proposition-value-premises pairings and motivate the option of reasoning with the related pairing.%
  \footnote{
    Note, in particular, non-deductive reasoning is fine.
    For, present epistemic state.
    May be the case that some novel information would overturn conclusion.
    However, novel information would require a revised epistemic State.
  }

  Favour these features in \scen{1} and examples as fairly general.
  Particular constants chosen are easily replaced.
  And, easy to find similar.%
  \footnote{
    For example, consider calculating exponents.
    One may calculated \(x^{n} \times x^{m}\) directly, or appeal to \(x^{n} \times x^{m} = x^{n + m}\).
 
    Also relatively simple, but there are a wealth of more complex examples.

    For example:
    See~\textcite{Fine:1997vc} for three distinct proofs of the fundamental theorem of algebra (i.e.\ any complex polynomial must have a complex root).
    Likewise, \textcite{Ribenboim:2012ts} contains eight proofs that their exist infinitely many prime numbers.
    And, \textcite{Wagon:1987vm} details fourteen proofs of a result about tiling a rectangle (specifically, whenever a rectangle is tiled by rectangles each of which has at least one integer side, then the tiled rectangle has at least one integer side).
  }
\end{note}

\begin{note}
  Simplify~\ref{illu:gist:roots} as a slight variation on~\ref{illu:gist:calc}.

  \begin{restatable}[\(\times\) and \(\div\)]{scenario}{scenarioClacMulDiv}
    \label{illu:sketch:math}
    An agent calculates \(345 \div 15 = 23\) via their understanding of arithmetic.

    \mbox{ }

    Given the agent's understanding of arithmetic, the agent observes:
    \begin{quote}
      \(345 \div 15 = 23\) \emph{only if} \(23 \times 15 = 345\).
    \end{quote}
    And, \emph{if} \(345 \div 15 = 23\), then they would not fail to conclude \(23 \times 15 = 345\).

    \mbox{ }

    The agent concludes \(345 \div 15 = 23\).
  \end{restatable}
\end{note}

\subsubsection{Non-\cScen{1}}

\begin{note}[Serial number]
  \begin{scenario}
    \label{illu:number-check}
    Handed a credit card.
    Conclude, will be able to bill after repairs are done.
  \end{scenario}

  Fairly straightforward partial check on whether the credit card is usable by applying the Luhn algorithm to check whether the credit card number is valid.
  Applying the Luhn algorithm requires only basic addition and multiplication.%
  \footnote{
    To illustrate.
    Credit card number is:
    \(4676\) \(2250\) \(1000\) \(0626\).
    Array:
    \([4,6,7,6,2,2,5,0,1,0,0,0,0,6,2]\)
    For every even index of the array (index from \(0\)), multiply the number by two, and add the resulting digits together if the results is greater than ten.
    \([8,6,5,6,4,2,1,0,1,0,0,0,0,6,4]\)
    Add elements of the array together with the check digit.
    Valid only if the result is equal to a multiple of ten.
  }
  However, if the agent is not aware of that the Lund algorithm may be applied to check whether the credit card number is valid, the agent will not have the option of checking given their present epistemic state.
\end{note}

\begin{note}[Calculator B]
  \begin{scenario}[Calculator B]
    \mbox{}
    \vspace{-\baselineskip}
    \begin{itemize}
    \item
      Calculation
    \item
      Only if calculator.
    \end{itemize}
  \end{scenario}

  Problem, not by reasoning alone.

  Here, reverse of original scenario.
  Problem is, using the calculator is not the agent's own reasoning.

  Interesting, and is a check in the same way.
  But, falls outside scope of interest.

  Similar, any instance of looking at solutions.
  So, for example, textbook with worked solutions.

  Taking a photo with a disposable camera.
  Only if, conclude negative is present on reel.
\end{note}

\section{Summary}

\paragraph*{Interest}

\begin{note}
  As seen from \illu{1}~\ref{illu:gist:calc} and \ref{illu:gist:roots}, there is an intuitive sense in which an agent concluding some proposition \(\phi\) has some value \(v\) involves certain pools of premises and does not involve other pools of premises.

  Calculator, understanding of arithmetic.
  Quadratic formula, factorisation.

  I am somewhat unsure about the intuitions expressed with respect to \scen{1} like~\autoref{illu:gist:calc}.
  However, I quite unsure about the intuitions expressed with respect to \scen{1} like~\autoref{illu:gist:roots}.
\end{note}

\chapter{Outline}
\label{cha:outline}

\begin{note}
  In this chapter we provide an outline the argument we will make for a negative resolution to \issueConstraint{}, and, by extension, \issueInclusion{}.

  At the highest level, the strategy is fairly straightforward:
  \begin{quote}
    Provide \scen{0} which motivate a negative resolution to \issueConstraint{}.
  \end{quote}

  We being with a very high level overview, detailing the key ideas and how they fit together.
  Following the very high level overview we then provide a slightly more detailed pass.
\end{note}

\begin{note}
  Though, this may be misleading.
  Considered various \scen{0}, and intuitions with respect to these \scen{0}.
  Our strategy is not to provide equally intuitive \scen{0} which are incompatible with a positive resolution to \issueConstraint{}.

  Rather, our strategy is to provide a detailed account of how a handful of ideas --- which are motivated independently of either a positive or negative resolution to  \issueConstraint{} --- combine to provide an abstract type of \scen{0}.

  Tension between instances of abstract type of \scen{0} and positive resolution to \issueConstraint{}.

  In this respect, I doubt the instantiations of the abstract type of \scen{0} will intuitively motivate a negative resolution to \issueConstraint{}.
  Rather, motivation \emph{given} background ideas.%
  \footnote{
    Indeed, I continue to find positive resolution to \issueConstraint{} intuitive.
    And, things are constructed very carefully to keep the range of cases as clear as possible.
    As we have seen, no revision to premises.
    Still puzzled about \scen{1} such as \autoref{illu:gist:calc}.
  }
  Hence, motivation.
\end{note}

\section{Gist}

\begin{note}
  \begin{enumerate}
  \item
    Support
  \item
    \cScen{1}
  \item
    If \fc{0}, then support.
  \item
    Relate support with \fc{0} to reasoning.
  \item
    \zS{}
  \item
    \zS{} compatible with either, so independent.
  \item
    Either concluded or \fc{0} is part of why.
  \item
    \cScen{0}, both disjuncts.
  \item
    Problem with restricting to concluded.
  \item
    So, \fc{0}
  \item
    \fc{0} is in part why.
  \item
    Negative resolution.
  \end{enumerate}
\end{note}

\subsection{\zS{}}
\label{sec:zs}

\begin{note}
  Basic observation.

  These conditionals.

  If were to fail, would not.

  Present in all \scen{1} considered, and in type of \scen{0} of interest, concern reasoning the agent has the option of doing.

  In some cases, seems a clear role for these type of conditionals.
\end{note}

\begin{note}
  Negative cases, where concluding is blocked due to the presence of some conditional, and doubt about whether it is the case.
\end{note}

\begin{note}
  Partial argument, by parity.
  Cases where blocks, then also cases where reason why.
\end{note}

\begin{note}
  Here, this is compatible with positive resolution to \issueConstraint{}.
  Agent has already witnessed reasoning for any such conditional.
\end{note}

\begin{note}
  Disjunction.
\end{note}

\begin{note}
  Motivation, range of cases where this kind of support would not hold.
\end{note}

\hozline{}

\paragraph{\zSN{0}}

\begin{note}[`\zSN{0}']
  Particular kind of support.
  \zSN{0}, or, rather, \zS{}.

  Is it the case that agent may fail to conclude?

  Additional property of relation of \support{}.
  If agent concludes, not only support, but \zS{}.
  \begin{itemize}
  \item
    \support{2}: premises and conclusion.
  \item
    \zS{}: checks.
  \end{itemize}

  In various cases, \support{} only if \zS{}.
\end{note}

\begin{note}
  \begin{idea}
    In cases of \zS{}:

    If agent were to take up option and fail to conclude, no support.
  \end{idea}
\end{note}

\begin{note}[Limitation and closure condition]
  So, conversely.

  \begin{itemize}
  \item
    Support \emph{only if} not the case that if the agent were to take up the option, would fail to conclude.
  \end{itemize}

  Simply:

  \begin{itemize}
  \item
    Support \emph{only if} if the agent were to take up the option, would not fail to conclude.
  \end{itemize}

  Here, turned into a closure condition.
\end{note}

\begin{note}
  Now, an important thing to note here is that we're not characterising a distinct instance of support.
  Rather, we have these additional constraints on the agent's epistemic state which, in turn, constrain support.

  Here, then, in part explanation why.

  For, support, only if conditional holds.
\end{note}


\begin{note}
  `Moorean'?
  \(\pv{\phi}{v}\) and may conclude \(\pv{\phi}{\overline{v}}\)?

  Well, distinct pools of premises.
  Still, these pools of premises are `present'.

  This is a very important observation.
  Interested in \zS{} cases.
  One option is to get rid of this.
  However, this seems quite difficult.
  If thought of place, then wouldn't conclude keys are missing.
  If problem with cards, wouldn't conclude conditional holds.
\end{note}

\paragraph*{Working with a case}

\begin{note}
  Return to~\autoref{illu:sketch:math}.

  \begin{quote}
    \scenarioClacMulDiv*
  \end{quote}

  Intuitively, if the agent were to \emph{conclude} \(23 \times 15 = 345\), the agent would also, at the same time, conclude \(345 \div 15 = 23\).

  Of course, this intuition may be resisted.
  For example, \(345 = (3 \times 5 \times 23)\) and \(15 = 3 \times 5\).
  Intuitively, it is not the case that the agent would conclude \(23 \times (3 \times 5) = (3 \times 5 \times 23)\).

  The equivalence between multiplication and division is sufficiently familiar.
\end{note}

\begin{note}
  {
    \color{red}
    Possibly to go in a footnote, or move to later chapter.
  }

  Suppose syntax.
  Well, check with semantics.
  If fail semantics, then something wrong with syntactic reasoning.

  Conversely, semantics.
  Then, syntax.

  Intuitively, \zS{0}.
  Not the case that agent would reach a different conclusion.
  Strength of reasoning for either syntax or semantics.

  Observation.
  Can't go from syntax to semantics while preserving \zS{}.
  Possible to check semantics ignoring proof.

  Conversely, semantics is no good for \zS{} without syntax.

  Key observation is, \zS{}, if either syntax or semantics is involved, then this doesn't answer the question.
  At issue is whether the agent may fail, and in doing so unwind the main conclusion.
\end{note}

\begin{note}[Options]
  \begin{enumerate}
  \item
    Give up on \zS{}.
    {
      \color{red}
      (Seems unintuitive, and, link to concluding.)
    }
  \item
    Conclude independently, and then get \zS{}.
    {
      \color{red}
      (Seems redundant.)
    }
  \item
    Get \fc{0} prior.
    {
      \color{red}
      (But, no information about what the result is.)
    }
  \item
    Same time.
    \begin{enumerate}
    \item
      Witness.
      {
        \color{red}
        (But, distinct premises.)
      }
    \item
      \fc{0}.
    \end{enumerate}
  \end{enumerate}
\end{note}

\begin{note}[Give up on \zS{}]
  Intuition, and \zS{} is quite weak.
  I mean, look, there's no doubt.
  This is clear with multiplication and division.
  There's no problem with reasoning via either multiplication or division.
  Observation that I would not conclude via X if I fail to conclude via Y.
  However, this does no suggest that there is anything problematic with reasoning.

  Compare to examples of failure.
  Not like keys.
  Not like\dots? (letter requires novel information.)

  The difficulty is accounting for why.
  Why would not fail, independent of multiplication.
\end{note}

\begin{note}[Do the reasoning]
  One option, do the reasoning.
  This seems excessive.
  For, mostly, the same reasons as above.
  Multiplication and division are straightforward.
\end{note}

\begin{note}[\fc{0} prior]
  Well, intuitively, \fc{0}.
  However, no information about \emph{which}.
\end{note}

\begin{note}[Simultaneous]
  Simultaneous conclusion.

  Reasoned from one, the other is a \fc{0}.
  Information from reasoning, \emph{which} \fc{0}.

  \fc{0}, \emph{why} \zS{}.

  Key point, premises for information are not premises for \fc{0}.
  If premise, then \zS{} is voided.
  Witnessing reasoning is in part \emph{how}, but is not tied to \emph{why}.

  Here, negative answers.
  No witnessed reasoning from division.
  Reasoning from division is not included in how.
\end{note}

\begin{note}
  Not clear to me how puzzling this is.

  On some days, quite puzzling.
  Agent has not witnessed reasoning.

  On other days, \fc{0}.
  There's really no need for the agent to witness.
  Though, it is clear how important this is for multiplication.
\end{note}

\begin{note}
  One issue, agent may still reason from division and fail.
  But, it is not clear to me how important this really is.
  Witness, then there is no guarantee that the reasoning is not faulty.
  This gets covered later.
\end{note}

\begin{note}[Variant with logic]
  Here, second go with syntax and semantics.
  This has the benefit of clarity over conclusion.
  Downside is that you may not be a logician.

  Syntactic reasoning is fine, and equally, semantic reasoning is fine.
\end{note}


\subsection{\fc{3}}
\label{sec:fc3}

\begin{note}
  So, general type of \scen{0}.

  Here, we have some test.

  Relation of support between \(\pvp{\psi}{v'}{\Psi}\) is, in part, answer to why.
\end{note}



\begin{note}[Outline]
  Idea of a \fc{0}.
  \(\phi\) having value \(v\) is a \fc{0} with respect to an agent's epistemic state just in case the agent would not fail to conclude \(\phi\) having value \(v\).

  If \fc{0}, then some pool of premises \(\Phi\) available to the agent such that it is possible for the agent to witness reasoning from \(\Phi\) to \(\phi\) having value \(v\).

  Future variant of~\autoref{idea:support}.
  If agent has concluded, then support.
  Agent has not concluded, but sufficient.

  Nothing too surprising.
  Recall, knowing whether.
  There is nothing apart from witnessing.

  \fc{0}, alone, then, not too interesting.
  Information that \(\phi\) having value \(v\) is a \fc{0}.
  A little more interesting.

  Now, here, \emph{that} \fc{0}.

  Information about the possibility of establishing some conclusion.
  Nothing too surprising.
  Questions in textbooks.

  Pair these two things together.
  Well, okay.
  Hint.
  Here, then, open to go from \emph{that} \fc{0} to \(\Phi\).

  Given \(\Phi\), everything else is redundant.

  With a \fc{0}, the pool of premises, these do the work of establishing the possibility of how.

\end{note}


\paragraph{Key idea: \fc{1}}

\begin{note}
  Core idea:
  \begin{idea}[\fc{1} and support]
    \label{idea:fc-and-support}
    If \(\phi\) having value \(v\) is a \fc{0}, then relation of support between \(\phi\) having value \(v\) and some pool of premises \(\Phi\).
  \end{idea}

  Following suggestion made with respect to \autoref{illu:gist:calc}.

  With this idea, possible for relation of support to be in part why.

  Given this, still a question of how \fc{0} are involved.
\end{note}

\begin{note}
  As with \autoref{illu:gist:calc}, possibility of failure to conclude.

  Particular type of support.

  Agent would not conclude otherwise.

  Fairly natural.
\end{note}

\begin{note}
  So, scope of a fairly natural type of support.%
  \footnote{
    \color{red}
    This should be moved somewhere else, but it would be useful to emphasise that \zS{} really is a type of support, in the sense that it is why the agent concludes in various cases.
    For, without support for each \requ{}, the agent would not conclude.
  }
\end{note}

\begin{note}
  \color{red}
  Important to note here is that this doesn't entail the relation of support, in part, answers \qWhyV{}.

  By-product.

  Still, interesting.
  This will, more-or-less be the basis for our argument.
\end{note}

\begin{note}
  \color{blue}
  Perhaps here include some comments on general and specific ability.
  This is in part how get these kind of scenarios.
  In some cases, same ability, different premises, and in other cases links between ability.
\end{note}

\begin{note}
  \autoref{idea:fc-and-support} is fundamental.

  Distinction between:
  \begin{enumerate}
  \item
    Support between premises and conclusion of a \fc{0}.
  \item
    Support between \fc{0} and conclusion of \fc{0}.
  \end{enumerate}

  To illustrate.
  Grant for a moment, understanding of arithmetic is involved in why.

  Not understanding of arithmetic, but that I, or you, understand arithmetic.
  Not understanding, but \emph{that} understand.
\end{note}

\begin{note}[Re-evaluate intuitions?]
  Of course, interest in this property has only just been made explicit.
  Perhaps revise intuition.
  Though, I expect not.

  Though it is true that the agent would not conclude, did not do the reasoning.

  Stated in other terms, \(\psi\) from \(v'\) is a \fc{} if \(\phi\) has value \(v\).
  Still, no relevance.
\end{note}

\paragraph*{Major and minor problems}

\begin{note}
  Two problems.

  Minor and major.

  Both comes from information required.

  Minor.
  \emph{that} \fc{0}.
  Distinction between \(\Phi\) and that conclude from \(\Phi\).
  Need \emph{that} \fc{0}.

  Major.

  \itp{} gives information.
  So, conclude from that.
\end{note}

\paragraph*{Minor}

\begin{note}[Minor]
  Minor problem.
  Thing is, no clear leverage.
  Certain nice things about \(\Phi\), and \emph{that} \fc{0} is much weaker.
  Only thing missing is witnessing.

  Basically, only really get \emph{that} \fc{0} doing any work if support between \(\Phi\) and \(\pv{\phi}{v}\).

  In part, this is why focus attention on support.

  As we have seen, independent motivation for relation of support.
  Tied to why.

  Part of what it is for something to be a \fc{0} is a relation of support.
\end{note}

\paragraph*{Major}

\begin{note}[Major]
  Redundant.
  Possible answer to \qWhy{}.
  However, this doesn't show that is an answer to \qWhy{}.

  In general, various possible answers to \qWhy{}.
  This is key.
  Issues \issueInclusion{} and \issueConstraint{} narrow down.

  \citeauthor{Boghossian:2014aa}, recall.
  Of course, much different that just saying, or being response dependent.
  \fc{0}.
  So, answers \qWhy{}, at least in principle.

  Still, relevant information, \itp{}, etc.\ must do enough to get \(\pv{\phi}{v}\).
  For, if not then it seems can't use that \(\pv{\phi}{v}\) is a \fc{0}.

  Squeeze out role for \fc{0}.

  Indeed, \fc{0} from understanding of arithmetic.
  But, it is not obvious that this is why.
  Calculator does it all.

  Find role for \fc{0}.
  Tied to why an agent concludes.
  This is our goal.
  Show how \fc{0} is, in part, why an agent concludes.

  \begin{itemize}
  \item
    From the agent's perspective.
  \item
    Support holds between \(\Phi'\) and \(\pv{\phi}{v}\), and in part this is why agent concludes \(\pv{\phi}{v}\) from \(\Phi\).
    Where, \(\Phi' \ne \Phi\).
  \end{itemize}

  Still, get to \(\pv{\phi}{v}\).
  So, \(\Phi'\) is not required to conclude \(\pv{\phi}{v}\), in general.
\end{note}

\paragraph*{Role for \fc{1}}

\begin{note}
  Role for \fc{1}.

  Concluding from some pool of premises.
  More complex.
  Key thing, check.
  Prior to concluding \(\pv{\phi}{v}\) from some pool of premises \(\Phi\), check on whether it makes sense, from agent's perspective, to conclude \(\pv{\phi}{v}\) from \(\Phi\).

  In particular, cases where, if \(\phi\) has value \(v\) then it is possible for the agent to conclude \(\psi\) has value \(v'\) from some pool of premises \(\Psi\).
  Here, permutations.
  Of interest for the moment:
  \(\phi = \psi\) but \(\Phi \ne \Psi\).
  However, also \(\phi \ne \psi\) and \(\Phi \ne \Psi\).

  Keys.

  This prevents.

  Parcel delivered, check the address before opening.

  Cases go the other way.
  Check is satisfied.

  Wason selection task.
  Here, it is clear what needs to be checked.
  If this proposition is true, then these things are possible.

  Here, consistent with witnessing.
  Turned over cards, then fine.
  Haven't reasoned from place to absence of keys.

  Many instances are.

  Relative, so long as conclusion is true.
\end{note}

\begin{note}[Not all concluding is like this]
  Not all concluding is like this.
  Testimony.
  No way to check.
  Of course, may be various ways to check the sources.
  However, focus on novel conclusions.
\end{note}




\subsection{Tension}
\label{sec:tension-1}

\section{Supplements}
\label{sec:overview:supplements}

\subsection{Back to testimony (and a variant of \zS{})}

\begin{note}
  The key difference between these two cases is:
  With multiplication and division, or syntax and semantics, question is about the agent's reasoning from premises to conclusion.

  However, with testimony, the question is with whether the premise of testimony is a good premise.

  The thing is, whether leave the premises fixed.

  Variant of \zS{}.
  Here, query premises, rather than the conclusion.
  Set this aside.

  Part of what makes \zS{} interesting is no revisions.
  In this respect, quite different to something like \citeauthor{Wright:2011wn} on transmission of warrant.

  Still, this is not too much of a stretch.
  For, would still prevent concluding.

  However, this gets tricky.
  Because, testimony is involved as a premise.
  Well, no clear recursion problem, assuming well-structured premise-conclusion.
  For, \zS{} still relative to premise-conclusion pairings.

  The real difficulty is conclusion being enough.

  I mean, it's just a different condition.
\end{note}

\begin{note}[Other cases are puzzling]
  The introductory \illu{0}, with the calculator, this is more puzzling.
  Seems, \fc{0} from calculator.

   Without \fc{0}, no concluding.
  Without calculator, no \fc{0}.

  No concluding, as would not conclude if different.
  \fc{0}, given understanding of arithmetic, but no account of which.

  However, difference.
  Calculator is independent of agent's own reasoning.
  Though, this gets somewhat tricky.
  Testimony, other agents.
\end{note}

\begin{note}
  Calculator.
  Check to see whether or not it's functioning correctly.
  Understanding of arithmetic.
  If fail to conclude sum, then calculator is no good.

  \zS{}.
  Again, key point here is that if something else, then wouldn't conclude.

  Conclude sum from calculator only if conclude sum from understanding of arithmetic.
\end{note}

\begin{note}
  {
    \color{blue}
    First thing, can't use calculator.

    More broadly, ordering problem.

    Without \fc{0}, no conclusion from testimony.
    Without testimony, no which for \fc{0}.
  }

  {
    \color{red}
    Solution.

    Well, key thing is that calculator is fine.
    And, if calc, then given understanding of arithmetic, would conclude.
    No suggestion that calculator is faulty in any way.
    However, this doesn't mean that we don't have a check.

    At the same time.
    So, calculator \emph{and} \fc{}.

    \fc{} is not coming from calculator.
    Only getting information from calculator.
    Not worries about calculator, because would conclude.

    This is a somewhat puzzling conclusion.
    However, it's fine.

    See, the best we can do here is press the idea that the agent may still conclude otherwise.
    But, not from the agent's present epistemic state.
    For, \fc{0}: Would not fail from present epistemic state.

    Of course, could still press this, but then no different from any other conclusion.

    Hence, would need to hold that the agent had to conclude from understanding of arithmetic strictly prior.
    This, the agent hasn't done.

    So, then, the problem with this is that in general, have cases of such `simultaneous conclusions'.
    This requirement, paired with idea of \zS{}, problem for ability.

    So, reject \zS{}.
    Yet, intuitive constraint on concluding.
    }

  In other words, calculator only if \fc{0}.
  Understanding of arithmetic also supports.

  Testimony.
  So, receive testimony.
  Also, understanding of arithmetic.
  No witnessing, so if testimony is right, then \fc{0}.
  But, if no support, then would not conclude.

  Testimony only to the extent something I already know (whether).
  So, part of why is that know whether.
  Only if already a \fc{0}.

  Hence, \qWhy{} not included in \qHow{}.
  And, more generally, no witnessing.

  Testimony\dots property of being testimony\dots
  Telling me things I already know (whether).
  No granting testimony if not already supported.


  Why is testimony fine?
  Because \fc{0}!
  Well, maybe.
  {
    \color{red}
    Ugh, this is difficult.
    The cases I have where \fc{0} is clearest involve other problems.
    I.e.\ sudoku, so don't need to test reasoning against any other problems.

    So, testimony is irrelevant to whether, it's not a \fc{0} because testimony.
    Already have \fc{0}, already `know' whether.
    What testimony does is inform \emph{which}.
  }

  {
    \color{red}
    This is kind of the puzzle.
    Without \fc{0}, don't get testimony (because, independent test).
    And,
    Without testimony, don't get \fc{0} (because, need info which).

    So, these two things come in at the same time.
    When go from testimony, also get that \fc{0}.

    But, why is only tied to understanding of arithmetic, because else an ordering problem.

    So, the core idea is that the relationship between testimony and understanding of arithmetic is already in place, prior to getting information about which from the calculator.

    Right, the key thing is that there are two sources of information.
    \begin{itemize}
    \item
      Testimony
    \item
      Understanding of arithmetic
    \end{itemize}
    What matters is that these align.
    So long as you have this, then when you get a new piece of information from either, expectation that both sources will provide the same information.
    If break equivalence between the two sources, then neither works.
    Here, each much function separately.

    Keeping parity.

    So, how really isn't all that important.
  }

  Going from testimony to \fc{0} doesn't work.
  Because, \fc{0} is independent check.
  Right, because then testimony is still pending on whether \fc{0}.

  This is delicate.
  It seems as though, check on whether testimony.
  So, no testimony.

  However, this is not quite right.
  It is a check on testimony.
  However, two things.
  First, understanding and second testimony.
  Testimony is fine, understanding of arithmetic only presents the option of checking.
  Understanding does not suggest that testimony is bad/statement does not amount to testimony.
  However, understanding of arithmetic is in part why because this dismisses the possibility.

  Testimony, pressure on understanding of arithmetic.

  Testimony, but if testimony and \fc{0}, then determine whether really is testimony.
  If go via testimony, then either limited support, or \fc{0} does work.

  Structurally similar to ability.
  If specific from general, then only so good as specific.

  Of course, only when possible to check.
  If not possible, then this restriction isn't in place.

  In other words, attention shifts from cases of concluding in general, to specific cases.

  If sufficient to conclude, then what role has alternative option?
\end{note}

\begin{note}
  Of course, \emph{that} \fc{0} is key with respect to how.
  If the agent has not witnessed reasoning, then need some source of information.
  However, not for \emph{why}.

  Note, possibility of witnessing is given by X, as is that X supports Y.
  X is sufficient.
  Nothing more is needed for X to support Y.
\end{note}



\section{Concluding}
\label{sec:ideas-1}

\begin{note}[Outline]
  Here, clarify our use of the terms `concludes', `concluding', `concluded', and so on.
\end{note}

\subsection{The agent's epistemic state}
\label{sec:agents-epist-state}

\begin{note}
  Idea.
\end{note}

\begin{note}
  Distinguish agent's epistemic state from \stance{} of the agent.

  Various things we hold to be the case, and these may be relativised to the agent's perspective on how things actually are.
  Other things, hold regardless of the agent's perspective on how things actually are.
  And, things that hold regardless of whether the agent recognises.

  Example.
  Sam shorter than Taylor.
  Then, from epistemic state, Taylor shorter than Sam.
  Doesn't matter whether Sam is shorter than Taylor.
  From perspective of agent's epistemic state.
  Likewise, doesn't matter whether agent recognises shorter.

  Similarly, classical and intuitionistic.
  From int.\ perspective not a proof.
  From classical, also a proof of \(\phi\).

  And, if left the oven on, should check.
  Regardless of whether really did, and regardless of agent's morals.

  No clean divide.
  For present purposes, concluding and \csN{} will take epistemic state as input, but ignore the agent's \stance{}.
  What this means in practice will be seen through the following discussion.
  Roughly, what an agent concludes will depend on epistemic state, and whether \csN{} in concluding will likewise depend.
  Neither will depend on whether the agent recognises, or takes themselves, to have concluded.
\end{note}

\section{Broader implications}

\begin{note}
  Separate concluding to district components.
  Witnessing a foregone-conclusion.
  There is nothing that witnessing adds which is not already determined by the agent's present epistemic state.

  Nothing of interest to be gain by witnessing, hence, in some sense of the term concluding, conclude conclusion from premises without witnessing reasoning from premises to conclusion.

  Conclusion, as a term up for question.
  Whether witnessing reasoning from premises to conclusion is part of what the phenomenon of concluding some conclusion from some premises is.
\end{note}

\begin{note}
  Main this is resolving issue.
  Two other upshots.

  \begin{enumerate}
  \item
    Reduction of concluding.
    In various cases, abundance of \fc{0} suggests witnessing is not explanatory.
    Limited to how.
  \item
    Concluding without witnessing.
    {
      \color{red}
      I think I get close to this regardless, by looking at cases where an agent develops some general ability.
    }
    Stronger variation.
    If \fc{0}, then don't need to witness.
    Note, this is strictly stronger.
    For, main issue only tells us that some pool of premises is involved in why.
  \end{enumerate}
\end{note}

{
  Goal is to argue that witnessing is the only distinguishing feature.
  There are cases, such as the one described above, in which equal role.

  Core idea, supports to more general points of interest.

  More broadly, separate witnessing from concluding.
  Suggest there are cases in which conclude without witnessing.
}

\paragraph*{Aside: Method}

\begin{note}
  Main points from above suggest including method.

  For example, independent set and vertex cover problem.
  Here, reduction.
  However, same premises and same conclusion (given understanding of equivalence).

  So, same issue.

  Here, to keep things relatively simple, avoid method.

  Problem here is that things are mostly the same in these cases, in contrast to calculator versus understanding of arithmetic.
\end{note}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End: