\chapter{Introduction}
\label{cha:intro}

\begin{note}
  \begin{scenario}[Multiplication]
    \label{illu:gist:calc}
    An agent enters `\(23 \cdot 15\)' into a calculator and presses a button marked `\(=\)'.
    The calculator displays `\(345\)'.

    The agent pauses for a moment.
    They have a good understanding of arithmetic.
    And, given the display on the calculator, it follows that if the calculator is trustworthy, then they would not fail to conclude \(23 \cdot 15 = 345\) via their understanding of arithmetic.

    The agent concludes \(23 \cdot 15 = 345\).
  \end{scenario}

  The agent concluded \(23 \cdot 15 = 345\) by their use of the calculator.
  Personifying a little, we may say the agent has concluded \(23 \cdot 15 = 345\) from the testimony of the calculator.

  Further, the agent did not, in part, conclude \(23 \cdot 15 = 345\) by their understanding of arithmetic.
  So long as the calculator was correct, the agent had the opportunity to conclude \(23 \cdot 15 = 345\).
  Still, the agent did not perform any arithmetic.
\end{note}

\begin{note}
  \autoref{illu:gist:calc} is simple, and I expect the commentary is intuitive.
  Let's consider a second \scen{0}.
\end{note}

\begin{note}
  \begin{scenario}[Animalism]
    \label{scen:animalism}
    `Four legs good, two legs bad.'
    This, he said, contained the essential principle of Animalism.
    Whoever had thoroughly grasped it would be safe from human influences.
    The birds at first objected, since it seemed to them that they also had two legs, but Snowball proved to them that this was not so.

    `A bird's wing, comrades,' he said, `\textsc{is} an organ of propulsion and not of manipulation.
    It should therefore be regarded as a leg.
    The distinguishing mark of Man is the \emph{hand}, the instrument with which he does all his mischief.'

    The birds did not understand Snowball's long words, but they accepted his explanation, and all the humbler animals set to work to learn the new maxim by heart.
    \textsc{four legs good, two legs bad}, was inscribed on the end wall of the barn\dots%
    \mbox{ }\hfill\mbox{(\cite[25]{Orwell:1976aa})}%
    \newline
  \end{scenario}

  The agents of interest are the birds, and the conclusion is the essential principle of Animalism:
  `Four legs good, two legs bad'.

  Snowball provided an argument against an objection from the birds, and the birds concluded `Four legs good, two legs bad' from Snowball's explanation.

  Though, as \citeauthor{Orwell:1976aa} highlights, the birds did not conclude `Four legs good, two legs bad' from \emph{the content of} Snowball's explanation.
  Some words were too long.
  Instead, the birds concluded `Four legs good, two legs bad', at least in part, from \emph{Snowball's explanation}.

  In parallel to the agent's understanding of arithmetic from~\autoref{illu:gist:calc} the birds of~\autoref{scen:animalism} did not, in part, conclude `Four legs good, two legs bad' from the content of Snowball's explanation.
\end{note}

\section*{\qWhy{} and \qHow{}}
\label{cha:intro:why-how}

\begin{note}
  Our interest is understanding the way in which an event in which some agent \vAgent{} concludes some proposition \(\phi\) has some value \(v\) happened.

  With respect to~\autoref{illu:gist:calc}, an unnamed agent concludes `\(23 \cdot 15 = 345\)', has value `\(\text{True}\)'.
  And, with respect to~\autoref{scen:animalism} the birds, conclude `Four legs good, two legs bad' is `\(\text{True}\)'.

  Further, in both \scen{1}, the agent concludes \(\phi\) has value \(v\) from some \poP{}.

  With respect to~\autoref{illu:gist:calc}, the agent concludes `\(23 \cdot 15 = 345\)' has value `\(\text{True}\)' \emph{from} the testimony of the calculator.
  And, with respect to~\autoref{scen:animalism} the agents conclude `Four legs good, two legs bad' has value `\(\text{True}\)' \emph{from} the existence of Snowball's explanation.%
  \footnote{
    Strictly, of interest is that the relevant conclusions follow from the agent evaluating the relevant state of affairs as \(\text{True}\).
    That is, with respect to~\autoref{illu:gist:calc}, of interest is that the agent concludes `\(23 \cdot 15 = 345\)' has value `\(\text{True}\)' \emph{from} the agent evaluating `the calculator testified \(23 \cdot 15 = 345\)' as `\(\text{True}\)'.
    And, with respect to~\autoref{illu:gist:calc} it is likewise the birds `perceiving' an explanation from Snowball exists.
    However, we adopt the shorthand for ease of expression.
  }

  Term considerations such as the testimony of the calculator and the existence of Snowball's explanation `premises'.
  Assume an agent always conclude some proposition \(\phi\) has value \(v\) from some \poP{} of premises \(\Phi\).
  And, grant that when an agent concludes \(\phi\) has value \(v\) from a \poP{} of premises, some relation holds between \(\phi\) having value \(v\) and the \poP{} of premises.

  It seems that the relation holds between \(\phi\) having value \(v\) and the \poP{} of premises grants understanding of the way in which the event in which the agent concluded \(\phi\) has value \(v\) happened.
\end{note}

\begin{note}[Not just concluding]
  \phantlabel{how-and-why-first-mention}
  We distinguish two questions; `\qWhy{}' and `\qHow{}':

  \begin{restatable}[\qWhy{}]{question}{questionWhyBasic}
    \label{q:why}
    \cenLine{
      \begin{itemize*}[noitemsep, label=\(\circ\)]
      \item
        Agent: \vAgent{}
      \item
        Proposition: \(\phi\)
      \item
        Value: \(v\)
      \item
        Event: \(e\)
      \item
        \mbox{ }
      \end{itemize*}
    }
    \begin{itemize}
    \item
      Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
      \begin{itemize}
      \item
        Which relations between some proposition-value pair and \poP{} of premises explain \emph{why} \(e\) is such that \vAgent{} concluded \(\phi\) has value \(v\)?
      \end{itemize}
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}

  \begin{restatable}[\qHow{}]{question}{questionHowBasic}
    \label{q:how}
    \cenLine{
      \begin{itemize*}[noitemsep, label=\(\circ\)]
      \item
        Agent: \vAgent{}
      \item
        Proposition: \(\phi\)
      \item
        Value: \(v\)
      \item
        Event: \(e\)
      \item
        \mbox{ }
      \end{itemize*}
    }
    \begin{itemize}
    \item
      Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
      \begin{itemize}
      \item
        Which events explain \emph{how} \(e\) is such that \vAgent{} concluded \(\phi\) has value \(v\)?
      \end{itemize}
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  \qWhy{} seeks an understanding of the way in which an agent concluded \(\phi\) has value \(v\) in terms of relations between proposition-value pairs and \poP{1} of premises.

  Following the analysis of~\autoref{illu:gist:calc} and~\autoref{scen:animalism} we have developed, the relevant relations, respectively, seem to be:
  \begin{enumerate*}[label=]
  \item
    The relation between `\(23 \cdot 15 = 345\)', `\(\text{True}\)', and the testimony of the calculator.
  \item
    And, the relation between `Four legs good, two legs bad', `\(\text{True}\)' and the existence of Snowball's explanation.
  \end{enumerate*}

  In particular why this conclusion as opposed to any other conclusion.%
  \footnote{
    The \illu{1} of \qWhy{} by \autoref{illu:gist:calc} and \autoref{scen:animalism} is somewhat limited, as neither \scen{0} involves an account of what motivates the respective agents.
    \qWhy{} is not designed to rule out what motivates an agent.
    For example, one may add to \autoref{illu:gist:calc} that the agent wants to calculate \(23 \cdot 15\).
    Functions as a premise, given the understanding of premises.
    More detail follows in~\autoref{cha:clar}.
  }

  We may add further details.
  For example, that testimony and explanations are factive.
  Hence, granting calculator provides testimony and Snowball has explained, then what the calculator has testified and what Snowball has explained must be the case.

  However, some relation between the relevant \poP{} of premises and conclusion, and from this understanding.

  In each \scen{0} it seems, respectively, the testimony of the calculator and Snowball's explanation are sufficient to understand the way in which the agent concluded the relevant proposition has the specified value.

  We do not, it seems, need to consider the agent calculating \(23 \cdot 15\) by their understanding of arithmetic, nor the birds understanding Snowball's explanation.
\end{note}

\begin{note}
  \qHow{} seeks an understanding of the way in which an agent concluded \(\phi\) has value \(v\) in terms of what happened.
  So, answers to \qHow{} when applied to~\autoref{illu:gist:calc} and~\autoref{scen:animalism}, at least, are the events captured by the descriptions given.

  Implicit in the events is `witness' for relation.
  Reasoned from \poP{} of premises to conclusion.
  Events of \autoref{illu:gist:calc} and \autoref{scen:animalism} seem to provide an account of the way in which conclusion was obtained from \poP{} of premises.
\end{note}

\begin{note}
  Given relation and witness, it may seem that, with focus on relations, both \qWhy{} and \qHow{} coincide.
  Relations are answer \qWhy{} only if get witness from an answer to \qHow{}.

  Suggest following constraint on answers to \qWhy{} in terms of answers to \qHow{}:
  \phantlabel{how-and-why-relation-first-mention}
  \begin{restatable}[\issueInclusion{}]{constraint}{issueInclusionFirst}
    \label{issue:why-inc-in-how}
    \mbox{ }
    \vspace{-\baselineskip}
    \begin{itemize}
    \item
      Some relation between proposition-value and some \poP{} of premises is, in part, an answer to \qWhy{}.
    \end{itemize}
    \emph{Only if:}
    \begin{itemize}
    \item
      An event in which the agent concludes the proposition has the value from the \poP{} of premises is, in part, \qHow{}.
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  Plausible.%
  \footnote{
    The observation also suggests the converse holds --- an answer, in part, to `how?' is also, in part, an answer to `why?' --- though I think the converse faces some immediate difficulties.
    For, it seems answers to `how?' may include details that are irrelevant to `why?'.
    For example, typing digits and operators into the calculator answers, in part, how the agent concluded \(23 \cdot 15 = 345\) but these actions seems irrelevant to why the agent concluded \(23 \cdot 15 = 345\).
    Rather, an answer to `why?' seems to be limited to the calculator providing testimony that \(23 \cdot 15 = 345\), regardless of whether it was the agent who used the calculator, or whether the agent observed someone else using the calculator.
  }

  \begin{itemize}
  \item
    \autoref{illu:gist:calc}

    The pairing of testimony of the calculator with \(23 \cdot 15 = 345\), is, in part, \emph{both} how \emph{and} why the agent concluded \(23 \cdot 15 = 345\).

    No witness for any relation between `\(23 \cdot 15 = 345\)', `\(\text{True}\)' and whatever \poP{} of premises would be associated with the agent calculating \(23 \cdot 15 = 345\) from their understanding of arithmetic.

    There may be other considerations which suggest such a relation fails to answer \qWhy{}.
    Still, if \issueInclusion{} holds, considerations are not required to exclude.
    For, absence of event is sufficient.%
    \footnote{
      Note, \qHow{} does not explicitly require the relevant event to be the event in which the agent concludes \(\phi\) has value \(v\) from the \poP{} of premises.
      Hence, a previous event in which the agent concluded `\(23 \cdot 15 = 345\)' has value `\(\text{True}\)' may answer \qHow{}.
      Still, given \(23 \cdot 15 = 345\) in~\autoref{illu:gist:calc} functions as some arbitrary multiplication that the agent may calculation, we may assume the agent has never calculated \(23 \cdot 15 = 345\).
    }

  \item
    Likewise, Snowball.

    Explanation is both why and how.

    The birds fail to understand the content of Snowball's explanation.
    Hence, there is no event in which the birds conclude `Four legs good, two legs bad' has value `\(\text{True}\)' from the content of Snowball's explanation.
    Therefore, there is no relation between `Four legs good, two legs bad', `\(\text{True}\)', and the content of Snowball's explanation which answers \qWhy{}.
  \end{itemize}
\end{note}

\begin{note}
  \issueInclusion{} is a constraint.
  It does not follow that answers to \qWhy{} are given in terms of answers to \qHow{}.
  To illustrate this point, consider the following \scen{}:

  \begin{scenario}[England AD 932]
    \vspace{-\baselineskip}
    \begin{screenplay}
    \item[OLD WOMAN:]
      Well, how did you become King, then?
    \item[ARTHUR:]
      The Lady of the Lake, her arm clad in purest shimmering samite, held Excalibur aloft from the bosom of the waters to signify that by Divine Providence\space\dots\space I, Arthur, was to carry Excalibur\dots\space that is why I am your King.
    \item[DENNIS:]
      Look, strange women lying on their backs in ponds handing over swords\space\dots\space that's no basis for a system of government.
      Supreme executive power derives from a mandate from the masses not from some farcical aquatic ceremony.%
      \mbox{ }\hfill\mbox{(\cite[8--9]{Cleese:1974aa})}
    \end{screenplay}
    \vspace{-\baselineskip}
  \end{scenario}

  The old woman asks Arthur \emph{how} the become king.
  Arthur provides an answer in terms of some events which happened, but emphasises that those events are \emph{why} Arthur is king.
  In turn, Dennis accepts the answer provided by Arthur as an account of how Arthur became king but rejects the answer an account of why Arthur is king.
  Instead, an answer is expected in involve the absence of an appropriate system of governance in England.
  So, the answer provided by Arthur is accepted by Dennis as an answer to how, but not as an answer to why.
\end{note}

\begin{note}
  Parallel with conclusions.
  We had the agent considering mental arithmetic.
  Part of how, but not why.
  And, content of Snowball's explanation.
  Part of how, but not why.
\end{note}

\begin{note}
  So, \qWhy{} and \qHow{} are distinct questions.
  \issueInclusion{} functions to constrain answers to \qWhy{} in terms of answers to \qHow{}.

  In short, for any relation between proposition-value pair and \poP{} of premises which grant some understanding of the way in which an agent concluded \(\phi\) has value \(v\), there is an event such that the agent has concluded the proposition-value pair from the \poP{} of premises.

  I consider \issueInclusion{} highly intuitive.
  The analysis given to~\autoref{illu:gist:calc} and~\autoref{scen:animalism} may be taken to motivate \issueInclusion{}, but I expect the analysis given is sensible given the adherence to \issueInclusion{}.

  Still, we have only considered two \scen{1} and \issueInclusion{} is a general constraint.
  Hence, if there is some doubt regarding \issueInclusion{} then further argument is required.
  It is not clear that there are \scen{1} in which \issueInclusion{} fails to hold.
  However, lack of apparent counterexamples is not argument.

  Though I would very much like to provide an argument for \issueInclusion{}, I am not aware of any.%
  \footnote{
    The particular construct of \qWhy{}, \qHow{}, and \issueInclusion{} is somewhat idiosyncratic, and so it is no surprise there are no direct argument for \issueInclusion{}.
    However, I take the idea captured by \issueInclusion{} to be intuitive, and I am not aware of any argument for this idea, regardless of the way in which it is expressed.
  }
  Perhaps \issueInclusion{} is sufficiently intuitive that it is taken for granted.
  Or, perhaps the failure of \issueInclusion{} is recognised and I have yet to stumble upon the acknowledgement of its failure.

  In any case, no argument will be provided.
  The goal of this document is to provide a recipe for generating counterexamples to \issueConstraint{}.
  By recipe, features of \scen{1} which lead to violations.

  Before closing this introduction, say a little more regarding the recipe for counterexamples.
  First, though no clear arguments for \issueInclusion{}, motivation by relation to reasons.
\end{note}

\section*{\issueInclusion{} and reasons}
\label{sec:reasons}

\begin{note}
  \qWhy{} and \qHow{} are questions about the way in which an event in which some agent \vAgent{} concludes some proposition \(\phi\) has some value \(v\) happened.

  Following \citeauthor{Hieronymi:2011aa}'s (\citeyear{Hieronymi:2011aa}) terminology, \qWhy{} seeks `explanatory reasons':
  % \footnote{
  %   Distinguish from normative.
  %   Normative: `reasons which show a given action, attitude, activity or outcome good, right, appropriate or called for'.
  % }

  \begin{quote}
    [T]he reasons why things happen, or why things are the way they are.%
    \mbox{ }\hfill\mbox{(\citeyear[410]{Hieronymi:2011aa})}
  \end{quote}

  In this sense, reasons are things we cite to explain other things.
  To borrow an an example given by \citeauthor{Hieronymi:2011aa}, the extreme heat or the faulty construction is a reason why the engine failed (\citeyear[409]{Hieronymi:2011aa}).
  Likewise, the engine failing is a reason why the steamboat is moored.

  In this respect, an explanatory reason is distinct from an \emph{agent's} reason, whatever this may be.
  This contrast forms the opening question of \citeauthor{Davidson:1963aa}'s \citetitle{Davidson:1963aa}:

  \begin{quote}
    What is the relation between a reason and an action when the reason explains the action by giving the agent's reason for doing what he did?
    We may call such explanations \emph{rationalizations}, and say that the reason \emph{rationalizes} the action.%
    \mbox{}\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}

  Observe, the initial reason \citeauthor{Davidson:1963aa} introduces is between a reason and an action, and the reason gives the agent's reason.

  At issue is why the agent did what they did, and the explanatory reason for this state of affairs involves the agent's reason.
  That is, the agent's reason coincides with the relevant explanatory reason.
  This coincidence allows \citeauthor{Davidson:1963aa} to unambiguously speak of the reason rationalising the action, as of interest is when an explanatory reasons and an agent's reason are one and the same.

  For \citeauthor{Davidson:1963aa} an agent's reason is, roughly; \textquote{some feature, consequence, or aspect of the action the agent wanted, desired, prized, held dear, thought dutiful, beneficial, obligatory, or agreeable} (\citeyear[685]{Davidson:1963aa}).

  In this respect, belief-desire pair, and action is something like buttering the toast.

  However, a conclusion is also the result of an act%
  \footnote{
    `The agent concluded \(\phi\) has value \(v\)' may be re-expressed as `the agent performed an act in which they concluded \(\phi\) has value \(v\)', in the same way as `the agent buttered the toast' may be re-expressed as `the agent performed an act in which the toast was buttered'.
  }
    and isolate the relevant belief component as the premises.

    For generality, some psychological fact about the agent.%
  \footnote{
    \citeauthor{Hieronymi:2011aa}, following~\citeauthor{Smith:1994wo} (\citeyear{Smith:1994wo}) speaks of `motivating reasons' (\citeyear[411--412]{Hieronymi:2011aa}).

    \citeauthor{Smith:1994wo}'s account is as follows:
    \begin{quote}
      The distinctive feature of a motivating reason to \(\phi\) is that, in virtue of having such a reason, an agent is in a state that is \emph{explanatory} of her \(\phi\)-ing, at least other things being equal --- other things must be equal because an agent may have a motivating reason to \(\phi\) without that reason's being overriding.%
      \mbox{}\hfill\mbox{(\citeyear{Smith:1994wo})}
    \end{quote}
  }
  Some wanting, psychological fact, regarding the display of the calculator as providing testimony, a psychological fact.
\end{note}

\begin{note}
  Now, psychological facts.
  Sufficient to get why.

  This, I take for granted.
  To get an understanding of event, interest in relation.
  Relation is for the agent, do not need to look outside the agent.%
  \footnote{
    Contrast to Dancy and Alverez?
    Nothing in particular hangs on this.
  }

  At issue is which psychological facts.

  Relation between proposition-value and \poP{} of premises.

  Key argument from \citeauthor{Davidson:1963aa} is:

  \begin{quote}
    \begin{enumerate}[label=\arabic*]
      [R]ationalization is a species of ordinary causal explanation.\newline
      \mbox{ }\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
    \end{enumerate}
  \end{quote}

  So, to get a relation, then seems either causation or relation is itself some psychological fact.

  With \autoref{illu:gist:calc}, causal.
  Testimony of the calculator is psychological fact.

  Same with~\autoref{scen:animalism}.

  \begin{itemize}
  \item
    The reason for which the agent concluded \(23 \cdot 15 = 345\) was the testimony of the calculator.
  \item
    The reason for which the birds concluded `Four legs good, two legs bad' was (the existence of) Snowball's explanation.
  \end{itemize}

  Relation between these reasons and conclusion is causation.
\end{note}

\begin{note}
  Analogue of \issueInclusion{}.

  For, motivating reasons are psychological facts.
  Psychological fact plausibly accounts for how.
\end{note}

\begin{note}
  \citeauthor{Broome:2013aa}'s account of active reasoning captures this:
  \begin{quote}
    I have arrived at necessary and sufficient conditions for a process to be active reasoning.

    Active reasoning is a particular sort of process by which conscious premise-attitudes cause you to acquire a conclusion-attitude.
    The process is that you operate on the contents of your premise-attitudes following a rule, to construct the conclusion, which is the content of a new attitude of yours that you acquire in the process.%
    \mbox{ }\hfill\mbox{(\citeyear[234]{Broome:2013aa})}
  \end{quote}
  Additional detail regarding causation.
  However, premise causes conclusion.

  Wait, necessary and sufficient.
  Do not need anything else to capture reasoning.
  So, concluding.
  Seems that no other relation between proposition-value pair and \poP{} of premises is required.

  Is there are argument?
  Grant that necessary.
  However, \citeauthor{Broome:2013aa} only considers and dismisses a number of possible sufficient conditions.
  Good motivation, but this does not rule out other sufficient conditions.
\end{note}

\begin{note}
  Not just causation.

  \begin{quote}
    [W]henever an agent acts for reasons, the agent, in some sense, takes certain considerations to settle the question of whether so to act, therein intends so to act, and executes that intention in action.

    If this much is uncontroversial (and, under some interpretation, I believe it must be), we can use it as a form for filling out.
    I propose, then, that we explain an event that is an action done for reasons by appealing to the fact that the agent took certain considerations to settle the question of whether to act in some way, therein intended so to act, and successfully executed that intention in action.
    I suggest that \emph{this} complex fact [\dots] explains the action by giving the agent's reason for acting.%
    \mbox{ }\hfill\mbox{(\citeyear[421]{Hieronymi:2011aa})}
  \end{quote}

  Considerations are sufficient.
  Don't need to look beyond these considerations.
\end{note}

\begin{note}
  Insight to capture by \issueInclusion{}.
  To get relation, then need to have a `witness' for the relation.
\end{note}

\newpage

% \begin{note}
%   To illustrate, consider \citeauthor{Broome:2013aa}'s (\citeyear{Broome:2013aa}) account of a `motivating reason'%
%   \footnote{
%     \citeauthor{Broome:2013aa} contrasts `motivating reasons' to `normative reasons'.
%     \begin{quote}
%       Whereas motivating reasons explain or help to explain why a person does something, normative reasons explain or help to explain why a person ought to do something, or to believe something, or to hope for something, or to like something, or in general to F, where ‘F' stands for a verb phrase.%
%     \mbox{}\hfill\mbox{(\citeyear[47]{Broome:2013aa})}
%     \end{quote}
%   }
%   \begin{quote}
%     Sometimes the explanation of why a person does something has a particular character:
%     roughly, it involves the person's rationality in a distinctive way that I shall not try to describe.
%     Then we say the person does what she does for a reason.
%     We might say ‘The reason for which Hannibal used elephants was to terrorize the Romans'.
%     The reason for which a person does something is called a ‘motivating reason'.
%     In general, a motivating reason is whatever explains or helps to explain what a person does in the distinctive way that involves her rationality.
%     \mbox{}\hfill\mbox{(\citeyear[46--47]{Broome:2013aa})}
%   \end{quote}
% \end{note}

% \begin{note}
%   \color{red}

%   Further,

%   For \citeauthor{Davidson:1963aa}, primary reason.

%   \begin{quote}
%     \emph{R} is a primary reason why an agent performed the action \emph{A} under the description \emph{d} only if \emph{R} consists of a pro attitude of the agent toward actions with a certain property, and a belief of the agent that \emph{A}, under the description \emph{d}, has that property.\newline
%     \mbox{ }\hfill\mbox{(\citeyear[687]{Davidson:1963aa})}
%   \end{quote}

%   We have distinguished \qWhy{} from pro-attitudes.
%   However, fill in whatever motivation.
%   What matters is the belief.
%   This is the relevant proposition-value pair.

%   If \citeauthor{Davidson:1963aa}, then granting restriction, seems we don't need to look beyond the proposition-value pair.
% \end{note}

% \begin{note}
%   So, answer to \qWhy{} is constrained by answer to \qHow{} by getting to a reason.

%   For, causal relation.
%   Indeed, from `explanatory', these things are identical.
%   However, from `motivating' still distinction.
%   Agent's reason is causal, but the content is not necessarily causal.%
%   \footnote{
%     On my understanding of \citeauthor{Davidson:1963aa}, there's a tight link between then content of some state and the causal relations that arise from the state.

%     So, go from content to state, and then proceed from here.

%     This, I think, is correct.
%     And, the problem of deviant causal chains highlights this.
%     For, \citeauthor{Davidson:1963aa} recognises there's a problem with the link between content and the causal relations which hold between the states.

%     \begin{quote}
%       Beliefs and desires that would rationalize an action if they caused it in the right way—through a course of practical reasoning, as we might try saying---may cause it in other ways.%
%       \mbox{ }\hfill\mbox{(\citeyear[79]{Davidson:1973vd})}
%     \end{quote}
%   }

%   Here, we get a causal trace.
%   No need to look for any relation of support other than premises of reasoning.
% \end{note}

\begin{note}
  Shifting to reasons seems to motivate the basic idea.

  Explicit through causation.
  Though I do not think the basic idea (directly, at least) motivates causal theories of action (or, specifically, concluding).
  In other words, for our purposes, answers to `how?' need not be causal explanations, though they may be.

  Nor do I think reasons.

  More broadly, I take the basic idea to capture a pre-theoretical constraint on classes of theories.
  There are theories that agree with the basic idea, such as \citeauthor{Davidson:1963aa}' causal theory of action (when the action is concluding) and there \emph{may be} theories which do not agree with the basic idea --- though I do not know of any specific theories that are explicitly of this kind.
\end{note}

\section*{Questioning \issueInclusion{}}

\begin{note}
  The basic idea is more-or-less the basic issue of this document.

  Both intuitions, such as those regarding \autoref{illu:gist:calc}, and theories, such as \citeauthor{Davidson:1963aa} causal theory of action, provide motivation for the basic issue.

  Our goal is to motivate the following, basic, contrary idea:

  \begin{itemize}
  \item
    There are cases in which something is, in part, an answer to `why?' and that something is \emph{not} (also), in part, an answer to `how?'.
  \end{itemize}

  The basic contrary idea is the negation of the basic idea.
  For, the basic idea states, roughly, answers to `why?' are always included in answers to `how?' while the basic contrary idea states that there are cases in which something that answers `why?' does not also answer `how?'.

  The basic contrary idea, then, has the form of an existential.
  We will not motivate the idea that there is always something which answers `why?' but does not also answer `how?'.
  And, in particular, it may be the case that the intuitions observed with respect to \autoref{illu:gist:calc} are correct.
\end{note}

\begin{note}
  With reasons, though, this is even more complex.
  As, it's the very idea of having a reason.
\end{note}

\begin{note}
  Key comes down to answering why exceeding what happens.

  Importance of \fc{}.

  Not only that the agent concluded, but that the agent the event may have developed otherwise, such that the agent concluded some other proposition-value pair.
\end{note}

\begin{note}
  No quick examples.

  Rather, recipe to construct \scen{1}.
\end{note}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:




% \begin{note}
%   Now, all this has been said without giving attention to the conditional observed by the agent in \autoref{illu:gist:calc}:

%   \begin{itemize}
%   \item
%     If the calculator is trustworthy, then the agent would not fail to conclude \(23 \cdot 15 = 345\) via their understanding of arithmetic.
%   \end{itemize}

%   Both natural, and somewhat surprising.

%   Consider the contraposition.

%   \begin{itemize}
%   \item
%     If the agent were to fail to conclude \(23 \cdot 15 = 345\) via their understanding of arithmetic, then the calculator is not trustworthy.
%   \end{itemize}

%   \begin{itemize}
%   \item
%     Is it possible for the agent to fail to conclude \(23 \cdot 15 = 345\) via their understanding of arithmetic?
%   \end{itemize}

%   If possible, then difficulty.
%   For, testimony, so must be, but at the same time, possible that it is not.
%   If not possible, then it doesn't seem that observing \(23 \cdot 15 = 345\) via the testimony of the calculator is sufficient.
%   For, by the previous observation, difficulty with the testimony of the calculator.

%   \begin{itemize}
%   \item
%     Testimony of the calculator \emph{only if} \(23 \cdot 15 = 345\) is a \fc{0} given the agent's understanding of arithmetic.
%   \end{itemize}
% \end{note}

% \begin{note}
%   Important:

%   Multiple ways to conclude.
%   So, have a check.

%   Differs to, for example, concluding {\color{red} ???} from a scientific calculator.
%   {\color{red} ???} goes beyond typical understanding of arithmetic.
%   Parallel pair of conditionals does not hold.

%   Or, alternatively, testimony that {\color{red} ???}.
%   Beyond understanding.
% \end{note}

% \begin{note}
%   I am not sure what to make of \ref{illu:gist:calc}.
%   Understanding of arithmetic is a partial check.
%   However, testimony.

%   Unsure because status of a premise.

%   Basic contrary idea only requires some instances.

%   Argument against this intuition.
%   Type of cases, premises are fixed.
%   Check on own reasoning.

%   First, expand on intuition.
%   Then, introduce type of \scen{0} of interest.
% \end{note}

% \begin{note}
%   Follow part, foundations.
%   Following, turn to details.

% {\color{red} Place somewhere?}.%
%   \footnote{
%     Roughly, if it were the agent failed to conclude \(23 \cdot 15 = 345\) in \autoref{illu:gist:calc}, then there would be conflict between the agent's understanding of arithmetic and the testimony of the calculator.
%     Expressed differently, there would be conflict between the agent's failure to conclude \(23 \cdot 15 = 345\) by their understanding of arithmetic, and a premises involved in concluding \(23 \cdot 15 = 345\) via the calculator.
%     I.e. supposing the agent concludes \(23 \cdot 15 \ne 345\), then for the agent the calculator is not a source of testimony.
%     In the \scen{1} of interest, this hypothetical --- or in some cases possible --- conflict will strictly be between the agent's reasoning from pools of premises to conclusions.
%   }
% \end{note}
