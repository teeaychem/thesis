\chapter{Introduction}
\label{cha:introduction}

\begin{note}
  \begin{scenario}[Multiplication]
    \label{illu:gist:calc}
    An agent enters `\(23 \cdot 15\)' into a calculator and presses a button marked `\(=\)'.
    The calculator displays `\(345\)'.

    The agent pauses for a moment.
    They have a good understanding of arithmetic.
    And, given the display on the calculator, it follows that if the calculator is trustworthy, then they would not fail to conclude \(23 \cdot 15 = 345\) via their understanding of arithmetic.

    The agent concludes \(23 \cdot 15 = 345\).
  \end{scenario}

  The agent concluded \(23 \cdot 15 = 345\) by their use of the calculator.
  Personifying a little, we may say the agent has concluded \(23 \cdot 15 = 345\) from the testimony of the calculator.

  Further, the agent did not, in part, conclude \(23 \cdot 15 = 345\) by their understanding of arithmetic.
  So long as the calculator was correct, the agent had the opportunity to conclude \(23 \cdot 15 = 345\).
  Still, the agent did not perform any arithmetic.
\end{note}

\begin{note}
  \autoref{illu:gist:calc} is simple, and I expect the commentary is intuitive.
  Let's consider a second \scen{0}.
\end{note}

\begin{note}
  \begin{scenario}[Animalism]
    \label{scen:animalism}
    `Four legs good, two legs bad.'
    This, he said, contained the essential principle of Animalism.
    Whoever had thoroughly grasped it would be safe from human influences.
    The birds at first objected, since it seemed to them that they also had two legs, but Snowball proved to them that this was not so.

    `A bird's wing, comrades,' he said, `\textsc{is} an organ of propulsion and not of manipulation.
    It should therefore be regarded as a leg.
    The distinguishing mark of Man is the \emph{hand}, the instrument with which he does all his mischief.'

    The birds did not understand Snowball's long words, but they accepted his explanation, and all the humbler animals set to work to learn the new maxim by heart.
    \textsc{four legs good, two legs bad}, was inscribed on the end wall of the barn\dots%
    \mbox{ }\hfill\mbox{(\cite[25]{Orwell:1976aa})}%
    \newline
  \end{scenario}

  The agents of interest are the birds, and the conclusion is the essential principle of Animalism:
  `Four legs good, two legs bad'.

  Snowball provided an argument against an objection from the birds, and the birds concluded `Four legs good, two legs bad' from Snowball's explanation.

  Though, as \citeauthor{Orwell:1976aa} highlights, the birds did not conclude `Four legs good, two legs bad' from \emph{the content of} Snowball's explanation.
  Some words were too long.
  Instead, the birds concluded `Four legs good, two legs bad', at least in part, from \emph{Snowball's explanation}.
\end{note}

\begin{note}
  In parallel to the agent's understanding of arithmetic from~\autoref{illu:gist:calc} the birds of~\autoref{scen:animalism} did not, in part, conclude `Four legs good, two legs bad' from the content of Snowball's explanation.

  Our interest is understanding the way in which an event happened.
  Specifically, an event in which some agent \vAgent{} concludes some proposition \(\phi\) has some value \(v\).
  For simplicity we assume an agent always conclude some proposition \(\phi\) has value \(v\) from some \poP{} of premises \(\Phi\).

  With respect to~\autoref{illu:gist:calc}, the agent is unnamed, the proposition is `\(23 \cdot 15 = 345\)', and the value is `\(\text{True}\)'.
  And, with respect to~\autoref{scen:animalism} the agents are the birds, the proposition is `Four legs good, two legs bad', and the value is `\(\text{True}\)'.
  In both \scen{1}, the \poP{} of premises is not specified.

  And, in each \scen{0} it seems, respectively, the testimony of the calculator and Snowball's explanation are sufficient to understand the way in which the agent concluded the relevant proposition has the specified value.
  We do not, it seems, need to consider the agent calculating \(23 \cdot 15\) by their understanding of arithmetic, nor the birds understanding Snowball's explanation.
\end{note}

\section{\qWhy{} and \qHow{}}

\begin{note}[Not just concluding]
  \phantlabel{how-and-why-first-mention}
  Our interest is understanding the way in which an event in which some agent \vAgent{} concludes some proposition \(\phi\) has some value \(v\) happened.

  We distinguish two questions:

  \begin{restatable}[\qWhy{}]{question}{questionWhyBasic}
    \label{q:why}
    \cenLine{
      \begin{itemize*}[noitemsep, label=\(\circ\)]
      \item
        Agent: \vAgent{}
      \item
        Proposition: \(\phi\)
      \item
        Value: \(v\)
      \item
        Event: \(e\)
      \item
        \mbox{ }
      \end{itemize*}
    }
    \begin{itemize}
    \item
      Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
      \begin{itemize}
      \item
        Which proposition-value-premise pairs explain \emph{why} \(e\) is such that \vAgent{} concluded \(\phi\) has value \(v\)?
      \end{itemize}
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}

  \begin{restatable}[\qHow{}]{question}{questionHowBasic}
    \label{q:how}
    \cenLine{
      \begin{itemize*}[noitemsep, label=\(\circ\)]
      \item
        Agent: \vAgent{}
      \item
        Proposition: \(\phi\)
      \item
        Value: \(v\)
      \item
        Event: \(e\)
      \item
        \mbox{ }
      \end{itemize*}
    }
    \begin{itemize}
    \item
      Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
      \begin{itemize}
      \item
        Which events explain \emph{how} \(e\) is such that \vAgent{} concluded \(\phi\) has value \(v\)?
      \end{itemize}
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}
\end{note}

\begin{note}
  \qWhy{} and \qHow{} are broad questions.

  Depend on sense with which `why' and `how' are interpreted.
\end{note}

\begin{note}
  Consider the general form of \autoref{q:why:v} with respect to making a cup of tea.

  \begin{scenario}[A cup of tea]
    \label{scen:cup-of-tea}
    A moment ago I:
    \begin{itemize}[noitemsep]
    \item
      Boiled some water.
    \item
      Placed a tea bag into a cup.
    \item
      Poured the water into the cup.
    \item
      Let the tea bag rest in the water for a while.
    \item
      Removed the tea bag.
    \end{itemize}
    I made myself a cup of tea.
  \end{scenario}

  \autoref{scen:cup-of-tea} captures an event in which I made a cup of tea.

  There is a straightforward sense with which the description given to the event captures \emph{how} I made a cup of tea.
  Further, there is also a sense with which the description also captures \emph{why} I made a cup of tea.

  For example, suppose I forgot to place a tea bag in the cup.
  The remainder of the description still captures some event, but the end result is a cup of warm water, rather than a cup of tea.

  There is also a sense with which the description fails to capture why I made a cup of tea.
  Placing a tea bag in a cup does not usually motivate making a cup of tea.%
  \footnote{
    Though we may imagine someone whose only pleasure is finding excuses to place tea bag into cups.
    (\cite[Cf.][379--380]{Rawls:1999aa})
  }

  Why the event resulted in a cup of tea versus why I wanted the event to result in a cup of tea.

  The former parallels our interest with conclusions.
  Not interested with why an agent wanted to reach a conclusion, but why an agent concluded \(\phi\) has value \(v\) as opposed to any other proposition-value pair, and why the agent concluded \(\phi\) has value \(v\) from \(\Phi\) as opposed to some other pool of premises.
\end{note}

\begin{note}
  Sense in which testimony of calculator answers why.
  For, agent needed to get the equality from somewhere.
  Did not do arithmetic.

  Likewise, sense in which the explanation answers why.
  For, adopted principle.
  Did not comprehend the content.

  Sense in which neither account answers why.
  For, does not capture motivation.

  Why the agent was motivated to find the answer to \(23 \cdot 15\), and why motivated to use a calculator.

  Why the animals of the farm were motivated to accept Snowball's explanation.

  So, why particular event developed in the way it did.
\end{note}

\subsection{Reasons}
\label{sec:reasons}

\begin{note}
  \qWhy{}.
  Understand in terms of reasons.
\end{note}

\begin{note}
  In \citeauthor{Hieronymi:2011aa}'s terminology, \qWhy{} seeks `explanatory reasons'.
  \footnote{
    Distinguish from normative.
    Normative: `reasons which show a given action, attitude, activity or outcome good, right, appropriate or called for'.
  }

  \begin{quote}
    the reasons why things happen, or why things are the way they are

    \citeyear[410]{Hieronymi:2011aa}
  \end{quote}

  Further, interested in agent.

  Motivating: `psychological facts which explain action'
  (\citeyear[411--412]{Hieronymi:2011aa})

  Motivating reason.

  Following \citeauthor{Broome:2013aa} `motivating reason':%
  \footnote{
     \citeauthor{Hieronymi:2011aa}'s account of motivating reasons follows~\citeauthor{Smith:1994wo}:

    \begin{quote}
      The distinctive feature of a motivating reason to \(\phi\) is that, in virtue of having such a reason, an agent is in a state that is \emph{explanatory} of her \(\phi\)-ing, at least other things being equal --- other things must be equal because an agent may have a motivating reason to \(\phi\) without that reason's being overriding.%
      \mbox{}\hfill\mbox{(\citeyear{Smith:1994wo})}
    \end{quote}
  }%
  \(^{,}\)%
  \footnote{
    \begin{quote}
      Whereas motivating reasons explain or help to explain why a person does something, normative reasons explain or help to explain why a person ought to do something, or to believe something, or to hope for something, or to like something, or in general to F, where â€˜F' stands for a verb phrase.%
    \mbox{}\hfill\mbox{(\citeyear[47]{Broome:2013aa})}
    \end{quote}
  }
  \begin{quote}
    Sometimes the explanation of why a person does something has a particular character:
    roughly, it involves the person's rationality in a distinctive way that I shall not try to describe.
    Then we say the person does what she does for a reason.
    We might say â€˜The reason for which Hannibal used elephants was to terrorize the Romans'.
    The reason for which a person does something is called a â€˜motivating reason'.
    In general, a motivating reason is whatever explains or helps to explain what a person does in the distinctive way that involves her rationality.
    \mbox{}\hfill\mbox{(\citeyear[46--47]{Broome:2013aa})}
  \end{quote}
\end{note}

\begin{note}
  However, continue with \qWhy{}.

  Link to reasons is helpful.
  However, not interested in any specific account of reasons.
  And, framing in terms of questions for dialectical purposes.
\end{note}

\section{Relationship between \qWhy{} and \qHow{}}

\begin{note}
  Previous section, two questions.
  \qWhy{} and \qHow{}.
  Relationship between these two questions.
\end{note}

\begin{note}
  \begin{quote}
    \begin{screenplay}
    \item[OLD WOMAN:]
      Well, how did you become King, then?
    \item[ARTHUR:]
      The Lady of the Lake, her arm clad in purest shimmering samite, held Excalibur aloft from the bosom of the waters to signify that by Divine Providence\dots I, Arthur, was to carry Excalibur\dots that is why I am your King.
    \item[DENNIS:]
      Look, strange women lying on their backs in ponds handing over swords\dots that's no basis for a system of government.
      Supreme executive power derives from a mandate from the masses not from some farcical aquatic ceremony.\newline
      \mbox{ }\hfill\mbox{(\cite[8--9]{Cleese:1974aa})}
    \end{screenplay}
  \end{quote}

  The Old Woman asks how, and is answered by why.
  Why is accepted as how, but rejected as why.
\end{note}

\begin{note}
  So, the intuitions expressed with respect to \autoref{illu:gist:calc} may answer `how?' but not `why?', or `why?' but not `how?'.

  Still, I suspect this is not the case.
  In the case of \autoref{illu:gist:calc} both have the same rough answer:

  \begin{itemize}
  \item
    The pairing of testimony of the calculator with \(23 \cdot 15 = 345\), is, in part, \emph{both} how \emph{and} why the agent concluded \(23 \cdot 15 = 345\).
  \end{itemize}
  That premises associated with the agent's understanding of arithmetic do not answer either `how?' or `why?' is implicit by omission.

  Again, the agent used the testimony of the calculator to conclude \(23 \cdot 15 = 345\), and the agent appealed to the testimony of the calculator to conclude \(23 \cdot 15 = 345\).
  The agent did not use their understanding of arithmetic to conclude \(23 \cdot 15 = 345\), and the agent did not appeal to their understanding of arithmetic to conclude \(23 \cdot 15 = 345\).
\end{note}


\begin{note}
  Our observation that the testimony of the calculator seems to answer both `why?' and `how?' the agent concluded \(23 \cdot 15 = 345\) suggests, even if --- as a single \scen{0} --- only slightly, the following basic idea:%
  \footnote{
    The observation also suggests the converse holds --- an answer, in part, to `how?' is also, in part, an answer to `why?' --- though I think the converse faces some immediate difficulties.
    For, it seems answers to `how?' may include details that are irrelevant to `why?'.
    For example, typing digits and operators into the calculator answers, in part, how the agent concluded \(23 \cdot 15 = 345\) but these actions seems irrelevant to why the agent concluded \(23 \cdot 15 = 345\).
    Rather, an answer to `why?' seems to be limited to the calculator providing testimony that \(23 \cdot 15 = 345\), regardless of whether it was the agent who used the calculator, or whether the agent observed someone else using the calculator.
  }

  \phantlabel{how-and-why-relation-first-mention}
  \begin{restatable}[\issueInclusion{}]{constraint}{issueInclusionFirst}
    \label{issue:why-inc-in-how}
    \mbox{ }
    \vspace{-\baselineskip}
    \begin{itemize}
    \item
      Some proposition-value-premises pair is, in part, an answer to \qWhy{}.
    \end{itemize}
    \emph{Only if:}
    \begin{itemize}
    \item
      There is an event that answers, in part, \qHow{} in which the agent concludes the proposition has the value from the pool of premises.
    \end{itemize}
    \vspace{-\baselineskip}
  \end{restatable}

  In other words, in order for premise to, in part, answer \qWhy{} an agent concluded \(\phi\) has value \(v\), that premise must also, in part, answer \qHow{} the agent concluded \(\phi\) has value \(v\).

  With respect to \autoref{illu:gist:calc}, the testimony of the calculator satisfies the constraint imposed by the idea, while the agent's understanding of arithmetic does not.
  Specifically, the testimony of the calculator was part of how the agent concluded \(23 \cdot 15 = 345\), and so the testimony of the calculator may be, in part, an answer to why the agent concluded \(23 \cdot 15 = 345\).
  However, the agent's understanding of arithmetic was \emph{not} part of how the agent concluded \(23 \cdot 15 = 345\), and so the agent's understanding of arithmetic \emph{may not}, in part, an answer to why the agent concluded \(23 \cdot 15 = 345\).

  In addition, the basic idea may be taken to capture some explanatory significance and we may even say:
  The agent's understanding of arithmetic is not, in part, an answer to why the agent concluded \(23 \cdot 15 = 345\) \emph{because} the agent's understanding of arithmetic was \emph{not} part of how the agent concluded \(23 \cdot 15 = 345\).
\end{note}

\subsection{Motivation from \citeauthor{Davidson:1963aa}}

\begin{note}
  I think the basic idea is sufficiently intuitive independently of individual \scen{1}.
  Instead, observe the basic idea may be motivated not only by \scen{1}, but also by theories.
  Consider \citeauthor{Davidson:1963aa}' causal theory of action.

  \citeauthor{Davidson:1963aa} opens \citetitle{Davidson:1963aa} with the following question:

  \begin{quote}
    What is the relation between a reason and an action when the reason explains the action by giving the agent's reason for doing what he did?
    We may call such explanations \emph{rationalizations}, and say that the reason \emph{rationalizes} the action.%
    \mbox{}\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}

  \citeauthor{Davidson:1963aa} distinguishes between a reason and the agent's reason.
  And, the question \citeauthor{Davidson:1963aa} asks concerns reasons, rather than the agent's reasons.

  As seen, answers to \qWhy{} then get a reason.%
  \footnote{
    Strictly, the variant.
  }

  \citeauthor{Davidson:1963aa} argues, in short, for the following answer to the relation between a reason and the rationalisation of an action:

  \begin{quote}
    \begin{enumerate}[label=\arabic*]
      [R]ationalization is a species of ordinary causal explanation.\newline
      \mbox{ }\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
    \end{enumerate}
  \end{quote}

  So, answer to \qWhy{} is constrained by answer to \qHow{}.
  For, causal relation.
  Indeed, from `explanatory', these things are identical.
  However, from `motivating' still distinction.
  Agent's reason is causal, but the content is not necessarily causal.%
  \footnote{
    Distinction is clear with deviant causal chains.
  }
  %
  \footnote{
    This is delicate.
  On my understanding of \citeauthor{Davidson:1963aa}, there's a tight link between then content of some state and the causal relations that arise from the state.

  So, go from content to state, and then proceed from here.

  This, I think, is correct.
  And, the problem of deviant causal chains highlights this.
  For, \citeauthor{Davidson:1963aa} recognises there's a problem with the link between content and the causal relations which hold between the states.

  \begin{quote}
    Beliefs and desires that would rationalize an action if they caused it in the right wayâ€”through a course of practical reasoning, as we might try saying---may cause it in other ways.%
    \mbox{ }\hfill\mbox{(\citeyear[79]{Davidson:1973vd})}
  \end{quote}
  }

  Here, we get a causal trace.
  No need to look for any relation of support other than premises of reasoning.

  Note, further, that \citeauthor{Davidson:1963aa}'s proposal is identity.
  This goes both ways.
  Reasons are causal relations, but it's only particular causal relations which matter.

  From our perspective, this is restricting these answers, but from \citeauthor{Davidson:1963aa}'s, plausible that constraint is already taken from granted.

  Still, the order doesn't matter.
  \citeauthor{Davidson:1963aa}'s theory is neat.
  And, as adopted, works in either direction.
\end{note}

\begin{note}
  Working through the details is a little more complex.
\end{note}

\begin{note}
  For \citeauthor{Davidson:1963aa}, primary reason.

  \begin{quote}
    \emph{R} is a primary reason why an agent performed the action \emph{A} under the description \emph{d} only if \emph{R} consists of a pro attitude of the agent toward actions with a certain property, and a belief of the agent that \emph{A}, under the description \emph{d}, has that property.\newline
    \mbox{ }\hfill\mbox{(\citeyear[687]{Davidson:1963aa})}
  \end{quote}

  We have distinguished \qWhy{} from pro-attitudes.
  However, fill in whatever motivation.
\end{note}

\begin{note}
  Causal theories of action seem to motivate the basic idea, though I do not think the basic idea (directly, at least) motivates causal theories of action (or, specifically, concluding).
  In other words, for our purposes, answers to `how?' need not be causal explanations, though they may be.

  More broadly, I take the basic idea to capture a pre-theoretical constraint on classes of theories.
  There are theories that agree with the basic idea, such as \citeauthor{Davidson:1963aa}' causal theory of action (when the action is concluding) and there \emph{may be} theories which do not agree with the basic idea --- though I do not know of any specific theories that are explicitly of this kind.
\end{note}

\section{Questioning the intuitive relationship}

\begin{note}
  The basic idea is more-or-less the basic issue of this document.

  Both intuitions, such as those regarding \autoref{illu:gist:calc}, and theories, such as \citeauthor{Davidson:1963aa} causal theory of action, provide motivation for the basic issue.

  Our goal is to motivate the following, basic, contrary idea:

  \begin{itemize}
  \item
    There are cases in which something is, in part, an answer to `why?' and that something is \emph{not} (also), in part, an answer to `how?'.
  \end{itemize}

  The basic contrary idea is the negation of the basic idea.
  For, the basic idea states, roughly, answers to `why?' are always included in answers to `how?' while the basic contrary idea states that there are cases in which something that answers `why?' does not also answer `how?'.

  The basic contrary idea, then, has the form of an existential.
  We will not motivate the idea that there is always something which answers `why?' but does not also answer `how?'.
  And, in particular, it may be the case that the intuitions observed with respect to \autoref{illu:gist:calc} are correct.
\end{note}

\begin{note}
  Key comes down to answering why exceeding what happens.

  Importance of \fc{}.

  Not only that the agent concluded, but that the agent the event may have developed otherwise, such that the agent concluded some other proposition-value pair.
\end{note}

\begin{note}
  No quick examples.

  Rather, recipe to construct \scen{1}.
\end{note}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:




% \begin{note}
%   Now, all this has been said without giving attention to the conditional observed by the agent in \autoref{illu:gist:calc}:

%   \begin{itemize}
%   \item
%     If the calculator is trustworthy, then the agent would not fail to conclude \(23 \cdot 15 = 345\) via their understanding of arithmetic.
%   \end{itemize}

%   Both natural, and somewhat surprising.

%   Consider the contraposition.

%   \begin{itemize}
%   \item
%     If the agent were to fail to conclude \(23 \cdot 15 = 345\) via their understanding of arithmetic, then the calculator is not trustworthy.
%   \end{itemize}

%   \begin{itemize}
%   \item
%     Is it possible for the agent to fail to conclude \(23 \cdot 15 = 345\) via their understanding of arithmetic?
%   \end{itemize}

%   If possible, then difficulty.
%   For, testimony, so must be, but at the same time, possible that it is not.
%   If not possible, then it doesn't seem that observing \(23 \cdot 15 = 345\) via the testimony of the calculator is sufficient.
%   For, by the previous observation, difficulty with the testimony of the calculator.

%   \begin{itemize}
%   \item
%     Testimony of the calculator \emph{only if} \(23 \cdot 15 = 345\) is a \fc{0} given the agent's understanding of arithmetic.
%   \end{itemize}
% \end{note}

% \begin{note}
%   Important:

%   Multiple ways to conclude.
%   So, have a check.

%   Differs to, for example, concluding {\color{red} ???} from a scientific calculator.
%   {\color{red} ???} goes beyond typical understanding of arithmetic.
%   Parallel pair of conditionals does not hold.

%   Or, alternatively, testimony that {\color{red} ???}.
%   Beyond understanding.
% \end{note}

% \begin{note}
%   I am not sure what to make of \ref{illu:gist:calc}.
%   Understanding of arithmetic is a partial check.
%   However, testimony.

%   Unsure because status of a premise.

%   Basic contrary idea only requires some instances.

%   Argument against this intuition.
%   Type of cases, premises are fixed.
%   Check on own reasoning.

%   First, expand on intuition.
%   Then, introduce type of \scen{0} of interest.
% \end{note}

% \begin{note}
%   Follow part, foundations.
%   Following, turn to details.

% {\color{red} Place somewhere?}.%
%   \footnote{
%     Roughly, if it were the agent failed to conclude \(23 \cdot 15 = 345\) in \autoref{illu:gist:calc}, then there would be conflict between the agent's understanding of arithmetic and the testimony of the calculator.
%     Expressed differently, there would be conflict between the agent's failure to conclude \(23 \cdot 15 = 345\) by their understanding of arithmetic, and a premises involved in concluding \(23 \cdot 15 = 345\) via the calculator.
%     I.e. supposing the agent concludes \(23 \cdot 15 \ne 345\), then for the agent the calculator is not a source of testimony.
%     In the \scen{1} of interest, this hypothetical --- or in some cases possible --- conflict will strictly be between the agent's reasoning from pools of premises to conclusions.
%   }
% \end{note}
