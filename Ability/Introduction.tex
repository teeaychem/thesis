\chapter{\qWhy{} and \qHow{}}
\label{cha:intro}

\begin{note}
  Our interest is understanding the way an event in which an agent concludes happens.

  \begin{scenario}[Multiplication]%
    \label{illu:gist:calc}%
    An agent enters `\gistCalcLHS{}' into a calculator and presses a button marked `\(=\)'.
    The calculator displays `\gistCalcRHS{}'.

    The agent pauses for a moment.
    They have a good understanding of arithmetic.
    And, given the display on the calculator, it follows that if the calculator is trustworthy, then they would not fail to conclude \propM{\gistCalcEq{}} via their understanding of arithmetic.

    The agent concludes \propM{\gistCalcEq{}}.
  \end{scenario}

  \noindent%
  Intuitively, the agent concludes \propM{\gistCalcEq{}} from the calculator.
  More could be said about the way the agent concludes but these details won't be of too much interest.%
  \footnote{
    For example, classify the agent as regarding the calculator as a source of testimony, adding that testimony are factive, and so concluded \propM{\gistCalcEq{}} from the testimony of the calculator.
  }

  The agent's understanding of arithmetic, it seems, had no significant role.
  So long as the calculator was correct, the agent had the opportunity to conclude \propM{\gistCalcEq{}} by their understanding of arithmetic, but the agent did not perform any arithmetic.
\end{note}

\begin{note}
  Abstracting a little, \propM{\gistCalcEq{}} corresponds to a state of affairs.
  If the truths of mathematics are necessary, then this state of affairs never fails to be, but \propM{\gistCalcEq{}} captures the way things are in the same way as \propI{Kangaroos have tails} captures the way things are.
  For ease we refer to states of affairs as propositions.

  Continuing the abstraction, when the agent concludes \propM{\gistCalcEq{}}, we may say the agent concludes \propM{\gistCalcEq{}} has value \valI{True}.
  Even if \propM{\gistCalcEq{}} never fails to be, the calculator may have been faulty and the agent may have concluded \propM{\gistCalcEqBad{}} has value \valI{True} or \propM{\gistCalcEq{}} has value \valI{False}.

  Likewise, as the agent concluded \propM{\gistCalcEq{}} has value \valI{True} from the calculator, we may say the agent concluded \propM{\gistCalcEq{}} has value \valI{True} from some \pool{} of premises.%
  % \footnote{
  %   Strictly, of interest is that the relevant conclusions follow from the agent evaluating the relevant state of affairs as \valI{True}.
  %   That is, with respect to~\autoref{illu:gist:calc}, of interest is that the agent concludes \propM{\gistCalcEq{}} has value \valI{True} \emph{from} the agent evaluating \propI{The calculator testified \propM{\gistCalcEq{}}} has \valI{True}.
  %   % And, with respect to~\autoref{illu:gist:calc} it is likewise the birds `perceiving' an explanation from Snowball exists.
  %   % However, we adopt the shorthand for ease of expression.
  % }
\end{note}

\begin{note}
  Abstracting from almost all the details of \autoref{illu:gist:calc} then, we say an agent concluded some \prop{} has some \val{} from some \pool{} of premises.

  For ease, we abbreviate `\pool{} of premises' to `\pool{}'.

  So, our interest is understanding the way an event in which some agent concludes some proposition \(\phi\) has some value \(v\) from some \pool{} \(\Phi\) happens.

  In this respect, our interest is with the intuition that the agent concluded \propM{\gistCalcEq{}} has value \valI{True} \emph{from} the calculator.
  This `\emph{from}' does work.
  Our understanding of \autoref{illu:gist:calc} would be different if the agent concluded \propM{\gistCalcEq{}} has value \valI{True} from the their understanding of arithmetic, or if the agent concluded \propM{\gistCalcEq{}} has value \valI{True} from their conviction that the calculator guessed correctly.

  What this relation amounts to is something we will not discuss.
  The core intuition is that the relation of interest captures something beyond the observation that there was a sequence of events in which the agent used the calculator and then concluded \propM{\gistCalcEq{}} has value \valI{True}.
  The conclusion was `from', `due to', `because of' \dots etc., the relevant \pool{}.
\end{note}

\begin{note}
  Here's a second, slightly more complex \scen{0}:

  \begin{scenario}[Animalism]%
    \label{scen:animalism}%
    `Four legs good, two legs bad.'
    This, he said, contained the essential principle of Animalism.
    Whoever had thoroughly grasped it would be safe from human influences.
    The birds at first objected, since it seemed to them that they also had two legs, but Snowball proved to them that this was not so.

    `A bird's wing, comrades,' he said, `\textsc{is} an organ of propulsion and not of manipulation.
    It should therefore be regarded as a leg.
    The distinguishing mark of Man is the \emph{hand}, the instrument with which he does all his mischief.'

    The birds did not understand Snowball's long words, but they accepted his explanation, and all the humbler animals set to work to learn the new maxim by heart.
    \textsc{four legs good, two legs bad}, was inscribed on the end wall of the barn\dots%
    \mbox{ }\hfill\mbox{(\cite[25]{Orwell:1976aa})}%
    \newline
  \end{scenario}

  \noindent%
  The agents of interest are the birds, and the conclusion is the essential principle of Animalism:
  \propI{Four legs good, two legs bad} has value \valI{True}.

  Snowball provided an argument against an objection from the birds, and the birds concluded \propI{Four legs good, two legs bad} is \valI{True} from Snowball's explanation.

  Though, as \citeauthor{Orwell:1976aa} highlights, the birds did not conclude \propI{Four legs good, two legs bad} from \emph{the content of} Snowball's explanation.
  (Some words were too long.)
  Instead, the birds concluded, at least in part, from (the existence of) \emph{Snowball's explanation}.

  % In parallel to the agent's understanding of arithmetic from~\autoref{illu:gist:calc} the birds of~\autoref{scen:animalism} did not, in part, conclude \propI{Four legs good, two legs bad} from the content of Snowball's explanation.
\end{note}

\begin{note}
  In line with the abstraction given, we may say:
  The birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the existence of Snowball's explanation.
  And, for each bird, a relation holds between \propI{Four legs good, two legs bad}, \valI{True}, and the existence of Snowball's explanation.
\end{note}

\section*{\qWhy{}, \qHow{} and \issueInclusion{}}
\label{cha:intro:why-how}

\begin{note}
  % Our interest is understanding the way an event in which some agent concludes some proposition \(\phi\) has some value \(v\) from some \pool{} \(\Phi\) happens.
  \phantlabel{how-and-why-first-mention}%
  We distinguish two questions; `\qWhy{}' and `\qHow{}':%
  \footnote{
    \qWhy{} and \qHow{} are questions about the event.
    Natural variation on the questions are about the agent:

    \begin{quote}
      Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
    \begin{itemize}
    \item
      Which relations between \prop{1}, \val{1}, and \pool{1} explain \emph{why} \vAgent{} concludes \(\phi\) has value \(v\) in \(e\)?
    \end{itemize}
  \end{quote}

  \begin{quote}
    Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
    \begin{itemize}
    \item
      Which events explain \emph{how} \vAgent{} concluded \(\phi\) has value \(v\) in \(e\)?
    \end{itemize}
  \end{quote}

  With \qWhy{}, thing is \prop{0}-\val{0}-\pool{0}.
  Capturing the way things are from the \agpe{}.
  So, maybe entails variant.
  However, variant suggests important part of explanation is agency.
  Why the agent performed the action in contrast to why an action was performed by the agent.

  This gets difficult.
  For, agency, \agpe{}.
  \agpe{}, then not clearly factive.
  Primary benefit is a clear factive third-person perspective.
  Downside is agency.
  Upside is plausible link to agency.
  Return to this at the end of the document.
  }

  \begin{question}{questionWhy}{\qWhy{}}
    \cenLine{
      \begin{VAREnum}
      \item
        Agent: \vAgent{}
      \item
        \prop{2}: \(\phi\)
      \item
        \val{2}: \(v\)
      \item
        Event: \(e\)
      \item
        \mbox{ }
      \end{VAREnum}
    }
    \medskip

    Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
    \begin{itemize}
    \item
      Which relations between \prop{1}, \val{1}, and \pool{1} explain \emph{why} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\)?
    \end{itemize}
    \vspace{-\baselineskip}
  \end{question}

  \begin{question}{questionHow}{\qHow{}}
    \label{q:how}
    \cenLine{
      \begin{VAREnum}
      \item
        Agent: \vAgent{}
      \item
        \prop{2}: \(\phi\)
      \item
        \val{2}: \(v\)
      \item
        Event: \(e\)
      \item
        \mbox{ }
      \end{VAREnum}
    }
    \medskip

    Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
    \begin{itemize}
    \item
      Which events explain \emph{how} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\)?
    \end{itemize}
    \vspace{-\baselineskip}
  \end{question}
\end{note}

\begin{note}
  \qWhy{} seeks an understanding of the way an agent concluded \(\phi\) has value \(v\) in terms of relations between \prop{1}, \val{1}, and \pool{1}.

  \qHow{} seeks an understanding of the way an agent concluded \(\phi\) has value \(v\) in terms of what happened.
\end{note}

\begin{note}
  In general, `why?' and `how?' are distinct questions.
  To illustrate, consider the following \scen{}:

  \begin{scenario}[England AD 932]
    \label{scen:king}
    \vspace{-\baselineskip}
    \begin{screenplay}
    \item[OLD WOMAN:]
      Well, how did you become King, then?
    \item[ARTHUR:]
      The Lady of the Lake, her arm clad in purest shimmering samite, held Excalibur aloft from the bosom of the waters to signify that by Divine Providence\space\dots\space I, Arthur, was to carry Excalibur\dots\space that is why I am your King.
    \item[DENNIS:]
      Look, strange women lying on their backs in ponds handing over swords\space\dots\space that's no basis for a system of government.
      Supreme executive power derives from a mandate from the masses not from some farcical aquatic ceremony.\newline
      \mbox{ }\hfill\mbox{(\cite[8--9]{Cleese:1974aa})}
    \end{screenplay}
    \vspace{-\baselineskip}
  \end{scenario}

  The old woman asks Arthur \emph{how} the become king.
  Arthur provides an answer in terms of some events which happened, but emphasises that those events are \emph{why} Arthur is king.
  In turn, Dennis accepts the answer provided by Arthur as an account of how Arthur became king but rejects the answer an account of why Arthur is king.
  Instead, an answer is expected in involve the absence of an appropriate system of governance in England.
  So, the answer provided by Arthur is accepted by Dennis as an answer to how, but not as an answer to why.

  The distinction between `why?' and `how?' present in \autoref{scen:king} parallels \qWhy{} and \qHow{} with respect to conclusions.
  In \autoref{illu:gist:calc}, the agent considered performing mental arithmetic, but the consideration of calculating \gistCalcEq{} seems no basis for the conclusion.
  Instead, it is the use of the calculator which is a basis.

  And, when we consider the relation between \propM{\gistCalcEq{}}, \valI{True}, and the calculator, we understand why (and not merely how) the agent concluded \gistCalcEq{}.
\end{note}

\begin{note}
  So, \qWhy{} and \qHow{} are plausibly distinct questions.
  Still, the following constraint on answers to \qWhy{} in terms of answers to \qHow{} seems intuitive:

  \begin{constraint}{consInclusion}{\issueInclusion{}}
    \mbox{ }
    \vspace{-\baselineskip}
    \begin{itemize}
    \item
      \begin{itenum}
      \item[\emph{If}:]
        Some relation between \prop{0}, \val{0}, and \pool{} is, in part, an answer to \qWhy{}.
      \item[\emph{Then}:]
      An event in which the agent concludes the proposition has the value from the \pool{} is, in part, \qHow{}.
    \end{itenum}
  \end{itemize}
  \vspace{-\baselineskip}
  \end{constraint}

  In short, for any relation between a \prop{0}, \val{0}, and \pool{} which grants some understanding of the way an agent concluded \(\phi\) has value \(v\), there is an event such that the agent has concluded the proposition has some value from the \pool{}.%
  \footnote{
    What happened does not entail a corresponding relation.
  For example, in \autoref{illu:gist:calc} the agent presses a button marked `\(=\)'.
  However, the agent does not conclude \propM{\gistCalcEq{}} has value \valI{True} \emph{from} pressing the button marked `\(=\)'.
  Hence, no relation seems to hold between \propM{\gistCalcEq{}}, \valI{True}, and the pressing the button marked `\(=\)'.
  }
\end{note}

\begin{note}
  With respect to \qWhy{}, the relevant relations of \scen{3}~\ref{illu:gist:calc}~and~\ref{scen:animalism} seem to be:%
  \footnote{
    The \illu{1} of \qWhy{} by \scen{3}~\ref{illu:gist:calc}~and~\ref{scen:animalism} is somewhat limited, as no \scen{0} involves an account of what motivates the respective agents.
    \qWhy{} is not designed to rule out what motivates an agent.
    For example, one may add to \autoref{illu:gist:calc} that the agent wants to calculate \gistCalcLHS{}.
    Functions as a premise, given the understanding of \pool{1}.
    More detail follows in~\autoref{cha:clar}.
  }

  \begin{itemize}[noitemsep]
  \item
    \begin{itemize}
    \item
      The relation between \propM{\gistCalcEq{}}, \valI{True}, and something about the calculator.
    \item
      The agent concludes \propM{\gistCalcEq{}} has value \valI{True} from the calculator.
    \end{itemize}

    The agent concluded \propM{\gistCalcEq{}} and \valI{True} from the calculator.
    Hence, if a relation between these items answers \qWhy{} (which it intuitively does), then there is a corresponding answer to \qHow{}.

    A relation may hold between \propM{\gistCalcEq{}}, \valI{True} and whatever \pool{} would be associated with the agent calculating \(\gistCalcEq{}\) from their understanding of Arithmetic.
    However, there is no event in which the agent concludes \propM{\gistCalcEq{}}, has value \valI{True} by performing arithmetic.
    So, there is no answer to \qHow{} with respect to the agent's understanding of arithmetic, and given \issueInclusion{}, it is not possible for the relation to answer \qWhy{}.
  \item
    \begin{itemize}
    \item
      The relation between \propI{Four legs good, two legs bad}, \valI{True} and something about the existence of Snowball's explanation.
    \item
      The birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the existence of Snowball's explanation.
    \end{itemize}

    The bird's conclusion \propI{Four legs good, two legs bad} has value \valI{True} from the existence of Snowball's explanation answers \qHow{}, and the relation between the \prop{0}, \val{0}, and \pool{} answers \qWhy{}, in line with \issueInclusion{}.

    And, while a relation may hold between \propI{Four legs good, two legs bad} \valI{True} and the \emph{content} of Snowball's explanation, the birds failed to understand the content.
    Hence, with no answer to \qHow{}, it is not possible for this relation to answer \qWhy{}.
  \end{itemize}
  %
  These relations seems to do work in guiding our understanding of the an event.
  To observe that a relation held indicates something in addition to the observation of what happened, but for a relation to answer \qWhy{} it seems we need a `\wit{}' for the respective.
  Hence, \issueInclusion{} requires that every relation which answers \qWhy{} has some \wit{}.
\end{note}

\begin{note}
  \issueInclusion{} seems plausible, and seems to do work.%
  \footnote{
    Note, \qHow{} does not explicitly require the relevant event to be the event in which the agent concludes \(\phi\) has value \(v\) from the \pool{}.
    Hence, a previous event in which the agent concluded \propM{\gistCalcEq{}} has value \valI{True} may answer \qHow{}.
    Still, given \(\gistCalcEq{}\) in~\autoref{illu:gist:calc} functions as some arbitrary multiplication that the agent may calculation, we may assume the agent has never calculated \(\gistCalcEq{}\).
  }\(^{,}\)%
  \footnote{
    Alternatively, \issueInclusion{} may be thought to narrow the range on answers to \qWhy{}.
    That is to say, \issueInclusion{} functions to disambiguate the sense of `why' used in the statement of \qWhy{}.
    If so, then \issueInclusion{} is not a constraint, it is simply part of the way \qWhy{} is understood.
    However, I do not think this is the case.
    I think it is plausible that the sense of `why' present in \qWhy{} may be understood without reference to \issueInclusion{}, and hence that \issueInclusion{} amounts to a substantive constraint.
    The document will assume this is the case, but only the framing depends on this.
  }

  Still, we have only considered two \scen{1} and \issueInclusion{} is a general constraint.
  Hence, if there is some doubt regarding \issueInclusion{} then further argument is required.
  It is not obvious that there are \scen{1} in which \issueInclusion{} fails to hold.
  However, lack of immediate counterexamples is no argument.

  Though I would like to consider an argument for \issueInclusion{}, I am not aware of any.%
  \footnote{
    The particular construct of \qWhy{}, \qHow{}, and \issueInclusion{} is somewhat idiosyncratic, and so it is no surprise there are no direct argument for \issueInclusion{}.
    However, I take the idea captured by \issueInclusion{} to be intuitive, and I am not aware of any argument for this idea.
  }
  Perhaps \issueInclusion{} is sufficiently intuitive that it is taken for granted.
  Or, perhaps the failure of \issueInclusion{} is recognised and I have yet to stumble upon the acknowledgement of its failure.

  In any case, no argument will be provided.
  The goal of this document is to provide a recipe for generating counterexamples to \issueInclusion{}.

  By `recipe', I mean an description of some features which hold of \scen{1} and an account of the way in which these combine which entails violations of \issueInclusion{}.
  With the recipe in hand, we will construct a few counter samples, but our interest is with the way in which \issueInclusion{} fails, rather than the failure of \issueInclusion{}.

  Before closing this introduction, say a little more regarding the recipe for counterexamples.
  First, we consider motivation for \issueInclusion{} via the literature on reasons.
  I am not aware of any arguments for \issueInclusion{}, but I think there is strong motivation for \issueInclusion{}.%
  \footnote{
    \color{red}
    And, refinement to questions, provide further motivation.
  }
\end{note}

\section*{\issueInclusion{} and reasons}
\label{sec:reasons}

\begin{note}
  \qWhy{} and \qHow{} are questions about the way an event in which an agent concludes some proposition has some value happened.

  \qWhy{} seeks `explanatory reasons', summarised by \citeauthor{Hieronymi:2011aa} (\citeyear{Hieronymi:2011aa}) as:

  \begin{quote}
    [T]he reasons why things happen, or why things are the way they are.\newline
    \mbox{ }\hfill\mbox{(\citeyear[410]{Hieronymi:2011aa})}
  \end{quote}

  To borrow an an example given by \citeauthor{Hieronymi:2011aa}, the extreme heat or the faulty construction is a reason why the engine failed (\citeyear[409]{Hieronymi:2011aa}).
  Likewise, the engine failing may be a reason why the steamboat is moored, and the steamboat being moored is a reason why the hotel is fully booked, etc.
\end{note}

\begin{note}
  In general, explanatory reasons are distinct from an \emph{\agents{}} reasons, whatever these may be.
  Though, in some cases, explanatory reasons may be involve an agent's reasons.
  This contrast and involvement forms the opening question of \citeauthor{Davidson:1963aa}'s \citetitle{Davidson:1963aa}:

  \begin{quote}
    What is the relation between a reason and an action when the reason explains the action by giving the agent's reason for doing what he did?
    We may call such explanations \emph{rationalizations}, and say that the reason \emph{rationalizes} the action.%
    \mbox{}\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}

  \citeauthor{Davidson:1963aa} is interested with explanatory reasons \emph{such that} the explanatory reason involves the agent's reason.%
  \footnote{
    These may also be understood, in line with \citeauthor{Smith:1994wo} (\citeyear{Smith:1994wo}), as `motivating reasons':
    \begin{quote}
      The distinctive feature of a motivating reason to \(\phi\) is that, in virtue of having such a reason, an agent is in a state that is \emph{explanatory} of her \(\phi\)-ing, at least other things being equal --- other things must be equal because an agent may have a motivating reason to \(\phi\) without that reason's being overriding.%
      \mbox{}\hfill\mbox{(\citeyear[96]{Smith:1994wo})}
    \end{quote}
  }

  For \citeauthor{Davidson:1963aa} specifying:
  \begin{enumerate*}[label=(\alph*), ref=(\alph*)]
  \item
    Some sort of pro attitude (a want, obligation, etc.) toward actions of a certain kind, and
  \item
    a belief (or perception, notice, etc.) that his action is of that kind.
  \end{enumerate*}
  Is sufficient to characterise the agent's reason for doing something.
  (\citeyear[Cf.][685,686]{Davidson:1963aa})

  Colloquially, a desire-belief pair.

  So, what is the relation between a reason and an action when the reason explains the action by giving a desire-belief pair?
\end{note}

\begin{note}
  For us, action is conclusion.
  Rather than desire-belief pair, relation between \prop{0}, \val{0}, and \pool{0}.

  Sufficient parallel.
  Conclusions, \citeauthor{Carroll:1895uj}.
  No attitude is sufficient.

  For example, we may say with relative ease that:

  \begin{itemize}[noitemsep]
  \item
    The reason for which the agent concluded \propM{\gistCalcEq{}} is \valI{True} was the relation between \propM{\gistCalcEq{}}, \valI{True} and the calculator.
  \item
    The reason for which the birds concluded \propI{Four legs good, two legs bad} is \valI{True} was the relation between \propI{Four legs good, two legs bad}, \valI{True}  and (the existence of) Snowball's explanation.
  \end{itemize}

  {
    \color{red}
    Difficult to capture as a propositional attitude.
    Still, no real issue here.

    Relation, as connection between these things.
    The \pool{} in isolation isn't clearly doing anything.
  }
\end{note}

\begin{note}
  Now, the main argument of made in \citetitle{Davidson:1963aa} is:
  %
  \begin{quote}
    [R]ationalization is a species of ordinary causal explanation.%
    \mbox{ }\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}
  %
  If we grant relations between a \prop{0}, \val{0}, and \pool{1} are rationalisations, and rationalisations are causal explanations, and relations between \prop{1}, \val{1}, and \pool{1} capture an agent's reasons then \issueInclusion{} seems to follow, at least when considering the \agents{} reasons.

  For, suppose some relation between a \prop{0}, \val{0}, and \pool{} which answers \qWhy{}.
  By assumption, this relation amounts to a rationalisation.
  And, by assumption rationalisations are causal explanations.
  Hence, there must be some causal relation holding between a \pool{0} and the agent's conclusion.
  And, grating there is a causal relation between the agent's conclusion and a \pool{0}, then there is some event in which the agent concludes the proposition has some value from the \pool{0}.
  This event is an answer to \qHow{}.
\end{note}

\begin{note}
  Limitation.

  Reason explains the action by giving the agent's reason.

  So, restricted to giving the agent's reasons.
  \qWhy{} is not clearly so restricted.

  For example, steamboat being moored, hotel.
  However, not in terms of hotel's reasons.
  Simply too many guests.

  Two difficult points.

  First, \qWhy{}, only about relations, but not clear that relations need to be the agent's reasons.

  This is a gap.
  I think it is plausible that these things line up.
  However, no real use in working through what an agent's reason is, for \citeauthor{Davidson:1963aa}.%
  \footnote{
    Following from the footnote.
    Issue is about agency.
  }

  Second, have not said anything about how relations interact with attitudes.
  Causal explanation.
  It may still be the case that relation has causal role, though it is not part of the event.
  In part, issue with causal explanation.
  

  Hence, motivation.
  
\end{note}

\begin{note}
  So, capturing explanatory reasons in terms of causal explanation motivations \issueInclusion{}.
  However, abstracting a little, the role of causation in \citeauthor{Davidson:1963aa}'s account is of interest only to the extent that the relevant causal relations ensure the relations between \prop{1}, \val{1}, and \pool{1} are sufficient.
  And, such accounts do not need to appeal to causation to ensure this sufficiency.

  Consider \citeauthor{Hieronymi:2011aa}'s (\citeyear{Hieronymi:2011aa}) account of action explanation:

  \begin{quote}
    [W]henever an agent acts for reasons, the agent, in some sense, takes certain considerations to settle the question of whether so to act, therein intends so to act, and executes that intention in action.

    If this much is uncontroversial (and, under some interpretation, I believe it must be), we can use it as a form for filling out.
    I propose, then, that we explain an event that is an action done for reasons by appealing to the fact that the agent took certain considerations to settle the question of whether to act in some way, therein intended so to act, and successfully executed that intention in action.
    I suggest that \emph{this} complex fact [\dots] explains the action by giving the agent's reason for acting.%
    \mbox{ }\hfill\mbox{(\citeyear[421]{Hieronymi:2011aa})}
  \end{quote}

  The key feature of \citeauthor{Hieronymi:2011aa}'s account is the agent taking certain considerations to settle the question of whether to act in some way.
  \citeauthor{Hieronymi:2011aa} only requires the agent took certain considerations to settle a question, whether this taking amounts to causation or otherwise.
  \citeauthor{Hieronymi:2011aa} understands this taking to be an activity, and hence there is a corresponding event.
  Therefore, if a relation between a \prop{0}, \val{0}, and \pool{} answers \qWhy{} and this relation is understood in terms of the agent taking the \pool{} to settle the question of whether to conclude the proposition has the value, we must have, by \citeauthor{Hieronymi:2011aa}'s account, an answer to \qHow{} in line with \issueInclusion{}.
\end{note}

\begin{note}
  Key idea.
  \issueInclusion{} is motivated by how an agent concludes being sufficient to understand why.
  Specifying the \pool{} gets us a reason, and this reason seems to be sufficient.
  Only need to observe cause and effect, or something like this.
\end{note}


\section*{Questioning \issueInclusion{}}

\begin{note}
  Our interest is understanding the way an event in which some agent \vAgent{} concludes some proposition \(\phi\) has some value \(v\) happened.

  We introduced two questions (\qWhy{}, \qHow{}) and a constraint (\issueInclusion{}) on answers to \qWhy{} by answers to \qHow{}.
  And, we motivated the constraint in part by a pair of \scen{1} (\scen{3}~\ref{illu:gist:calc}~and~\ref{scen:animalism}) and then more generally in terms of reasons.
  %(\cite{Davidson:1963aa},\cite{Broome:2019aa},\cite{Hieronymi:2011aa})

  I think \issueInclusion{}, while intuitive, fails to hold in general.
\end{note}

\begin{note}
  I think that answers to \qWhy{} reduce to psychological facts of an agent, specifically psychological facts which hold of the agent when they conclude.%
  \footnote{
    This is incompatible with views of reasons explanation advanced by~(\cite{Dancy:2000aa}) and~(\cite{Alvarez:2013aa}), in which the state of affairs may be an agent's reason (and not just the evaluation of some state of affairs).
    Though, the argument will not depend on assuming that the relations reduce to psychological facts.

    See~(\cite[413--418]{Hieronymi:2011aa}),~(\cite[3--5]{DOro:2013vh}), and~(\cite[\S2]{Alvarez:2017aa}) for more.
  }
  However, I do not think that a relation between the \prop{0}, \val{0}, and \pool{} exhaust the relevant psychological facts.
  In particular, I think that in various cases additional relations between distinct \prop{1}, \val{1} and \pool{1} answer \qWhy{} without there being an event in which the agent concluded the propositions have values from \pool{1}.
\end{note}

\begin{note}
  As seen above with respect to \autoref{scen:animalism}, it follows from \issueInclusion{} that the content of Snowball's explanation is irrelevant.
  For, the birds do not understand Snowball's explanation, hence there is no event in which the birds reason from the content to \propI{Four legs good, two legs bad} has value \valI{True}.
  And, I think this is correct.

  However, parallel reasoning entails the agent's understanding of arithmetic is irrelevant with respect to \autoref{illu:gist:calc}.
  And, I do not think this entailment holds.
  I think it may be the case that a relation between \propM{\gistCalcEq{}}, \valI{True} and the agent's understanding of arithmetic \emph{may} answer \qWhy{}.
  Whether this is the case will depend on whether some additional details hold of~\autoref{illu:gist:calc}.
  Still, as the details matter, the entailment, and hence \issueInclusion{}, is not right.
\end{note}

\begin{note}
  In other words, I think there are counterexamples to \issueInclusion{}.
  The primary goal of this document is to provide a recipe for generating counterexample to \issueInclusion{}.
\end{note}

\begin{note}
  The document has three parts:

  \begin{TOCEnum}
  \item
    \autoref{part:prep}: \nameref{part:prep}.

    We begin by clarifying our understanding of conclusions, \qWhy{}, \qHow{}, and \issueInclusion{}.
    In particular, we provide variations to \qWhy{}, \qHow{}, and \issueInclusion{} in order to precisely capture what the counterexamples we generate our counterexamples to.
  \item
    \autoref{part:ing}: \nameref{part:ing}

    We detail three ideas which will be used to generate counterexamples.
    Each idea captures some phenomenon.
    The counterexamples occur when each idea applies to a \scen{0} in which an agent concludes some proposition has some value from some \pool{}.

    The key idea is that of a \fc{}.
    However, the ideas of \tC{}, and \requ{} will tie \fc{1} to instances in which an agent concludes.
  \item
    \autoref{part:dir}: \nameref{part:dir}

    With the preparation and ingredients in hand, we show how to combine the ingredients to generate counterexamples to \issueInclusion{}.

    We also provide a few sample \scen{1} where \issueInclusion{} fails, and consider any leftover issues from the recipe.
    Here we return to \autoref{illu:gist:calc}.
  \end{TOCEnum}

  This covers how things will happen.
  I do not have a brief account of what will happen.
  The details are too important.
  The recipe is not based on an intuitive understanding of any particular \scen{}.
  Instead, the recipe is based on the way a number of ideas come together when we understand the way some agent concludes some proposition \(\phi\) has some value \(v\) happened.

  The beginning of each part has additional details on the way in which the part is structured.
  Brief account of the chapters, and occasionally supplementary details.
\end{note}


% \begin{note}
%   First, expand on intuition.
%   Then, introduce type of \scen{0} of interest.
% \end{note}

% \begin{note}
%   Follow part, foundations.
%   Following, turn to details.

% {\color{red} Place somewhere?}.%
%   \footnote{
%     Roughly, if it were the agent failed to conclude \propM{\gistCalcEq{}} in \autoref{illu:gist:calc}, then there would be conflict between the agent's understanding of arithmetic and the testimony of the calculator.
%     Expressed differently, there would be conflict between the agent's failure to conclude \propM{\gistCalcEq{}} by their understanding of arithmetic, and a premises involved in concluding \propM{\gistCalcEq{}} via the calculator.
%     I.e. supposing the agent concludes \(\gistCalcLHS{} \ne \gistCalcRHS{}\), then for the agent the calculator is not a source of testimony.
%     In the \scen{1} of interest, this hypothetical --- or in some cases possible --- conflict will strictly be between the agent's reasoning from \pool{1} to conclusions.
%   }
% \end{note}

% \begin{note}
%   To illustrate, consider \citeauthor{Broome:2013aa}'s (\citeyear{Broome:2013aa}) account of a `motivating reason'%
%   \footnote{
%     \citeauthor{Broome:2013aa} contrasts `motivating reasons' to `normative reasons'.
%     \begin{quote}
%       Whereas motivating reasons explain or help to explain why a person does something, normative reasons explain or help to explain why a person ought to do something, or to believe something, or to hope for something, or to like something, or in general to F, where ‘F' stands for a verb phrase.%
%     \mbox{}\hfill\mbox{(\citeyear[47]{Broome:2013aa})}
%     \end{quote}
%   }
%   \begin{quote}
%     Sometimes the explanation of why a person does something has a particular character:
%     roughly, it involves the person's rationality in a distinctive way that I shall not try to describe.
%     Then we say the person does what she does for a reason.
%     We might say ‘The reason for which Hannibal used elephants was to terrorize the Romans'.
%     The reason for which a person does something is called a ‘motivating reason'.
%     In general, a motivating reason is whatever explains or helps to explain what a person does in the distinctive way that involves her rationality.
%     \mbox{}\hfill\mbox{(\citeyear[46--47]{Broome:2013aa})}
%   \end{quote}
% \end{note}

% \begin{note}
%   \color{red}

%   Further,

%   For \citeauthor{Davidson:1963aa}, primary reason.

%   \begin{quote}
%     \emph{R} is a primary reason why an agent performed the action \emph{A} under the description \emph{d} only if \emph{R} consists of a pro attitude of the agent toward actions with a certain property, and a belief of the agent that \emph{A}, under the description \emph{d}, has that property.\newline
%     \mbox{ }\hfill\mbox{(\citeyear[687]{Davidson:1963aa})}
%   \end{quote}

%   We have distinguished \qWhy{} from pro-attitudes.
%   However, fill in whatever motivation.
%   What matters is the belief.
%   This is the relevant proposition-value pair.

%   If \citeauthor{Davidson:1963aa}, then granting restriction, seems we don't need to look beyond the proposition-value pair.
% \end{note}

% \begin{note}
%   So, answer to \qWhy{} is constrained by answer to \qHow{} by getting to a reason.

%   For, causal relation.
%   Indeed, from `explanatory', these things are identical.
%   However, from `motivating' still distinction.
%   Agent's reason is causal, but the content is not necessarily causal.%
%   \footnote{
%     On my understanding of \citeauthor{Davidson:1963aa}, there's a tight link between then content of some state and the causal relations that arise from the state.

%     So, go from content to state, and then proceed from here.

%     This, I think, is correct.
%     And, the problem of deviant causal chains highlights this.
%     For, \citeauthor{Davidson:1963aa} recognises there's a problem with the link between content and the causal relations which hold between the states.

%     \begin{quote}
%       Beliefs and desires that would rationalize an action if they caused it in the right way—through a course of practical reasoning, as we might try saying---may cause it in other ways.%
%       \mbox{ }\hfill\mbox{(\citeyear[79]{Davidson:1973vd})}
%     \end{quote}
%   }

%   Here, we get a causal trace.
%   No need to look for any relation of support other than premises of reasoning.
% \end{note}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% TeX-engine: luatex
%%% End:
