\chapter{\qWhy{} and \qHow{} an agent concludes}
\label{cha:intro}

\begin{note}
  Our interest is understanding the way an event in which an agent concludes happens.

  \begin{scenario}[Calculation]%
    \label{scen:calc}%
    An agent enters `\gistCalcLHS{}' into a calculator and presses a button marked `\(=\)'.
    The calculator displays `\gistCalcRHS{}'.

    The agent pauses for a moment.
    They have a good understanding of arithmetic.
    And, given the display on the calculator, it follows that if the calculator is trustworthy, then they would not fail to conclude \propM{\gistCalcEq{}} via their understanding of arithmetic.

    The agent concludes \propM{\gistCalcEq{}}.
  \end{scenario}

  \noindent%
  Intuitively, the agent concludes \propM{\gistCalcEq{}} from the calculator.
  More could be said about the way the agent concludes but these details won't be of too much interest.%
  \footnote{
    For example, classify the agent as regarding the calculator as a source of testimony, adding that testimony are factive, and so concluded \propM{\gistCalcEq{}} from the testimony of the calculator.
  }

  The agent's understanding of arithmetic, it seems, had no significant role.
  So long as the calculator was correct, the agent had the opportunity to conclude \propM{\gistCalcEq{}} by their understanding of arithmetic, but the agent did not do any arithmetic.
\end{note}

\begin{note}
  Abstracting a little, \propM{\gistCalcEq{}} corresponds to a state of affairs.
  If the truths of mathematics are necessary, then this state of affairs never fails to be, but \propM{\gistCalcEq{}} captures the way things are in the same way as \propI{Kangaroos have tails} captures the way things are.
  For ease we refer to states of affairs as propositions.

  Continuing the abstraction, when the agent concludes \propM{\gistCalcEq{}}, we may say the agent concludes \propM{\gistCalcEq{}} has value \valI{True}.
  Even if \propM{\gistCalcEq{}} never fails to be, the calculator may have been faulty and the agent may have concluded \propM{\gistCalcEqBad{}} has value \valI{True} or \propM{\gistCalcEq{}} has value \valI{False}.

  Likewise, as the agent concluded \propM{\gistCalcEq{}} has value \valI{True} from the calculator, we may say the agent concluded \propM{\gistCalcEq{}} has value \valI{True} from some \pool{} of premises.
\end{note}

\begin{note}
  Abstracting from almost all the details of \autoref{scen:calc} then, we say an agent concluded some \prop{} \(\phi\) has some \val{} \(v\) from some \pool{} of premises \(\Phi\).%
  \footnote{
    For ease, we abbreviate `\pool{} of premises' to `\pool{}'.
  }

  The `\emph{from}' in the previous statement seems to do work.
  A sequence happened in which the agent used the calculator and then concluded \propM{\gistCalcEq{}} has value \valI{True}.
  However, in addition to this sequence, something about the calculator led the agent to conclude \propM{\gistCalcEq{}} has value \valI{True}.

  Our understanding of \autoref{scen:calc} is be different if the agent applied their understanding of arithmetic, or if the agent asked some other person.
\end{note}

\begin{note}
  Abstracting further, we say something about the calculator \emph{supports} \propM{\gistCalcEq{}} being \valI{True}, from the \agpe{}.

  We limit ourselves to two basic assumptions about \ros{1}:
  %
  \begin{enumerate}
  \item
    When an agent concludes \(\phi\) has value \(v\) from \(\Phi\) a \ros{} between \(\phi\), \(v\) and \(\Phi\) holds, from the \agpe{}
  \item
    A \ros{} between \(\phi\), \(v\) and \(\Phi\) may hold, from an \agpe{}, without a prior event in which agent concludes \(\phi\) has value \(v\) from \(\Phi\).
  \end{enumerate}
  %
  Speaking in terms of \ros{1} allows abstraction from what happens when an agent concludes.
  A \ros{} holds between \propM{\gistCalcEq{}}, \valI{True} and the calculator when the agent concludes \propM{\gistCalcEq{}}, \valI{True} from the calculator.
  Still, a \ros{} may also hold between \propM{\gistCalcEq{}}, \valI{True} and the \agents{} understanding of arithmetic, though the agent did not conclude from their understanding of arithmetic.

  Further, it seems \ros{1} provide some understanding of the way an event in which some agent concludes happens.
  In particular, a \ros{} seems to provide some understanding of \emph{why} an event in which some agent concludes happens.
  A \ros{} does not clearly provide some understanding of \emph{how} the event in which the agent concludes happens.

  Still, there is a plausible connexion between `why' and `how' with respect to \autoref{scen:calc}.
  For, the agent concludes \propM{\gistCalcEq{}} has value \valI{True} from some \pool{}, and hence the agent has a `\wit{}' for the relevant \ros{}.
  In other words, a \ros{} between \(\psi\), \(v'\), and \(\Psi\) may hold when an agent concludes \(\phi\) has value \(v\) from \(\Phi\), as the agent does not conclude \(\psi\) has value \(v'\) from \(\Psi\), this \ros{} is irrelevant to why the agent concludes \(\phi\) has value \(v\) from \(\Phi\).
\end{note}

\begin{note}
  Here's a second, slightly more complex \scen{0}:

  \begin{scenario}[Animalism]%
    \label{scen:animalism}%
    `Four legs good, two legs bad.'
    This, he said, contained the essential principle of Animalism.
    Whoever had thoroughly grasped it would be safe from human influences.
    The birds at first objected, since it seemed to them that they also had two legs, but Snowball proved to them that this was not so.

    `A bird's wing, comrades,' he said, `\textsc{is} an organ of propulsion and not of manipulation.
    It should therefore be regarded as a leg.
    The distinguishing mark of Man is the \emph{hand}, the instrument with which he does all his mischief.'

    The birds did not understand Snowball's long words, but they accepted his explanation, and all the humbler animals set to work to learn the new maxim by heart.
    \textsc{four legs good, two legs bad}, was inscribed on the end wall of the barn\dots%
    \mbox{ }\hfill\mbox{(\cite[25]{Orwell:1976aa})}%
    \newline
  \end{scenario}

  \noindent%
  The agents of interest are the birds, and the conclusion is the essential principle of Animalism:
  \propI{Four legs good, two legs bad} has value \valI{True}.

  Snowball provided an argument against an objection from the birds, and the birds concluded \propI{Four legs good, two legs bad} is \valI{True} from Snowball's explanation.

  Though, as \citeauthor{Orwell:1976aa} highlights, the birds did not conclude \propI{Four legs good, two legs bad} from \emph{the content of} Snowball's explanation.
  (Some words were too long.)
  Instead, the birds concluded, at least in part, from (the existence of) \emph{Snowball's explanation}.

  % In parallel to the agent's understanding of arithmetic from~\autoref{scen:calc} the birds of~\autoref{scen:animalism} did not, in part, conclude \propI{Four legs good, two legs bad} from the content of Snowball's explanation.
\end{note}

\begin{note}
  In line with the abstraction given, we may say:
  The birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the existence of Snowball's explanation.
  And, for each bird, a \ros{} holds between \propI{Four legs good, two legs bad}, \valI{True}, and the existence of Snowball's explanation.
  {
    \color{red}
    And, \wit{0}.
  }
\end{note}

\section*{\qWhy{}, \qHow{} and \issueInclusion{}}
\label{cha:intro:why-how}

\begin{note}
  % Our interest is understanding the way an event in which some agent concludes some proposition \(\phi\) has some value \(v\) from some \pool{} \(\Phi\) happens.
  \phantlabel{how-and-why-first-mention}%
  With respect to understanding the way an event in which an agent concludes happens we distinguish two questions; `\qWhy{}' and `\qHow{}':

  \begin{question}{questionWhy}{\qWhy{}}
    Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
    \begin{itemize}
    \item
      Which \ros{} between \prop{1}, \val{1}, and \pool{1} explain \emph{why} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\)?
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{question}

  \begin{question}{questionHow}{\qHow{}}
    \label{q:how}
    Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
    \begin{itemize}
    \item
      Which past or present events explain \emph{how} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\)?
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{question}
\end{note}

\begin{note}
  \qWhy{} seeks an understanding of the way an event developed so that an agent concluded \(\phi\) has value \(v\) in terms of \ros{} between \prop{1}, \val{1}, and \pool{1}.
  And \qHow{} seeks an understanding of the way an event developed so that an agent concluded \(\phi\) has value \(v\) in terms of what happened.

  \phantlabel{HierExpR}
  Specifically, both \qWhy{} and \qHow{} seek `explanatory reasons', summarised by \citeauthor{Hieronymi:2011aa} (\citeyear{Hieronymi:2011aa}) as:
  % 
  \begin{quote}
    [T]he reasons why things happen, or why things are the way they are.\newline
    \mbox{ }\hfill\mbox{(\citeyear[410]{Hieronymi:2011aa})}
  \end{quote}
  % 
  To borrow an an example given by \citeauthor{Hieronymi:2011aa}, the extreme heat or the faulty construction is a reason why the engine failed (\citeyear[409]{Hieronymi:2011aa}).
  Likewise, the engine failing may be a reason why the steamboat is moored, and the steambot being moored is a reason why the hotel is fully booked, etc.%
  \footnote{
    Neither \qWhy{} nor \qHow{} seek exhaustive reasons.
    Following \citeauthor{Hieronymi:2011aa}'s example, the faulty construction is a reason why the engine failed, but the faulty construction may only lead to engine failure in specific use cases, and so `the engine was used in salt water' is also an explanatory reason.
  }
\end{note}

\begin{note}
  In general, `why?' and `how?' are distinct questions.
  For example, consider:

  \begin{scenario}[England AD 932]
    \label{scen:king}
    \vspace{-\baselineskip}
    \begin{screenplay}
    \item[OLD WOMAN:]
      Well, how did you become King, then?
    \item[ARTHUR:]
      The Lady of the Lake, her arm clad in purest shimmering samite, held Excalibur aloft from the bosom of the waters to signify that by Divine Providence\space\dots\space I, Arthur, was to carry Excalibur\dots\space that is why I am your King.
    \item[DENNIS:]
      Look, strange women lying on their backs in ponds handing over swords\space\dots\space that's no basis for a system of government.
      Supreme executive power derives from a mandate from the masses not from some farcical aquatic ceremony.\newline
      \mbox{ }\hfill\mbox{(\cite[8--9]{Cleese:1974aa})}
    \end{screenplay}
    \vspace{-\baselineskip}
  \end{scenario}

  The old woman asks Arthur \emph{how} the become king.
  Arthur provides an answer in terms of some events which happened, but emphasises that those events are \emph{why} Arthur is king.
  In turn, Dennis accepts the answer provided by Arthur as an account of how Arthur became king but rejects the answer an account of why Arthur is king.
  Instead, an answer is expected in involve the absence of an appropriate system of governance in England.
  So, the answer provided by Arthur is accepted by Dennis as an answer to how, but not as an answer to why.
  % The distinction between `why?' and `how?' present in \autoref{scen:king} parallels \qWhy{} and \qHow{} with respect to conclusions.
  % In \autoref{scen:calc}, the agent considered applying their understanding of arithmetic, but their understanding of arithmetic seems no basis for the conclusion.
  % Instead, it is the use of the calculator.
  % When we consider the \ros{} between \propM{\gistCalcEq{}}, \valI{True}, and the calculator, we seem to get some understanding of why the agent concluded \gistCalcEq{}.
  % In parallel, the sequence of the agent using the calculator and concluding \propM{\gistCalcEq{}} has value \valI{True}
\end{note}

\begin{note}
  So, \qWhy{} and \qHow{} are plausibly distinct questions.
  Still, in the case of \qWhy{} and \qHow{} the following constraint on answers to \qWhy{} in terms of answers to \qHow{} seems intuitive:

  \begin{constraint}{consInclusion}{\issueInclusion{}}
    \mbox{ }
    \vspace{-\baselineskip}
    \begin{itenum}
    \item[\emph{If}:]
      A \ros{} between \(\psi\), \(v'\), and \(\Psi\) answers \qWhy{}.
    \item[\emph{Then}:]
      An event in which the agent concludes \(\psi\) has value \(v'\) from \(\Psi\) answers \qHow{}.
    \end{itenum}
    \vspace{-\baselineskip}
  \end{constraint}

  \noindent%
  In short, for any \ros{} between a \prop{0}, \val{0}, and \pool{} which grants some understanding of the way an agent concluded \(\phi\) has value \(v\), there is an event such that the agent concludes the proposition has the value from the \pool{}.%
  \footnote{
    What happened does not entail a corresponding \ros{}.
    For example, in \autoref{scen:calc} the agent presses a button marked `\(=\)'.
    However, the agent does not conclude \propM{\gistCalcEq{}} has value \valI{True} \emph{from} pressing the button marked `\(=\)'.
    Hence, no \ros{} seems to hold between \propM{\gistCalcEq{}}, \valI{True}, and the pressing the button marked `\(=\)'.
  }
\end{note}

\begin{note}
  \scen{3}~\ref{scen:calc}~and~\ref{scen:animalism} suggest \issueInclusion{} holds:%
  % \footnote{
  % The \illu{1} of \qWhy{} by \scen{3}~\ref{scen:calc}~and~\ref{scen:animalism} is somewhat limited, as no \scen{0} involves an account of what motivates the respective agents.
  % \qWhy{} is not designed to rule out what motivates an agent.
  % For example, one may add to \autoref{scen:calc} that the agent wants to calculate \gistCalcLHS{}.
  % Functions as a premise, given the understanding of \pool{1}.
  % More detail follows in~\autoref{cha:clar}.
  % }
  %
  \begin{itemize}[noitemsep]
  \item
    With respect to~\autoref{scen:calc}, the only answer to \qWhy{} seems to be the \ros{} between \propM{\gistCalcEq{}}, \valI{True}, and something about the calculator.
    And, the agent concludes \propM{\gistCalcEq{}} has value \valI{True} from the calculator.
    Hence, there is a corresponding answer to \qHow{}.

    A \ros{} may hold between \propM{\gistCalcEq{}}, \valI{True} and whatever \pool{} would be associated with the agent calculating \gistCalcEq{} from their understanding of arithmetic.
    However, there is no event in which the agent concludes \propM{\gistCalcEq{}}, has value \valI{True} by doing arithmetic.
    So, there is no answer to \qHow{} with respect to the agent's understanding of arithmetic, and given \issueInclusion{}, it is not possible for a \ros{} to answer \qWhy{}.
  \item
    With respect to~\autoref{scen:animalism}, the only answer to \qWhy{} seems to be the \ros{} between \propI{Four legs good, two legs bad}, \valI{True} and something about the existence of Snowball's explanation.
    And, the birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the existence of Snowball's explanation.

    As the birds did not understand the content of Snowball's explanation, it seems implausible that a \ros{} held between \propI{Four legs good, two legs bad}, \valI{True}, and the content of Snowball's explanation.
    Still, as there is no event in which the birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the content of Snowball's explanation, and no such \ros{} may answer \qWhy{} if \issueInclusion{} holds.
  \end{itemize}
\end{note}

\begin{note}
  \issueInclusion{} seems plausible, and seems to do work.%
  \footnote{
    Note, \qHow{} does not explicitly require the relevant event to be the event in which the agent concludes \(\phi\) has value \(v\) from \(\Phi\).
    Hence, a previous event in which the agent concluded \propM{\gistCalcEq{}} has value \valI{True} may answer \qHow{}.
    Still, given \gistCalcEq{} in~\autoref{scen:calc} functions as some arbitrary multiplication that the agent may calculation, we may assume the agent has never calculated \gistCalcEq{}.
  }\(^{,}\)%
  \footnote{
    Alternatively, \issueInclusion{} may be thought to narrow the range on answers to \qWhy{}.
    That is to say, \issueInclusion{} functions to disambiguate the sense of `why' used in the statement of \qWhy{}.
    If so, then \issueInclusion{} is not a constraint, it is simply part of the way \qWhy{} is understood.
    However, I think the sense of `why' present in \qWhy{} may be understood without reference to \issueInclusion{}, and hence that \issueInclusion{} amounts to a substantive constraint.
    The document will assume this is the case, but only framing depends on this.
  }

  Still, we have only considered two \scen{1} and \issueInclusion{} is a general constraint.
  Hence, if there is some doubt regarding \issueInclusion{} then further argument is required.
  It is not obvious that there are \scen{1} in which \issueInclusion{} fails to hold.
  However, lack of apparent counterexamples is no argument.

  Though I would like to consider an argument for \issueInclusion{}, I am not aware of any.%
  \footnote{
    The particular construct of \qWhy{}, \qHow{}, and \issueInclusion{} is somewhat idiosyncratic, and so it is no surprise there are no direct argument for \issueInclusion{}.
    However, I take the idea captured by \issueInclusion{} to be intuitive, and I am not aware of any argument for this idea.
  }
  Perhaps \issueInclusion{} is sufficiently intuitive that it is taken for granted.
  Perhaps the failure of \issueInclusion{} is recognised and I have yet to stumble upon the acknowledgement of its failure.
  Or, perhaps this constraint isn't of significant interest.

  I think \scen{1}~\ref{scen:calc}~and~\ref{scen:animalism} intuitively motivate \issueInclusion{}.
  For, consider the following observation:

  \begin{observation}%
    \label{obs:iIceRestriction}%
    Any counterexample to \issueInclusion{} must involve an event in which an agent concludes \(\phi\) has value \(v\) from \(\Phi\) where:
    % 
    \begin{itemize}
    \item
      A \ros{} between \(\psi\), \(v'\), and \(\Psi\) answers \qWhy{}, such that:
      \begin{itemize}
      \item
        Either \(\psi\) is distinct from \(\phi\), \(v'\) is distinct from \(v\), or \(\Psi\) is distinct from \(\Phi\).
      \item
        There is no prior or present event in which the agent concludes \(\psi\) has value \(v'\) from \(\Psi\).
      \end{itemize}
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{observation}
  %
  \begin{motivation}{obs:iIceRestriction}
    Suppose an agent concludes \(\phi\) has value \(v\) from \(\Phi\).
    Then, the agent has a \wit{} for a \ros{} between \(\phi\), \(v\), and \(\Phi\).
    Hence, a \ros{} between \(\phi\), \(v\), and \(\Phi\) answering \qWhy{} is compatible with \issueInclusion{}.

    Likewise if there is a prior or present event in which the agent concludes \(\psi\) has value \(v'\) from \(\Psi\) then the agent has a \wit{} for a \ros{} between \(\phi\), \(v\), and \(\Phi\).
  \end{motivation}

  \autoref{obs:iIceRestriction} neatly combines with the intuition that the only \ros{1} which answer \qWhy{} with respect to \scen{1}~\ref{scen:calc}~and~\ref{scen:animalism} are, respectively:
  \begin{itemize}
  \item
    The \ros{} between \propM{\gistCalcEq{}}, \valI{True}, and something about the calculator.
  \item
    The \ros{} between \propI{Four legs good, two legs bad}, \valI{True} and something about the existence of Snowball's explanation.
  \end{itemize}
  %
  Indeed, an implicit acceptance of \issueInclusion{} may motivate the given intuitions.
\end{note}

\begin{note}
  No argument for \issueInclusion{} will be given.
  The goal of this document is to provide a recipe for generating counterexamples to \issueInclusion{}.

  By `recipe', I mean an description of some features which hold of \scen{1} and an account of the way in which these combine which entails violations of \issueInclusion{}.
  With the recipe in hand, we will construct a few counter samples, but our interest is with the way in which \issueInclusion{} fails, rather than the failure of \issueInclusion{}.

  In other words, the goal of this document is to show that any \scen{0} which satisfies a collection of features deductively entails \issueInclusion{} does not hold.
  This means definitions, and propositions which extract features from definitions and propositions which link definitions together.%
  \footnote{
    More carefully put, the goal is to establish a collection of features \emph{more-or-less} deductively entails \issueInclusion{} does not hold.
    Some propositions (I think three) fall short of being deductive.
    Though, there is an important distinction between definitions and propositions and the motivation for definitions and propositions.
    I do not claim the relevant motivation is (more-or-less) deductive.
  }

  % \begin{scenario}[Multiplication]%
  %   \label{scen:calc:var}%
  %   An agent enters `\gistCalcLHS{}' into a calculator and presses a button marked `\(=\)'.
  %   The calculator displays `\gistCalcRHS{}'.

  %   The agent pauses for a moment.
  %   They have a good understanding of arithmetic.
  %   And, given the display on the calculator, it follows that if the calculator is trustworthy, then they would not fail to conclude \propM{\gistCalcEq{}} via their understanding of arithmetic.

  %   The agent does the arithmetic and concludes \propM{\gistCalcEq{}}.
  % \end{scenario}

  % \noindent%
  % \autoref{scen:calc:var} is a variation of \autoref{scen:calc} where the agent does arithmetic.

  % Now, suggest that \ros{} holds between the agent's understanding of arithmetic and various other equations.

  % Do any of these \ros{} answer \qWhy{}?
  % Of course, understanding of arithmetic, but are \ros{} required for this?
  % I don't think this is obvious.
  % For example, if reasoning is rule governed,%
  % \footnote{
  %   See, for example, \textcite{Boghossian:2008vf} and \textcite{Broome:2013aa}.
  % }
  % then it seems sufficient to observe the agent followed the relevant rule.


  % Likewise, variation of \autoref{scen:animalism} where the birds understand Snowball's long words but are swayed by Snowball's rhetoric.
  % A \ros{} may hold, but seems irrelevant.
\end{note}

\begin{note}
  Before closing this introduction, we say a little more regarding the recipe for counterexamples.
  First, we briefly consider constraints similar to \issueInclusion{} in the literature on reasons, but highlight some differences.
\end{note}

\subsection*{\issueInclusion{} and rationalisations}
\label{sec:reasons}

% \begin{note}
%   \qWhy{} and \qHow{} are questions about the way an event in which an agent concludes some proposition has some value happened.
% \end{note}

\begin{note}
  \citeauthor{Davidson:1963aa} opens \citetitle{Davidson:1963aa} with the following question:
  % 
  \begin{quote}
    What is the relation between a reason and an action when the reason explains the action by giving the agent's reason for doing what he did?
    We may call such explanations \emph{rationalizations}, and say that the reason \emph{rationalizes} the action.%
    \mbox{}\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}
  % 
  In short, a rationalisation is an explanatory reason for why an agent did some action which states the \agents{} reason for doing what they did.%
  \footnote{
    The \agents{} reason may be understood, in line with \citeauthor{Smith:1994wo} (\citeyear{Smith:1994wo}), as a `motivating reason' where
    \textquote{[t]he distinctive feature of a motivating reason to \(\phi\) is that, in virtue of having such a reason, an agent is in a state that is \emph{explanatory} of her \(\phi\)-ing, at least other things being equal --- other things must be equal because an agent may have a motivating reason to \(\phi\) without that reason's being overriding}
    (\citeyear[96]{Smith:1994wo}).
  }

  Variants of \qWhy{} and \qHow{} suited to rationalisations and actions follow:

  \begin{question}{questionWhyR}{\qWhyR{}}
    Given \(e\) is an event in which \vAgent{} does \(a\):

    \begin{itemize}
    \item
      Which rationalisations explain \emph{why} \(e\) is an event in which \vAgent{} does \(a\)?
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{question}

  \begin{question}{questionHowR}{\qHowR{}}
    Given \(e\) is an event in which \vAgent{} does \(a\):

    \begin{itemize}
    \item
      Which past or present events explain \emph{how} \(e\) is an event in which \vAgent{} does \(a\)?
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{question}

  \noindent%
  \qWhyR{} seeks an understanding of the way an event developed such that an agent did some action in terms of rationalisations.
  In contrast, \qWhy{} seeks an understanding of the way an event developed such that an agent concludes \(\phi\) has value \(v\) from \(\Phi\) in terms of \ros{}.
  Likewise, \qHowR{} seeks an understanding of the way an event developed such that an agent did some action in terms of what happened, while \qHow{} is a restriction of \qHowR{} to events in which the relevant action is `concludes \(\phi\) has value \(v\) from \(\Phi\)'.
\end{note}

\begin{note}
  \qWhyR{} is a variant of \qWhy{} and \qHowR{} is a variant of \qHow{}.
  We make two observations.

  \begin{enumerate}
  \item
    Variants of \issueInclusion{} have been proposed for \qWhyR{} and \qHow{}.
  \item
    There is no straightforward motivation for \issueInclusion{} by constraints on answers to \qWhyR{} in terms of answers to \qHow{}.
  \end{enumerate}
\end{note}

\begin{note}
  \begin{observation}%
    \label{obs:whRconstraintMotivation}%
    Variants of \issueInclusion{} have been proposed for \qWhyR{} and \qHow{}.
  \end{observation}
  \begin{motivation}{obs:whRconstraintMotivation}
    We consider proposals by \citeauthor{Davidson:1963aa} and \citeauthor{Hieronymi:2011aa} in turn.
    \medskip

    \noindent%
    \citeauthor{Davidson:1963aa}'s argument of \citetitle{Davidson:1963aa} is:
    % 
    \begin{quote}
      [R]ationalization is a species of ordinary causal explanation.%
      \mbox{ }\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
    \end{quote}
    % 
    So, a reason explains the action by giving the agent's reason for doing what he did when the agent's reason \emph{causes} the action.

    A causal relation captures how something happened, and \citeauthor{Davidson:1963aa} holds causal relation explains how event happens.
    Hence, \citeauthor{Davidson:1963aa} constrains answers to \qWhyR{} by answers to \qHowR{}.
    \medskip

    \noindent%
    In contrast to causal explanation, \citeauthor{Hieronymi:2011aa} (\citeyear{Hieronymi:2011aa}) appeals to a complex fact:%
    \footnote{
      Consider also \citeauthor{Harman:1973ww}'s account of reason explanation:
      \textquote{Reasons may or may not be causes; but explanation by reasons is not causal or deterministic explanation.
        It describes the sequence of considerations that led to belief in a conclusion without supposing that the sequence was determined} (\citeyear[52]{Harman:1973ww}).
    }
    % 
    \begin{quote}
      [W]henever an agent acts for reasons, the agent, in some sense, takes certain considerations to settle the question of whether so to act, therein intends so to act, and executes that intention in action.

      If this much is uncontroversial (and, under some interpretation, I believe it must be), we can use it as a form for filling out.
      I propose, then, that we explain an event that is an action done for reasons by appealing to the fact that the agent took certain considerations to settle the question of whether to act in some way, therein intended so to act, and successfully executed that intention in action.
      I suggest that \emph{this} complex fact [\dots] is the reason that rationalizes the action---that explains the action by giving the agent's reason for acting.%
      \mbox{ }\hfill\mbox{(\citeyear[421]{Hieronymi:2011aa})}
    \end{quote}
    % 
    In short, \citeauthor{Hieronymi:2011aa} observes a particular (complex) fact holds when an agent agents for reasons.
    If we grant that the fact \citeauthor{Hieronymi:2011aa} observes explains how an agent did what they did, then \citeauthor{Hieronymi:2011aa}'s proposal likewise constrains answers to \qWhyR{} in terms of answers to \qHowR{} --- in order for a rationalisation to explain why and agent did what they did there must be an event where the agent settles what to do via the (\agents{}) reasons present in the rationalisation.
  \end{motivation}

  \noindent%
  In short, the arguments/proposals of \citeauthor{Davidson:1963aa} and \citeauthor{Hieronymi:2011aa} entail a constraint which parallels \issueInclusion{}, with respect to the variant questions \qWhyR{} and \qHowR{}.

  Still, to argue \issueInclusion{} follows from either \citeauthor{Davidson:1963aa}'s or \citeauthor{Hieronymi:2011aa}'s account of rationalisations requires an argument for the following conditional:
  % 
  \begin{itemize}
  \item
    \emph{If} a \ros{} answers \qWhy{} \emph{then} there is a corresponding rationalisation.
  \end{itemize}
  % 
  Given this conditional, \ros{1} which answer \qWhy{} are constrained by answers to \qHowR{}.
  And, answers to \qHow{} are just a special case of answers to \qHowR{} where the action is the agent's conclusion of \(\phi\) having value \(v\) from \(\Phi\).
\end{note}

\begin{note}
  Intuitively, certain \ros{1} correspond to rationalisations.
  For example, we may casually say with relative ease:%
  \footnote{
    This intuition ignores details about what \citeauthor{Davidson:1963aa} and \citeauthor{Hieronymi:2011aa} think reasons are.
  }

  \begin{itemize}
  \item
    The reason for which the agent concluded \propM{\gistCalcEq{}} is \valI{True} was the calculator.
  \item
    The reason for which the birds concluded \propI{Four legs good, two legs bad} is \valI{True} was (the existence of) Snowball's explanation.
  \end{itemize}
  % 
  Abstractly, the following conditional seems plausible:
  \begin{itemize}
  \item
    \begin{itenum}
    \item[\emph{If}:]
      \(e\) is an event in which an agent concludes \(\phi\) has value \(v\) from \(\Phi\).
    \item[\emph{And}:]
      A \ros{} between \(\phi\), \(v\), and \(\Phi\) answers \qWhy{}.
    \item[\emph{Then}:]
      \(\Phi\) rationalises the act in which the agent concludes \(\phi\) has value \(v\).
    \end{itenum}
  \end{itemize}
  % 
  Still, we observed any counterexample to \issueInclusion{} must involve a \ros{} between \(\psi\), \(v'\), and \(\Psi\) (where either \(\psi\) is distinct from \(\phi\), \(v'\) is distinct from \(v\), or \(\Psi\) is distinct from \(\Phi\)).
  Hence, the plausible conditional does not cover \ros{1} which \emph{may} be counterexamples to \issueInclusion{}.

  \begin{observation}
    \label{obs:whRdifficult}%
    There is no straightforward motivation for \issueInclusion{} by constraints on answers to \qWhyR{} in terms of answers to \qHow{}.

    In particular, there is no way link a \ros{} between \(\psi\), \(v'\), and \(\Psi\) to a rationalisation if either \(\psi\) is distinct from \(\phi\) or \(v\) is distinct from \(v'\).
  \end{observation}

  \begin{motivation}{obs:whRdifficult}%
    A rationalisation explains an action by giving an agent's reason for doing the action.
    Hence, rationalisations have a single free variable for the \agents{} reason.

    Applied to conclusions, rationalisations are of the form:
    % 
    \begin{itemize}
    \item
      \(R\) is the \agents{} reason for the conclusion \(\phi\) has value \(v\) (from \(\Phi\)).
    \end{itemize}
    % 
    Where \(R\) stands for an \agents{} reason.

    Now, assume a \ros{} between \(\psi\), \(v'\), and \(\Psi\) answers \qWhy{}, where \(\psi\) is distinct from \(\phi\) and \(v'\) is distinct from \(v\).

    By assumption, the \ros{} answers \qWhy{}, and so to capture the explanatory relation between the \ros{} and the \ros{} and the \agents {} conclusion \(\phi\) has value \(v\) (from \(\Phi\)), \(\phi\) or \(v'\) must be referenced by \(R\).

    Further \(\psi\) is distinct from \(\phi\) and \(v'\) is distinct from \(v\), the relevant rationalisation is for the conclusion \(\psi\) has value \(v'\) (from \(\Phi\)).

    I think the only plausible proposal given these constraints is to understand the \ros{} between \(\psi\), \(v'\) and \(\Psi\) must be understood as the \agents{} reason:
    % 
    \begin{itemize}
    \item
      The \ros{} between \(\psi\), \(v'\), and \(\Psi\) is the \agents{} reason for the conclusion \(\phi\) has value \(v\) (from \(\Phi\)).
    \end{itemize}
    % 
    Yet, we introduced \ros{} as a act-neutral account of what follows from what.
    Hence, the above suggests conclusion \(\phi\) has value \(v\) (from \(\Phi\)) is \emph{from} the \ros{} between \(\psi\), \(v'\), and \(\Psi\).
    So, the relevant \ros{} which answers \qWhy{} is a \ros{} between \(\phi\) having value \(v\) and [the \ros{} between \(\psi\), \(v'\), and \(\Psi\)].
    Yet, our assumption was the \ros{} between \(\psi\), \(v'\), and \(\Psi\) answers \qWhy{}.
  \end{motivation}

  \noindent%
  A rationalisation implicitly may capture a specific kind of \ros{}.
  However, as a rationalisation is, at best, restricted to a specific \ros{1}, rationalisations are not suitable for capturing \ros{1} in general.

  So, while certain accounts of rationalisations constrain answers to a why question by answers to a how question in a similar way to \issueInclusion{}, I doubt it is possible to motivate \issueInclusion{} directly by those accounts of rationalisations.

  To progress further some additional premise is needed.
  For example, if you hold:
  % 
  \begin{itemize}
  \item
    A \ros{} answers \qWhy{} \emph{only if} there is a corresponding rationalisation that answers \qWhyR{} (in line with the plausible conditional above).
  \end{itemize}
  % 
  Then a more carefully developed version of \autoref{obs:whRdifficult} entails it is not possible for a \ros{} between \(\phi\), \(v'\), and \(\Phi\) to answer \qWhy{} (where \(\psi\) is distinct from \(\phi\) or \(v'\) is distinct from \(v\)).
  And, combined with \citeauthor{Davidson:1963aa}'s or \citeauthor{Hieronymi:2011aa}'s account of rationalisations, \issueInclusion{} follows.%
  % \footnote{
  % A key part of such an argument requires specifying the way in which \ros{} connect to an \agents{} reasons.
  % And, I suspect any such specification would amount to a substantive constraint on what an \agents{} reasons may be.
  % 
  % I.e.\ I think such specification is possible, but would not hold for an arbitrary account of what an \agents{} reasons are.
  % In particular, I think counterexamples to \issueInclusion{} are compatible with \citeauthor{Davidson:1963aa}'s, \citeauthor{Hieronymi:2011aa}'s restriction on answers to \qWhyR{} in terms of answers to \qHowR{}.
  % }%
  %   \(^{,}\)%
  \footnote{
    Variants of \qWhy{} and \qHow{} stated in terms of the (epistemic) basing relation.
    Where, the basing relation is understood as a \textquote{relation which holds between a reason and a belief if and only if the reason is a reason for which the belief is held} (\cite{Korcz:2021ue}).

    In contrast to rationalisations, instances of the basing relation concern a belief, rather than action.
    Further, instances of the basing relation are typically tied to justification rather than explanation.
    (See \cite{Korcz:2021ue} and \cite[35]{Pollock:1999tm})
    Still, as an abstract relation, accounts of the basing relation may suggest motivation for or against \issueInclusion{}.

    Now, the core of \autoref{obs:whRdifficult} concerns how rationalisations hold fixed an action.
    And, as basing relations hold fixed a belief, a variant of \autoref{obs:whRdifficult} extends to the basing relation.
    So, accounts of the basing relation do not provide direct motivation \emph{for} \issueInclusion{}.

    Still, given variants of \qWhy{} and \qHow{}, motivation \emph{against} \issueInclusion{}.

    For example, \citeauthor{Swain:1981wd}'s (\citeyear{Swain:1981wd}) `causal-counterfactual' account of the basing relation is promising in name.
    Perhaps there are instances of the basing relation which hold given the causal relations of counterfactual events!
    Yet, the relevant counterfactuals of \citeauthor{Swain:1981wd}'s concern events which happened that would have been a cause if the actual cause of an \agents{} belief had not occurred, and hence require a \wit{0}.

    Indeed, the \emph{causal} accounts of the basing relation I have worked through in detail (\cite{Moser:1989tv}, \cite{Ye:2020ux}, and \cite{Turri:2011aa}) seem to motivate \issueInclusion{}, at best.

    \emph{Doxastic} accounts of the basing relation are more permissive, and \citeauthor{Tolliver:1982us}'s (\citeyear{Tolliver:1982us}) account is compatible with failures of a variant of \issueInclusion{} as the account makes no reference to anything that happened, only what the agent believes at a given time.
    Still, the examples \citeauthor{Tolliver:1982us} gives to motivate their account are consistent with a variant of \issueInclusion{}.

    Further, some care must be taken in order to understand the way in which an account of the basing relation is connected to concluding.
    For example, taken at face value, \citeauthor{Evans:2013tw}'s disposition account of the basing relation holds:
    \textquote{S's belief that \emph{p} is based on \emph{m} iff S is disposed to revise her belief that \emph{p} when she loses \emph{m}} (\citeyear[2952]{Evans:2013tw})/
  This is suggestive of counterexamples to a variant of \issueInclusion{} as an agent may be disposed without witnessing the disposition.
  However, \citeauthor{Evans:2013tw}' theory is designed to capture what \emph{sustains} an agent's belief.%
  And, our interest with \issueInclusion{} is restricted to the event in which an agent concludes \(\phi\) has value \(v\) from \(\Phi\).
  \issueInclusion{} is silent about whatever happens after an agent concludes.

  Similar observations extend to \citeauthor{Moretti:2019wx}'s (\citeyear{Moretti:2019wx}) account of basing via enthymematic inferences, and to  \citeauthor{Audi:1986to}'s suggestion of cases in which `[b]elieving for a reason does not entail having \textbf{come} to believe for that reason, or for any reason' (\citeyear[32--33]{Audi:1986to}).
  % Expansion of an enthymematic inferences may be basis for an \agents{} belief with respect to justification, but it is not clear the expansion of an enthymematic inference matters with respect to an \agents{} conclusion if the agent concludes via an enthymematic inference.
  % 
  % An agent may come to believe for one reason, and sustain the belief by some other reason, but unless the sustaining reason explains why the agent formed the initial belief, such cases are of no interest to us.
  }
\end{note}

% \begin{note}
%   Motivation.
%   Difficulty here is that both \citeauthor{Davidson:1963aa} and \citeauthor{Hieronymi:2011aa} are concerned with an agent's reason(s).

%   It is not clear that \ros{} which answers \qWhy{} captures agent's reasons.


%   In general, lots of this explain why.

%   I do not think \issueInclusion{} is too distinct.
%   \ros{} is from the \agpe{}.
%   Hence, answers to \qWhy{} are close.
%   But this is still distinct from a reason.
% \end{note}

\section*{Counterexamples to \issueInclusion{}}

\begin{note}
  The goal is to provide a recipe for constructing counterexamples to \issueInclusion{}.
  Specifically, the recipe identifies \scen{1} with three key features:
  %
  \begin{enumerate}
  \item
    An event \(e\) in which an agent \vAgent{} concludes \(\phi\) has value \(v\) from \(\Phi\).
  \item
    A \ros{} between \(\psi\), \(v'\), and \(\Psi\) such that:
    \begin{itemize}
    \item
      There is no prior or present event in which the agent concludes \(\psi\) has value \(v'\) from \(\Psi\).
    \item
      The \ros{} explains \emph{why} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\).
    \end{itemize}
  \end{enumerate}
  %
  And, from \autoref{obs:iIceRestriction}, we have established either \(\psi\) is distinct from \(\phi\), \(v'\) is distinct from \(v\), or \(\Psi\) is distinct from \(\Phi\).
\end{note}

\begin{note}
  This document has three parts.
  \begin{TOCEnum}
  \item
    \autoref{part:prep} (\nameref{part:prep})

    Before constructing counterexamples to \issueInclusion{} we detail key ideas introduced in this introduction.

    In particular, we detail the way in which we understand an event in which an agent concludes, and \ros{1}.
    And, we provide a precise account of answers to \qWhy{} and \qHow{}.

    The details are important.
    For, without a sufficiently detailed account of the phenomena of interest, any recipe proposed with fail to identify \scen{1}.
    And, without a detailed account of \qWhy{} and \qHow{} it is unclear whether any identified \scen{1} is a counterexample to \issueInclusion{}.

    Strictly, then, the main argument focuses on \emph{variations} of \qWhy{}, \qHow{}, and \issueInclusion{}.
    We argue any counterexample to the variation of \issueInclusion{} is a counterexample to \issueInclusion{} itself.
    Whether this argument holds depends on the way in which you understand `why' and `how', though whether the recipe constructs counterexamples to the variation of \issueInclusion{} should be clear for you to evaluate.
  \item
    \autoref{part:ing}: (\nameref{part:ing})

    To construct counterexamples to \issueInclusion{} we require a \ros{} between \(\psi\), \(v'\), and \(\Psi\) such that there is no prior or present event in which the agent concludes \(\psi\) has value \(v'\) from \(\Psi\).

    The idea of a \fc{} is used to identify candidate \ros{}.

    And, the \ros{} between \(\psi\), \(v'\), and \(\Psi\) also explains \emph{why} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\).

    To link \ros{1} obtained from \fc{1} to answers to \qWhy{} we introduce two ideas.
    First, the idea of an agent \tCV{}, and second the idea of a \requ{}.

    \requ{3} are the key link between \ros{} and answers to \qWhy{}, and whether an agent is \tCV{} \(\phi\) has value \(v\) from \(\Phi\) is used to motivate the existence of \requ{1}.

    Still, \fc{1}, an agent \tCV{0}, and the idea of a \requ{} do not (individually or collectively) entail counterexamples to \issueInclusion{}, these ingredients must be combined in the right way to obtain the desired counterexamples.
    Hence, these ingredients are introduced and motivated without presupposing counterexamples to \issueInclusion{} exist.
  \item
    \autoref{part:dir} (\nameref{part:dir})

    The final part details the way in which \fc{1}, an agent \tCV{0}, and \requ{} combine with respect to particular events to obtain counterexamples to \issueInclusion{}.
    A handful of counter-samples are given, and a few remaining issues are considered.
  \end{TOCEnum}
\end{note}

\begin{note}
  This is an outline of what is to follow.
  I do not have a brief account.

  Still, a pair of quick notes:

  First, I hold explanatory reasons are factive, and I think that answers to \qWhy{} reduce to psychological facts of an agent, specifically psychological facts which hold of the agent when they conclude.%
  % \footnote{
  %   This is in slight tension with views of reasons explanation advanced by~(\cite{Dancy:2000aa}) and~(\cite{Alvarez:2013aa}), in which the state of affairs may be an agent's reason (and not just the evaluation of some state of affairs).
  %   Though, the argument will not depend on assuming that the relations reduce to psychological facts.

  %   See~(\cite[413--418]{Hieronymi:2011aa}),~(\cite[3--5]{DOro:2013vh}), and~(\cite[\S2]{Alvarez:2017aa}) for more.
  % }

  Given what I hold and think, from a very broad perspective, \issueInclusion{} is a restriction on which psychological facts of an agent matter when an agent concludes:

  If \issueInclusion{} holds, the only facts which matter are those which secure the \ros{} between \(\phi\), \(v\), and \(\Phi\).

  And, if \issueInclusion{} fails, facts other than those which secure the \ros{} between \(\phi\), \(v\), and \(\Phi\) matter, specifically, facts which secure some \ros{} between \(\phi\), \(v\), and \(\Phi\).
\end{note}

% \begin{note}
%   As seen above with respect to \autoref{scen:animalism}, it follows from \issueInclusion{} that the content of Snowball's explanation is irrelevant.
%   For, the birds do not understand Snowball's explanation, hence there is no event in which the birds reason from the content to \propI{Four legs good, two legs bad} has value \valI{True}.
%   And, I think this is correct.

%   However, parallel reasoning entails the agent's understanding of arithmetic is irrelevant with respect to \autoref{scen:calc}.
%   And, I do not think this entailment holds.
%   I think it may be the case that a relation between \propM{\gistCalcEq{}}, \valI{True} and the agent's understanding of arithmetic \emph{may} answer \qWhy{}.
%   Whether this is the case will depend on whether some additional details hold of~\autoref{scen:calc}.
%   Still, as the details matter, the entailment, and hence \issueInclusion{}, is not right.
% \end{note}

\begin{note}
  Still, there is distinction between psychological facts and the exercise of agency.
  To illustrate, there a senses in which the following two questions are distinct:

  \begin{itemize}
  \item
    \emph{Why} is \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\)?
  \item
    \emph{Why} is it the case \vAgent{} concludes \(\phi\) has value \(v\) in \(e\)?
  \end{itemize}

  Consider \citeauthor{Davidson:1973vd}'s climber:

  \begin{quote}
    A climber might want to rid himself of the weight and danger of holding another man on a rope, and he might know that by loosening his hold on the rope he could rid himself of the weight and danger.
    This belief and want might so unnerve him as to cause him to loosen his hold, and yet it might be the case that he never chose to loosen his hold, nor did he do it intentionally.%
    \mbox{ }\hfill\mbox{(\citeauthor[79]{Davidson:1973vd})}
  \end{quote}

  The \agents{} belief and want are psychological facts about the agent, and answer why \emph{the event} is an event in which the agent loosens their hold on the rope.
  However, the \agents{} belief and want do not answer why \emph{the agent} loosens their hold on the rope.
  Indeed, there seems no answer to why the agent loosens their hold on the rope --- the act was not an exercise of agency.

  \citeauthor{Davidson:1973vd}'s climber does not conclude.
  Still, if an agent may loosen their grip without exercising their agency, it is seems plausible that a \ros{} between \(\psi\), \(v'\) and \(\Psi\) which answers why is \emph{\(e\) is an event} in which \vAgent{} concludes \(\phi\) has value \(v\) may fail to answer why is it the case the agent concludes \(\phi\) has value \(v\) in \(e\).

  In short, it is not clear that any counterexample to \issueInclusion{} relates to an exercise of agency.
  Whether this matters is for you to decide.
  On some days I think this matters a great deal, and on other days I doubt there is any coherent idea of what an exercise of agency amounts to.

  We set concerns about agency aside for the argument against \issueInclusion{}, and then motivate that relevant counterexamples either involve agency or have nearby neighbours which involve agency.
\end{note}

%   \begin{quote}
%     Sometimes the explanation of why a person does something has a particular character:
%     roughly, it involves the person's rationality in a distinctive way that I shall not try to describe.
%     Then we say the person does what she does for a reason.
%     We might say ‘The reason for which Hannibal used elephants was to terrorize the Romans'.
%     The reason for which a person does something is called a ‘motivating reason'.
%     In general, a motivating reason is whatever explains or helps to explain what a person does in the distinctive way that involves her rationality.
%     \mbox{}\hfill\mbox{(\citeyear[46--47]{Broome:2013aa})}
%   \end{quote}
% \end{note}

% \begin{note}
%   \color{red}
%   \begin{quote}
%     \emph{R} is a primary reason why an agent performed the action \emph{A} under the description \emph{d} only if \emph{R} consists of a pro attitude of the agent toward actions with a certain property, and a belief of the agent that \emph{A}, under the description \emph{d}, has that property.\newline
%     \mbox{ }\hfill\mbox{(\citeyear[687]{Davidson:1963aa})}
%   \end{quote}

%   We have distinguished \qWhy{} from pro-attitudes.
%   However, fill in whatever motivation.
%   What matters is the belief.
%   This is the relevant proposition-value pair.

%   If \citeauthor{Davidson:1963aa}, then granting restriction, seems we don't need to look beyond the proposition-value pair.
% \end{note}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% TeX-engine: luatex
%%% End:
