\chapter{\qWhy{} and \qHow{} an agent concludes}
\label{cha:intro}

\begin{note}
  Our interest is understanding the way an event in which an agent concludes happens.

  \begin{scenario}[Calculation]%
    \label{scen:calc}%
    An agent enters `\gistCalcLHS{}' into a calculator and presses a button marked `\(=\)'.
    The calculator displays `\gistCalcRHS{}'.

    The agent pauses for a moment.
    They have a good understanding of arithmetic.
    And, given the display on the calculator, it follows that if the calculator is trustworthy, then they would not fail to conclude \propM{\gistCalcEq{}} via their understanding of arithmetic.

    The agent concludes \propM{\gistCalcEq{}}.
  \end{scenario}

  \noindent%
  Intuitively, the agent concludes \propM{\gistCalcEq{}} from the calculator.
  More could be said about the way the agent concludes but these details won't be of too much interest.%
  \footnote{
    For example, classify the agent as regarding the calculator as a source of testimony, adding that testimony are factive, and so concluded \propM{\gistCalcEq{}} from the testimony of the calculator.
  }

  The agent's understanding of arithmetic, it seems, had no significant role.
  So long as the calculator was correct, the agent had the opportunity to conclude \propM{\gistCalcEq{}} by their understanding of arithmetic, but the agent did not do any arithmetic.
\end{note}

\begin{note}
  Abstracting a little, \propM{\gistCalcEq{}} corresponds to a state of affairs.
  If the truths of mathematics are necessary, then this state of affairs never fails to be, but \propM{\gistCalcEq{}} captures the way things are in the same way as \propI{Kangaroos have tails} captures the way things are.
  For ease we refer to states of affairs as propositions.

  Continuing the abstraction, when the agent concludes \propM{\gistCalcEq{}}, we may say the agent concludes \propM{\gistCalcEq{}} has value \valI{True}.
  Even if \propM{\gistCalcEq{}} never fails to be, the calculator may have been faulty and the agent may have concluded \propM{\gistCalcEqBad{}} has value \valI{True} or \propM{\gistCalcEq{}} has value \valI{False}.

  Likewise, as the agent concluded \propM{\gistCalcEq{}} has value \valI{True} from the calculator, we may say the agent concluded \propM{\gistCalcEq{}} has value \valI{True} from some \pool{} of premises.
\end{note}

\begin{note}
  Abstracting from almost all the details of \autoref{scen:calc} then, we say an agent concluded some \prop{} \(\phi\) has some \val{} \(v\) from some \pool{} of premises \(\Phi\).%
  \footnote{
    For ease, we abbreviate `\pool{} of premises' to `\pool{}'.
  }

  The `\emph{from}' in the previous statement seems to do work.
  A sequence happened in which the agent used the calculator and then concluded \propM{\gistCalcEq{}} has value \valI{True}.
  However, in addition to this sequence, something about the calculator led the agent to conclude \propM{\gistCalcEq{}} has value \valI{True}.

  Our understanding of \autoref{scen:calc} is be different if the agent applied their understanding of arithmetic, or if the agent asked some other person.

  Abstractly, we say something about the calculator \emph{supports} \propM{\gistCalcEq{}} being \valI{True}, from the \agpe{}.

  We limit ourselves to two basic assumptions about \ros{1}:
  %
  \begin{enumerate}
  \item
    When an agent concludes \(\phi\) has value \(v\) from \(\Phi\) a \ros{} between \(\phi\), \(v\) and \(\Phi\) holds, from the \agpe{}
  \item
    A \ros{} between \(\phi\), \(v\) and \(\Phi\) may hold, from an \agpe{}, without a prior event in which agent concludes \(\phi\) has value \(v\) from \(\Phi\).
  \end{enumerate}
  %
  Speaking in terms of \ros{1} allows abstraction from what happens when an agent concludes.
  A \ros{} holds between \propM{\gistCalcEq{}}, \valI{True} and the calculator when the agent concludes \propM{\gistCalcEq{}}, \valI{True} from the calculator.
  Still, a \ros{} may also hold between \propM{\gistCalcEq{}}, \valI{True} and the \agents{} understanding of arithmetic, though the agent did not conclude from their understanding of arithmetic.

  Further, it seems \ros{1} provide some understanding of the way an event in which some agent concludes happens.

  Specifically, a \ros{} seems to provide some understanding of \emph{why} an event in which some agent concludes happens.
  A \ros{} does not clearly provide some understanding of \emph{how} the event in which the agent concludes happens.

  Still, there is a plausible connexion between `why' and `how' with respect to \autoref{scen:calc}.
  For, the agent concludes \propM{\gistCalcEq{}} has value \valI{True} from some \pool{}, and hence the agent has a `\wit{}' for the relevant \ros{}.
  In other words, a \ros{} between \(\psi\), \(v'\), and \(\Psi\) may hold when an agent concludes \(\phi\) has value \(v\) from \(\Phi\), as the agent does not conclude \(\psi\) has value \(v'\) from \(\Psi\), this \ros{} is irrelevant to why the agent concludes \(\phi\) has value \(v\) from \(\Phi\).
\end{note}

\begin{note}
  Here's a second, slightly more complex \scen{0}:

  \begin{scenario}[Animalism]%
    \label{scen:animalism}%
    `Four legs good, two legs bad.'
    This, he said, contained the essential principle of Animalism.
    Whoever had thoroughly grasped it would be safe from human influences.
    The birds at first objected, since it seemed to them that they also had two legs, but Snowball proved to them that this was not so.

    `A bird's wing, comrades,' he said, `\textsc{is} an organ of propulsion and not of manipulation.
    It should therefore be regarded as a leg.
    The distinguishing mark of Man is the \emph{hand}, the instrument with which he does all his mischief.'

    The birds did not understand Snowball's long words, but they accepted his explanation, and all the humbler animals set to work to learn the new maxim by heart.
    \textsc{four legs good, two legs bad}, was inscribed on the end wall of the barn\dots%
    \mbox{ }\hfill\mbox{(\cite[25]{Orwell:1976aa})}%
    \newline
  \end{scenario}

  \noindent%
  The agents of interest are the birds, and the conclusion is the essential principle of Animalism:
  \propI{Four legs good, two legs bad} has value \valI{True}.

  Snowball provided an argument against an objection from the birds, and the birds concluded \propI{Four legs good, two legs bad} is \valI{True} from Snowball's explanation.

  Though, as \citeauthor{Orwell:1976aa} highlights, the birds did not conclude \propI{Four legs good, two legs bad} from \emph{the content of} Snowball's explanation.
  (Some words were too long.)
  Instead, the birds concluded, at least in part, from (the existence of) \emph{Snowball's explanation}.

  % In parallel to the agent's understanding of arithmetic from~\autoref{scen:calc} the birds of~\autoref{scen:animalism} did not, in part, conclude \propI{Four legs good, two legs bad} from the content of Snowball's explanation.
\end{note}

\begin{note}
  In line with the abstraction given, we may say:
  The birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the existence of Snowball's explanation.
  And, for each bird, a \ros{} holds between \propI{Four legs good, two legs bad}, \valI{True}, and the existence of Snowball's explanation.
  {
    \color{red}
    And, \wit{0}.
  }
\end{note}

\section*{\qWhy{}, \qHow{} and \issueInclusion{}}
\label{cha:intro:why-how}

\begin{note}
  % Our interest is understanding the way an event in which some agent concludes some proposition \(\phi\) has some value \(v\) from some \pool{} \(\Phi\) happens.
  \phantlabel{how-and-why-first-mention}%
  With respect to understanding the way an event in which an agent concludes happens we distinguish two questions; `\qWhy{}' and `\qHow{}':

  \begin{question}{questionWhy}{\qWhy{}}
    \cenLine{
      \begin{VAREnum}
      \item
        Agent: \vAgent{}
      \item
        \prop{2}: \(\phi\)
      \item
        \val{2}: \(v\)
      \item
        Event: \(e\)
      \item
        \mbox{ }
      \end{VAREnum}
    }
    \medskip

    Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
    \begin{itemize}
    \item
      Which \ros{} between \prop{1}, \val{1}, and \pool{1} explain \emph{why} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\)?
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{question}

  \begin{question}{questionHow}{\qHow{}}
    \label{q:how}
    \cenLine{
      \begin{VAREnum}
      \item
        Agent: \vAgent{}
      \item
        \prop{2}: \(\phi\)
      \item
        \val{2}: \(v\)
      \item
        Event: \(e\)
      \item
        \mbox{ }
      \end{VAREnum}
    }
    \medskip

    Given \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\):
    \begin{itemize}
    \item
      Which past or present events explain \emph{how} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\)?
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{question}
\end{note}

\begin{note}
  \qWhy{} seeks an understanding of the way an agent concluded \(\phi\) has value \(v\) in terms of \ros{} between \prop{1}, \val{1}, and \pool{1}.
  And \qHow{} seeks an understanding of the way an agent concluded \(\phi\) has value \(v\) in terms of what happened.

  Specifically, both \qWhy{} and \qHow{} seek `explanatory reasons', summarised by \citeauthor{Hieronymi:2011aa} (\citeyear{Hieronymi:2011aa}) as:
  % 
  \begin{quote}
    [T]he reasons why things happen, or why things are the way they are.\newline
    \mbox{ }\hfill\mbox{(\citeyear[410]{Hieronymi:2011aa})}
  \end{quote}
  % 
  To borrow an an example given by \citeauthor{Hieronymi:2011aa}, the extreme heat or the faulty construction is a reason why the engine failed (\citeyear[409]{Hieronymi:2011aa}).
  Likewise, the engine failing may be a reason why the steamboat is moored, and the steambot being moored is a reason why the hotel is fully booked, etc.%
  \footnote{
    Neither \qWhy{} nor \qHow{} seek exhaustive reasons.
    Following \citeauthor{Hieronymi:2011aa}'s example, the faulty construction is a reason why the engine failed, but the faulty construction may only lead to engine failure in specific use cases, and so `the engine was used in salt water' is also an explanatory reason.
  }
\end{note}

\begin{note}
  In general, `why?' and `how?' are distinct questions.
  For example, consider:

  \begin{scenario}[England AD 932]
    \label{scen:king}
    \vspace{-\baselineskip}
    \begin{screenplay}
    \item[OLD WOMAN:]
      Well, how did you become King, then?
    \item[ARTHUR:]
      The Lady of the Lake, her arm clad in purest shimmering samite, held Excalibur aloft from the bosom of the waters to signify that by Divine Providence\space\dots\space I, Arthur, was to carry Excalibur\dots\space that is why I am your King.
    \item[DENNIS:]
      Look, strange women lying on their backs in ponds handing over swords\space\dots\space that's no basis for a system of government.
      Supreme executive power derives from a mandate from the masses not from some farcical aquatic ceremony.\newline
      \mbox{ }\hfill\mbox{(\cite[8--9]{Cleese:1974aa})}
    \end{screenplay}
    \vspace{-\baselineskip}
  \end{scenario}

  The old woman asks Arthur \emph{how} the become king.
  Arthur provides an answer in terms of some events which happened, but emphasises that those events are \emph{why} Arthur is king.
  In turn, Dennis accepts the answer provided by Arthur as an account of how Arthur became king but rejects the answer an account of why Arthur is king.
  Instead, an answer is expected in involve the absence of an appropriate system of governance in England.
  So, the answer provided by Arthur is accepted by Dennis as an answer to how, but not as an answer to why.
  % The distinction between `why?' and `how?' present in \autoref{scen:king} parallels \qWhy{} and \qHow{} with respect to conclusions.
  % In \autoref{scen:calc}, the agent considered applying their understanding of arithmetic, but their understanding of arithmetic seems no basis for the conclusion.
  % Instead, it is the use of the calculator.
  % When we consider the \ros{} between \propM{\gistCalcEq{}}, \valI{True}, and the calculator, we seem to get some understanding of why the agent concluded \gistCalcEq{}.
  % In parallel, the sequence of the agent using the calculator and concluding \propM{\gistCalcEq{}} has value \valI{True}
\end{note}

\begin{note}
  So, \qWhy{} and \qHow{} are plausibly distinct questions.
  Still, in the case of \qWhy{} and \qHow{} the following constraint on answers to \qWhy{} in terms of answers to \qHow{} seems intuitive:

  \begin{constraint}{consInclusion}{\issueInclusion{}}
    \mbox{ }
    \vspace{-\baselineskip}
    \begin{itemize}
    \item
      \begin{itenum}
      \item[\emph{If}:]
        Some \ros{} between \prop{0}, \val{0}, and \pool{} answers \qWhy{}.
      \item[\emph{Then}:]
        An event in which the agent concludes the proposition has the value from the \pool{} answers \qHow{}.
      \end{itenum}
    \end{itemize}
    \vspace{-\baselineskip}
  \end{constraint}

  \noindent%
  In short, for any \ros{} between a \prop{0}, \val{0}, and \pool{} which grants some understanding of the way an agent concluded \(\phi\) has value \(v\), there is an event such that the agent concludes the proposition has the value from the \pool{}.%
  \footnote{
    What happened does not entail a corresponding \ros{}.
    For example, in \autoref{scen:calc} the agent presses a button marked `\(=\)'.
    However, the agent does not conclude \propM{\gistCalcEq{}} has value \valI{True} \emph{from} pressing the button marked `\(=\)'.
    Hence, no \ros{} seems to hold between \propM{\gistCalcEq{}}, \valI{True}, and the pressing the button marked `\(=\)'.
  }
\end{note}

\begin{note}
  \scen{3}~\ref{scen:calc}~and~\ref{scen:animalism} suggest \issueInclusion{} holds:%
  % \footnote{
  % The \illu{1} of \qWhy{} by \scen{3}~\ref{scen:calc}~and~\ref{scen:animalism} is somewhat limited, as no \scen{0} involves an account of what motivates the respective agents.
  % \qWhy{} is not designed to rule out what motivates an agent.
  % For example, one may add to \autoref{scen:calc} that the agent wants to calculate \gistCalcLHS{}.
  % Functions as a premise, given the understanding of \pool{1}.
  % More detail follows in~\autoref{cha:clar}.
  % }
  %
  \begin{itemize}[noitemsep]
  \item
    With respect to~\autoref{scen:calc}, the only answer to \qWhy{} seems to be the \ros{} between \propM{\gistCalcEq{}}, \valI{True}, and something about the calculator.
    And, the agent concludes \propM{\gistCalcEq{}} has value \valI{True} from the calculator.
    Hence, there is a corresponding answer to \qHow{}.

    A \ros{} may hold between \propM{\gistCalcEq{}}, \valI{True} and whatever \pool{} would be associated with the agent calculating \gistCalcEq{} from their understanding of arithmetic.
    However, there is no event in which the agent concludes \propM{\gistCalcEq{}}, has value \valI{True} by doing arithmetic.
    So, there is no answer to \qHow{} with respect to the agent's understanding of arithmetic, and given \issueInclusion{}, it is not possible for a \ros{} to answer \qWhy{}.
  \item
    With respect to~\autoref{scen:animalism}, the only answer to \qWhy{} seems to be the \ros{} between \propI{Four legs good, two legs bad}, \valI{True} and something about the existence of Snowball's explanation.
    And, the birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the existence of Snowball's explanation.

    As the birds did not understand the content of Snowball's explanation, it seems implausible that a \ros{} held between \propI{Four legs good, two legs bad}, \valI{True}, and the content of Snowball's explanation.
    Still, as there is no event in which the birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the content of Snowball's explanation, and no such \ros{} may answer \qWhy{} if \issueInclusion{} holds.
  \end{itemize}
\end{note}

\begin{note}
  \issueInclusion{} seems plausible, and seems to do work.%
  \footnote{
    Note, \qHow{} does not explicitly require the relevant event to be the event in which the agent concludes \(\phi\) has value \(v\) from \(\Phi\).
    Hence, a previous event in which the agent concluded \propM{\gistCalcEq{}} has value \valI{True} may answer \qHow{}.
    Still, given \gistCalcEq{} in~\autoref{scen:calc} functions as some arbitrary multiplication that the agent may calculation, we may assume the agent has never calculated \gistCalcEq{}.
  }\(^{,}\)%
  \footnote{
    Alternatively, \issueInclusion{} may be thought to narrow the range on answers to \qWhy{}.
    That is to say, \issueInclusion{} functions to disambiguate the sense of `why' used in the statement of \qWhy{}.
    If so, then \issueInclusion{} is not a constraint, it is simply part of the way \qWhy{} is understood.
    However, I think the sense of `why' present in \qWhy{} may be understood without reference to \issueInclusion{}, and hence that \issueInclusion{} amounts to a substantive constraint.
    The document will assume this is the case, but only framing depends on this.
  }

  Still, we have only considered two \scen{1} and \issueInclusion{} is a general constraint.
  Hence, if there is some doubt regarding \issueInclusion{} then further argument is required.
  It is not obvious that there are \scen{1} in which \issueInclusion{} fails to hold.
  However, lack of apparent counterexamples is no argument.

  Though I would like to consider an argument for \issueInclusion{}, I am not aware of any.%
  \footnote{
    The particular construct of \qWhy{}, \qHow{}, and \issueInclusion{} is somewhat idiosyncratic, and so it is no surprise there are no direct argument for \issueInclusion{}.
    However, I take the idea captured by \issueInclusion{} to be intuitive, and I am not aware of any argument for this idea.
  }
  Perhaps \issueInclusion{} is sufficiently intuitive that it is taken for granted.
  Perhaps the failure of \issueInclusion{} is recognised and I have yet to stumble upon the acknowledgement of its failure.
  Or, perhaps this constraint isn't of significant interest.

  In any case, no argument for \issueInclusion{} will be given.
  Instead, the goal of this document is to provide a recipe for generating counterexamples to \issueInclusion{}.

  By `recipe', I mean an description of some features which hold of \scen{1} and an account of the way in which these combine which entails violations of \issueInclusion{}.
  With the recipe in hand, we will construct a few counter samples, but our interest is with the way in which \issueInclusion{} fails, rather than the failure of \issueInclusion{}.

  In other words, the goal of this document is to show that any \scen{0} which satisfies a collection of features deductively entails \issueInclusion{} does not hold.
  This means definitions, and propositions which extract features from definitions and propositions which link definitions together.%
  \footnote{
    More carefully put, the goal is to establish a collection of features \emph{more-or-less} deductively entails \issueInclusion{} does not hold.
    Some propositions (I think three) fall short of being deductive.
    Though, there is an important distinction between definitions and propositions and the motivation for definitions and propositions.
    I do not claim the relevant motivation is (more-or-less) deductive.
  }
\end{note}

\begin{note}
  Note, any counterexample to \issueInclusion{} must involve an event in which an agent concludes \(\phi\) has value \(v\) from \(\Phi\) where:
  % 
  \begin{itemize}
  \item
    A \ros{} between \(\psi\), \(v'\), and \(\Psi\) answers \qWhy{}, such that:
    \begin{itemize}
    \item
      Either \(\psi\) is distinct from \(\phi\), \(v'\) is distinct from \(v\), or \(\Psi\) is distinct from \(\Phi\).
    \item
      There is no prior or present event in which the agent concludes \(\psi\) has value \(v'\) from \(\Psi\).
    \end{itemize}
  \end{itemize}
  % 
  To see this, observe that when an agent concludes \(\phi\) has value \(v\) from \(\Phi\) have an answer to \qHow{}.
  Hence, a \ros{} between \(\phi\), \(v\), and \(\Phi\) answering \qWhy{} is compatible with \issueInclusion{}.

  Intuition of \scen{1}~\ref{scen:calc}~and~\ref{scen:animalism} is that no other \ros{} matters.

  \begin{scenario}[Multiplication]%
    \label{scen:calc:var}%
    An agent enters `\gistCalcLHS{}' into a calculator and presses a button marked `\(=\)'.
    The calculator displays `\gistCalcRHS{}'.

    The agent pauses for a moment.
    They have a good understanding of arithmetic.
    And, given the display on the calculator, it follows that if the calculator is trustworthy, then they would not fail to conclude \propM{\gistCalcEq{}} via their understanding of arithmetic.

    The agent does the arithmetic and concludes \propM{\gistCalcEq{}}.
  \end{scenario}

  \noindent%
  \autoref{scen:calc:var} is a variation of \autoref{scen:calc} where the agent does arithmetic.

  Now, suggest that \ros{} holds between the agent's understanding of arithmetic and various other equations.

  Do any of these \ros{} answer \qWhy{}?
  Of course, understanding of arithmetic, but are \ros{} required for this?
  I don't think this is obvious.
  For example, if reasoning is rule governed,%
  \footnote{
    See, for example, \textcite{Boghossian:2008vf} and \textcite{Broome:2013aa}.
  }
  then it seems sufficient to observe the agent followed the relevant rule.


  Likewise, variation of \autoref{scen:animalism} where the birds understand Snowball's long words but are swayed by Snowball's rhetoric.
  A \ros{} may hold, but seems irrelevant.
\end{note}

\begin{note}
  Before closing this introduction, say a little more regarding the recipe for counterexamples.
  First, we briefly consider constraints similar to \issueInclusion{} in the literature on reasons, but highlight a key difference.
\end{note}

\section*{Rationalalisations and the basing relations}

\subsection*{\issueInclusion{} and rationalisations}
\label{sec:reasons}

\begin{note}
  \qWhy{} and \qHow{} are questions about the way an event in which an agent concludes some proposition has some value happened.
\end{note}

\begin{note}
  \citeauthor{Davidson:1963aa} opens \citetitle{Davidson:1963aa} with the following question:
  % 
  \begin{quote}
    What is the relation between a reason and an action when the reason explains the action by giving the agent's reason for doing what he did?
    We may call such explanations \emph{rationalizations}, and say that the reason \emph{rationalizes} the action.%
    \mbox{}\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}
  % 
  \citeauthor{Davidson:1963aa}'s interest is with explanatory reasons \emph{such that} the explanatory reason involves the agent's reason.%
  \footnote{
    These may also be understood, in line with \citeauthor{Smith:1994wo} (\citeyear{Smith:1994wo}), as `motivating reasons':
    \begin{quote}
      The distinctive feature of a motivating reason to \(\phi\) is that, in virtue of having such a reason, an agent is in a state that is \emph{explanatory} of her \(\phi\)-ing, at least other things being equal --- other things must be equal because an agent may have a motivating reason to \(\phi\) without that reason's being overriding.%
      \mbox{}\hfill\mbox{(\citeyear[96]{Smith:1994wo})}
    \end{quote}
  }

  So, two questions, which mirror \qWhy{} and \qHow{}:

  \begin{question}{questionWhyR}{\qWhyR{}}
    \cenLine{
      \begin{VAREnum}
      \item
        Agent: \vAgent{}
      \item
        Action: \(a\)
      \item
        \mbox{ }
      \end{VAREnum}
    }
    \medskip

    Given \(e\) is an event in which \vAgent{} does \(a\):

    \begin{itemize}
    \item
      Which rationalisations explain \emph{why} \(e\) is an event in which \vAgent{} does \(a\)?
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{question}

  \begin{question}{questionHowR}{\qHowR{}}
    \cenLine{
      \begin{VAREnum}
      \item
        Agent: \vAgent{}
      \item
        Action: \(a\)
      \item
        \mbox{ }
      \end{VAREnum}
    }
    \medskip

    Given \(e\) is an event in which \vAgent{} does \(a\):

    \begin{itemize}
    \item
      Which past or present events explain \emph{how} \(e\) is an event in which \vAgent{} does \(a\)?
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \end{question}

  \noindent%
  Parallel to \ros{} as answers to \qWhy{}.

  \begin{itemize}
  \item
    \ros{} explains why agent concluded \(\phi\) has value \(v\) from \(\Phi\).
  \item
    Rationalisation explains why an agent did some action.
  \end{itemize}
\end{note}

\paragraph*{Constraints on rationalisations}

\begin{note}
  \citeauthor{Davidson:1963aa}'s argument of \citetitle{Davidson:1963aa} is:
  % 
  \begin{quote}
    [R]ationalization is a species of ordinary causal explanation.%
    \mbox{ }\hfill\mbox{(\citeyear[685]{Davidson:1963aa})}
  \end{quote}
  % 
  So, a reason explains the action by giving the agent's reason for doing what he did when the agent's reason \emph{causes} the action.

  A causal relation captures how something happened, and \citeauthor{Davidson:1963aa} holds causal relation explains how event happens.
  Hence, \citeauthor{Davidson:1963aa} constrains answers to \qWhyR{} by answers to \qHowR{}.
\end{note}

\begin{note}
  In contrast to causal explanation, \citeauthor{Hieronymi:2011aa} (\citeyear{Hieronymi:2011aa}) appeals to a complex fact:%
  \footnote{
    Consider also \citeauthor{Harman:1973ww} account of reason explanation:
    % 
    \begin{quote}
      Reasons may or may not be causes; but explanation by reasons is not causal or deterministic explanation.
      It describes the sequence of considerations that led to belief in a conclusion without supposing that the sequence was determined.%
      \mbox{ }\hfill\mbox{(\citeyear[52]{Harman:1973ww})}
    \end{quote}
  }
  % 
  \begin{quote}
    [W]henever an agent acts for reasons, the agent, in some sense, takes certain considerations to settle the question of whether so to act, therein intends so to act, and executes that intention in action.

    If this much is uncontroversial (and, under some interpretation, I believe it must be), we can use it as a form for filling out.
    I propose, then, that we explain an event that is an action done for reasons by appealing to the fact that the agent took certain considerations to settle the question of whether to act in some way, therein intended so to act, and successfully executed that intention in action.
    I suggest that \emph{this} complex fact [\dots] is the reason that rationalizes the action---that explains the action by giving the agent's reason for acting.%
    \mbox{ }\hfill\mbox{(\citeyear[421]{Hieronymi:2011aa})}
  \end{quote}
  % 
  In short, \citeauthor{Hieronymi:2011aa} observes a particular (complex) fact holds when an agent agents for reasons.
  If we grant that the fact \citeauthor{Hieronymi:2011aa} observes explains how an agent did what they did, then \citeauthor{Hieronymi:2011aa}'s proposal likewise constrains answers to \qWhyR{} in terms of answers to \qHowR{} --- in order for a rationalisation to explain why and agent did what they did there must be an event where the agent settles what to do via the (\agents{}) reasons present in the rationalisation.
\end{note}

\begin{note}
  In short, then, the arguments/proposals of \citeauthor{Davidson:1963aa} and \citeauthor{Hieronymi:2011aa} entail a constraint which parallels \issueInclusion{}, with respect to the variant questions \qWhyR{} and \qHowR{}.

  Still, to argue \issueInclusion{} follows from either \citeauthor{Davidson:1963aa}'s or \citeauthor{Hieronymi:2011aa}'s account of rationalisations requires an argument for the following conditional:
  % 
  \begin{itemize}
  \item
    \emph{If} a \ros{} answers \qWhy{} \emph{then} there is a corresponding rationalisation.
  \end{itemize}
  % 
  Given this conditional, \ros{1} which answer \qWhy{} are constrained by answers to \qHowR{}.
  And, answers to \qHow{} are just a special case of answers to \qHowR{} where the action is the agent's conclusion of \(\phi\) having value \(v\) from \(\Phi\).
\end{note}

\begin{note}
  Intuitively, certain \ros{1} correspond to rationalisations.
  For example, we may casually say with relative ease:%
  \footnote{
    This intuition ignores details about what \citeauthor{Davidson:1963aa} and \citeauthor{Hieronymi:2011aa} think reasons are.
    We consider issues about what reasons are below.
  }

  \begin{itemize}
  \item
    The reason for which the agent concluded \propM{\gistCalcEq{}} is \valI{True} was the calculator.
  \item
    The reason for which the birds concluded \propI{Four legs good, two legs bad} is \valI{True} was (the existence of) Snowball's explanation.
  \end{itemize}
  % 
  Abstractly, the following conditional seems plausible:
  \begin{itemize}
  \item
    \begin{itenum}
    \item[\emph{If}:]
      \(e\) is an event in which an agent concludes \(\phi\) has value \(v\) from \(\Phi\).
    \item[\emph{And}:]
      A \ros{} between \(\phi\), \(v\), and \(\Phi\) answers \qWhy{}.
    \item[\emph{Then}:]
      \(\Phi\) rationalises the act in which the agent concludes \(\phi\) has value \(v\).
    \end{itenum}
  \end{itemize}
  % 
  Still, we observed any counterexample to \issueInclusion{} must involve a \ros{} between \(\psi\), \(v'\), and \(\Psi\) (where either \(\psi\) is distinct from \(\phi\), \(v'\) is distinct from \(v\), or \(\Psi\) is distinct from \(\Phi\).)

  And, it seems there is no way link a \ros{} between \(\psi\), \(v'\), and \(\Psi\) to a rationalisation if either \(\psi\) is distinct from \(\phi\) or \(v\) is distinct from \(v'\).

  For, a rationalisation explains an action by giving an agent's reason for doing the action.
  For us, the relevant action is fixed as the action by which the agent concludes \(\phi\) has value \(v\).
  So, with respect to conclusions rationalisations have a single free variable \(X\) for the \agents{} reason:
  % 
  \begin{itemize}
  \item
    \(X\) is the \agents{} reason for the conclusion \(\phi\) has value \(v\) (from \(\Phi\)).
  \end{itemize}
  % 
  Therefore, if \(\psi\) is distinct from \(\phi\) or \(v'\) is distinct from \(v\), \(\phi\) or \(v'\) must be referenced by \(X\).
  In short, it seems the \ros{} between \(\psi\), \(v'\) and \(\Psi\) must be understood as the \agents{} reason:
  % 
  \begin{itemize}
  \item
    The \ros{} between \(\psi\), \(v'\), and \(\Psi\) is the \agents{} reason for the conclusion \(\phi\) has value \(v\) (from \(\Phi\)).
  \end{itemize}
  % 
  To see why this proposal is insufficient, consider it applied to the \ros{} between \(\phi\), \(v\), and \(\Phi\):
  % 
  \begin{itemize}
  \item
    The \ros{} between \(\phi\), \(v\), and \(\Phi\) is the \agents{} reason for the conclusion \(\phi\) has value \(v\) (from \(\Phi\)).
  \end{itemize}
  % 
  We introduced \ros{} as a act-neutral account of what follows from what.
  Hence, the above suggests conclusion \(\phi\) has value \(v\) (from \(\Phi\)) is \emph{from} the \ros{} between \(\phi\), \(v\), and \(\Phi\).
  And, in turn this suggests the relevant \ros{} which answers \qWhy{} is a \ros{} between \(\phi\) having value \(v\) and [the \ros{} between \(\phi\), \(v\), and \(\Phi\)].

  In short, a it seems a rationalisation implicitly captures a specific kind of \ros{}.
  And, as a rationalisation implicitly captures a specific \ros{1}, a rationalisation is not suitable for capturing general \ros{1}.
\end{note}

\begin{note}
  Still, may argue no \ros{} between \(\phi\), \(v\), and \(\Psi\) is a counterexample to \issueInclusion{}.
  For, the \(\Psi\) rationalises conclusion \(\phi\) has value \(v\).
  But, then causal relation or complex fact which secures a \wit{} for the \ros{}.
\end{note}

\begin{note}
  So, while certain accounts of rationalisations constrain answers to a why question by answers to a how question in a similar way to \issueInclusion{}, I doubt it is possible to motivate \issueInclusion{} directly by those accounts of rationalisations.

  At least, not without an additional premise regarding rationalisations.
  For example, if you hold:
  % 
  \begin{itemize}
  \item
    A \ros{} answers \qWhy{} \emph{only if} there is a corresponding rationalisation that answers \qWhyR{}
  \end{itemize}
  % 
  Then a more carefully developed version of the argument just made entails it is not possible for a \ros{} between \(\phi\), \(v'\), and \(\Phi\) (where \(\psi\) is distinct from \(\phi\) or \(v'\) is distinct from \(v\)) to answer \qWhy{}.

  A key part of such an argument requires specifying the way in which \ros{} connect to an \agents{} reasons.
  And, I suspect any such specification would amount to a substantive constraint on what an \agents{} reasons may be.%
  \footnote{
    I.e.\ I think such specification is possible, but would not hold for an arbitrary account of what an \agents{} reasons are.
    In other words, I think it is possible that counterexamples to \issueInclusion{} are compatible with \citeauthor{Davidson:1963aa}'s, \citeauthor{Hieronymi:2011aa}'s, or any other similar restriction on answers to \qWhyR{} in terms of answers to \qHowR{}.
  }
\end{note}

% \begin{note}
%   Motivation.
%   Difficulty here is that both \citeauthor{Davidson:1963aa} and \citeauthor{Hieronymi:2011aa} are concerned with an agent's reason(s).

%   It is not clear that \ros{} which answers \qWhy{} captures agent's reasons.


%   In general, lots of this explain why.

%   I do not think \issueInclusion{} is too distinct.
%   \ros{} is from the \agpe{}.
%   Hence, answers to \qWhy{} are close.
%   But this is still distinct from a reason.
% \end{note}

\subsection*{The basing relation}

\begin{note}
  \citeauthor{Pollock:1999tm} introduce the basing relation with the following observation:
  % 
  \begin{quote}
    To be justified in believing something it is not sufficient merely to \emph{have} a good reason for believing it.
    One could have a good reason at one's disposal but never make the connection.
    [\dots]
    Surely, you are not justified in believing [a conclusion], despite the fact that you have impeccable reasons for it at your disposal [if] you do not believe the conclusion on the basis of those reasons.%
    \mbox{}\hfill\mbox{(\citeyear[35]{Pollock:1999tm})}
  \end{quote}
  % 
  The observation falls short of being an account of the basing relation, but the intuition \citeauthor{Pollock:1999tm} appeal to is instructive.
  It seems that an agent must connect reasons and the content of a belief in order for the belief to be formed on the basis of those reasons, and hence be justified by those reasons.
\end{note}

\begin{note}
  Difficulty, no explicit link between basing relations and explanations.
  Instead, justification.
  These two things are distinct.
  Need not require justification for \ros{} to explain.

  Still, basing relations are superficially similar to \ros{1}.
  For, concern way in which conclusion.
  And, it disappointing if counterexamples to \issueInclusion{} required unjustified \ros{1}.
\end{note}

\begin{note}
  Same issue as rationalisations.

  Basing relation is between a conclusion and the basis for the conclusion.

  However, possibility of a case where \(\Psi\) is distinct from \(\Phi\).
\end{note}

\begin{note}
  Still, suggests \issueInclusion{} may fail.

  For example, \citeauthor{Swain:1981wd}'s (\citeyear{Swain:1981wd}) `causal-counterfactual' account of the basing relation is promising in name.
  Yet, the relevant counterfactuals concern events which happened that would have been a cause if the actual cause of an \agents{} belief had not occurred, and hence require a \wit{0}.

  Causal, \textcite{Moser:1989tv}, \textcite{Ye:2020ux}, and \citeauthor{Turri:2011aa}.
  Doxasitc.
  \textcite{Tolliver:1982us}.
  Is technically compatible.
  However, belief at time, and belief that these connect.
  However, examples \citeauthor{Tolliver:1982us} gives are consistent with constraint.
\end{note}

\begin{note}
  Further, some care must be taken in order to understand the way in which an account of the basing relation is connected to concluding.
  For example, taken at face value, \citeauthor{Evans:2013tw}'s disposition account of the basing relation suggests :

  \begin{quote}
    S's belief that \emph{p} is based on \emph{m} iff S is disposed to revise her belief that \emph{p} when she loses \emph{m}.%
    \mbox{}\hfill\mbox{(\citeyear[2952]{Evans:2013tw})}
  \end{quote}

  However, \citeauthor{Evans:2013tw}' dispositional theory is designed to capture what \emph{sustains} an agent's belief.%
  And, our interest with \issueInclusion{} is restricted to the event in which an agent concludes \(\phi\) has value \(v\) from \(\Phi\).
  \issueInclusion{} is silent about whatever happens after an agent concludes.%
  \footnote{
    A similar observation extends to \citeauthor{Moretti:2019wx}'s (\citeyear{Moretti:2019wx}) account of basing via enthymematic inferences.
    Expansion of an enthymematic inferences may be basis for an \agents{} belief with respect to justification, but it is not clear the expansion of an enthymematic inference matters with respect to an \agents{} conclusion if the agent concludes via an enthymematic inference.

    Likewise, to \citeauthor{Audi:1986to}'s suggestion of cases in which `[b]elieving for a reason does not entail having \textbf{come} to believe for that reason, or for any reason' (\citeyear[32--33]{Audi:1986to}).
    An agent may come to believe for one reason, and sustain the belief by some other reason, but unless the sustaining reason explains why the agent formed the initial belief, such cases are of no interest to us.
  }
\end{note}

\section*{Counterexamples to \issueInclusion{}}

\begin{note}
  The goal is to provide a recipe for constructing counterexamples to \issueInclusion{}.
  \scen{3} where:
  \begin{itemize}
  \item
    An event \(e\) in which an agent \vAgent{} concludes \(\phi\) has value \(v\) from \(\Phi\).
  \item
    A \ros{} between \(\psi\), \(v'\), and \(\Psi\) explains \emph{why} \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\).
  \item
    There is no prior or present event in which the agent concludes \(\psi\) has value \(v'\) from \(\Psi\).
  \item
    Either \(\psi\) is distinct from \(\phi\), \(v'\) is distinct from \(v\), or \(\Psi\) is distinct from \(\Phi\).
  \end{itemize}
\end{note}

\begin{note}
  Document has three parts.
  \begin{TOCEnum}
  \item
    \autoref{part:prep} (\nameref{part:prep})

    Refine everything.

    Conclusions, \ros{}, and variations on \qWhy{} and \qHow{}.
    In particular, precise variation on \qWhy{}.

    Precisely capture what the counterexamples we generate our counterexamples to
  \item
    \autoref{part:ing}: (\nameref{part:ing})

    Second part, a handful of observations used to generate counterexamples.

    \fc{3}.
    However, additional things.
  \item
    \autoref{part:dir} (\nameref{part:dir})

    Third part, combine.

    Link things together, and provide a handful of samples.
  \end{TOCEnum}
\end{note}

\begin{note}
  This covers how things will happen.
  I do not have a brief account of what will happen.
  The details are too important.
  The recipe is not based on an intuitive understanding of any particular \scen{}.
  Instead, the recipe is based on the way a number of ideas come together when we understand the way some agent concludes some proposition \(\phi\) has some value \(v\) happened.
\end{note}

\begin{note}
  Does it matter what else the premises may do?

  Does it matter if alternative premises for conclusion?
\end{note}


\begin{note}
  Still, a pair of brief notes:
\end{note}

\begin{note}
  I think that answers to \qWhy{} reduce to psychological facts of an agent, specifically psychological facts which hold of the agent when they conclude.%
  \footnote{
    This is incompatible with views of reasons explanation advanced by~(\cite{Dancy:2000aa}) and~(\cite{Alvarez:2013aa}), in which the state of affairs may be an agent's reason (and not just the evaluation of some state of affairs).
    Though, the argument will not depend on assuming that the relations reduce to psychological facts.

    See~(\cite[413--418]{Hieronymi:2011aa}),~(\cite[3--5]{DOro:2013vh}), and~(\cite[\S2]{Alvarez:2017aa}) for more.
  }
  However, I do not think that a relation between the \prop{0}, \val{0}, and \pool{} exhaust the relevant psychological facts.
  In particular, I think that in various cases additional relations between distinct \prop{1}, \val{1} and \pool{1} answer \qWhy{} without there being an event in which the agent concluded the propositions have values from \pool{1}.
\end{note}

\begin{note}
  As seen above with respect to \autoref{scen:animalism}, it follows from \issueInclusion{} that the content of Snowball's explanation is irrelevant.
  For, the birds do not understand Snowball's explanation, hence there is no event in which the birds reason from the content to \propI{Four legs good, two legs bad} has value \valI{True}.
  And, I think this is correct.

  However, parallel reasoning entails the agent's understanding of arithmetic is irrelevant with respect to \autoref{scen:calc}.
  And, I do not think this entailment holds.
  I think it may be the case that a relation between \propM{\gistCalcEq{}}, \valI{True} and the agent's understanding of arithmetic \emph{may} answer \qWhy{}.
  Whether this is the case will depend on whether some additional details hold of~\autoref{scen:calc}.
  Still, as the details matter, the entailment, and hence \issueInclusion{}, is not right.
\end{note}

\begin{note}
  Still, distinction between psychological facts exercise of agency.

  \begin{itemize}
  \item
    \emph{Why} is \(e\) is an event in which \vAgent{} concludes \(\phi\) has value \(v\)?
  \item
    \emph{Why} is it the case \vAgent{} concludes \(\phi\) has value \(v\) in \(e\)?
  \end{itemize}

  For example, steamboat being moored, hotel.
  However, not in terms of hotel's reasons.
  Simply too many guests.

  Capturing the way things are from the \agpe{}.
  Still, issue about agency.
  Worry, answers to \qWhy{} are not necessarily sufficiently restricted to explanations in terms of the exercise of the agent's \emph{agency}.%
  \footnote{
    In particular, agency is problem for \citeauthor{Davidson:1963aa}.
    Problem of deviant causal chains.
    \citeauthor[79]{Davidson:1973vd}
    Climber.
    \begin{quote}
      Beliefs and desires that would rationalize an action if they caused it in the right way—through a course of practical reasoning, as we might try saying---may cause it in other ways.%
      \mbox{ }\hfill\mbox{(\citeyear[79]{Davidson:1973vd})}
    \end{quote}
  }
\end{note}

\begin{note}
  Rather than attempt to incorporate, argument against \issueInclusion{}, and then motivate that relevant counterexamples either involve agency or have nearby neighbours which involve agency.
\end{note}

%   \begin{quote}
%     Sometimes the explanation of why a person does something has a particular character:
%     roughly, it involves the person's rationality in a distinctive way that I shall not try to describe.
%     Then we say the person does what she does for a reason.
%     We might say ‘The reason for which Hannibal used elephants was to terrorize the Romans'.
%     The reason for which a person does something is called a ‘motivating reason'.
%     In general, a motivating reason is whatever explains or helps to explain what a person does in the distinctive way that involves her rationality.
%     \mbox{}\hfill\mbox{(\citeyear[46--47]{Broome:2013aa})}
%   \end{quote}
% \end{note}

% \begin{note}
%   \color{red}
%   \begin{quote}
%     \emph{R} is a primary reason why an agent performed the action \emph{A} under the description \emph{d} only if \emph{R} consists of a pro attitude of the agent toward actions with a certain property, and a belief of the agent that \emph{A}, under the description \emph{d}, has that property.\newline
%     \mbox{ }\hfill\mbox{(\citeyear[687]{Davidson:1963aa})}
%   \end{quote}

%   We have distinguished \qWhy{} from pro-attitudes.
%   However, fill in whatever motivation.
%   What matters is the belief.
%   This is the relevant proposition-value pair.

%   If \citeauthor{Davidson:1963aa}, then granting restriction, seems we don't need to look beyond the proposition-value pair.
% \end{note}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% TeX-engine: luatex
%%% End:
