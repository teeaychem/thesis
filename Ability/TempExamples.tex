\chapter{TempExamples}
\label{cha:tempexamples}

\begin{note}[Gifts]
  \begin{illustration}
    \label{illu:S:gifts}
    \begin{enumerate}
    \item S knows me very well.
    \item Whatever S has gifted me satisfies some desire I have.
    \end{enumerate}
  \end{illustration}
  Perhaps wishful thinking, but fine with respect to \zS{}.

  {
    \color{red}
    Maybe useful to include, as this shows how \zS{} is kind of weak.
    The key thing to think about is whether there is something that could lead the agent to conclude that their friend doesn't know them very well.
  }

  The same basic idea underlying~\autoref{illu:S:gifts} extends to various other premise-conclusion instances.
  Consider, for example:

  \begin{enumerate}
  \item The newspaper reported \(S\) said that \(p\).
  \item \(S\) said that \(p\).
  \end{enumerate}

  It seems plausible that the reasoning from premise to conclusion assumes that the paper has a history of accurate reporting.
  And, and if available to the agent are various premises which suggest that the paper does not have such a history, then the agent may refrain from concluding \(S\) said that \(p\) from the report.
  Still, even if the agent were to relax their epistemic state so that the newspaper lacking such a history is \epVAd{}, the agent may still have sufficient premises to conclude that the newspaper does have the history, those premises may resist questioning, and so on.
  Hence, whether or not an agent has \support{} for the conclusion broadly depends on the agent's epistemic state.
  Further, the agent may also have some other premise from which to conclude \(S\) said that \(p\).
  For example, by having been in the room when \(S\) said that \(p\).
\end{note}

\begin{note}
  Pair of trivial instances.
  Inspection immediately grants.
  \begin{illustration}
    \begin{figure}[h!]
    \mbox{}\hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item
        That persons' eyes have been closed for a long time and their breathing is slow.
      \item
        That person is asleep.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item
        The die has rolled even in \(5251\) of \(6000\) samples.
      \item
        The die is biased.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill\mbox{}
    \caption{}
    \label{fig:ideaS:basic-examples}
  \end{figure}
\end{illustration}
\end{note}

% % % Spot the difference % % %

\paragraph{A trip to the zoo}

\begin{note}[Failure but no option]
  \citeauthor{Dretske:1970to}.
  \begin{scenario}[A trip to the zoo]\mbox{ }
    \label{scen:trip-to-zoo}
    \vspace{-\baselineskip}
    \begin{quote}
      You take your son to the zoo, see several zebras, and, when questioned by your son, tell him they are zebras.
      Do you know they are zebras?
      [\dots]
      We know what zebras look like, and, besides, this is the city zoo and the animals are in a pen clearly marked ``Zebras.''
      Yet, something's being a zebra implies that it is not a mule and, in particular, not a mule cleverly disguised by the zoo authorities to look like a zebra.
      Do you know that these animals are not mules cleverly disguised by the zoo authorities to look like zebras?\newline
      \mbox{ }\hfill\mbox{(\citeyear[1015--1016]{Dretske:1970to})}
    \end{quote}
    \vspace{-\baselineskip}
  \end{scenario}

  \autoref{scen:trip-to-zoo} is framed in terms of knowledge, and is designed to raise a problem for conclude of knowledge under known entailment.
  Intuitively, you know the animals in the pen are zebras.
  And, you know the following conditional is true:
  The animals in the pen are zebras \emph{only if} the animals in the pen are not cleverly disguised mules.
  However, you (intuitively) don't know the animals in the pen are not cleverly disguised mules.

  If knowledge is closed under known entailment, then you:

  \begin{enumerate}
  \item
    \(\phi\) has value \(v\) only if \(\psi\) has value \(v'\)
  \end{enumerate}

  then, if

  \begin{enumerate}
  \item
    \(\phi\) has value \(v\), then
  \end{enumerate}

  \begin{enumerate}
  \item
    \(\psi\) has value \(v'\)
  \end{enumerate}

  So, if closure of knowledge under know entailment, and conclusion is that you know, then any further reasoning, need to conclude.

  So, right now, from the current \poP{}, not counting additional information.

  Intuitively, don't know, and there is no \pevent{}.
  However, this is not due to.

  For, holds regardless of whether or not.
\end{note}

\begin{note}
  Still, knowledge.

  Not concluding unless knows.
  Then, if no \pevent{}, then agent doesn't know.
  {
    \color{red}
    I should come back to this point.
    For, it does seem a weakness.
    One could deny that knowledge ever interacts in this way.
    For example, possibility of no external world.

    However, if this is a concern, then it's not clear to me that there is anything interesting to be said about concluding.
    To the extent have concluded via understanding of rules of Sudoku, know that \pevent{}.
    If worried about lack of external world, then no guarantee that concluded from rules of Sudoku.

    So, really, the point is that it seems strange to break this link.
  }

  Event does not develop unless know.
  Therefore, does not develop unless there is some \pevent{}.

  Because, if do not know then will check.
  And, if check fails then will not conclude.
\end{note}

% \begin{note}
%   \begin{illustration}[Fraction]
%     \label{illu:fc:surds}
%     \[\frac{(3 + \sqrt{3})^{2} + \sqrt{6}^{2} - (2\sqrt{3})^{2}}{2(3 + \sqrt{3})\sqrt{6}} = \frac{1}{\sqrt{2}}\]
%   \end{illustration}

%   Granting knowledge of a handful of equalities, beyond basic addition and subtraction,%
%   \footnote{
%     \(\sfrac{ab}{ac} = \sfrac{b}{c}\),
%     \(\sqrt{a b} = \sqrt{a}\sqrt{b}\), and
%     \((a + b)^{2} = (a^{2} + 2ab + b^{2})\).
%   }
%   whether or not the equation is true a \fc{}, and further the truth of the equation is a \fc{}.%
%   \footnote{
%     \label{illu:fc:surds:fn}
%     First, consider the numerator.
%     Each element of the numerator may be rewritten as follows:
%     \((3 + \sqrt{3})^{2} = 12 + 6\sqrt{3}\), \(\sqrt{6}^{2} = 6\), \((2\sqrt{3})^{2} = 12\).
%     By summing the elements we obtain \(6\sqrt{3} + 6\).
%     Hence, by rewriting, the numerator may be replaced with, \(2(3\sqrt{3} + 3)\).

%     Now consider the denominator.
%     Observe we may cancel multiplication by \(2\) from both the numerator and denominator.
%     Further, observe \(\sqrt{6} = \sqrt{2}\sqrt{3}\).
%     Hence, by distributing we  obtain, \((3\sqrt{3} + \sqrt{3}\sqrt{3})\sqrt{2}\).
%     Likewise, observe \(\sqrt{3}\sqrt{3} = \sqrt{9} = 3\).
%     Hence, by rewriting the denominator reads \((3\sqrt{3} + 3)\sqrt{2}\).
%     As both the numerator and denominator contain \((3\sqrt{3} + 3)\), we may cancel to obtain the desired equality.
%   }
%   Though, if like me you may end up exploring a handful of unsuccessful ideas before stumbling across the path to the solution.
%   In particular, don't conclude any intermediary miscalculations.
%   And, keep going until solution is clear.
% \end{note}

\begin{note}[Wally]
  \begin{illustration}[Where's Wally]
    \label{illu:CS:wheres-wally}
    \nagent{15} has a book containing numerous drawings of scenes in which various characters are doing a variety of things.
    And, somewhere in each scene is a character called `Wally', identifiable by a collection of individually necessary and jointly sufficient distinguishing features.
    These features include a red and white striped jumper, blue trousers, short brown wavy hair, and so on.

    \nagent{15} has searched through one particular scene, and has identified a character with a variety of the features.
    Before concluding that the character is Wally, \nagent{15} remembers that there is a picture of Wally On the cover of the book, with all the identifying features present.

    Wally is always wearing a pair of round glasses, but this was not a feature \nagent{15} kept in mind when searching for Wally.
    So, perhaps the character \nagent{15} identified is not wearing round glasses  --- \nagent{15} only recalls the features they identified.
  \end{illustration}

  Interest is with whether \nagent{15} may conclude from the variety of features identified that the character is Wally.

  The difficulty for \nagent{15} is that if \nagent{15} were to check whether the character is wearing a pair of round glasses, and the character is not wearing a pair of round glasses, then \nagent{15} would conclude that the character is not Wally.
  Hence, a \requ{}.
  And, not a \fc{}.

  I'm going to ask whether Wally is usually carrying a cane.

  Here, keep in mind premises.
  Most plausible thing is that go back and check.
  However, this plausibly results in an additional premise.
  There is some information that is missing, and once you add it, you will conclude.
  However, not from present information.
\end{note}

\begin{note}
  Two ways in which this works.

  First, soundness of `Squish'-elimination.

  Second, from basic rules.

  \begin{center}
    \begin{fitch}
      \fa (P \rightarrow Q) \rightarrow P \\
      \fj Q \\
      \fa \fh P & \\
      \fa \fa Q & \textbf{Reit:} 2 \\
      \fa P \rightarrow Q & \(\rightarrow\)\textbf{Intro:} 3--4 \\
      \fa P & \(\rightarrow\)\textbf{Elim:} 1,5 \\
      \fa P \land Q & \(\land\)\textbf{Intro:} 2,6
    \end{fitch}
  \end{center}
\end{note}


\begin{note}[Spot the difference]
  \begin{illustration}[Spot the difference]
    \label{illu:CS:spot-the-diff}
    The agent has been working through a spot-the-difference to pass some time.

    Though the time is not completely passed, the agent examined the two images with what seems sufficient care to claim support that they have found all the differences.
    However, the agent did not keep track of the number of differences.

    The agent announces `I have found all the differences' and their companion responds `All fifteen?'

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*)]
      \setcounter{enumi}{-1}
    \item
      \label{illu:CS:spot-the-diff:info}
      If I have found all the differences, I have found fifteen differences.
    \end{enumerate}

    The agent then reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*), resume]
    \item Exhaustive search.
    \item
      \label{illu:CS:spot-the-diff:all}
      I found all the differences.
    \item
      \label{illu:CS:spot-the-diff:fif}
      So, I have found fifteen differences. \hfill (From \ref{illu:CS:spot-the-diff:info} and \ref{illu:CS:spot-the-diff:all})
    \end{enumerate}
  \end{illustration}

  So, as doing the exhaustive search, get this information.

  Here, plausibly a \wit{}.
  For, proposition is just a state of affairs.
  These are the same state of affairs.

  Ugh, too messy.
\end{note}

\begin{note}
  \begin{illustration}
    A search for `Measurement Theory' via the LCC `H61 .R593' returned no results.

    Consider the possibility that library does not use DDC indexing.

    Checked the indexing system, do not conclude the library does not have a copy of `Measurement Theory'.
  \end{illustration}

  So, this is type B because there is no clear entailment.
  However, incompatible, as then may have searched.
  Indeed, this is just a variant on lost keys.
\end{note}

\subsection{Not a \requ{}}
\label{sec:not-requ}

\begin{note}
  \illu{3}~\ref{illu:lost-key}~\ref{scen:squish} are \illu{1} of \requ{1}.
  The contrast between~\ref{illu:lost-key} and~\ref{scen:squish} is whether the agent is concluding \(\pv{\phi}{v}\) from \(\Phi\) given that \(\pvp{\psi}{v'}{\Psi}\) is a \requ{} of concluding \(\pv{\phi}{v}\) from \(\Phi\).

  Still, \requ{1} are various ways in which \(\pvp{\psi}{v'}{\Psi}\) may fail to be a \requ{0} of concluding \(\pv{\phi}{v}\) from \(\Phi\).
  Consider the following \scen{0}:

  \begin{scenario}[Testimony as a layperson]
    \label{illu:testimony-layperson}
    An agent is informed that there are exactly five intermediate logics that have the interpolation property.%
    \footnote{Cf.\ \textcite{Maksimova:1977un}}
  \end{scenario}

  The agent does not have the means to query the proof.

    The agent concludes there are exactly five intermediate logics that have the interpolation property.

  Here, also, logic with syntax and semantics.
\end{note}



% \begin{note}
%   \begin{scenario}[A cup of tea]%
%     \label{scen:cup-of-tea}%
%     A moment ago I:
%     \begin{itemize}[noitemsep]
%     \item
%       Boiled some water.
%     \item
%       Placed a tea bag into a cup.
%     \item
%       Poured the water into the cup.
%     \item
%       Let the tea bag rest in the water for a while.
%     \item
%       Removed the tea bag.
%     \end{itemize}
%     \vspace{-\baselineskip}
%   \end{scenario}

%   \autoref{scen:cup-of-tea} captures an event in which I made a cup of tea.

%   Each step is a sub-event.
%   In particular, consider the sub-event in which I pour water into the cup.
%   It seems the truth of the following conditional more is-or-less immediate:
%   \begin{itemize}
%   \item
%     If the water isn't boiled, tea isn't made.
%   \end{itemize}
%   For, tea does not infuse in cold water.%
%   \footnote{
%     Provided I wasn't cold-brewing tea, didn't have time to boil the water after noticing it was cold, etc\dots
%   }
% \end{note}

% \begin{note}
%   There is a clear sense with \autoref{scen:cup-of-tea} captures \emph{how} I made a cup of tea.
%   Indeed, with a little adjustment the presentation of \autoref{scen:cup-of-tea} functions as a series of instructions for how to make a cup of tea.

%   Still, there is also a sense with which \autoref{scen:cup-of-tea} captures \emph{why} I made a cup of tea.
%   For, given the truth of the conditional, the event in which I boiled explains, in part, why some other event did not happen.

%   There is a sense with which the description fails to capture why I made a cup of tea.
%   For, does not capture motivation.
%   However,

%   \begin{itemize}
%   \item
%     If I don't want to make tea, tea isn't made.
%   \end{itemize}

%   Presence of a desire to make tea parallels boiling water.
%   And, build out from this.

%   \begin{itemize}
%   \item
%     If not tired, then I don't want to make tea.
%   \end{itemize}

%   Understand why an event happened by identifying features of the event such that, without those features the event does not happen.
%   Motivation is just one such feature.
% \end{note}

% \begin{note}
% The former parallels our interest with conclusions.
%   Not interested with why an agent wanted to reach a conclusion, but why an agent concluded \(\phi\) has value \(v\) as opposed to any other proposition-value pair, and why the agent concluded \(\phi\) has value \(v\) from \(\Phi\) as opposed to some other pool of premises.
% \end{note}


% \begin{note}
%   \begin{illustration}[Modal logic I]
%     \label{illu:fc:logic:CR}
%     The modal system obtained from adding \(\Diamond\Box p \rightarrow \Box\Diamond p\) as an axiom to \(\mathbf{K}\) is canonical for the Church-Rosser property.

%     I.e. the canonical model \(W,R,V\) for \(\mathbf{K} + \Diamond\Box p \rightarrow \Box\Diamond p\) is such that \(\forall s,t,u((Rst \land Rsu) \rightarrow \exists v(Rtv \land Ruv))\).
%   \end{illustration}

%   \autoref{illu:fc:logic:CR} is a \fc{} for me.
%   Though, in contrast to the previous \illu{1}, I think there is a reasonable change that \autoref{illu:fc:logic:CR} is not a \fc{} for you.

%   Fairly routine, but two important things.
%   First, grasp on the relevant concepts.
%   If you are unaware of how to construct canonical models for normal modal logics, then unlikely that you will complete the relevant proof.
%   Second, sufficient familiarity with the relevant concepts.
%   The proof is mostly straightforward, though some care needs to be taken in showing that the canonical model for \(\mathbf{K} + \Diamond\Box p \rightarrow \Box\Diamond p\) has the Church-Rosser property.
%   Proof by contradiction is my preferred way of obtaining the result, but this requires keeping certain facts about the canonical model in mind.%
%   \footnote{
%     A slightly more interesting variation is showing that \(\mathbf{K} + \Diamond\Box p \rightarrow \Box\Diamond p\) is (strongly) complete with respect to the class of frame which have the Church-Rosser property without detour via a canonical model.
%   }

%   Similar features as \illu{1} given above.

%   In particular, perhaps clearer than \autoref{illu:gist:Sudoku} in terms of mistakes.
%   For, go down some wrong path, still will not conclude until counterexample.
%   And, this is very hard to get.
% \end{note}



% \paragraph*{Preferences}

% \begin{note}
%   Type of reasoning isn't basic EU, etc.
% \end{note}

% \begin{note}
%   The situations, as presented by \citeauthor{Allais:1979aa}:%
%   \footnote{
%     The units in \citeauthor{Allais:1979aa}'s situations are French francs at 1952 prices (\citeauthor[138, fn.94]{Allais:1979aa}).\newline
%     100 French francs in 1952 is worth about the same as 50 US Dollars in 2022.
%   }
%   \begin{quote}
%     \begin{enumerate}[label=(\arabic*), ref=(\arabic*)]
%     \item
%       \emph{Do you prefer Situation A to Situation B}?

%       Situation A:
%         \begin{enumerate}[label=--]
%         \item
%           \emph{certainty} of receiving 100 million
%         \end{enumerate}
%         Situation B:
%         \begin{enumerate}[label=--]
%         \item
%           \emph{a} 10\% \emph{chance} of winning 500 million,
%         \item
%           \emph{an} 89\% \emph{chance} of winning 100 million,
%         \item
%           \emph{a} 1\% \emph{chance} of winning nothing.
%         \end{enumerate}
%       \item
%       \emph{Do you prefer Situation C to Situation D}?

%       Situation C:
%         \begin{enumerate}[label=--]
%         \item
%           \emph{a} 11\% \emph{chance} of winning 100 million,
%         \item
%           \emph{an} 89\% \emph{chance} of winning nothing.
%         \end{enumerate}
%         Situation D:
%         \begin{enumerate}[label=--]
%         \item
%           \emph{a} 10\% \emph{chance} of winning 500 million,
%         \item
%           \emph{a} 90\% \emph{chance} of winning nothing.%
%           \mbox{ }\hfill\mbox{(\citeyear[89]{Allais:1979aa})}
%         \end{enumerate}
%     \end{enumerate}
%   \end{quote}

%   \begin{quote}
%     The preference \(\text{A} > \text{B}\) should entail \(\text{C} > \text{D}\).%
%     \footnote{
%       First, write out expected utility for each situation.

%       \smallskip
%       \mbox{ }\hfill%
%       \EU{Sit.\ A} = \(\Util{100\text{m}}\)%
%       \hfill%
%       \EU{Sit.\ B} = \(.10 \cdot \Util{500\text{m}} + .89 \cdot \Util{100\text{m}} + .1 \cdot \Util{0\text{m}}\)%
%       \hfill\mbox{ }

%       \mbox{ }\hfill%
%       \EU{Sit.\ C} = \(.11 \cdot \Util{100\text{m}} + .89 \cdot \Util{0\text{m}}\)%
%       \hfill%
%       \EU{Sit.\ D} = \(.10 \cdot \Util{500\text{m}} + .90 \cdot \Util{0\text{m}}\)%
%       \hfill\mbox{ }
%       \smallskip

%       Suppose Situation A is preferred to Situation B.
%       Hence, \(\EU{Sit.\ A} > \EU{Sit.\ B}\).
%       Expanding, we obtain:
%       %
%       \[
%         \Util{100\text{m}} > .10 \cdot \Util{500\text{m}} + .89 \cdot \Util{100\text{m}} + .1 \cdot \Util{0\text{m}}
%       \]

%       Now, consider subtracting \(.89 \cdot \Util{100\text{m}}\) from each side of the inequality and adding \(.89 \cdot \Util{0\text{m}}\):
%       %
%       \begin{align*}
%         \Util{100\text{m}} - .89 \cdot \Util{100\text{m}} &> .10 \cdot \Util{500\text{m}} + .01 \cdot \Util{0\text{m}} \\
%          .11 \cdot \Util{100\text{m}} + .89 \cdot \Util{0\text{m}} &> .10 \cdot \Util{500\text{m}} + .90 \cdot \Util{0\text{m}}
%       \end{align*}

%       The left and right side of the inequality are \EU{Sit.\ C} and \EU{Sit.\ D}, respectively.
%       Therefore, it should be the case that Situation C is preferred to Situation D.
%     }
%   \end{quote}
%   However, this is not the case.
%   \citeauthor{Allais:1979aa} highlights pattern to the contrary:
%   \textquote{\emph{[T]he pattern for most highly prudent persons [\dots] who are considered generally as rational, is the pairing \(\text{A} > \text{B}\) and \(\text{C} < \text{D}\).}}
%   (\citeyear[89]{Allais:1979aa})

%   So, we have a something lawlike.%

%   Two things here.
%   \begin{itemize}
%   \item
%     Entailment between preferences.
%   \item
%     Circumstance in which conflicting preferences.
%   \end{itemize}

%   Both work, but the latter is of interest.%
%   \footnote{
%     \color{red}
%     The former \dots
%   }

%   For, if axioms, then preferences.
% \end{note}


% \begin{note}
%   In general, `why?' and `how?' are distinct questions.
%   For example, consider:

%   \begin{scenario}[England AD 932]
%     \label{scen:king}
%     \vspace{-\baselineskip}
%     \begin{screenplay}
%     \item[OLD WOMAN:]
%       Well, how did you become King, then?
%     \item[ARTHUR:]
%       The Lady of the Lake, her arm clad in purest shimmering samite, held Excalibur aloft from the bosom of the waters to signify that by Divine Providence\space\dots\space I, Arthur, was to carry Excalibur\dots\space that is why I am your King.
%     \item[DENNIS:]
%       Look, strange women lying on their backs in ponds handing over swords\space\dots\space that's no basis for a system of government.
%       Supreme executive power derives from a mandate from the masses not from some farcical aquatic ceremony.\newline
%       \mbox{ }\hfill\mbox{(\cite[8--9]{Cleese:1974aa})}
%     \end{screenplay}
%     \vspace{-\baselineskip}
%   \end{scenario}

%   The old woman asks Arthur \emph{how} the become king.
%   Arthur provides an answer in terms of some events which happened, but emphasises that those events are \emph{why} Arthur is king.
%   In turn, Dennis accepts the answer provided by Arthur as an account of how Arthur became king but rejects the answer an account of why Arthur is king.
%   Instead, an answer is expected in involve the absence of an appropriate system of governance in England.
%   So, the answer provided by Arthur is accepted by Dennis as an answer to how, but not as an answer to why.
%   % The distinction between `why?' and `how?' present in \autoref{scen:king} parallels \qWhy{} and \qHow{} with respect to conclusions.
%   % In \autoref{scen:calc}, the agent considered applying their understanding of arithmetic, but their understanding of arithmetic seems no basis for the conclusion.
%   % Instead, it is the use of the calculator.
%   % When we consider the \ros{} between \propM{\gistCalcEq{}}, \valI{True}, and the calculator, we seem to get some understanding of why the agent concluded \gistCalcEq{}.
%   % In parallel, the sequence of the agent using the calculator and concluding \propM{\gistCalcEq{}} has value \valI{True}
% \end{note}


\begin{note}
  Here's an additional, slightly more complex \scen{0}:

  \begin{scenario}[Animalism]%
    \label{scen:animalism}%
    `Four legs good, two legs bad.'
    This, he said, contained the essential principle of Animalism.
    Whoever had thoroughly grasped it would be safe from human influences.
    The birds at first objected, since it seemed to them that they also had two legs, but Snowball proved to them that this was not so.

    `A bird's wing, comrades,' he said, `\textsc{is} an organ of propulsion and not of manipulation.
    It should therefore be regarded as a leg.
    The distinguishing mark of Man is the \emph{hand}, the instrument with which he does all his mischief.'

    The birds did not understand Snowball's long words, but they accepted his explanation, and all the humbler animals set to work to learn the new maxim by heart.\newline
    \mbox{ }\hfill\mbox{(\cite[25]{Orwell:1976aa})}%
    \newline
  \end{scenario}

  \noindent%
  The agents of interest are the birds, and the conclusion is the essential principle of Animalism:
  \propI{Four legs good, two legs bad} has value \valI{True}.

  Snowball provided an argument against an objection from the birds, and the birds concluded \propI{Four legs good, two legs bad} is \valI{True} from Snowball's explanation.

  Though, 
  

  % In parallel to the agent's understanding of arithmetic from~\autoref{scen:calc} the birds of~\autoref{scen:animalism} did not, in part, conclude \propI{Four legs good, two legs bad} from the content of Snowball's explanation.
\end{note}


\begin{note}
  In line with the abstraction given, we may say:
  The birds conclude \propI{Four legs good, two legs bad} has value \valI{True} from the existence of Snowball's explanation.

  Likewise, during Snowball's explanation the birds were concluding \propI{Four legs good, two legs bad} has value \valI{True}.
  And, a \ros{} between \propI{Four legs good, two legs bad}, \valI{True}, and a \pool{} which captures some way things are from each \agpe{bird's} prior to the end of Snowball's explanation held prior to the conclusion of each bird.

  For, as \citeauthor{Orwell:1976aa} highlights, the birds did not conclude \propI{Four legs good, two legs bad} from \emph{the content of} Snowball's explanation.
  (Some words were too long.)
  Hence, in contrast to a weather report, no novel information was required.




  Instead, the birds concluded, at least in part, from (the existence of) \emph{Snowball's explanation}.


  That Snowball has given an explanation.
  But, it seems plausible the existence is irrelevant.
  

  In contrast to a weather report, Snowball beings with their thesis, 

  Plausibly, the birds are sufficiently caught up in Snowball's rhetoric that some time 
  
  And, for each bird, a \ros{} holds between \propI{Four legs good, two legs bad}, \valI{True}, and the existence of Snowball's explanation.
\end{note}



\begin{note}
  % \begin{scenario}[Multiplication]%
  %   \label{scen:calc:var}%
  %   An agent enters `\gistCalcLHS{}' into a calculator and presses a button marked `\(=\)'.
  %   The calculator displays `\gistCalcRHS{}'.

  %   The agent pauses for a moment.
  %   They have a good understanding of arithmetic.
  %   And, given the display on the calculator, it follows that if the calculator is trustworthy, then they would not fail to conclude \propM{\gistCalcEq{}} via their understanding of arithmetic.

  %   The agent does the arithmetic and concludes \propM{\gistCalcEq{}}.
  % \end{scenario}

  % \noindent%
  % \autoref{scen:calc:var} is a variation of \autoref{scen:calc} where the agent does arithmetic.

  % Now, suggest that \ros{} holds between the agent's understanding of arithmetic and various other equations.

  % Do any of these \ros{} answer \qWhy{}?
  % Of course, understanding of arithmetic, but are \ros{} required for this?
  % I don't think this is obvious.
  % For example, if reasoning is rule governed,%
  % \footnote{
  %   See, for example, \textcite{Boghossian:2008vf} and \textcite{Broome:2013aa}.
  % }
  % then it seems sufficient to observe the agent followed the relevant rule.


  % Likewise, variation of \autoref{scen:animalism} where the birds understand Snowball's long words but are swayed by Snowball's rhetoric.
  % A \ros{} may hold, but seems irrelevant.
\end{note}


\section{An \illu{0}}


\begin{note}
  To close this chapter we offer a final \illu{0} of \tCV{}, though this time with a focus on \fc{1} given \autoref{prop:tCV-fc}.
\end{note}


\begin{note}
  \phantlabel{squish-elimination-proof}

  \begin{scenario}[Squish elimination]%
    \label{scen:squish}%
    Some time ago the agent showed \sqE{} is sound.

    It is now late morning on a sunny day.
    The agent ate a good breakfast, and drank some nice coffee and does the following syntactic proof:
    %
    \begin{center}
      \begin{fitch}
        \phantlabel{illu:sP:1}\fa (P \rightarrow Q) \rightarrow P \\
        \phantlabel{illu:sP:2}\fj R \\
        \phantlabel{illu:sP:3}\fa P & \sqE{}:\hyperref[illu:sP:1]{1} \\
        \phantlabel{illu:sP:4}\fa P \land R & \(\land\)\textbf{Intro:} \hyperref[illu:sP:2]{2},\hyperref[illu:sP:3]{3}
      \end{fitch}
    \end{center}
    %
    The agent concludes \((P \rightarrow Q) \rightarrow P, R \vdash P \land R\).
  \end{scenario}

  \noindent%
  Intuitively, agent \tCV{} \((P \rightarrow Q) \rightarrow P, R \vdash P \land R\) from some \pool{} which captures the \agents{} understanding of the relevant Fitch-style proof system.
  And, as the agent is \tCV{}, some \torNa{} captures the \agents{} understanding of the relevant Fitch-style proof system.
\end{note}


\begin{note}
  Still, in \autoref{scen:squish} the agent uses the non-standard \sqE{} rule.
  Specifically:

  \begin{definition}[\sqE{}]%
    \label{def:sque}%
    \sqE{} is the following rule:
    \begin{center}
      \begin{fitch}
        \ftag{\text{\scriptsize \emph{i}}}{\fa (\phi \rightarrow \psi) \rightarrow \phi} \\
        \ftag{\text{\scriptsize }}{\fa \vdots } \\
        \ftag{\text{\scriptsize \emph{j}}}{\fa \phi } & \sqE{}:\emph{i} \\
      \end{fitch}
    \end{center}
  \end{definition}

  \noindent%
  By stipulation, the agent has proved \sqE{} is sound.
  And, \sqE{} is indeed sound.%
  \footnote{
    \label{prop:sqE-sound}
    Rather than prove \sqE{} is sound (which would require a detailed statement of the proof system in question), we show that the key corresponding semantic entailment holds:

    Let \(v\) be an arbitrary (truth-functional) valuation, and assume \(v((\phi \rightarrow \psi) \rightarrow \phi) = \valI{True}\).
    Further, assume for contradiction \(v(\phi) = \valI{False}\).

    As \(v(\phi) = \valI{False}\), it immediately follows that \(v(\phi \rightarrow \psi) = \valI{True}\).
    Therefore, by the first assumption, it must be the case that \(v(\phi) = \valI{True}\).
    This contradictions the second assumption.
  }

  Still, \((P \rightarrow Q) \rightarrow P, R \vdash P \land R\) may be logic soup.
  The agent has proved \sqE{} is sound.
  Though, there no guarantee that the \agents{} recollection of \sqE{} is tied to their understanding of the relevant Fitch-style proof system.

  In parallel to failing to identify correct cards, or failing solve exercise, something wrong.
\end{note}


\begin{note}
  Further, the proof of the soundness of \sqE{} is fairly straightforward.
  Hence, if the agent is \tCV{}, some action such that concluding \sqE{} is sound.%
  \footnote{
    Two options.
    Either directly show \sqE{} follows from the \agents{} understanding of the proof system via constructing a meta-proof of \sqE{} or indirectly show \sqE{} follows by providing a semantic argument and combine with completeness result.
    If neither direct or indirect, then the \agents{} use of \sqE{} does not follow from the \agents{} understanding of relevant Fitch-style proof system.
  }
  From \autoref{prop:tCV-fc}, \fc{}.
\end{note}


\begin{note}
  Does not require that the agent (re)proves \sqE{} is sound.
  At issue is that the agent has the option.
  Likewise, this does not state this is enough to state the agent is \tCV{}.
  \autoref{idea:tC} is a partial definition.
\end{note}


\begin{note}
  As with earlier prop.\ this is compatible with \issueConstraint{}.
  Selection tasks.
  \sqE{}.
  Powers is less clear.
  Plausible that a well-held agent only really concludes the answers to each of the exercises after completing all (and perhaps checking their answers) as failure on a further exercise would lead to a problem.

  Though, at some point confident in understanding.
  And, there are far more equations.
\end{note}


% \paragraph*{Rules}

% \begin{note}
%   Selection tasks are events which happen, and \citeauthor{Wason:1966aa}'s hypothesis is that people \emph{in general} do not do not reason about conditionals using only \valI{True} and \valI{False}.
%   However, the events the law of \autoref{idea:tC} quantifies over need not happen, and the event at issue may be a single event.
% \end{note}

% \begin{note}
%   \begin{scenario}[Addition]%
%     \label{illu:quus}%
%     An agent is given pairs of numbers \(x\) and \(y\) and asked to respond with \(x + y\).
%     The table below represents the event as the agent responds to the pairs.

%     \medskip
%     \hspace{2.8em}%
%     \(
%       \begin{array}{ccccccc}
%       x & 3 & 54 & 21 & 3 & 17 & 0 \\
%       y & 7 & 32 & 64 & 2 & 25 & 6 \\
%       \hline
%       \text{Response} & 10 & 86 & 85 & 5 & 42 & 6 \\
%     \end{array}
%     \)
%     \medskip

%     \noindent%
%     The agent is distracted.
%     However, if the agent had not been distracted, they would have continued as follows:

%     \medskip
%     \hfill%
%     \(
%     \begin{array}{ccccc}
%       \cdots & 8 & 68 & 21 & 58 \\
%       \cdots & 92 & 57 & 23 & 92 \\
%       \hline
%       \cdots & 100 & 5 & 44 & 5 \\
%     \end{array}
%     \)%
%     \hspace{2.8em}%
%     \mbox{ }%
%     \newline%
%   \end{scenario}

%   \noindent%
%   It seems the agent was not reasoning by addition.%
%   \footnote{
%     Rather, it seems the agent was reasoning by quaddition, following \citeauthor{Kripke:1982aa}'s (\citeyear{Kripke:1982aa}) definition of `quss':
%     \begin{align*}
%       x \text{ quss y} &= x \text{ plus } y, \text{ if } x,y < 57 \\
%                        &= 5 \phantom{pl if x,,,} \text{ otherwise }
%     \end{align*}
%     \vspace{-\baselineskip}
%   }

%   For, consider the counterfactual event.
%   The agent concluded \pv{\propI{x + y is 5}}{\valI{True}} from some \pool{} containing \pv{\propI{x is 68}}{\valI{True}} and \pv{\propI{y is 57}}{\valI{True}}.
%   Hence, it seems the agent was not concluding \pv{\propI{x + y is 125}}{\valI{True}}.

%   Further, though the counterfactual event suggests the agent was not reasoning by addition, it is less clear that the agent never reasons by addition.
%   The agent's interpretation of `\(+\)' as something other than `plus' may be no different from interpreting `\(A \land B\)' as `\(A\) and \(B\)' rather than `the meet of sets \(A\) and \(B\)'.
% \end{note}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% TeX-engine: luatex
%%% End:
