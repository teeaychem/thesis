\chapter{TempExamples}
\label{cha:tempexamples}

\begin{note}
  \begin{illustration}[Sudoku]
    \label{illu:gist:sudoku}
    % https://tex.stackexchange.com/questions/91422/tikz-sudoku-circle-and-connect-with-lines-some-cells
    \begin{figure}[H]
      \mbox{ }\hfill
      \begin{subfigure}{0.45\linewidth}
        \centering
        \sudokuGrid{}
        \caption{The starting grid \dots}
        \label{fig:sudoku:grid}
      \end{subfigure}
      \hfill
      \begin{subfigure}{0.45\linewidth}
        \centering
        \sudokuGridHints{}
        \caption{\dots with hints}
        \label{fig:sudoku:hint}
      \end{subfigure}
      \hfill\mbox{ }
      \caption{Sudoku}
      \label{fig:sudoku}
    \end{figure}
    An agent presses the `hint' button next to the Sudoku grid shown in~\autoref{fig:sudoku:grid}
    The Sudoku grid is updated as in~\autoref{fig:sudoku:hint}.

    The agent concludes that the current state of the grid rules out \(1\) as a candidate for the bottom left cell of the bottom left square.
  \end{illustration}
\end{note}


% \begin{note}[Illustration of \USE{}]
%   \begin{illustration}
%     \label{ill:rectangle:basic}
%     \mbox{}
%     \vspace{-\baselineskip}
%     \begin{enumerate}
%     \item The length of this rectangle measures \(19\text{cm}\) and the breadth of this rectangle measures \(7\text{cm}\).
%     \item So, the length of this rectangle is \(19\text{cm}\) and the breadth of this rectangle is \(7\text{cm}\).
%     \item
%       It is possible that my measuring device in inaccurate, but I purchased it from a reliable hardware store.
%     \item
%       To calculate the area of a rectangle, one multiples the length of the rectangle by breadth.
%     \item
%       \label{ill:rectangle:basic:reasoning}
%       \(19\text{cm}\) multiplied by \(7\text{cm}\) is \(133\text{cm}^{2}\).
%     \item
%       So, the area of the rectangle is \(133\text{cm}^{2}\).
%     \end{enumerate}
%     \vspace{-\baselineskip}
%   \end{illustration}
% \end{note}

\subparagraph{Theorem \illu{1}}

\begin{note}[A few illustrations]
  Let us now turn to a few illustrations before discussing \nI{} in further detail.

  We'll begin with a somewhat detailed illustration.
  \nI{} identifies a particular way in which an agent may fail to claim support, and the primary goal of the initial demonstration is to highlight why the agent would fail to claim support.
  Hence, the illustration treads a fine line between highlighting a problematic method, but not necessarily a problematic result.
  This is by design.
  And, I will continue to stress that \nI{} concerns a way of claiming support for some proposition, rather than the possibility of claiming support for some proposition.

  Following two illustrations will be variations on the initial.

  Still, it may be helpful to observe how \nI{} relates to an intuitively problematic result.
  Therefore, we will provide an additional, simple, illustration of a failure to claim support.

  The final illustration in the trio will complement the initial par of illustrations by highlighting an instance where~\nI{} does not apply.

  \phantlabel{dogmatism-wrt-nI}
  The reader may note structural similarities between these illustrations and \citeauthor{Kripke:2011wv}'s Dogmatism paradox.
  We will discuss the relation after the illustrations.
\end{note}

\paragraph{First}

\begin{note}[Brief illustration of \nI{}]
  The first illustration considers theories and counterexamples.

  \begin{illustration}
    \label{ill:CE:main}
    Suppose a researcher have constructed a theory of some general phenomenon.

    The theory seems to capture the phenomenon, and the researcher has claimed (inductive) support that the theory is adequate by applying it to various instances of the general phenomenon.
    Even if the theory isn't adequate, the theory has been (seemingly) successful applied to sufficient specific instances of the phenomenon.
    Hence, even if \mom{}.

    However, as the phenomenon is a \emph{general} phenomenon it also makes various predictions about what must happen in all other instances to which the researcher has not (yet, at least) applied the theory to.

    Hence, there is a possible counterexample to the theory associated with each instance the researcher has not (yet) applied the theory to.
    If some particular instance does not conform to the theory, the theory is inadequate.
    Conversely, if the theory is adequate, every particular instance of the phenomenon conforms the theory.
    In other words, if the theory is adequate, then there are no counterexamples to the theory.

    Of course, it may be simple to revise the theory is a counterexample exists, and the fundamental ideas of the theory may remain sound (\cite[Cf.][]{Bonevac:2011tz}).
    And, the theory may have sufficient resources to explain why any apparent counterexample is not a counterexample.
    Yet, it remains the case that the theory would need to be revised in light of a counterexample.

    Now, to summarise, the researcher may claim support for two propositions allow the agent to claim support that there are no counterexamples.

    \begin{enumerate}
    \item The theory is adequate, and
    \item If the theory is adequate, then there are no counterexamples.
    \end{enumerate}

    At issue is whether the researcher may claim support that there are no counterexamples to the theory from the claimed support for the two propositions in the following way:

    \begin{enumerate}
    \item I have claimed support that the theory is adequate.
    \item So, given the claimed support, theory is adequate.
    \item Therefore, as the theory is adequate, given the claimed support, it follows that there are no counterexamples.
    \item Hence, I claim support that there are no counterexamples to the theory.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{illustration}
\end{note}

\begin{note}[Seems problematic]
  Seems problematic.
  Claimed support that the theory is adequate is qualified by the possibility of counterexamples.
  {
    \color{red}
    Note, agent is, here, only claiming support that there are no counterexamples.
    And, claiming support may be \mom{}.
    So, it does not follow that the agent is ruling out the possibility of counterexamples to the theory.
    Plausible that the agent \emph{may} claim support.
    Problem is the way in which the agent goes about this.
  }

  {
    Even if not convinced about support, this way of claiming support seems problematic.
    Relying on theory being adequate.
    However, if this is the case, then no possible counterexamples.
    Issue is that such counterexamples are possible given the state of your claimed support.
    Hence, claiming support in this way seems to take for granted that there are no counterexamples.
  }

  Problem is that the reasoning only works if there are no counterexamples.
  If there are counterexamples, misled.
  Hence, problem to go from the theory is adequate.
  However, without this step, researcher doesn't get to no counterexamples.
\end{note}

\begin{note}
  So, relation between theory and counterexample \emph{undercuts} using way of using theory to get no counterexample.

  Now, given that the researcher has claimed support that the theory is adequate, the researcher may \emph{expect} that there are no counterexamples to the theory.
  And, it doesn't follow that the researcher may not claim support.
  Plausible that details of the theory provide some way of claiming support.

  Indeed, it seems the researcher is require to take the alternative path --- to show that the proposed counterexample is accounted for by the contents of the theory, regardless of whether the theory is true.

  Fault here is with respect to \ideaCS{}.
  {
    \color{red}
    Here, conditions of~{\color{red} inclusion} are satisfied, but we did not explicitly appeal to them.
    Purpose of~{\color{red} inclusion} is conditions sufficient for this kind of problem to arise.
    So, to do in argument for \nI{} is to develop is why~{\color{red} inclusion} does something similar.
    Upshot is that \nI{} is general.

    In the third illustration, we'll see why the way of claiming support is okay in some cases.
  }
  Difficult part is to account for why~{\color{red} inclusion} sets things up and ensures that things don't go too far.
\end{note}

\paragraph{Second}

\begin{note}[Idea main part of \nI{} works]
  As noted above, it is unclear whether or not there may be some way for the researcher to claim that there are no counterexamples to the theory.

  In other words, one may be wondering whether \ideaCS{} is a plausible constraint on claiming support.
  We gave a general argument for \ideaCS{} in~\autoref{cha:claiming-support}.
  However, it may help to see how the issue highlighted relates to an intuitively problematic instance of reasoning, regardless of how support is claimed.

  \begin{illustration}\label{ill:CE:colleague}
    Suppose a colleague has studied the researcher's theory, and they (the colleague) thinks they have found a counterexample.

    The colleague has informed the researcher that they think they have observed a counterexample.

    However, the colleague has not provided the researcher with any further details about the counterexample.

    Now, the conditional of interest may be made more precise:
    \begin{enumerate}
    \item If the theory is adequate, then the colleague has failed to identify a counterexample to the theory.
    \end{enumerate}

    Now, let's replicate the way of claiming support from before.

    \begin{enumerate}
    \item I have claimed support that the theory is adequate.
    \item So, given the claimed support, theory is adequate.
    \item Therefore, as the theory is adequate, given the claimed support, it follows that the colleague has failed to identify a counterexample to the theory.
    \item Hence, I claim support that the colleague has failed to identify a counterexample to the theory.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{illustration}

  I take this illustration to be intuitively problematic.
  In short, if claim support, then doesn't need to examine counterexample to claim support that it is not a counterexample.

  Possible response is that researcher does claim support, but information colleague impacts claimed support for theory.
  However, this is also puzzling.
  Researcher has no information.
  Hence, if retain confidence, then equally against counterexample.
  And, if does not retain confidence, then down the theory in a way that seems implausible.

  Seems, instead, that claimed support for theory persists, but that this doesn't extend to counterexample.\nolinebreak
  \footnote{
    Inclined to apply this to previous illustration.

    However, there's a difference between two illustrations.
    Here, someone (the colleague) has reason to think there is a counterexample, and this seems a sufficiently important difference to draw any quick conclusions.
    And, as we don't require a resolution to this issue, I won't explore further.
  }

  Perhaps more detail is needed.
  I have some doubts that claiming support is always bad.
  However, clearer that developed in a way such that problem remains.

  Now, seems that the researcher doesn't get to claim support because if counterexample, then theory is bad.
  Hence, requires that counterexample is not true in order to progress.
  But, then, doesn't make the move regardless of whether or not there is a counterexample.

  So, it seems \ideaCS{} does the work.
\end{note}


\begin{note}
  ``Undercuts using \(\phi\) for \(\psi\).''
  Same problem, failure of \ideaCS{}.

  For, the agent has already `assumed' that they may reason.

  Problem is that the agent doesn't get to claim support for \(\psi\) because fail the \ideaCS{} thing.
  If \(\psi\) isn't really the case, then reasoning collapses.
  Key thing about our understanding of claimed support is that it holds up even if the agent is \mom{} about the value of the proposition.

  {
    \color{red}
    Note:
    There's possible tension here.
    It seems that if the first illustration is okay, then this (second) illustration should also be okay.
    Maybe.
    But, this is too quick.
    Additional information here.

    Now, still some difficulty, as I think \EAS{} might apply to the first.
    So, shouldn't it apply to this?
    Well, no.
    For, \EAS{} only suggests possibility in some cases.
    Fine to think of this additional information as constraint on appeal via ability.
    For, if the colleague thinks they've found a counterexample, then this suggests a problem with the agent's ability.
  }
\end{note}

\paragraph{Third}

\begin{note}[Variation where \nI{} does not apply]
  \begin{illustration}\label{ill:CE:testimony}
    Suppose the researcher has published a paper containing the details of the theory.

    Our attention now turns to a novice who has read far enough into the paper to understand, at least, the general phenomenon that the theory applies to and that the researcher has claimed inductive support for the theory.
    We'll also assume that the novice does not possess the expertise required to apply the theory.\nolinebreak
    \footnote{
      Though I don't think this assumption is important.
    }

    The novice is thinking about instances of the general phenomenon, and identifies one.

    The conditional of interest is:
    \begin{enumerate}
    \item If theory is adequate, it accounts for this instance of the phenomenon.
    \end{enumerate}

    Of course, the novice also recognises that the theory is inadequate if it  does not account for the particular instance of the phenomenon.
    Still, the novice claims support in the familiar manner.

    \begin{enumerate}
    \item I have claimed support that the theory is adequate (this time by reading a published paper).
    \item So, given the claimed support, the theory is adequate.
    \item Therefore, as the theory is adequate, given the claimed support, it follows that the theory accounts for this instance of the phenomenon.
    \item Hence, I claim support that the theory accounts for this instance of the phenomenon.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{illustration}

  In contrast to the previous illustrations, it seems the novice may claim support in such a way.

  Possibility of being either \mom{} remains.
  Still, not in position to reason through theory and phenomena.
  Hence, claiming support from something like status of peer review --- or testimony.
  And, not accounting would not show peer review is bad.
\end{note}

\paragraph{Summary of illustration and variations}

\begin{note}
  These three illustrations.
  First, kind of scenario that's the main interest.
  Where claiming support in a certain way seems problematic, even if it not clear that the agent may claim support in some other way.

  To stress the problem, considered a cleaner case, where it seems agent may not claim support, and argued that same problem is a plausible account of why.

  Third illustration, way of claiming support is okay.
  As all instances of \nI{}, and hence the previous two illustrations, focus on particular way of claiming support illustrated that it's okay.
\end{note}

\begin{note}[Intuition]
  In short, \nI{} captures a limitation: An agent is not in a position to claim support for some proposition \(\psi\) when circumstances are such that the claimed support requires (from agent's point of view) that the agent is already in position to claim support for \(\psi\).

  No claiming support for\(\psi\) if failure to establish support for \(\psi\) independently of the value of \(\phi\) would reveal problem with the support claim for \(\phi\).

  Hence, \nI{} focuses on when an agent may claim support for some proposition by noting that (from the agent's perspective) that the value of the proposition is determined by further propositions the agent has claimed support for.

  Some other way of claiming support for \(\psi\).
  However, not merely an alternative path, but an alternative path that must be possible given claimed support for \(\phi\).

  Issue is that given {\color{red} background} and~{\color{red} inclusion}, agent expect that they have the resources, and hence expects \(\psi\) is the case.

  So, that \(\phi\) has value \(v\).
  In doing so, resources to claim support for \(\psi\) has value \(v'\).
  Hence, \(\psi\) has value \(v'\).
  So, \(\psi\) having value \(v'\) is a requirement on claimed support for \(\phi\) being any good.
  However, no support claimed for \(\psi\) having value \(v'\).

  In cases of reasoning with a conditional, such as the illustrations given, that value of \(\phi\) constrains value of \(\psi\) is in general helpful information, but in these specific cases it does not help the agent claim support for \(\psi\) having value \(v'\) because if \(\psi\) isn't already so constrained, then no appeal to \(\phi\) having value \(v\).

  Similar to other principles, failure because establishing something that needs to be the case in order to be in a position to establish.
\end{note}

\begin{note}[Illustration, testimony]
  To illustrate, consider expert testimony to a layperson.
  Suppose you, the expert, have testified to me, the layperson, that there are exactly five intermediate logics that have the interpolation property.\nolinebreak
  \footnote{Cf.\ \textcite{Maksimova:1977un}}
  From this it follows that there is an intermediate logics that has the interpolation property.

  However, I am quite confident that I would not be in a position to claim support for the latter proposition without your testimony.
  So, given that I do not have the expertise involved, any failure by me to claim support that there is a intermediate logic with the interpolation property is uninformative.
\end{note}

\begin{note}
  Still, an issue arises if we are both experts.

  To illustrate, suppose you and I are both experts.
  You claim to have developed a sound and complete proof system for an logic and presented me with a paper containing the system and a proof.
  Given that I have the paper and the expertise, I am confident that I would be mistaken or misled by your testimony if I am not in a position to claim support that the system is sound and complete by working through the paper.\nolinebreak
  \footnote{
    Here, complexity of understanding of having resources shows.
    For, it may be that the reader learns something new, a lemma etc.\ which could be considered a new resource.
    Likewise, one may think that it's fine to continue to follow testimony given a problematic proof as one is confident that the prover has the resources to revise the proof.
    If so, not clear whether conditional holds, and will depend having resources.
    If proof synthesises resources, then may still hold.
    If proof introduces new information, then conditional does not hold.

    No clear answer for these cases.
    Intend to be compatible with your understanding of resources.
    Will only take a stance on this when applying.
  }
\end{note}

\begin{note}
  \begin{illustration}
    \label{ideaS:illu:clock}
    Suppose an agent considers it \epPAd{} that the clock is not functioning, and has reasoned as follows:
    \begin{enumerate}
    \item The clock is in the centre of the library, and has been seen by many people.
    \item The clock is functioning.
    \end{enumerate}
    \vspace{-\baselineskip}
  \end{illustration}

  Still, the agent may observe that:
  \begin{enumerate}
    \setcounter{enumi}{-1}
  \item It is exam week so the library is busy and many students will be sensitive to what time it is.
  \end{enumerate}

  {
    \color{red}
    Possibly useful observation here is that it seems there are additional considerations which may `bolster' the agent's conclusion.
    However, this isn't a \requ{}.
  }
\end{note}

\begin{note}[Gifts]
  \begin{illustration}
    \label{illu:S:gifts}
    \begin{enumerate}
    \item S knows me very well.
    \item Whatever S has gifted me satisfies some desire I have.
    \end{enumerate}
  \end{illustration}
  Perhaps wishful thinking, but fine with respect to \zS{}.

  {
    \color{red}
    Maybe useful to include, as this shows how \zS{} is kind of weak.
    The key thing to think about is whether there is something that could lead the agent to conclude that their friend doesn't know them very well.
  }

  The same basic idea underlying~\autoref{illu:S:gifts} extends to various other premise-conclusion instances.
  Consider, for example:
  \begin{enumerate}
  \item The newspaper reported \(S\) said that \(p\).
  \item \(S\) said that \(p\).
  \end{enumerate}
  It seems plausible that the reasoning from premise to conclusion assumes that the paper has a history of accurate reporting.
  And, and if available to the agent are various premises which suggest that the paper does not have such a history, then the agent may refrain from concluding \(S\) said that \(p\) from the report.
  Still, even if the agent were to relax their epistemic state so that the newspaper lacking such a history is \epVAd{}, the agent may still have sufficient premises to conclude that the newspaper does have the history, those premises may resist questioning, and so on.
  Hence, whether or not an agent has \support{} for the conclusion broadly depends on the agent's epistemic state.
  Further, the agent may also have some other premise from which to conclude \(S\) said that \(p\).
  For example, by having been in the room when \(S\) said that \(p\).
\end{note}

\begin{note}
  \begin{illustration}
    Suppose the check engine light of the agent's car has come on.
    As a result the agent has concluded that their is some fault with their car's engine.

    Of course, the agent is aware that it is possible for the check engine light to be on with no fault in the engine.
    Still, even if the agent were to consider the possibility that their is no fault in the engine, the presence of the check engine light would lead the agent to conclude that there is some fault in the engine.
  \end{illustration}

  The agent's reasoning is non-deductive, and the agent recognises that by moving from the check engine light to a problem with the engine that they may conclude that there is a problem with the engine when there is none, but as the agent would reason regardless,~{\color{red} ???} is satisfied.
\end{note}

\begin{note}
  Pair of trivial instances.
  Inspection immediately grants.
  \begin{illustration}
    \begin{figure}[h!]
    \mbox{}\hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item That persons' eyes have been closed for a long time and their breathing is slow.
      \item That person is asleep.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
      \begin{enumerate}
      \item The die has rolled even in \(5251\) of \(6000\) samples.
      \item The die is biased.
      \end{enumerate}
      \caption{}
    \end{subfigure}
    \hfill\mbox{}
    \caption{}
    \label{fig:ideaS:basic-examples}
  \end{figure}
\end{illustration}
\end{note}

\begin{note}
  Similar to verifying an algorithm may be implemented.
  Break down all of the steps in the algorithm, and then ensure that it is possible to express each of the steps in the programming language of choice.

  \begin{quote}
    \textsc{factorial}(\(n\)):\newline
    \textbf{if} \(n = 1\)\newline
    \mbox{}\indent \textbf{return} \(1\)\newline
    \textbf{else}\newline
    \mbox{}\indent \textbf{return} \(n \times\) \textsc{factorial}(\(n-1\))
  \end{quote}

  Fortran 77 does not support recursion, a function may not call an instance of itself.\nolinebreak
  \footnote{
    This is not to say that one may not compute factorials using Fortran 77.
    It's a Turing complete language.
    However, would require a different (non-recursive) algorithm.
  }
  By contrast, the recursive factorial algorithm may implemented in languages that support recursion, such as Lisp or Python.
\end{note}

% \begin{note}[Milk]
%   \begin{illustration}
%     Suppose \nagent{13} is interested in concluding that they're set to have coffee before travelling to work from the premises that they have the time and resources to make a cup of coffee.
%     And, the additional premise that they have milk.
%     (For, the milk will cool the coffee quickly enough for \nagent{13} to drink before leaving.)

%     Still, \nagent{13} is unsure about whether the milk is safe to drink.
%     The milk smells okay-ish and \nagent{13} is fairly sure that they bought it fairly recently.

%     \nagent{13} holds that if the milk is past it's expiry date, then it is not safe to drink.
%     But, if the milk is within it's expiry date, then as it smells okay-ish, \nagent{13} would conclude that the milk is safe to drink.
%   \end{illustration}
%   \epVAd{} that the milk is not safe to drink.
%   It is not \epVAd{} for \nagent{13} to conclude conclusion from premises if the milk is not safe to drink.
%   \nagent{13} is holding the milk, so trivial to check the expiry date.

%   It seems intuitive, at least to me, that \nagent{13} should check the expiry date.

%   For present purposes, this intuition is accounted for by there being an antecedent check on whether it makes sense for the agent to conclude.
%   The expiry date.

%   {
%     \color{red}
%     Here, revise to:
%     Bad if the milk is over a week old.
%     So, remember last time went shopping, and reason from there.

%     Then, observe that this also extends more straightforwardly to checking the expiration date.
%   }
% \end{note}

% % % Spot the difference % % %

\begin{note}[Spot the difference]
  \begin{illustration}[Spot the difference]
    \label{illu:CS:spot-the-diff}
    The agent has been working through a spot-the-difference to pass some time.

    Though the time is not completely passed, the agent examined the two images with what seems sufficient care to claim support that they have found all the differences.
    However, the agent did not keep track of the number of differences.

    The agent announces `I have found all the differences' and their companion responds `All fifteen?'.

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*)]
      \setcounter{enumi}{-1}
    \item
      \label{illu:CS:spot-the-diff:info}
      If I have found all the differences, I have found fifteen differences.
    \end{enumerate}

    The agent then reasons as follows:

    \begin{enumerate}[label=\arabic*., ref=(I\ref{illu:CS:spot-the-diff}.\arabic*), resume]
    \item Exhaustive search.
    \item
      \label{illu:CS:spot-the-diff:all}
      I found all the differences.
    % \item\label{illu:CS:spot-the-diff:info} My companion has testified that there are fifteen differences.
    % \item\label{illu:CS:spot-the-diff:cond} If I have found all the differences, I have found fifteen differences.
    \item
      \label{illu:CS:spot-the-diff:fif}
      So, I have found fifteen differences. \hfill (From \ref{illu:CS:spot-the-diff:info} and \ref{illu:CS:spot-the-diff:all})
    \end{enumerate}
  \end{illustration}

  Before going further, structure of this.

  The agent performed some reasoning, and concluded that they found all the differences.
  However, that reasoning is mentioned but not stated in the \illu{0}.
  Rather, present is distinct instance of reasoning after being provided with information.
  ``If not 15, then problem''.
  Present reasoning appeals to past reasoning, and draws out consequence of this given new information.
  Important: the present reasoning does not consider possibility that the agent did not find all 15 differences.
  Instead, consequence of conclusion of previous instance of reasoning.
  Still, epistemically possible that the agent did not find 15 differences.
\end{note}

\begin{note}
    Providing additional information about what the agent has claimed support for.
  Recall, \autoref{assu:CSVP}, information rather than \world{}.
  \nolinebreak
  \footnote{
    Still slight issue.
    Offering a redescription.
    You met Clark Kent, so you met Superman.
    In this case, rather than claiming support for meeting Superman, provided information is seen as an equivalent formulation.
    It is possible to read \autoref{illu:CS:spot-the-diff} in this way, and this might be the most natural interpretation.
    However, it is not the interpretation under which see the problem.
    Rather, problem is where the conditional is explicit.
    Unlike Superman case, proper conditional.
  }
\end{note}

\begin{note}
  Information leads to \requ{}.

  Possibility of not fifteen.
  And, not merely that the agent performed the reasoning, but that the reasoning identified all.
  If not fifteen, then not all, so would involve appeal to something that is not the case.

  And, present reasoning does not include reasoning about \requ{}.
\end{note}

\begin{note}
  \color{red}
  Though, this is interesting.
  For, the agent may have found fifteen.
  This, then, helps stress the point that it's not just reasoning to the conclusion.
\end{note}

% % % Wally % % %


\begin{note}[Wally]
  \begin{illustration}[Where's Wally]
    \label{illu:CS:wheres-wally}
    \nagent{15} has a book containing numerous drawings of bustling scenes in which various characters are doing a variety of things.
    And, somewhere in each scene is a character called `Wally', identifiable by a collection of individually necessary and jointly sufficient distinguishing features.
    These features include a red and white striped jumper, blue trousers, short brown wavy hair, and so on.

    \nagent{15} has searched through one particular scene, and has identified a character with a variety of the features.
    Before concluding that the character is Wally, \nagent{15} remembers that there is a picture of Wally On the cover of the book, with all the identifying features present.

    Wally is always wearing a pair of round glasses, but this was not a feature \nagent{15} kept in mind when searching for Wally, and it is \epVAd{} for \nagent{15} that the character they identified is not wearing round glasses  --- \nagent{15} only recalls the features they identified.
  \end{illustration}

  Our interest is, generally, in whether \nagent{15} may conclude from the variety of features identified that the character is Wally.

  Descriptively, of course, there seems no barrier.
  An agent may reason to an arbitrary conclusion to arbitrary premises.

  So, specifically, our interest is in whether \nagent{15} would claim support that the character is Wally by concluding that the character is Wally from the variety of features identified.

  The difficulty for \nagent{15} is that so long as they consider it \epVAd{} that the character is not wearing round glasses, then there a clear check on whether \nagent{15} may reason to a different conclusion.
  For, if \nagent{15} were to check whether the character is wearing a pair of round glasses, and the character is not wearing a pair of round glasses, then \nagent{15} would conclude that the character is not Wally.
\end{note}

\begin{note}
  {
    \color{red}
    Here, revise the Wally scenario to involve reasoning about the characteristic features of Wally from memory.

    Part of the interest here, then, is that in some cases there is an `internal parallel' to doing something that doesn't involve reasoning.
  }
\end{note}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
