\begin{note}[Misleading is okay most of the time]
  Indeed, Misleading support is not, in general, a problem.
  Roll a die, claim support for bias, misleading --- and clear that it may be misleading, but fine.
  Or, director's previous films to claim support that one will find the new film enjoyable.
  Support is not conclusive.

  Following, moving to value given support is not problematic.
  Looks like rain, if rain then plants watered, looks line plants will be watered.
  Note looks genuine, purchase item.
  Cold, is cold, heating has broken.
\end{note}


\begin{note}[Explanation of \nI{}]
  With some illustrations in hand, we now turn to sketching an argument for \nI{}.

  Two conditions.
  \begin{enumerate}
  \item Support claimed for \(\phi\), which may be misleading.
  \item Information that implies support claimed for \(\phi\) is misleading if \(\psi\) does not have some value.
  \end{enumerate}
  Goal is to show that agent is not in a position to claim support for \(\psi\) by using implication.
  In other words, no claiming support for \(\phi\) because support for \(\phi\) would be misleading if \(\psi\) were not the case.

  Observations:
  \begin{enumerate}
  \item No claim about \(\psi\) without appealing to \(\phi\) having value.
  \item As misleading,
  \end{enumerate}

  Using information only.
  So, required to get antecedent.
  Antecedent is that support claimed for \(\phi\) is not misleading.
  Hence, that \(\phi\) has the value indicated by the support claimed for \(\phi\).
  For, if agent does not, then \(\phi\) may be misleading, and then no basis for \(\psi\).

  So, requirement that \(\phi\) have value.
  Move from claiming support for \(\phi\) to holding that \(\phi\) has value.
  For, if no claim about \(\phi\) having value, then no claim about support not being misleading.

  These two things are different.
  May wish to observe here that the agent isn't in a position to move to the stronger claim.
  However, difficult\dots
  View this as something that may be discharged.

  Then, obtain that \(\psi\) has value.
  This is difficult, but I think correct.
  For, agent has moved to \(\phi\) having value, and hence is not appealing to support claimed.
  So, implausible that the agent is in a position to claim support for \(\psi\) prior to holding that \(\psi\) has value.
  From \(\phi\) having value to \(\psi\) having value.

  The question is whether there is a way to discharge additional claim about \(\phi\).

  For example, with \(BK\phi\), then this seems plausible, because have seen that \(\phi\) follows given belief.

  {Visual representation is having these two things leading to \(\psi\)}
  Circularity?
  In order to get stronger claim, need \(\psi\) to be the case, but without stronger claim, no getting that \(\psi\) is the case.
  In other words, prevent discharging because then lose the okayness of the initial transition.

  I.e.\ the point is not simply that the agent isn't in a position for stronger claim, but that without stronger claim there's no other way for the agent to get to \(\psi\).
\end{note}

\begin{note}[Clarifying]
  Why first part isn't sufficient by itself.
  May be the case that agent gets some information about extending.
  Plausible that other agent knowledge is like this.
  Support claimed that some other agent knows that \(p\) doesn't really help with \(p\).
  However, given that they know, factivity means that one is in a position to claim support for \(p\) being the case.

  What the second part adds is that there's no equivalent explanation in the instances described.

  So, it's the combination of these two things.
  Support isn't strong enough to do anything more robust, and no account of why \(\psi\) without being more robust.
\end{note}

\begin{note}[Expand on examples]
  Return to Rolex.
  Support claim for watch being genuine.
  From weaker, \nagent{1} doesn't have sufficiently strong support.
  Hence, no claim to support for jewellery shop.
  How does this show anything about the store?
  Haven't stated that the acquaintance purchased from the shop, nor that within time frame.
  There's nothing from the watch genuine to jewellery apart from information about mistaken.

  Go for pragmatics, but then agent doesn't need misleading premise, it's different information.
  Like gallery case, something else.

  In turn, then, replying on \(\psi\) having value in order to claim support for \(\psi\).
  Support claimed for \(\psi\) is in part that \(\psi\) has value.

  This is a problem.
  Value prior to claim of support to value.

  Trace back to where agent goes beyond support claimed.
  Distinction between appealing to support and appealing to having value.
  Agent steps beyond support.
  \(\psi\) results from this.
  Hence, \(\psi\) isn't obtained from support for \(\phi\) plus information.

  This, then, applies quite generally, there's always going to be a problem when moving from support claimed to proposition having value.

  This is fairly restricted, as relies on not misleading to `force' interest in value.

  Clearer example may be variant of transmission failure.
  So, simple knowledge, zebra or whatever.
  Visual perception, zebra, not donkey, etc.
  Change so that conditions are a little rough, and eye sight is to some extent at issue.
  This would be an instance.
  Possible that support claimed for perception in good conditions is different --- some new information would be required to find issue with sight.
  Or, may extends to resist alternatives, the agent needn't go through how things are.
  \nI{} does not clearly extend to such cases.
\end{note}

 Note, this doesn't mean that support is independent of what the designated value is.
  Accuracy first epistemology, for example.
  Understand support may come down to getting the value right, but this is compatible.\nolinebreak
  \footnote{
    \color{red}
    To do: read \cite{Pettigrew:2019td}
  }
  Remains case that in order to have support the agent needs to be sensible regardless of whether the agent is correct.

  May be misleading, but does suggest.

  Likewise, may be mistaken, but still in a position to claim.
  Variant of highlighted proposition.

  {
    Two propositions so far.
    If an agent has traced, then have something to say.
  }


\begin{note}[Moore's proof]
  On Moore's proof.
  Something problematic if going from hands to external world, as this would fit.
  However, nothing clearly problematic about noting that hands includes external world.
\end{note}


\begin{note}[Notes on \nI{}]
  Stress that this doesn't raise an issue for the support claimed for \(\phi\).
  For, there is no indication that the support claimed for \(\phi\) is misleading or mistaken.
  The problem is that what secures resistance against these two properties with respect to \(\phi\) does not extend to resistance with respect to \(\psi\) if require the value of \(\phi\) in order to get to \(\psi\).
\end{note}



  Would be misleading, but information allows the agent to establish an `is-also' relation of support.\nolinebreak
  \footnote{
    Example.
    If not in London, then in Paris.

    This is a `is-also' support.
    Conditional states that support for not in London is also support for Paris.
    Does the agent obtain support for Paris on the basis that the support for not London is misleading if Paris is not the case?
    Well, would not show that the \emph{support} is misleading.
    Because, the conditional establishes something that doesn't follow from the antecedent without information.

    By contrast, the general-to-specific is such that the support the agent has for general must also extend to specific.

    So, not London to Paris has this `is-also' understanding.
    If not in Paris, then it seems the agent is still going to have support for not in London.
    Puzzle here is contraposition.
    For, it follows that if not in Paris then in London.
    However, this is not so obvious.
    May give up conditional.

    Looking ahead, \gsi{} is an `includes' conditional --- support claimed for general includes support for specific.
  }



  Useful problem claim for bootstrapping:
  Unless you already have complete faith in me, I am more trustworthy than you think.


  Another important assumption about support is that it's linked.
  This should be stated early, as it's important.
  Key example is going to be something like addition, for ease.
  If you've understood addition, then provide support for x*y=z.





  1. Issue isn't with possibility of different value for psi.
  2. In lots of cases, different value of psi would be a defeater, but a possible defeater isn't necessarily a defeater.
  3. Third person variation on main cases seems equally bad.
    a. So, same chess example in the third person.
    Observer is confident that the agent understands the basics of chess.
    Observer gets the novel information.
    So, also novel to the observer.
    It's not clear that the observer can easily be confident that the agent is going to demonstrate the existence of the strategy.
    At least, from going via attribution.
  4. Paired with uRa, the impact of nI is that the agent needs to reason from the support they have to claim support for novel proposition.

When going by value without inclusion, retain the independence properties.


\begin{note}[Ball scenario]
  \nagent{3} picking balls from a bag of 1000.
  \nagent{3} has picked 600 from the bag, all have been red or green, even split.
  \nagent{3} doesn't have support for next ball red with 50.
  Unlucky to not pick any of the blue balls, or to have an even split.
  Still, may claim support for it being unlikely that, i.e.\ some weaker claim which is compatible with the agent having picked a non-representative sample.
\end{note}


\begin{note}[Mistaken]
  \emph{Mistake} --- relies on distinction between support and claiming support.
  An agent may be mistaken about support they have.
  Intuitive case, diary entry, speeding ticket.
  Entry was actually from previous year, and bug in the software.
  Agent didn't really have support, but was fine to claim as support.
  It's not the case that the diary continues to provide support, which is overshadowed by the discovery of the software bug and/or the CCTV footage.

  One may hold that the agent still has support as it was a bug.
  If redo as a mistake made by the agent by not checking the year, then agent isn't in a position to claim support.
  Generalising, not possible claim support and be mistaken.
  So, any `proper' claim of support is having support.

  So, significant assumption is that mistakes are possible but do not prevent agent from claiming support.
  Compatible with a directive to fix mistakes.

  Simple example, classical and intuitionist mathematicians.
  Each may deny that the other obtains support, but clear that each is in a position to claim support for conflicting theorems.
\end{note}


  % Reasoning is a process.
  % Reasoning is an action performed by an agent.
  % Some success condition for claiming support.
  % However, this success condition does not require anything independent of the process.
  % Seen this from the conditions imposed on support, it doesn't matter whether proposition has value, or whether there is a relation of support between premises and conclusion via steps.

  % If premise or step is not used, then the premise or step is not required to provide an account of the action performed.
  % Action which does not depend on things being a certain way in order to be successful.
  % And, given such a process, you only need to appeal to the constituents of the process to account for success.


  \begin{note}[Motivating idea, value]
  Thinking about attitudes.
  Some kind of value on the attitude.
  Doxastic, truth, maybe.
  Why should it matter that the reasoning has been performed prior to forming the attitude?

  Well, providing support regardless of what the value turns out to be.

  Here, a little different.
  Cases in which, whatever it turns out to be, agent is permitted to form such an attitude, constrain with additional condition which seems harder to give up.
\end{note}

\begin{note}[Motivating idea, normative]
  Seems as though there's a plausible normative dimension, in which an agent may be criticised on what they are able to do.
  In particular, ability to reason further, but did not do so.
  Difficult to understand this as a requirement to reason, given constraints on resources.
  Doesn't seem to excuse, or so one may think.

  That is, this is something in between
  \begin{enumerate}
  \item The agent not having the resources.
  \item The agent having the resources, but being unaware that they may use them.
  \item The agent having the resources, and being aware that they may use them.
  \item The agent using the resources.
  \end{enumerate}
\end{note}


\begin{note}[Small corollary/motivation]
  Small corollary is that if the agent has reasoned, then don't need to rely on memory as premise for claiming support.
  Rather, memory works to provide information.

  To extent this is plausible, this is the `backwards' looking part of~\rC{}.
  It's the `forwards' looking part that we will focus on.
\end{note}


% % %
Possible different take on NI:
% %
  In short, violate the basic constraint on support.

  In contrast, if~\ref{nI:inclusion} does not hold, then the agent would not be required to assign a value to \(\psi\) when moving to the value of \(\phi\).

  The problem is claiming support for \(\psi\).
  The agent has claimed support for \(\phi\), and therefore may expect that they are in a position to claim support for \(\psi\).
  However, if the agent goes by value, then they are already expect that \(\psi\) is the case.
  For, if no expectation that \(\psi\) is the case, then no move from claimed support for \(\phi\) to \(\phi\).
  Expanded, from~\ref{nI:inclusion} claimed support for \(\phi\) requires the agent to expect position to claim support for \(\psi\).
  However, only in a position to claim support for \(\psi\) if committed to \(\psi\) having that value.

  The point here is that given~\ref{nI:inclusion}, the agent already stands in a certain relation to \(\psi\) regardless of whatever value \(\phi\) has.
  Expect in a position to claim support for \(\psi\).
  Therefore, moving from claimed support to value (already) requires value of \(\psi\).

  So, claimed support for \(\phi\), fine.
  However, if the agent were to claim support by value.
  Then, claimed support for \(\phi\) is what's establishing.
  Yet, in turn, this is in part that the agent expects \(\psi\) to have value.
  For, given \ref{nI:inclusion} the agent is required to expect that \(\psi\) has value.
  Therefore, escalating expectation to claim, in a sense.

  The issue lies in the move from \(\psi\) to claiming support.
  However, the source of the issue is moving to the value of \(\phi\).
  Because, this is a particular kind of reasoning, reasoning that requires support is not misleading or mistaken.
  It is this way that expectation regarding claimed support for \(\psi\) gets drawn in.

  \emph{Escalating expectation to claim}.
  Because, require expectation to move to \(\phi\), but in turn use \(\phi\) to claim support for \(\psi\).
  Not possible to move without expectation, 
  Or, alternatively, 
