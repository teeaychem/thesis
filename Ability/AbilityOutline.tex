%%% Local Variables:
%%% TeX-master: "master"
%%% End:

\chapter{Overview}
\label{cha:overview}

\section{Outline}
\label{sec:outline}

\begin{note}
  In this chapter we provide a high level overview of the main arguments made in this thesis.
  A significant part of the high level overview of arguments is an overview of the premises and assumptions that those arguments rest on.

  By given high level overview, clarify on how premises, assumptions, and conclusions relate.
  In the main body of the thesis, afford to elaborate.
  And, allow choice of where to seek elaboration.
\end{note}

\begin{itemize}
\item Start with claiming support, used throughout, so important.
\item Introduce and motivate plausible constraint on support, to be argued against/exception for.
\item Outline exception.
\item High level overview of argument for exception.
\item Major and minor.
\item Largely fairly high level sketch of major argument.
\item Type of ability information.
\item Understanding \emph{de re} ability reading.
\item \AR{} and \WR{}.
\item For the moment, brief, much more detail in relevant chapter.
\item Relation between \AR{} and \uRa{}.
\item Constraint on reading of ability.
\item Requires argument for \WR{}.
\item Introduce \nI{}.
\item Sketch argument for \nI{}.
\item Link \nI{} and \AR{}.
\item Completes overview of major argument.
\end{itemize}

\section{Ability and access to claimed support}
\label{sec:abil-access-supp}

\begin{note}
  Following introduction, interest is with ability.
  In particular, observation that \gsi{} information, and confidence in general ability seems to allow agent to claim support for result.

  Question on what basis the agent claims support.

  Slightly more general statement.
  \begin{quote}
    When and why an agent may claim support for the result of reasoning that the agent has not witnessed.
  \end{quote}
  Ability claims of interest provide some answer to `when'.
  For, ability provides information about what the result is, and also that the agent has the opportunity to perform the reasoning.\nolinebreak
  \footnote{No claim to necessity}

  Suggested in introduction, answer to `why' is more complex.
  % \begin{quote}
  %   Our interest is in when an agent may claim support for some conclusion of some instance of reasoning on the basis of the support the agent may claim for the premises of the instances of reasoning.
  % \end{quote}
\end{note}

\begin{note}[Introducing support]
  Initial clarification is with respect to claiming support.
  Emphasis on `\emph{claim}'.

  The thesis is not about when and why an agent \emph{has} support for the result of reasoning that the agent has not witnessed.

  Two reasons for this.
  First, neutral for main thread of argument on what support amounts to.
  Interest is with structure of claim, and background assumption that if success in claiming then structure of support follows structure of claim.

  Second, whether or not an agent has support often seems secondary.
  To illustrate:
  It may be that any claimed support for a proposition is support for that proposition, but perhaps not.
  Suppose `flan' is written on the side of a container.
  I may claim support that the container contains flan.
  And, it may be that the writing on the side of the container is support for the box containing flan.
  However, the straps ensuring the container remains closed is unfortunately placed, and if moved would reveal the side of the container reads `flannels'.
  The unfortunate placing of the straps does not seem to prevent \emph{claiming} support, but I'm not sure whether it is right to say that the writing on the side of the box (straps in place) \emph{does} the box containing flan.
  So, in what follows I will speak in terms of claiming support, and leave open whether what is claimed reflects on whether an agent has support.\nolinebreak
  \footnote{
    In particular, claiming allows focus on internal constrains, while remaining silent on whether having support is (in part) determined by external factors.
  }
  \(^{,}\)\nolinebreak
  \footnote{
    Distinction between propositional and doxastic support.
    Propositional, support agent has whether or not made a claim.
    Doxastic is successful claim and propositional support.
    So, both require that the agent has support.
    Claimed support is the agentive component of doxastic support.
    Not interested in whether the agent also has propositional support, though more or less assume.
  }
  \(^{,}\)\nolinebreak
  \footnote{
    {
      \color{red}
      English is somewhat difficult.
      It is somewhat unfortunate that `an agent has claimed support for \(\phi\)' may be read `there is support which the agent has claimed for \(\phi\)'.
      Still, this seems to follow more easily from `support claimed'.
      So, `claimed support' emphasises the claim, while `support claimed' emphasises support.
    }
  }
\end{note}

\subsection{Background for claiming support and reasoning}
\label{sec:claimed-support}

\begin{note}[Understanding of claiming support]
  Understanding of claiming support.

  Begin with a sufficient condition.
  In short, most instances of reasoning.
  Claiming support is common.

  Then, two types of defeaters.
  Mistaken and misled.
  Use to form a necessary condition.
  If claimed support, then agent deems that claimed support is not defeated.
  `Deem' is a placeholder.
  Strong or weak.
  Single constraint is that when claiming support, potential defeaters that aren't ruled out.\nolinebreak
  \footnote{
    At least two ways of viewing this.
    First, claiming support is restricted.
    Second, \emph{claiming} support only applies when there are potential defeaters, and some other relation to support when possible defeaters get ruled out.

    These are different, but I don't think the difference matter for resource bound agents of interest.
    Lack of resources is that always potential defeater, even if every possible defeater may be ruled out.
    }
  Finally, property, that claimed support does not depend on whether proposition the agent has claimed support for is true, or whether the claimed support \emph{does} support (if these are separated).
  Property will be important.
\end{note}

\begin{note}[Sufficient condition]
  We start with a sufficient condition for claiming support:
  \begin{proposition}[\bP{-} --- \bP{}]\label{prem:bP}
    If an agent may claim support for premises and steps of reasoning, accesses those premises and traces claim to support through those steps of reasoning, then agent may claim support for conclusion on basis of the claimed support for the steps and premises of reasoning.
    (Given that the agent deems that the claims to support for premises and steps used are undefeated when drawing conclusion.)
  \end{proposition}

  The purpose of taking~\bP{} as basic is to fix a basic understanding of when an agent may claim support.
  In short, an agent may claim support when reasoning goes well.
  And, reasoning goes well when there are premises and steps of reasoning available to the agent, and the agent draws on these to claim support for the conclusion.
  The parenthetical remark is a simple safeguard, the agent does not lose a claim to support for the premises or steps in the process of reasoning.\nolinebreak
  \footnote{
    May think that this is the wrong safeguard.
    Consider the liar paradox:
    `This sentence is false.'
    \bP{} prevents agent from claiming support that the sentence is true or false.
    However, may think that agent is in a position to claim support that the sentence is both true and false.
    Indeed, standard reasoning associated with the liar suggests that the sentence is both true and false.
    Still, it's not obvious from demonstrating that the sentence is both true and false that one may claim support for the sentence being true and the sentence being false.
    That is, one may confine the paradox to the truth value of the sentence, rather than (associated) surplus of support.
  }
  We consider defeaters below.
  First, an illustration.


  Suppose an agent measures that the box in front of them has the dimensions of \(19\text{cm}\) by \(7\text{cm}\).
  The agent understands how to calculate the area of a box, and by performing some reasoning comes to hold that the area of the box is \(133\text{cm}^{2}\).
  The support the agent has for holding that the area of the box is \(133\text{cm}^{2}\) is obtained (at least in part) on the measurement of box, understanding how to calculate the area of box, and some grasp of arithmetic.

  Whether some (or all) of the required arithmetic is to be included as a premise or a step of reasoning may be set aside.
  Similarly, set aside whether further arguments, or whether some premises and steps are taken as basic.
  For example, perhaps some the agent requires some further claim to support for using the ruler to measure the box such as comparison to a standard, or perhaps the agent's claim to support terminates by noting that their use of the ruler is a reliable process.
\end{note}

\begin{note}[Value proposition]
  Reasoning and claims to support focus.
  Briefly introduce a pair of propositions to clarify claim to support and reasoning.

  \begin{proposition}[Claimed support is for the value of a proposition]\label{prop:csifvoap}
    When an agent claims support for some proposition, the agent claims that the proposition has some value.
    Where:
    \begin{itemize}
    \item A proposition is some state of affairs. And,
    \item A value is an assessment of a state of affairs.
    \end{itemize}
  \end{proposition}
  The role of \autoref{prop:csifvoap} is primarily to fix terminology.
  To illustrate, when stating the conclusion of the reasoning sketched above we used the proposition that \emph{the area of the box is \(133\text{cm}^{2}\)}.
  The proposition refers to the state of affairs in which the area of the box is \(133\text{cm}^{2}\), and speaking a little more precisely, the agent claimed that the proposition has the value `true' --- though it may be the value turns out to be `false'.
  Or, perhaps if the agent was a little unsure about the accuracy of the ruler, that the proposition has the value `likely', `probable', or some quantitative credence.
  And, some other instance of reasoning may have concluded that the proposition has the value `desirable' --- e.g.\ if the agent was searching for a box of some approximate size.\nolinebreak
  \footnote{
    Nothing in particular hangs on the distinction between different values.
    If you prefer, you may expand the proposition (state of affairs) to include additional factors, and consider only the values `true' and `false'.
    For example, the proposition that \emph{I desire the bath to be warm} is false, as opposed to the proposition that \emph{the bath is warm} is valued undesirable by me.
  }

  Core idea is that claim of support is that things are a certain way.
  Proposition, what the thing is.
  Value, the way it is.
  In most cases the value will be clear (i.e. that the proposition is true, though sometimes that the proposition is desirable), and so we will talk of claiming support for the proposition.
  A handful of additional examples will be provided when illustrating the next proposition.
\end{note}

\begin{note}[Reasoning proposition]
  \begin{proposition}[Reasoning as establishing value]\label{prop:RisTV}
    Reasoning, tracing value through propositions/establishing that proposition has value.
  \end{proposition}

  \begin{itemize}
  \item Testimony, so claim support that \emph{p} is true.
  \item Unreliable, so claim support that \emph{p} improbable.
  \item Religious text, so claim support that \emph{p} ought to be the case.
  \item Producer, so claim support that album is desirable.
  \end{itemize}

  In a deductive case, if the premises are true, then the conclusion is true.
  Means-end reasoning for desire.
  The value is important.
  If it is true that it past 6pm, then it is true the shop is closed.
  Provides value of shop being closed.

  However, if agent desires that it is past 6pm, then it doesn't follow that the agent desires that the shop is closed.
  Question an agent as to why they think their desires conform to truth --- is-ought problem.

  Means-end reasoning.
  It is true that there is cheese at the centre of the maze.
  And, it is desirable that I obtain the cheese at the centre of the maze.
  Further, it is true that I may only obtain the cheese at the centre of the maze by solving the maze.
  Therefore, it is desirable that I solve the maze.
\end{note}

\begin{note}
  \begin{proposition}[Defeaters for claimed support]
    There are at least two ways in which a claim to support may be defeated.
    \begin{itemize}
    \item Claimed support may (discovered to be) be \emph{misled} by suggesting that a proposition has some value that it does not (in fact) have. And,
    \item Claimed support may (discovered to be) be \emph{mistaken} by appealing to factors that do not indicate the value of the proposition.
    \end{itemize}
  \end{proposition}
  Misleading support may indicate value, and value may have value indicated by mistaken support.
  Both are defeaters in the sense that, were the agent to learn that the claim to support was misleading or mistaken, then the agent would not hold that the proposition has the value indicated by the (problematic) claim to support or the basis of that (problematic) claim to support.

  Common to distinguish between countervailing and undercutting defeaters.
  Countervailing, support for some other proposition.
  Undercutting, force of claimed support is mitigated.

  Both misled and mistaken are instances of being undercut.
  For, if mistaken or misled then the support is no good.

  Neither are clearly cases of countervailing.
  For, no relation to other support is required.
  However, presence of countervailing implies misled.
  Countervailing does not imply mistaken, though may in some cases demonstrate so.

  Below suggest that when claiming support the agent excepts that claimed support is not misleading or mistaken.
  Hence, given that countervailing implies misled, implicitly take claimed support for a proposition to indicate absence.
  (This is another purpose from separation from support.)

  ???
\end{note}

\begin{note}[M\&M Illustration]
  To illustrate:

  Suppose I glance at the clock on the wall.
  The clock reads 11:45a, so I claim support that it is 11:45a.
  However, it may be the case that the clock is incorrectly set, and the time is 11:15a, or 12:15p, etc.\
  By claiming support from the time expressed by the clock, I would have been \emph{misled} about what the time actually is.
  For, it is not true that the time is 11:45a.
  Though, in all other respects, there may be no fault with claiming that the time is as expressed by the clock and so the claim to support is not mistaken.

  By contrast, suppose I glace at the clock on the wall.
  The clock reads 11:45a, so I claim support that it is 11:45a.
  By claiming support from the time expressed by the clock, I would have been \emph{mistaken} about what the time actually is.
  For, the time expressed by a broken clock is not a good indicator of what the time actually is.
  Though, despite the clock being broken, it is 11:45a and so the claim to support is not misleading.

  And, claimed support for the time from a broken clock expressing the wrong time would be both misled \emph{and} mistaken.\nolinebreak
  \footnote{
    A second illustration:
    Consider a smoke detector, designed to sound an alarm if and only if sufficient levels of smoke are detected.
    Hence, if the alarm sounds, one may claim support there being smoke in the room where the alarm is installed.
    One may be misled; the alarm may have malfunctioned, so no fire.
    Or, one may be mistaken; the same type of alarm may be installed in a different room, wouldn't be a useful indicator.
  }
\end{note}

\begin{note}[Subjectively sound]
  Of course, clocks are typically glanced at, and a glance at a clock is often insufficient to determine whether the clock is incorrectly set or broken.
  Hence, the \emph{possibility} that a clock is incorrectly set or broken --- or more broadly the possibility that claimed support is misleading or mistaken --- does not prevent an agent from claiming support.
  So, ensuring that to-be-claimed support would be neither mistaken or misleading is not a necessary condition for claiming support.
  Rather, we endorse the following condition with respect to these types of defeaters:

  \begin{proposition}[Adequacy of claimed support]\label{prop:CSNMORM}
    If agent claims support for some proposition, then
    % from the perspective of the agent,
    the agent deems that the claimed support
    % adequate whether or not the claimed support may (in fact) be
    is not misleading nor mistaken --- the agent has some expectation that possible defeaters (of the two types of noted) do not obtain.\nolinebreak
    \footnote{
      Stronger than distinct claim that the agent does not deem that the claimed support is misleading or mistaken.
      Stronger requires, presence of some deeming.
      Later does not.
    }
  \end{proposition}
  If some expectation that they do, then this seems enough to deny support.
  If no attention to defeaters, questionable whether any claimed support.

  If the claimed support is not misleading, then the proposition has the value the claimed support indicates the proposition has.
  And, if the claimed support is not mistaken, then the claimed support indicates the value.
\end{note}

\begin{note}[Agents are fallible]
  The missing piece of \autoref{prop:CSNMORM} is an account of what `deem' amounts to.
  The following proposition (\ref{prop:fallibility}) states an assumption, which allows a (general) functional characterisation of `deem'.

  \begin{proposition}[Agents are fallible]\label{prop:fallibility}
    When claiming support for a proposition and agent is never in a position to rule out the (epistemic) possibility that the claimed support is not misled or mistaken.
  \end{proposition}

  I take it to be intuitive that agents are fallible in many cases of claiming support.
  It is not too difficult to think of ways in which claimed support may be misleading or mistaken.
  As noted above, claiming support for what the time is from glancing at a clock seems sufficient, but clocks may be incorrectly set (misled) or broken (mistake).
  Similarly, a sample of \(1,000\) rolls may mislead me into thinking that a die is unbiased, or an overloaded operator may lead to a mistake in claiming support for the proposition that \(x = 4\) is an expression of equality rather than variable assignment.

  \autoref{prop:fallibility} states that an agent is never in a position to rule out the possibility that the claimed support is not misled or mistaken.
  This does not entail that there are defeaters, nor that there are any possible defeaters --- only that defeaters are an epistemic possibility.

  Still, in some cases, this may seem absurd.
  Suppose in front of me are two apples and two pears.
  So, four pieces of fruit.

  However, those appears and pears may not be real pieces of fruit, they may be replicas.
  So beings the process of attempting to quarantine fallibility from infallibility.

  There are two pairs of objects in front of me, and the objects appear to be fruit.
  So, there are four objects in front of me, which appear to be fruit.

  There are two pairs of objects hence there are four objects.

  But I may be hallucinating.

  There appear to be two pairs of objects in front of me, which appear to be fruit.
  So, there appear to be four objects in front of me, which appear to be fruit.

  Whenever there are two pairs of objects, there are four objects.

  Even so, I'm not in a position to rule out the possibility that arithmetic is inconsistent.

  Perhaps identity is a stronger candidate: Any object is identical with itself --- but I doubt one needs to claim support for reflexivity of equality.
  Similarly, it doesn't seem to be the case that I need to claim support for the proposition that my name is ミスタ --- no matter what my birth certificate says, I get to decide what my name is.

  Rather than fix a specific account of the `possibility' modal used, here are a handful compatible interpretations:

  \begin{enumerate}[label=\Alph*., ref=(\Alph*)]
  \item\label{CS:I:Never} \emph{In principle} it is not possible for any agent to rule out the possibility that claimed support is not misleading or mistaken.
  \item\label{CS:I:Resources} It is not possible for a \emph{resource bound agent} to rule out the possibility that claimed support is not misleading or mistaken.
  \item\label{CS:I:Class} There is a restricted class of propositions for which and agent is required to claim support, and it is not possible for any agent to rule out the possibility that claimed support for a proposition belonging the class is not misleading or mistaken.
  \end{enumerate}

  To illustrate, consider the proposition that there is an external world:
  \ref{CS:I:Never} denies that there could be, e.g.\ proof of an external world.
  \ref{CS:I:Resources} denies that agents of interest could not demonstrate such a proof even if it were to exist.
  \ref{CS:I:Class} allows an agent may not be required to claim support for the existence of an external world.

  I expect the intended application of claimed support will be compatible with each interpretation, and specifically with respect to \ref{CS:I:Class}, that the propositions will belong to the highlighted class.\nolinebreak
  \footnote{
    I favour the combination of \ref{CS:I:Resources} and \ref{CS:I:Class}, and to leave open whether an idealised agent may rule out the possibility of being misled or mistaken with respect to some propositions when claiming support.
  }\(^{,}\)\nolinebreak
  \footnote{
    In particular, true of ability.
  }
\end{note}

\begin{note}
  Given some interpretation of the possibility modal, the functional role of `deem' is to provide resistance to possible defeaters that an agent is not in a position to rule out.
  How resistant the agent's claimed support needs to be is up to you.

  Provide a test below to help with intuition.
  Before doing so, final proposition, which follows as a corollary from previous.
\end{note}

\begin{note}[\eiS{}]
  Subjectively sound, claimed support indicates value.

  Final proposition.
  Definition.

  \begin{definition}[Dependence and independence]
    An agent's claimed support for \(\phi\) \emph{depends} on some value of \(\psi\) just in case the agent would not claim support for \(\phi\) given any other value of \(\psi\).

    An agent's claimed support for \(\phi\) is independent of \(\psi\) just in case the agent's claimed support does not depend on the value of \(\psi\).
  \end{definition}

  Claiming support is independent of value.

  \begin{proposition}[\eiS{-} --- \eiS{}]\label{prop:supp:independence}
    If agent claims support for some proposition, \(\phi\), then the claimed support is taken to indicate the value of \(\phi\) independently of the value of \(\phi\) or whether the claimed support is `genuine' support.
    Equivalently, the claimed support is taken to indicate the value of \(\phi\) does not require that the claimed support is not misled or mistaken.\nolinebreak
    \footnote{
      Possibly goes against externalism, but I don't think this is right.
      External circumstances may impact the support the agent has.
      However, as these are external, it seems this condition plausibly holds for \emph{claiming} support.
      This is how you get puzzles for externalism.
      In both cases, it's fine for the agent to claim support, but the external circumstances impact whether the agent \emph{has} support.
      The internalist/externalist divide would seem to affect the conditions on claiming.

      Way to expand on this is reconstructing bootstrapping examples with and without \eiS{}.
      If the agent would only get basic support if reliable, then it's not clear that bootstrapping is a problem.
    }\(^{,}\)\nolinebreak
    \footnote{
      One way independence.
      Not clear that value is independent of support.
      So long as sufficiently strong support, not possible for proposition to have value other than claimed support.
    }
  \end{proposition}
  \eiS{} follows from Propositions~\ref{prop:CSNMORM} and~\ref{prop:fallibility}.

  From Proposition~\ref{prop:CSNMORM}, deemed that claimed support is neither mistaken nor misled.
  From Proposition~\ref{prop:fallibility}, always possibility.

  Suppose depends on value of \(\phi\).
  Still, from Proposition~\ref{prop:fallibility}, (epistemic) possibility that value of \(\phi\) differs.
  If differs, then claim to support is misleading.
  By Proposition~\ref{prop:CSNMORM} agent deems not mistaken or misled, and so deems that possible defeaters do not obtain.
  However, requirement of \(\phi\) denies the relevant possibility.
  For, if different value of \(\phi\) then no claim to support.
  Therefore, agent does not deem the claimed support not misleading.


  For, possibility that \(\phi\) does not have value, or that claimed support does not indicate.
  And, given claim to support requires that the possibility does not obtain, agent has not deemed that the claimed support is not misled or mistaken --- rather the agent requires that the claimed support is not misled or mistaken.

  \eiS{} does not deny that things may need to be a certain way for an agent to claim, or to be in a position to, claim support.
  It may be the case that no agent would be in a position to claim support that the speed of light is constant if the speed of light were not constant, but in claiming support an agent must deem that possible defeaters do not obtain, e.g.\ that the laws of nature are constant, and that no mistakes have been made when observing relevant phenomena.

  The force of the corollary is that agent does not require \(\phi\) related things being a certain way in order to claim support for \(\phi\).

  See with failures of `even if\dots' test.
\end{note}

\begin{note}[Quick clarification on \eiS{}]
  A quick clarification may be in order.

  \eiS{} is only about value/support for\(\phi\).
  So, \eiS{} does not prevent agent from claiming support for \(\psi\) from value of \(\xi\) given claimed support that \(\xi\) has that value.
  For example, an agent may claim support that \emph{p} is true from claimed support that \emph{S} knows \emph{p}.
  And, the agent may do so because the proposition that \emph{S} knows \emph{p} is true only if \emph{p} is true.
  That is, so long as the agent does not require \emph{p} to be true in order to claim support for the proposition that \emph{S} knows \emph{p} is true.
  We will return to \eiS{}, expand on this quick clarification, and note related observations in Section~\ref{sec:second-conditional}.
\end{note}


\begin{note}[Adequate reasoning]
  Term this \emph{adequate} reasoning.
  May be good, may involve mistakes, may be bad.
  Kind of reasoning that we, the folk, do.
  Distinction for claiming support is that this is different from whether the agent has support, and we may set issues about whether the agent has support.

  Our interest is what is required for an agent to \emph{claim} support for (premises and) steps of reasoning, rather than what is required for an agent to \emph{have} support for (premises and) steps of reasoning.

  Use support as opposed to justification.
  Initial focus is on epistemic/doxastic attitudes.
  However, practical reasoning.
  For example, means-end.
  Support considered quite general to also include this.
\end{note}




\begin{note}
  To help fix intuitions, I suggest a (hypothetical) test to clarify what is meant by `deem': The `even if\dots' test.
  So long as an agent may provide an adequate responses to the test, the agent will be in a position to claim support.
\end{note}

\begin{note}[The `Even if\dots' test]
  The `Even if\dots' test queries whether an agent's claimed support permits an agent to expect that some (epistemically) possible defeater fails to obtain `even if' it does obtain.

  For example, even if \(0.999\dots = 1\), there must be \emph{some} difference between \(0.999\dots\) and \(1\) --- no matter how small --- and some difference between to things is sufficient to establish that they are not equal.

  Implied in this response is something like the observation that \(0.9 = (1 - 0.1)\) and \(0.99 = (1 - 0.01)\), and so \(0.999\dots = (1 - 0.000\dots 1)\), hence \(1 = (0.999\dots + 0.000\dots 1)\), and because \(0.999\dots\) refers to some quantity, \(0.000\dots 1\) likewise refers to some quantity.
  It seems reasonable for an agent to expect that the Archimedean property does not hold for real numbers.

  The example given is an instance of the applied to the possibility that the agent's claimed support that \(0.999\dots \ne 1\) may be misleading, as the antecedent supposes that \(0.999\dots = 1\).

  Generalising, we have outlined two kinds of defeaters that would prevent an agent from claiming support.
  The two types of defeaters suggest two basic instances of the test:
  \begin{enumerate}
  \item[(ML)] Even if \(\phi\) does not have value my claimed support indicates, I deem it to be the case that\dots
  \item[(MT)] Even if I some part (or whole) of my claimed support for the value of \(\phi\) is mistaken, I deem it to be the case that\dots
  \end{enumerate}
  Below we provide three examples for each basic instance of the test, two (plausibly) successful responses and one (plausibly) unsuccessful response..\nolinebreak
  \footnote{
    You may think that some of the adequate responses I suggest are too weak, but for future purposes I require only that some positive answer many be given, and so you may strengthen the requirements on a positive answer as you see fit.
  }
\end{note}

\begin{note}[Even if: misled]

  We being with two plausibly satisfactory responses to being misled.

  \begin{enumerate}[label=(ML\arabic*), ref=(ML\arabic*), series=ML_counter]
  \item\label{ML:asleep} Even if that person is not sleeping, their eyes have been closed for a long time and their breathing is slow.
  \item\label{ML:lying} Even if you are telling the truth, the scientific consensus is against you.
  \end{enumerate}

  With \ref{ML:asleep} the agent has claimed support for the proposition that the person is sleeping.
  It's not too hard to give the impression of being asleep, so there is some possibility that the person is awake and support claimed is misleading.
  Still, even if the person is awake, the person is exhibiting sufficient signs of being asleep for the agent to expect that they are not misled.

  Turning to \ref{ML:lying}, it may be that the person is telling the truth and if the person is indeed telling the truth then any claimed support for a conflicting proposition must be mistaken.
  However, scientific consensus seems sufficient to claim support for the relevant conflicting proposition --- one expects that scientific consensus is not misleading given the rigours of the scientific process.
  Scientific consensus does not (at least typically) require that the person is not telling the truth (though will imply that to be the case).

  In contrast, consider an unsatisfactory response.

  \begin{enumerate}[label=(ML\arabic*), ref=(ML\arabic*), resume*=ML_counter]
  \item\label{ML:forgery} Even if this certificate is a forgery, it professes to be the real thing.
  \end{enumerate}
  If the certificate is a forgery, then the claimed support for the proposition that the certificate is not a forgery would be misleading.

  The response to the (epistemic) possibility that the certificate is a forgery is unsatisfactory because the agent depends on the certificate not being a forgery.
  Hence, that the certificate self-certifies it's authenticity is no response to the (possibility) that it is a forgery.
  Immediate conflict with \eiS{}, and traces back to \autoref{prop:CSNMORM} because it seems quite unreasonable to expect that the certificate is not a forgery based on it's self-certification.

  Of course, many certificates do self-certify (it would be excessive effort to identify a certificate and then be required to find information about what the certificate is for), and perhaps a simple observation that there are no signs of tampering may be a sufficient response to the `even if\dots' test.
\end{note}

\begin{note}[Even if: mistaken]
  Turning to the possibility of mistaken support, consider the following two instances of the `even if\dots' test.

  \begin{enumerate}[label=(MT\arabic*), ref=(MT\arabic*), series=MT_counter]
  \item\label{MT:fake-wound} Even if that is a fake wound, I have no way to tell and the actions of the (apparently) wounded would be a feat of acting.
  \item\label{MT:misquote} Even if the newspaper has quoted the wrong person, the paper has a strong record of accurate reporting.
  \end{enumerate}

  With respect to~\ref{MT:fake-wound}, it seems a mistake to treat a fake wound as indicate the presence of an actual wound, as a fake wound does not require a genuine would but likewise a fake wound may cover a genuine wound.
  The response to the `Even if\dots' test notes that the behaviour of the (apparently) wounded person is sufficiently consistent with their expectations of the behaviour of a person with the (apparent) wound, and would lead to be surprised if the person was not in fact wounded.

  Turning to~\ref{MT:misquote}, if the paper has quoted the wrong person then it would be a mistake to claim support that the person said whatever-it-is-they-said, though it may still be the case that the person did say whatever-it-is-they-said.
  Even so, the strong record of the paper seems sufficient for the agent to expect that the newspaper has not misattributed or imagined the quote on the relevant occasion.

  In contrast, consider an unsatisfactory response.

  \begin{enumerate}[label=(MT\arabic*), ref=(MT\arabic*), resume*=MT_counter]
  \item Even if this library does not using LCC indexing, the library does not have a copy of `Measurement Theory' because as search for `H61 .R593' returns no results.
  \end{enumerate}
  Holding that a library does not have a copy of a book because a search for the book under a particular indexing system would be a mistake.
  For, if the library does not use the particular indexing system then a search using that indexing system will always fail, regardless of whether or not the library has a copy of the book.

  In turn, a failed search for an LCC index in the library's database does not seems sufficient for an agent to claim that the library does not have a copy of the book unless the agent is in a position to claim support that the library uses LCC indexing.
  Following, it seems the failed response to the `Even if\dots' test may be supplemented by noting that the library is a research library, and therefore likely uses LCC indexing, etc.\
\end{note}

\begin{note}[Even if: more]
  Primary observation from these examples is that in positive cases provided responses indicate that some response to possibility of being misled or mistaken is available to the agent.
  In the failure cases, no response.

  % Cases of entailment, preface paradox.
  % Mistake somewhere.
  % Here, support is good for each of the claims made in the preface, but these do not combine to make a case that no mistake has been made across any of the claims.
  % May come down to familiar concerns, too significant possibility of being misled.
  % May also think that claimed support for each might require a mistake in one.
  % I.e. source for claim includes further claims which state that source for some other claim is mistaken.
  % Problem with using both sources, even if for distinct propositions.

  % Interesting problem later.
  % For now, simple example.
  An interesting case for misled is the preface paradox.
  Claimed support for everything in the preface, but also claimed support for mistake.
  Credence resolves tension, remains noteworthy that even if confident of some potential defeater, claimed support is sufficient to resist undermining claimed support.

\end{note}

\begin{note}[???]
  \color{red}
  Possible defeaters, so no claim that the reasoning is sound.
  However, agent deems that no defeaters, so may term this `\emph{subjectively} sound' reasoning.

  At least two worries.
  First, given general use of the term `support', considerations may suggest iterated support.
  Second, worries about over-intellectualisation of claiming support.
\end{note}


\begin{note}[Closing support]
  To summarise, claim of support.
  Certain kind of independence.
  Only interested in support, and not how this relates to attitudes.
  Somewhat intuitive, but no claims that this is the only understanding of support.

  For the moment, this provides clarity for understanding of support.
  Below, use to argue for failure to claim support.
\end{note}

\subsection{Interest with claiming support and reasoning}
\label{sec:inter-with-claim}

\begin{note}[Focus]
  We will argue against the converse of~\bP{}:

  \begin{proposition}[\uRa{-} --- \uRa{}]\label{denied-claim}
    An agent may claim support for some conclusion of reasoning by claiming that the conclusion of reasoning is supported by premises and steps of reasoning \emph{only if} the agent has witnessed the reasoning (i.e.\ traced the claimed support for those premises and steps used to claim support for the conclusion).\nolinebreak
      \footnote{
    Three brief notes on~\uRa{}:

    First, the `has' in~\uRa{} only requires `at some point in the past'.
    Hence,~\uRa{} does not require the agent to reason from premises to conclusion each time the agent claims support for the conclusion.
    For example, if an agent proved the Deduction Theorem for propositional logic last week, then the agent would not be in conflict with~\uRa{} if they claimed support for the Deduction Theorem on the basis of the premises and reasoning they performed in the past.

    Second, and following from the first,~\uRa{} will also hold for any stronger statement --- for example if `has' is read as `has just'.
    For example, requiring that the agent's memory of proving the Deduction Theorem allows the agent to claim support, rather than the premises and steps used in the past.
    The argument (stated below) denies that, given certain information, the agent needs witnesses any reasoning in order to claim support for the result of witnessing the reasoning.

    Third, as~\uRa{} is about when an agent may \emph{claim} support, it is compatible with~\uRa{} to hold that the agent \emph{has} support --- regardless of whether the agent has witnessing the reasoning.
  }
  \end{proposition}

  \uRa{}, as the converse of~\bP{} focuses on reasoning, and our focus will be with~\uRa{} because our interest is with reasoning.
  However, the key claims of~\uRa{} are independent of reasoning.
  To clarify,~\GuRa{} is a generalisation of~\uRa{}.

  \begin{proposition}[\GuRa{}]
    An agent may claim support for some proposition \emph{p} by appealing to some materia\nolinebreak
    \footnote{Latin.
      Material, matter, basis, information, foundation, ground, etc.
    }
    \emph{M} only if the agent has used \emph{M} to claim support for proposition \emph{p}.
  \end{proposition}
  Our focus is with whether an agent is required to have \emph{used} something in order to appeal to that thing when claiming support.
  No fixed understanding of `use' is assumed in the statement of~\uRa{} and~\GuRa{}, and we will offer some disambiguation below.
  First, a basic illustration.
\end{note}

\begin{note}[Illustration]
  To illustrate~\uRa{}, consider the illustration provided for~\bP{}.

    If the agent did not measure the box, understand how to calculate the area of a box, or perform the arithmetic, the agent would not be in a position to claim support that area of the box is \(133\text{cm}^{2}\).
  A lucky guess that the area of the box is \(133\text{cm}^{2}\) would not allow the agent to hold that the area of the box is  \(133\text{cm}^{2}\) on the basis of the dimensions of the box, the agent's understanding of how to calculate the area of a box, and arithmetic.
  And, it seems the agent is not in a position to base their lucky guess in such a way because the agent did not reason from the dimensions of the box, the agent's understanding of how to calculate the area of a box, and arithmetic.\nolinebreak
  \footnote{
    Moving to another agent, observe doing the work, get report.
    Easy to resist, by adding in additional premise.
    Still, no presupposing that this needs to be done.
  }
  Similarly, if an agent learns that a box with dimensions of \(19\text{cm}\) by \(7\text{cm}\) may be calculated to have an area of \(133\text{cm}^{2}\), then the agent may not claim support for the area of the box on the basis of the calculation.
  If the agent has not performed the calculation, then the agent may not appeal to the use of the calculation when claiming support --- rather, the agent mentions that the calculation is true.\nolinebreak
  \footnote{
    Slight weakening of~\uRa{} may be made.
    So long as \emph{some} agent has performed the calculation.
    Argue against~\uRa{}, and the argument made will hold for this weakening.
  }
\end{note}

\begin{note}[Intuition]
  \uRa{} and~\GuRa{} seems quite plausible, at least to me.
  The proposition is a careful statement of an intuitive ideas:

  Whether or not an agent claims support is the result of the structure of the reasoning process, and if some premises or step is not used, then it is irrelevant to the structure of the process.
  Hence, the only premises and steps of interest when claiming support are those used in the reasoning process.

  Rests on the broader idea from~\GuRa{}.
  Claiming support is the result of some agentive process, and the result of an agentive process is explained by the constituents of the process.\nolinebreak
  \footnote{
    Ah, the homonculus.

    Question about whether the agent is important.

    This gets difficult.

    Consider clocks.
    Clock does not keep track of time.
    Rather, mechanical system designed to change in constant with some passage of time. (Cf.\ \textcite{Smith:1988aa.}.)

    Agent may be like this.
    Distinction is intentionality.
    When I go about keeping track of the time, I'm attempting (at least typically) to maintain reference to what the time is.
    Figure out a way to approximate a second, and that's what's happening.
    Approximation.
    If it is noted that I requarly sigh every minute, use this, but I wouldn't be keep tracking of time, though you may be using regularity to do so.
    So, in the former case, using understanding of time, while in the latter not doing so.
  }

  As~\GuRa{} is restricted to an agent claiming support, things seem a little easier.
  Problems with interpretation, however.
  Transparency.
  Familiar, if debatable, illustration.
  Freud.
  (Here, adjourning the meeting by saying something mistaken.)
\end{note}

\begin{note}[Analogy]
  By analogy, whether or not my mug of (once cold) coffee overheats in the microwave is the result of some process involving electromagnetic radiation.
  My desire that the mug of coffee does not overheat is not used as part of the process of heating the coffee, and so is irrelevant to the structure of the process.

  My desire may explain why the mug of coffee is taking part in a certain process, and an unused premise or step may explain why an agent performed so reasoning.
  Still, a premise or step must be used as part of the process of reasoning to stand in explanation for the result of reasoning.

  Press the analogy further: Reasoning is a causal process.
  And, any property of reasoning reduces to cause and effect.
  If premises or steps are not used, then those premises or steps stands outside the relevant causal trace, and may not be appealed to when accounting for some structural property of the conclusion of the instance of reasoning (here, that the agent claims support for the conclusion).
\end{note}

\begin{note}[Causal theories of basing]
  Indeed,~\uRa{} seems to be implied by causal theories of basing.
  Consider \citeauthor{Moser:1989tv}'s account of the basing relation:
  \begin{quote}
    \emph{S}'s believing or assenting to \emph{P} is based on his justifying propositional reason \emph{Q} \(=_{\text{df}}\) \emph{S}'s believing or assenting to \emph{P} is causally sustained in a nondeviant manner by his believing or assenting to \emph{Q}, and by his associating \emph{P} and \emph{Q}.\nolinebreak
    \mbox{}\hfill\mbox{(\cite*[157]{Moser:1989tv})}
  \end{quote}
  Believing or assenting is plausibly general enough to encompass claiming support for \emph{P},\nolinebreak
  \footnote{
    Recall, intuitive explanation of claiming support is whatever it is that happens with doxastic justification.
  }
  and \emph{Q} may stand for premises and steps of reasoning.
  \citeauthor{Moser:1989tv}'s definition is with relation to propositional reason \emph{Q}, which may be understood as support (in contrast to \emph{claimed} support).
  Still, this is defined in terms of believing or assenting to \emph{Q}, i.e.\ claiming support for \emph{Q}, and a causal relation between \emph{P} and \emph{Q}.

  The causal requirement distinguishes \citeauthor{Moser:1989tv}'s account of the basis relation.
  However, our focus was on the relation to \emph{Q}.
  So, may expect that the observation extends to other accounts of the basing relation.\nolinebreak
  \footnote{
    \color{red}
    Need some quick mentions here.
  }
\end{note}

\begin{note}[\uRa{} does not imply CTB]
  Important, however, is that \uRa{} does not imply any causal theory of basing.
  For, \uRa{} does not imply any theory of basing.
  Rather, \uRa{} is about when an agent may claim support, and does not touch on how the support is based.
\end{note}

\begin{note}[Segue]
  Causal, use as having some effect.
  Contrast, understand use for intentionality.
\end{note}

\begin{note}[Moving on from basing]
  Still, as basing relation is epistemic, it may be useful to observe a further example, even if structurally similar.
\end{note}

\begin{note}[Representationalism]
  \citeauthor{Neta:2019aa} generalises (purely) epistemic interest in basing relations to cover the explanatory relation between reasons and (rationally evaluable) states held, or actions performed, by an agent.

  On the way to a novel proposal, \citeauthor{Neta:2019aa} sketches a broad characterisation of representationalist theories of (generalised) basing:
  \begin{quote}
    (R1\('\)) for an agent to C based on reason R involves not merely the agent's representing R as justifying C---it also involves this latter representation (or its content) being part of the reason why the agent C's.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[197]{Neta:2019aa})}
  \end{quote}

  To illustrate, claim support that [some number] is prime.
  It's possible that I did the prime factorisation, and possible that I took that representation to be part of the reason why I claim that [XXX] is prime.
  However, represented query of whether prime to wolfram alpha as justifying, and that's why I claimed support.

  Broadly stated, representationalist and causal accounts of the basing relation are compatible.
  Still, the relation between representationalist accounts and~\uRa{} may be more visible.
  For, a representationalist account would require (minimally) that an agent represents premises and steps of reasoning as justifying when claiming support for some conclusion of reasoning, which suggests use of those premises and steps.
  The implied use may be weaker than an intuitive reading of `use' --- it is not clear that representing an entailment is the same as reasoning with an entailment --- but it seems plain to me that representing some reason as justifying is a use of that reason.\nolinebreak
  \footnote{
    Alternatively, a clause may be added to~\uRa{} which denies that the agent represents the relevant premises and steps of reasoning.
    The argument made against~\uRa{} is compatible with the use of representations, or mere representation even if unused --- though it is unclear to me what an unused but represented premise or step would matter when claiming support.
  }
\end{note}

\begin{note}[Responding to reasons]
  As final motivation, consider the proposal at the core of \citeauthor{Lord:2018aa}'s (\citeyear{Lord:2018aa}) thesis that being rational is to correctly respond to reasons.

  \begin{quote}
    \textbf{Correctly Responding:} What it is for A's \(\phi\)-ing to be ex post rational is for A to possess sufficient reason S to \(\phi\) and for A's \(\phi\)-ing to be a manifestation of knowledge about how to use S as sufficient reason to \(\phi\).\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[143]{Lord:2018aa})}
  \end{quote}

  An agent's action is rational only if the action is a manifestation of some know-how.
  \citeauthor{Lord:2018aa} summaries:

  \begin{quote}
    \dots when one manifests one's know-how, dispositions that are directly sensitive to normative facts are manifesting. Thus, the competences involved in the relevant know-how make one directly sensitive to the normative facts\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[16]{Lord:2018aa})}
  \end{quote}

  For our purposes, following example of manifesting know-how directly relates to reasoning:

  \begin{quote}
    The most salient disposition [when appealing to \emph{p} as a reason]\nolinebreak
    \footnote{Note, \citeauthor{Lord:2018aa} (explicitly) not talking about believing that \emph{p} is a reason, but argues that the cited disposition to present both when appealing to p as a reason and believing that \emph{p} is a reason.}
    is the disposition to (competently) use \emph{p} as a premise in reasoning.\nolinebreak
    \mbox{}\hfill\mbox{(\citeyear[25]{Lord:2018aa})}
  \end{quote}

  Hence, suppose an agent appeals to a premise of reasoning in order to claim support for some conclusion.
  Then, if the agent does not use the premise of reasoning, it seems the agent does not manifest know-how, which is required for the appeal to meet \citeauthor{Lord:2018aa}'s account of rational action.

  Of course, that the noted disposition is the most salient does not rule out alternative, less noteworthy, dispositions.
  However, it is unclear to me how to \emph{manifest} know-how without use.
  Looking ahead, it does not seem to be the case that I manifest my ability to show that a certain rule of inference is sound when skipping over details in a completeness proof.
  However, I may manifest know-how regarding the (presumed) truth of the ability attribution.

  Likewise with my ability to establish a preference for tofu over any other kind of miso when ordering soup.
\end{note}

\begin{note}[Summarising illustrations]
  Three examples of claiming or establishing relations of support have been given.
  Each example suggests that if an agent does not use a premises or steps when claiming support, then an agent may not claim support by appeal to the unused premises or steps.

  Stepping back,~\uRa{} may be seen as a desiderata for any account of (successfully) claiming support.
  For:
  If an agent (successfully) claims support for some conclusion of reasoning, then that claim of support is the result of some reasoning.
  The relevant reasoning that culminated with the claim to support involved some premises and steps of reasoning.
  So, given that the agent appealed to certain premises and steps when claiming support for conclusion, some property of the premises and steps an adequate account of claiming support must explain how the premises and steps used permit the agent to claim support.\nolinebreak
  \footnote{
    Note, however, that this argument does not imply that support for the conclusion must be accounted for in terms of the premises and steps used by the agent to claim support.
    For example, one may hold that an enthymematic argument permits an agent to claim support, while the relevant relation of support is secured by the corresponding non-enthymematic argument.
    Cf.\ \textcite{Moretti:2019wx} for suggestions along these lines.
  }
\end{note}

\begin{note}[Where \uRa{} is okay]
  I think~\uRa{} and~\GuRa{} are fine from an aetiological perspective --- account for how or why it came to be that the agent claimed support --- but question whether this restricts what the agent appeals to.
\end{note}

\begin{note}[Alternative]
  \uRa{} is a universal claim, and so applies to all instances in which an agent may claim support for conclusion on basis of support for premises and steps of reasoning --- an agent may only claim support if the agent reasoned from the premises via the steps to the conclusion.

  Our goal is to motivate an exception to \uRa{}:
  \begin{proposition}[\rC{-} --- \rC{}]\label{rC}
    If an agent has claimed support that they have the ability to (adequately) reason to some conclusion, then the agent may claim support for the conclusion by claiming support for the premises and steps of reasoning that the agent would use when witnessing their ability to reason to the conclusion.
  \end{proposition}

    The exception is motivated by the agent having information that they have the ability to (adequately) reason to the conclusion.
  Key is that if~\rC{} is true, then the agent is not required to use having the ability to reason as a premise.
  Instead, the agent may instead appeal to the premises (and steps) that would be used when witnessing the ability.

  Loosely restated,~\rC{} holds that if an agent may claim support for having the ability to witness some reasoning, and is aware of the conclusion of that reasoning, then the way in which the agent claims support for the conclusion of that reasoning may mirror the way in which the agent would claim support for the conclusion by witnessing the reasoning (and hence using the relevant premises and steps).

  So, if~\rC{} is true, then there are cases in which an agent is not required to reason from premises they may claim support for to some conclusion in order to obtain support for the conclusion on the basis the support the agent has for the premises.\nolinebreak
  \footnote{
    Stated~\rC{} as an exception to~\uRa{}.
    And, we will argue that~\rC{} is true.
    However, we will not argue that~\rC{} \emph{is an exception} to~\uRa{}.
    To do so would require an argument that \uRa{} holds for other cases.
    Likewise, no argument that~\rC{} is the only exception, as to do so would require argument that~\uRa{} holds for all other cases.
  Take~\uRa{} to be plausible, and suspect that there are few, if any, further exceptions, but~\rC{} may stand independently on any further statements about claiming support.
  }

  The alternative, in line with~\uRa{}, would be for the agent to use the proposition that they have the ability.

  To illustrate.
  Inform me that I have the ability to demonstrate that the area of a box with dimensions \(19\text{cm}\) by \(7\text{cm}\) has area \(133\text{cm}^{2}\), then so long as long as I get to claim support for having the ability.
  However, \emph{that I have the ability to demonstrate that the box has the certain area} and \emph{that the box has a certain area} are distinct propositions.
  \rC{}, when I claim for \emph{that the box has a certain area}, I appeal to dimensions and formula, though as I do not witness the ability, I do not use the premise and step.

  This is by no means obvious.
  A plausible view is that there is an entailment form the proposition \emph{that I have the ability to demonstrate that the box has the certain area} to \emph{that the box has a certain area}, and (in line with \uRa{}) I use the entailment.

  Indeed, I think that such reasoning is permissible in many cases.
  \rC{} permits exceptions to \uRa{}, but it does not require all instances of reasoning with ability is an exception to \uRa{}.
  The primary argument for \rC{} is that \uRa{}, certain instances of reasoning with information about ability, and a principle concerning when an agent is permitted to claim support are in tension.

  Specifically:
  Information that one has some specific ability so long as one has some general ability --- such as the (specific) ability to show that \(25^{\circ}\text{C} = 77^{\circ}\text{F}\) given the (general) ability to convert between Celsius and Fahrenheit.
  And, agent is never permitted to claim support for proposition if require value in order to claim support.
  The details matters, and we postpone detailing this argument to section~\ref{sec:broad-argum-overv}.
\end{note}

\begin{note}[Segue]
  For now, we close the present section with a handful of remarks concerning ability and~\rC{}.
\end{note}

\begin{note}[Ability]
  Idealised agents have no need to appeal to ability.
  However, for limited agents, ability is abundant, while the resources required to witness abilities are scarce.
  That the exception to~\uRa{} is narrow does not entail that there are few occurrences of the exception.

  Information about ability may be abundant while the resources for witnessing abilities are either scarce or temporarily unavailable.
  So, for example, agent has the option of conserving or deferring use of resources.

  If~\rC{} then a novel perspective on limited agents.
  When and why limited agent may claim support for result of reasoning.
  Here, conflict with appeal to~\uRa{} it its unrestricted form.

  And, in between propositional and doxastic support (or more commonly justification).
  Propositional support doesn't allow agent to claim support.
  Doxastic support, agent does claim support.
  If ability allows agent to claim support, \dots

  Secondary motivation is with ability to reason itself.
  Even if arguments for~\rC{} fail to convince, not much has been said on ability to reason, and first steps are useful.

  Third, use of~\uRa{}.
  Potential alternative conclusions to arguments that appeal to~\uRa{} as a premise.
  Revise premises for arguments in which~\uRa{} is a conclusion.
  As an exception, even if~\rC{}, conclusion of arguments which appeal to or assume \uRa{} may be restricted.
\end{note}

\begin{note}[Actual support]
  As with~\uRa{}, \rC{} does not entail that the agent \emph{has} support.
  Doesn't show that the agent has support.
  {
    \color{red}
    Some more notes on why this is important.
    Basically, this means that~\rC{} isn't too strong.
  }
  Still, it take it to be plausible that support traces a successful claim.
  From this perspective,~\rC{} may seem a little more intuitive.
  Given an intuitive understanding of support, if an agent does have the ability to reason to some conclusion, then the conclusion stands in the relation of being support by certain premises and steps of reasoning, whether or not the agent witnesses their ability.
  In turn, if the agent may claim support for the having the relevant ability then the agent may claim support for the conclusion from the premises and steps that would be used when witnessing their ability because witnessing would not contribute to the relation of support between the conclusion and the relevant premises and steps --- witnessing would only clarify to the agent the specifics of the relation.

  Of course, agent may be mistaken or misled about having ability, and witnessing may be expected to highlight.
  The combination of relevant premises and steps may fail to establish the conclusion, or be out of reach of the agent.
  However, consequences of the possibility of mistaken or misled regarding having the ability.
  Not clearly any worse than being mistaken or misled and using that one has the ability as a premise, which in turn seems no different to the possibility of being mistaken or misled about any arbitrary premise.
\end{note}

\begin{note}[Examples]
  Need quick truth and desire examples.
  I don't think I need to make these examples compelling, as giving borderline examples may help motivate interest.

  Claimed support is general, extends to desires.\nolinebreak
  \footnote{
    Strong view on which an agent may be mistaken about desires in the same way as an agent may be mistaken about evidence.
    View on which desires are independent of representation.
    Hence, misleading or mistaken support when an agent fails to represent desire.
  }
  Here, temptation.
  Ability to demonstrate that abstaining from a \(\text{n}^{\text{th}}\) glass of wine, even though the reasoning the agent performs after the \(\text{n-1}^{\text{th}}\) glass supports drinking another glass.

  There are alternatives.
  One follows motivation of \uRa{} as a desiderata.
  Agent abstains, and so some part of the reasoning involved sufficiently strong desire to abstain.
  Or, appeal to an intention, blocking out relevance of a (stronger) desire to drink the \(\text{n}^{\text{th}}\) glass of wine and to allow action to follow from the (weaker) desire to abstain.
  Or, desire to do what your are confident you are able to establish as the result of reasoning about the thing to do.

  Still, proposal in line with~\rC{} is of some interest.
  Weakness of will (in some cases) as reluctance to expend resources.
  So, true that strongest desire is to abstain, and stronger recognised desire is to drink.
  Ability allows acting on strongest desire without establishing as strongest desire.

  To the extent that cases of this kind rely on intuition, they will not be the focus of the major argument.
  However, auxiliary argument by highlighting novel perspectives that arise from~\rC{}.
\end{note}

\section{Structure of argument}
\label{sec:structure-argument}

\begin{note}[Structure of argument]
  Two lines of argument for endorsing~\rC{}, and hence denying~\uRa{}.
  \begin{enumerate}[label=(L\arabic*), ref=(L\arabic*)]
  \item\label{arg:line:1} Motivate~\rC{} as resolution to tension resulting from~\uRa{}.\newline
    Specifically:
    \begin{enumerate}[label=(L1\alph*)]
    \item\label{arg:line:1:a} Provide recipe for generating scenarios where~\uRa{} is in tension with particular scenarios involving information that an agent has the ability reason to some conclusion and a further claim regarding when it permissible for an agent to claim support for a proposition.
    \item\label{arg:line:1:b} Motivate~\rC{} as a resolution to the tension.
    \end{enumerate}
  \item\label{arg:line:2} Argue that granting~\rC{} as an exception to~\uRa{} allows for an intuitive understanding of cases in which agent has the option of appealing to ability, even if there are alternative ways of interpreting the scenario in line with~\uRa{}.
  \end{enumerate}
  These two lines of argument work together.
  The tension of~\ref{arg:line:1} generates interest in witnessing that may be flatly rejected by prior endorsement of~\uRa{}.
  The intuitive understanding of scenarios involving ability of~\ref{arg:line:2} suggests there's more to witnessing than resolving the tension in narrow cases.
\end{note}

\begin{note}[Details of \ref{arg:line:1}]
  The initial focus is on the first line of argument,~\ref{arg:line:1}.
  The tension developed in part~\ref{arg:line:1:a} is delicate, but hopefully informative.
  We will establish a number of corollaries regarding ability and the interaction between~\uRa{} and ability.
\end{note}

% \begin{note}[Before turning to the argument\dots]
%   Before turning to the argument, we conclude this introduction with a handful of notes regarding~\uRa{} and~\rC{}.
% \end{note}

% \begin{note}[Scope of \uRa{}]
%   \uRa{} does not say anything in particular about what the agent may claim support for, only what must be the case in order for an agent to appeal to support for some conclusion on the basis of support for premises.

%   Talking in terms of (support for) premises and conclusions restricts attention to reasoning.
%   There may be broader use of `premise' and `conclusion' where an agent is not required to reason from premise to conclusion in order for the premise to support the conclusion.
%   For example, if visual perception is immediate.
%   Perhaps it may be said that an agent's visual experience is a premise to the conclusion that a dog is sleeping.
%   Still, for present purposes, `conclusion' refers to the output of some process of reasoning performed by an agent which is either actual or potential, and `premises' to the input of that process.

%   Note, also, that in both cases the relation between premises and conclusion is important.
%   If agent does not reason, then neither~\bP{} nor~\uRa{} apply.
%   If there are multiple ways to obtain a conclusion, then~\uRa{} does not require the agent to reason from a particular set of premises.

%   Likewise,~\uRa{} does not require that an agent is required to obtain support for a proposition by valid and subjectively sound reasoning from some premises.

%   Rather,~\uRa{} requires that an agent reason from premises to conclusion in order to establishes support between premises and conclusion
%   By contrast,~\bP{} holds that reasoning is sufficient to establish such a relation.
% \end{note}

% \begin{note}[\uRa{} is intuitive]
%   \uRa{} is intuitive, and is quite common, though not without exceptions.
% (For example, there's views on testimony in which the testifier provides agent access to support the testifier has.
% One may understand this as conflicting with~\uRa{}, or that the fact that these are accessible is the relevant piece of support.)
% \end{note}

% \begin{note}[Alternative]
%   \rC{} restricts~\uRa{}.
%   This is not to say the agent obtains support equivalent to that which would be obtained were the agent to do, or have done, the reasoning.
%   Nor, that the agent is aware of the relevant premises.

%   Intuitively, \rC{} states that the agent may appeal to the reasoning they are able to perform in support for the conclusion of that reasoning, and as that reasoning moves from premises to conclusion, it is on the basis of the support for those premises that the agent would identify by reasoning that the agent obtains (some) support for the conclusion.

%   Hence, \rC{} is in line with the spirit of~\bP{}.
%   For the exception to~\uRa{} is granted by the agent appealing to a witnessing event in which the antecedent (and consequent) of~\bP{} are satisfied.
% \end{note}

% \begin{note}[Ability ensures propositional?]
%   Plausible that if the agent has the ability, then the agent already has propositional support for the relevant proposition.
% \end{note}

\section{Main argument overview}
\label{sec:broad-argum-overv}

\begin{note}[Overview]
  Tension resulting from the unrestricted scope of~\uRa{}.
  We begin by introducing a particular type of scenario involving ability, and observe how~\uRa{} requires a unique interpretation of the scenario.
  We then introduce an additional principle regarding support, which conflicts with the interpretation of the type of scenario introduction required by~\uRa{}.
\end{note}

\begin{note}[Introducing key parts]
  Type of information and entailment.
  Two ways to understand entailment.
  Then, if information and entailment \dots
  Principles constrain understanding.
  \uRa{} and a second principle.
\end{note}

\subsection{Type of scenario}
\label{sec:type-scenario}

\begin{note}[Tension, information]
  The tension arises when an agent receives (limited) information that:
  \begin{enumerate}[label=(\GSI{}), ref=(\GSI{})]
  \item If the agent has a general ability to \(\gamma\), then the agent has a specific ability to \(\varsigma\) (as an instance of the general ability).
  \end{enumerate}
  The information is limited because it does not directly provide the agent with the information that the agent has the specific ability, nor that the result of witnessing the specific ability is the case.

  \GSI{} as \gsi{}.
  Information is that if the agent has a general ability to \(\gamma\), then as an instance of the general ability the agent has the specific ability to \(\varsigma\).

  For example,
  \begin{enumerate}[label=(\GSI{}\arabic*), ref=(\GSI{}\arabic*)]
  \item\label{qe:cond} If you have the ability to reason with the rules of chess, you have the ability to demonstrating that there is a sequences of moves that will ensure a win for one of the players (as an instance of the general ability).
  \end{enumerate}
  The conditional structure\nolinebreak
  \footnote{
    Strictly speaking the formulation as a conditional isn't important.
    What matters is that the agent is required to endorse general ability.
    \begin{enumerate}[label=(\GSI{}\('\)), ref=(\GSI{}\('\))]
    \item Either the agent does not have the general ability to \(\gamma\), or the agent has a specific ability to \(\varsigma\).
    \end{enumerate}
  }
  of the information distinguishes \GSI{} from (\dSI{}):
  \begin{enumerate}[label=(\dSI{}), ref=(\dSI{})]
  \item You have the ability to \(\varsigma\).
  \end{enumerate}
  With respect to the example:
  \begin{enumerate}[label=(\dSI{}\arabic*), ref=(\dSI{}\arabic*), series=dsi_count]
  \item\label{qe:cons} You have the ability to demonstrate that there is a sequences of moves that will ensure a win for one of the players.
  \end{enumerate}
  Where `\dSI{}' stands for direct specific ability information as the agent directly receives information that they have a specific ability.

  By contrast, with \GSI{} the agent is required to obtain~\ref{qe:cons} from~\ref{qe:cond} by endorsing the antecedent --- that they have the (general) ability to reason with the rules of chess --- and so it may not be the case that the agent has the specific ability.

  So, from \GSI{}, the agent is not provided with information that:
  \begin{enumerate}[label=(\dSI{}\arabic*), ref=(\dSI{}\arabic*), , resume*=dsi_count]
  \item\label{qe:result} There is a sequences of moves that will ensure a win for one of the players.
  \end{enumerate}
  For, it need not be the case that~\ref{qe:result} is true if~\ref{qe:cond} is true by virtue of a false antecedent.
  While, \ref{qe:result} does follow from~\ref{qe:cons}.

  Of course, the antecedent of~\ref{qe:cond} need not be false.
  Rather, the observation that the antecedent of~\ref{qe:cond} highlights how \GSI{} requires the agent to appeal to their general ability in order to obtain information about how the agent's general ability extends to a particular case.

  However, if the agent holds that they have the ability to demonstrate that there is a sequences of moves that will ensure a win for one of the players, then the agent may reason to~\ref{qe:result}.
\end{note}

\subsection{(An) ability entailment}
\label{sec:ability-entailment}

\begin{note}[\aben{}]
  Note here on \aben{}.
  Then  ways of understanding \aben{}.

  \begin{proposition}[Ability entailment]
    Entailment of the from `S has (specific) ability to \emph{V} that \(\phi\)' and so `\(\phi\) is the case'.
  \end{proposition}

  \aben{} links ability and result.

  Intuitive that \aben{} holds.

  Cases of interest, \aben{} applies to obtaining result.
  Hence, specific ability to demonstrate the existence of a strategy, so a strategy exists.

  Focus is on why it holds.
  Distinguish two ways in which ability is used in some instance of reasoning, and then use these to elaborate on \aben{}.

  Outline two interpretations, and argue that these are exhaustive.

  Argue that only one understanding is compatible with \GSI{} and \aben{}.
\end{note}

\subsection{\WR{} and \AR{}}
\label{sec:wr-ar}

\begin{note}[\WR{} and \AR{}]
  We term these \AR{} and \WR{}, respectively.
  Brief descriptions from detached perspective.

  \begin{definition}[\AR{}]\label{A:s}
    Appeal to attribute of ability for each use of ability.
  \end{definition}

  \AR{} applies to use of ability in some reasoning.
  In all cases, appeal the attribute.

  Support for general, so support for specific, and hence support for conclusion.
  With this, apply to \aben{}.

  \begin{definition}[\WR{}]
    Appeal to witnessing ability at some point in reasoning.
  \end{definition}

  Key idea of witnessing is that there is \emph{some} use.
  And, existential to allow use of attributes, as with use of general.

  \AR{} is always in line with \uRa{}, the role of witnessing in \WR{} is in conflict with \uRa{}.
\end{note}

\begin{note}[\PA{} and \PW{}]
  \begin{proposition}[\PA{}]
    A strategy must exist in order for it to be the case that an agent to possess the ability to demonstrate that a strategy exists.

    Therefore, if an agent may claim support for possessing the ability to demonstrate that a strategy exists, then the agent may claim support for the existence of a strategy, and support transmits over entailment.

    So, the attribute is sufficient to grant the entailment.
  \end{proposition}

  Applying to scenarios of interest, \AR{}, attribute of specific ability, and in turn from attribute of general ability.
  Agent claims support for general, so allows agent to claim support for specific, and in turn claim support for result.

  \begin{proposition}[\PW{}]\label{W:s}
    Event of reasoning from premises to conclusion.
    Specific ability, requires being in a position to claim support for premises and steps.
    Hence, appeal to support for premises and steps.
    (Rather than attribute.)
  \end{proposition}

  There is a slight alternative.
  Here, the agent diverges and claims that they have the attribute.
  Then, in line with \PA{}.
  Remains a case of \WR{}, as witnessing from general to specific.
\end{note}

\begin{note}[Applied to scenarios]
  With scenarios, \gsi{}.
  \AR{} is attributions all the way through, finish with \PA{}.

  \WR{} is witnessing at some point.
  General and information, to instance of specific.
  Claim support for each premise or step used, given attribute, and so claim support for conclusion, finish with \PW{}.
\end{note}

\begin{note}[Terminology]
  Use \AR{} and \WR{}, as these imply \PA{} and \PW{}.
  \PA{} and \PW{} to further disambiguate if needed.
\end{note}

\begin{note}[Intuition for \AR{} and \WR{}]
  Both \AR{} and \WR{} are ways to understand \aben{}, which is in turn about what is entailed by an agent having a (certain kind of) specific ability.

  \AR{} focuses on the idea that the agent may claim support from having the attribute (or the truth) of the specific ability.
  \WR{} focuses on the idea that the agent may claim support from witnessing (or using) the specific ability.

  \AR{} requires support for attribute, which in turn suggests in a position to claim support for premises and steps.
  \WR{} requires support for premises and steps, which in turn suggests in a position to claim support for attribute.

  \AR{} doesn't require agent to claim support for premises and steps.
  \WR{} doesn't require agent to claim support for attribute.

  Intuitive example.
  Answer on a test.
  Student puts in the correct answer.
  What matters is that the answer is correct, attribute of the student.
  What matters is that the student has performed the reasoning correctly, the result of some process.

  It seems there is some difference to strength of claimed support.
  However, interest is not in reasoning that has been witnessed.
  Rather, reasoning that the agent has the ability to witness.\nolinebreak
  \footnote{
    \uRa{} provides an explanation here.
    For, if agent did not reason, then wasn't in a position to claim support.
    Hence, trace of the process suggests this condition has been met.

    Arguing against \uRa{}, however.
    This doesn't block the observation, as we're restricting \uRa{} rather than denying \uRa{}.

    Imagine student being provided with information about what to use.
    Student clarifies their understanding.
    To me, this does seem distinct form the two mentioned observations.
  }

  Shortly distinguish these with \uRa{} --- bad for \WR{}.
\end{note}

\begin{note}[Quite brief]
  Sketches of \AR{} and \WR{} are brief.
  Expand on these in the following sections (\ref{sec:first-conditional} and~\ref{sec:second-conditional}) to some extent, and chapter~\ref{cha:potent-infer-attr} will focus on a detailed account of both.
\end{note}

\begin{note}[No third option]
  \begin{proposition}\label{prop:WR-and-AR-exhaustive}
    \AR{} and \WR{} seem exhaustive.
  \end{proposition}
  No alternative source of information about conclusion.
  Hence, specific ability is required, and is likewise novel.
  So general ability is a required premise.

  Ability is describing some action that may be witnessed by the agent.
  Unclear what else there is than mentioning or witnessing action.

  \begin{proposition}\label{either-AR-or-WR}
    Either \WR{} or \AR{} for \aben{}.
  \end{proposition}
\end{note}

\begin{note}[\WR{} alternative]
  Key is support for premises and steps, so invoke general ability in understanding of \WR{}.

  \begin{enumerate}
  \item Agent has support for general ability, and specific ability is an instance of general ability.
  \item So, given the \GSI{}, there is a potential event in which agent does reasoning, and given general ability, the agent is in a position to claim support for each premise and step of reasoning.
  \end{enumerate}

  Possible to reformulate with anything that places agent in a position to claim support.
  Likewise, general will be used to develop tension for \AR{}, but may be possible to formulate without.

  Hence, given \label{either-AR-or-WR}, if problem with \AR{} then \WR{} and not \uRa{}.
\end{note}

\begin{note}[Basic idea]
  We will return to \GSI{} in greater detail below.
  For now, the basic idea is that the agent is on the hook, so to speak, for holding that they have the specific ability.

  Scenarios of this kind are likely uncommon.
  If assume some Gricean maxims, then seems to require that the informer does not have stronger information, or that stronger information is not relevant.

  Perhaps the informer does not want the agent to rely on the informer's information for the existence of the strategy.
  Or, perhaps the agent only wants to appeal to their own understanding of chess.

  Or may be read as a slight challenge.
  The relevant interpretation of `if you're smart enough, you can solve this problem' seems clear.
  `If your ability to reason is of sufficient worth, then by extension of that ability, you have the ability to solve this problem.'
  Paraphrased, `if you're smart enough, you have the ability to solve this problem'.
  So challenged, and confident in one's smarts, one may expect to solve the problem.
  The slight difference with the limited information of interest is that the informer provides information about what the solution to the problem is if the agent is `smart enough'.

  Scenarios require the agent to use this information.
  May be the case that this kind of information is used when alternatives are available.
  E.g.\ hold \(\phi\) not only because testimony, but because ability.

  Main point is moving from general to specific.
  However, focus point is use of specific.
  How this works when the agent appeals to ability.
  Role of \GSI{} is to capture idea that agent may have reason to appeal to specific ability.
  Plausible that if agent appeals to specific then something like general in the background.
  Even if somewhat rare, then, fairly clean set-up for appeal to specific ability.

  Note, in particular with \ref{qe:cons} the agent may hold that \(\phi\) without holding that they have the specific ability to demonstrate that \(\phi\).
  For example, consider instructor telling a student that they have the ability to show that ? is the solution to the problem.
  Student may reason that the instructor is not wrong about the solution, but is wrong about the student's ability.

  If student is given \GSI{} then it's not clear that the agent gets the solution.
  Plausible that variant information, though.
  ? is the answer, and so long as general, then specific.
  Though, as before, agent doesn't need to consider ability with such a variant, as route to ? which is independent of the agent's ability.
\end{note}

\begin{note}[Scenario proposition]
  For ease of reference, we wrap scenarios involving the limited information as a proposition.
  \begin{proposition}[\eA{-} --- \eA{}]\label{prem:ab}
    {
      {\color{red}
        Reform this with \aben{}.
      }
      Interest in cases is an instance of \aben{} with certain type of support for specific ability.
    }
    It is possible for an agent to use information that they have some specific ability so long as the agent has some general ability to claim support for what follows from the specific ability.
    (Where the agent lacks doxastic support for what follows, and for \(A(\varsigma)\) without information).
  \end{proposition}
\end{note}

\begin{note}[Possible restrictions]
  The important aspect of premise~\eA{} is that there are cases in which the agent may appeal to ability to obtain support.
  This is quite weak.

  Understanding of support here is primarily for the agent.

  It allows that there may be cases in which the details of the cases outlined are satisfied, but where kind of support is unsuitable for certain purposes.
\end{note}

\begin{note}[Normative, again]
  In particular, some witness of ability may be demanded by a third-party.
  Perhaps due to lack of confidence in agent, or contextual features of the scenario.
  This is no different from memory.
  Memory of proving \(\phi\) provides support for \(\phi\).
  Still, one may still demand a demonstration of \(\phi\).
  Perhaps the third-party considers the agent's memory unreliable, or perhaps context has been set so that memory is insufficient to add a proposition to the common ground, etc.
\end{note}

\subsection{\uRa{} and \WR{}}
\label{sec:first-conditional}

\begin{note}[Summary]
  In this section, argue that \uRa{} conflicts with \WR{} understanding of \aben{}.
  And, show that \AR{} is compatible with \uRa{}.
  So, as long as disjunction holds, \uRa{} requires \AR{}.

  That's the main takeaway.
  Secondary takeaway is that \gsi{} needs allow the agent to claim support for having attribute for specific ability from claimed support for general ability.
  This will be important in the following section.
\end{note}

\subsection{Incompatibility of \WR{} and \uRa{}}
\label{sec:incomp-wr-ura}

\begin{note}[Proposition]
   \begin{proposition}\label{mcA:WR-and-denied-claim}
    \WR{} is incompatible with~\uRa{}.
  \end{proposition}
    For,~\ref{P:ab-and-dc:W:ab} and~\ref{P:ab-and-dc:W:uRa}.
  Then, agent obtains support by~\ref{P:ab-and-dc:W:ab}.
  As \uRa{}, then from \ref{mcA:WR-and-denied-claim} not \WR{}.
  So, from~\ref{either-AR-or-WR}, must be \AR{}.
\end{note}

\begin{note}[To argument]
  {
    \color{red}
    We provided a brief argument for~\ref{either-AR-or-WR} in the previous section.
  }
  So, what follows is a brief argument for~\ref{mcA:WR-and-denied-claim}.
\end{note}

\begin{note}[Attribute]
  \WR{} is an instance of~\rC{}, as the agent obtains support for the conclusion of the reasoning is able to do on the basis of the reasoning that would be performed in a witnessing event.
  Hence, the supported obtained for the conclusion is obtained on the basis of the support the agent has for the premises that would be used.
  Again, this does not imply that the agent obtains support for the conclusion which is equivalent to the support the agent would obtain by witnessing their ability by performing the reasoning.
\end{note}


\begin{note}[Compatibility]
  However, \AR{} suggests an alternative way to obtain support for the conclusion of reasoning the agent is able to do.
  Specifically, if order for the agent to \emph{have} the attribute of being able to reason to the conclusion, the conclusion of the reasoning must be true.
  The relevant entailment is in part secured by the verb chosen, and in part by what the verb is applied to.
  Here, `demonstrate' is a factive verb, if an agent demonstrates that \(\phi\), then it is true that \(\phi\).
  And, the existence of a chess strategy does not depend on the agent demonstrating that the relevant strategy exists.

  To take another example, you only have the ability to identify a typo on this page if there is a typo on this page.
  So, if I were to provide you with testimony that you have the ability to identify a typo on this page, you may begin searching for the typo, or you may note that there must be a typo in order for me to be in a position to provide you with testimony that you have the ability.

  The reasoning is summarised with the following sketch.

  \begin{enumerate}[label=(\textsf{A}\arabic*), ref=(\textsf{A}\arabic*)]
  \item\label{WR:Sketch:1} I have the attribute of being able to \emph{V} that \(\phi\).
  \item\label{WR:Sketch:2} In order to have the attribute of being able to \emph{V} that \(\phi\), \(\phi\) must be the case independent of whether or not I witness the ability.
  \item\label{WR:Sketch:3} \(\phi\) is the case.
  \end{enumerate}

  To keep things simple, we will refer to the principle behind the pattern sketched as \AR{}.
  And agent may bundle~\ref{WR:Sketch:1} and~\ref{WR:Sketch:3} into a conditional, and avoid instantiating the reasoning pattern, but so long as the conditional is (implicitly) held on the basis of the intermediate premise~\ref{WR:Sketch:2}, we take use of such a conditional to be an instance of \AR{}.

  \AR{} is compatible with \uRa{}.
  For, the two premises~\ref{WR:Sketch:1} and~\ref{WR:Sketch:2} are accessible to the agent, and obtaining \ref{WR:Sketch:3} from~\ref{WR:Sketch:1} and~\ref{WR:Sketch:2} appears to be straightforwardly sound reasoning.
\end{note}

\subsubsection{Summary}
\label{sec:uRa-and-wr-summary}

\begin{note}[Conditional A]
  The first conditional we establish highlights how \uRa{} constrains how an agent may use \gsi{} in the type of scenarios described by \eA{}.

  \begin{proposition}[\mcA{}]
  \begin{enumerate}[label=(C\Alph*), ref=(C\Alph*), series=CC_counter]
  \item\label{P:ab-and-dc:W} If
    \begin{enumerate}[label=(\roman*), ref=(CA.\roman*), series=CCA_counter]
    \item\label{P:ab-and-dc:W:ab} an agent may claim support for the conclusion of reasoning they are able to do in cases described by~\eA{}, and
    \item\label{P:ab-and-dc:W:uRa} \uRa{} is true,
    \end{enumerate}
    then
    \begin{enumerate}[label=(\roman*), ref=(CA.\roman*), resume*=CCA_counter]
    \item\label{P:ab-and-dc:W:AR} the claimed support for \(\phi\) is obtained on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (i.e.\ \AR{}).
    \end{enumerate}
  \end{enumerate}
\end{proposition}

  The reasoning described in the consequent of the conditional, \ref{P:ab-and-dc:W:AR}, is in line with \AR{} --- the support the agent obtains for the conclusion of the reasoning that they are able to do is obtained from the support the agent has for having the attribute of being able to reason to the conclusion.
\end{note}

\begin{note}[Summarising]
  ???
\end{note}

\begin{note}[Note on why \AR{} does not conflict with \uRa{}]
  \AR{} and \uRa{} are compatible.
  For, \AR{} is attribute.
  So, if instance of \AR{} agent is claiming support for attribute.
  This is accessed.
\end{note}

\subsection{\nI{} and \AR{}}
\label{sec:second-conditional}

\begin{note}[Redo of section]
  Seen \uRa{} and \WR{}.
  Turn to \AR{}.
  Also saw in last section certain kind of support required.

  Introduce a general constraint on claiming support.
  The general constraint will relate to moving from general to specific ability information --- agent is not in a position to claim support for having specific ability from information and claimed support for general ability.
  However, initial statement and motivation apply to all instances of claiming support.
  After statement and motivation, show how the constraint relates to \AR{}.
  If so, agent lacks support for having specific ability, and does not have the option of claiming support for result of specific ability by \AR{}.
\end{note}

\subsubsection{Statement of \nI{}}
\label{sec:ni-1}


\begin{note}[\nI{}]
  We turn to the general constraint on claiming support.
  \begin{proposition}[\nI{-}  --- \nI{}]\label{prem:ni}
    For any agent \(S\).
    Suppose:
    \begin{enumerate}[ref=(\textsf{NI}:\arabic*), series=nI_counter]
    \item\label{nI:claimed-support} \(S\) has claimed support that some proposition \(\phi\) has value \(v\) from materia \(M\) and continues to claim support for \(\phi\) having value \(v\) from materia \(M\).\nolinebreak
      \footnote{
        The agent has at some time in the past (perhaps a moment ago) claimed support for \(\phi\) having \(v\) from materia \(M\), and at the present time the agent continues to hold that \(\phi\) has value \(v\) from \(M\).
        In some cases, an agent may revise materia.
        E.g.\ this may be the case when appealing to memory, a new source, etc.
        Note, however, that this does not require that the agent initially claimed support for \(\phi\) from materia \(M\) --- may be in instance of memory.
      }
    \item\label{nI:received-info} \(S\) has claimed support that if proposition \(\phi\) has value \(v\) then proposition \(\psi\) has value \(v'\).
    \end{enumerate}
    And, suppose:
    \begin{enumerate}[ref=(\textsf{NI}:\arabic*), resume*=nI_counter]
    \item\label{nI:inclusion} \(S\) is confident that their claimed support for \(\phi\) having value \(v\) is mistaken or misled if \(S\) is not (given relevant context) in a position to claim support that \(\psi\) has value \(v'\) without appealing to \(\phi\) having value \(v\).\nolinebreak
      \footnote{
        Agent considers.
        This should be stressed.
        And, in most cases, it is mistaken that's at issue.
        For, failure of \(\psi\) condition doesn't raise any issue in particular for \(\phi\).
      }
    \end{enumerate}
    Then:
    \begin{enumerate}[ref=(\textsf{NI}:\arabic*), resume*=nI_counter]
    \item\label{nI:going-by-value} \(S\) is not permitted to claim support for \(\psi\) having value \(v'\) by appeal to:
      \begin{enumerate*}[label=(\roman*)]
      \item \(\phi\) having value \(v\) from~\ref{nI:claimed-support}, and
      \item the corresponding implication that \(\psi\) has value \(v'\) from~\ref{nI:received-info}.
      \end{enumerate*}
    \end{enumerate}
  \end{proposition}
\end{note}


\begin{note}
  \nI{} highlights a restriction on the way in which an agent may claim support for some proposition.

  The intuition behind~\nI{} follows with the help of previous proposition and \eit{}.

  The problem is claiming support for \(\psi\).
  Here, the issue is that there's a relation between two instances of claiming support.
  Hence, in moving to the value of \(\phi\), the agent already needs to expect that \(\psi\) is the case.
  However, given this, support claimed for \(\psi\) by value requires \(\psi\) to be the case.

  A researcher is never permitted to claim support that some data is result of machine malfunction given theory if data would show that claimed support for theory is problematic.
  For, moving from theory to what is the case already requires data to be result of machine malfunction.
  No claim for support that it's the result of a machine malfunction even if the machine did not malfunction.
  Consistent with expectation that the machine malfunctioned, but this is weaker than claiming support that the machine did malfunction.

  However, this is too quick.
  Going through the details with a toy example where intuitions may be less clear will help.

  The initial conditions, \ref{nI:claimed-support} and~\ref{nI:received-info}, are background conditions, separated to allow a clean statement of the final condition \ref{nI:inclusion} and the restriction \ref{nI:going-by-value}.
\end{note}

\subsubsection{Illustration of \nI{}}
\label{sec:illustration-ni}

\begin{note}[Illustration]
  To illustrate, let \(\phi\) be the proposition that a certain individual in a given illustration is Wally.\nolinebreak
  \footnote{
    Or Waldo.
    Background on `Where's Wally?'.
  }
  Most likely you have searched the picture and identified an individual with a sufficient collection of visually-identifying properties say: glasses, brown hair, blue trousers, and a red and white striped jumper).
  Let \(\psi\) be some other identifying trait that you did you use to identify Wally, say round glasses (or perhaps a vertically striped jumper, a held cane, etc.).
  So, you may claim support that if you found Wally, then the individual identified is wearing round glasses.

  The third condition~\ref{nI:inclusion} queries whether claimed support for finding Wally has a certain property.
  Would the claimed support for having found Wally be mistaken or misled if you are not in a position to claim support that the identified individual is not wearing round glasses?
  Clearly, you would be mistaken or misled if the identified individual is not wearing round glasses, as Wally is always wearing a pair of round glasses.
  However, \ref{nI:inclusion} whether you would be mistaken or misled if you are not in a position to claim support that Wally is wearing round glasses.
  Intuitively, the latter is true because you identified the individual as Wally by a sufficient collection of visually-identifying properties, you're at least in a position to find the individual again and check that they're wearing round glasses, though you may have also taken a photo, or your may have good visual memory.
  If the individual is not wearing round glasses, then you were mistaken or misled when claiming support that the individual is Wally.

  \ref{nI:inclusion} restricts application of \nI{} to cases in which the agent `should' be in position to claim support for some other proposition.
  Hence: \emph{given} that you have the opportunity to reinspect the individual, there is a problem claiming support that the individual is Wally if you are not in position to claim support that the individual is not wearing round glasses.
  If you do not have the opportunity, then there may be no reason to consider the claimed support for the individual being Wally may be problematic.

  Why?
  \ref{nI:inclusion} sets up \(\psi\) as a potential defeater for claimed support with respect to how the agent has claimed support for \(\phi\).
  Broadly, \nI{} is not identifying an issue with support claimed for \(\phi\) --- issue is with whether the agent may claim support for \(\psi\) in a certain way.\nolinebreak
  \footnote{
    Indeed, \ref{nI:claimed-support} grants that the agent has claimed support for \(\phi\).
    Claimed does not imply success, but is consistent with success, so this is fine.
  }
  Potential defeater with respect to successful claimed support.

  So, if the picture is destroyed, there's no interest.
  However, if faded, then okay.
  If rely on testimony, then still a problem.
  But, if sold the book and testimony, then fine.

  Summarising.
  Simple case used, plausible claimed support given inspection of image.\nolinebreak
  \footnote{
    Given \ref{nI:inclusion} this is compatible with memory.
  }
  \ref{nI:claimed-support}, things looked good.
  \ref{nI:received-info}, wearing round glasses.
  \ref{nI:inclusion}, potential defeater that agent expects not to hold.

  Finally, the fourth condition~\ref{nI:going-by-value} denies that I may claim support that the individual is wearing glasses in a certain way.
  Specifically, I may not claim support that the individual is wearing rounded glasses from:
  \begin{enumerate*}
  \item it is true that the individual is Wally, and
  \item it is true that if the individual is Wally then the individual is wearing glasses, and the entailment that,
  \item it is true that the individual is wearing glasses.
  \end{enumerate*}.
  We term this type of reasoning `\RBV{-}', and will expand below.
  For now, important observation is that in order to `reason by value' the agent infers from claimed support for a proposition having some value that the corresponding proposition has the value, and then reasons from the proposition having the value.

  Difference.
  Perhaps easy to illustrate with the Preface Paradox.
  Claimed support for each claim in preface.
  So, each is true.
  Therefore, conjunction is true.
  However, do not claim support that all are true.
  Prevented from claiming support.

  Possible for similar situation here.
  Claimed support requires some overlap, and possible for \(\psi\) to fall below some threshold.
  However, different.

  Issue is with the kind of defeater.
  Need \(\psi\) to be the case in order to reason this way.
  Constraint on support is `even if\dots'
  Kind of defeater means \RBV{} conflicts with this.

  Need to hold that in a position to claim support for \(\psi\) in order to move from claimed support for \(\phi\) to value of \(\phi\).
  If go to value, then require support to be good.
  If support is good, then in position.
  Therefore, in moving to \(\phi\) already require that I am in position to claim support for \(\psi\).
  Hence, that \(\psi\) holds up.
  Yet, result of this is that need \(\psi\) to be the case in order to reason this way.\nolinebreak
  \footnote{
    Edge cases provide further illustration.
    If you found Wally, then you actually found a one of many as the illustrator made a mistake in this illustration.
  }

  Again, no suggested problem with claimed support for \(\phi\).
  Expect to be in a position to claim support.
  However, issue with \(\psi\) by value is that requires me to be in position.
  Some other proposition would not have this result.
  To illustrate, `faster than X'.
  In moving to value, not required to hold that I am faster.
  Even if I am not faster than X, I am still in a position to claim support that I am, because of info and finding.
\end{note}

\begin{note}[\emph{Summary}]
Still, in position to claim support, but I am not permitted to use this to extend to proposition that would show support is problematic.
\end{note}

\subsubsection{Details of --- and argument for --- \nI{}}
\label{sec:details-ni}

\begin{note}
  Initial three conditions are background conditions.
\end{note}

\begin{note}
  \ref{nI:claimed-support} and \ref{nI:received-info} fix what the agent has claimed support for.
  Claimed support, potential defeater.
  As agent has claimed support, agent expects that potential defeaters do not obtain.

  From \ref{nI:received-info}, follows that \(\lnot\psi\) is a defeater for claimed support for  \(\phi\).
  So, from this, the agent excepts \(\psi\) have value \(v'\).
  However, this is distinct from claiming support for \(\psi\).

  {
    \color{red}
    This illustration should be with the introduction of expectation, and a repeat here.
  }
  Illustration.
  Claim support for it being true that library has a copy of a book.
  Materia, a search of the library website, earlier today.

  It is true now only if someone has not borrowed (all the copies of) the book.
  However, I do not have the resources.
  The library is closed, and website is down.\nolinebreak
  \footnote{
    Resources are relative.
    I could break in to the library\dots
  }

  Somewhat similar to \citeauthor{Wright:2011wn}'s `presuppositions'.
  Here, however, different.
  That I made no mistake may be presupposition, for sure.
  Likewise for library accurately reporting.
  However, that someone has not taken the book is not a presupposition.
  Rather, expectation.
  Claim support for why this expectation holds, but

  With library example.
  Why not merely except that the book has not been withdrawn by now?
  The issue is that I have the result from the website, this is stuff.
  And, the problem with interveining time is that invalidates the stuff.
  Understand this as weakening the claimed support, but the point is I have no way at present to ensure that defeater does not obtain, but am safe to expect that it does not obtain.
  So, weakening support is fine, defeater would wipe all support, and at the moment I retain sufficient.
  And, really that no support for it not being withdrawn.

  Look, it's only a \emph{potential} defeater.
\end{note}

\begin{note}
  \ref{nI:inclusion} requires care.

  Conditional.
  A handful of ways to reformulate the conditional.
  Note, how resources are indexed to state of the agent.

  Highlighting a potential defeater only.
  And, this means that claimed support for \(\phi\), so agent expects that they have the resources.

  How this is a defeater.
  Already have claimed support that \(\phi \rightarrow \psi\).
  However, the \(\psi\) condition here is only about claiming support.
  \ref{nI:received-info} is a separate condition.
  If included in \ref{nI:received-info} this would imply (given \ref{nI:claimed-support}) that the resources are insufficient.
  Hence, the only use of this conditional is when the agent thinks they lack resources.
  Still, do not need this when evaluating conditional.
  If no resources because \(\psi\) does not have value, then this is relevant.

  To illustrate, Wally relied on this.

  By contrast, consider something like a theory modelling some real world phenomena.
  May follow that so long as collection of conditions hold, then explanation of phenomena.
  No doubt that the phenomena is real, and if theory does not provide resources, then there's something wrong.
  The result of being mistaken or misled is not specified, so in this kind of case the result may simply be to restrict application of theory (e.g.\ classic to quantum).
  Or, to discard the theory (e.g.\ ???)

  It doesn't follow from this that not being in a position to claim support for \(\psi\) independently of whether \(\phi\) holds is a defeater.
  You tell me that you're feeling sad over the phone.
  I claim support for the proposition that you are feeling sad.
  If you are not feeling sad, then the claimed support is misleading, you have misled me.
  Yet, I'm not in a position to claim support that you are feeling sad without appeal to your (presumed) testimony.

  With these examples, note the variance in what the fixed condition is.
  With Wally, very local, but with the theory, quite broad.
  However, doubt that this is purely a function of the relevant instances of \(\phi\) and \(\psi\).
  For example, different individuals.
  If an individual doesn't have the research budget, then while potential defeater, it doesn't follow that the individual is in a position to claim support.

  Similarly, even if agent expects to have resources, it doesn't follow that failure is sufficient to show problem with \(\phi\).
  Consider calculator.

  If \(3 \times 14 = 42\) then \(4 \times 14 = 56\).
  Question is whether the instances apply to \ref{nI:inclusion}.
  Things may go either way.
  On the one hand, I would think that I've got things wrong if \(4 \times 14 \ne 56\).
  On the other hand, someone building a calculator may be using this as a test.

  I don't think that use of the calculator is mistaken or misleading.
  However, designer may use this as a test.
  And, further contrast, division.
  Recognise this is a problem, but in these cases typically weaken the proposition.
  I claim support that it's roughly XXX rather than being XXX.

  Final clause, without appealing to \(\phi\) is also important.
  Two aspects.
  First, this is in part why potential defeater.
  There is some way to test whether claimed support for \(\phi\) works out or not.
  Second, required to prevent \ref{nI:inclusion} being vacuous, as \ref{nI:claimed-support} and~\ref{nI:received-info} arguably provide resources.

  Note, could split \nI{} into distinct conditions depending on mistaken/misled.
  Do not do this, as argument does not distinguish.
  So, option is only relevant for evaluating whether the conditional holds.

  {
    \color{red}
    For main application, the relevant reading of `in a position' is whether or not the agent requires novel information.
    This works for reasoning cases.
  }
\end{note}

\begin{note}[Background to Restriction]
  These are the background conditions.
  Final is the restriction.
\end{note}

\begin{note}[~\ref{nI:going-by-value}]
  \ref{nI:going-by-value} describes a particular way of claiming support.
  Termed this `\RBV{-}' above.
  For, reason about what follows from value.
  Same reasoning for why \(\psi\) is a potential defeater to \(\phi\).

  Here, role of successful instance of \ref{nI:going-by-value} helps clarify.
  The function is to obtain something stronger than the expectation that potential defeater does not hold.
  If \RBV{} works out, then the agent does not merely expect, but provides materia to establish the potential defeater does not obtain.

  Conditional of \ref{nI:received-info} is important here, because the value, regardless of the state of the claimed support for the value, requires that potential defeater does not obtain.

  Illustration.
  Searching for YYY in the building.
  If I search, there are various defeaters I expect not to obtain.
  Ask secretary.
  If not in LLL, then not in building.
  Now I only need to check LLL.
  From this, \RBV{} and then claim support for potential defeaters of obscure places.
  Why?
  Because regardless of my reasoning, XXX not being in LLL entails that XXX in not in the building.
  Given this type of value information, establish an also-is relation of support.
  XXX not in LLL also-is support for XXX not in building.
  Without, don't get this.

  Following illustration:
  Distinctive is that \(\mathcal{V}(\phi) = v\).

  Highlight the distinction by considering alternative way of claiming support.
  Consider again the box.
  The box has certain dimensions, and calculations are only relevant given dimensions.
  So, the reasoning proceeds independently.
  There's nothing in the core part of the reasoning that requires the box itself to have the noted dimensions.
  At no point do I need to appeal to it being true.
  Rather, I background that it is true, and derive additional results.

  Contrast, if the alarm is beeping then there is a fire.
  It matters whether or not the alarm really is beeping.
  
\end{note}

\begin{note}[Summary, and testimony]
    Final case to summarise:
  Knowledge via testimony.
  This condition doesn't necessarily apply, as agent may not be in position to claim support for what follows from knowledge claim.

  Two reasons for this.
  First, agent may not be in a position to check.
  E.g.\ missing premise, or layperson, e.g.\ missing steps of reasoning.

  Second, agent may not need to \RBV{-}.
  For, if you've testified, then it follows from your statement.
  I don't need to appeal to me having heard from you.
  Instead, given the additional information that I have, you've already made the claim.
  Even if \(\phi\) doesn't have value, this is still an okay reinterpretation of the testimony you have provided.
  Here, to get the intuition, it's really not clear that I need to endorse that I do have the option to check.
  {
    \color{red}
    This point only really makes sense after the argument has been given.
  }
\end{note}

\begin{note}[General form of difficult cases]
  Generate difficult cases in a systematic way.
  Roughly, any time someone implements something that is a shortcut to other information.
  Return to calculator illustration.
  Something puzzling about the technician.
  However, this is quite common.

  Bookmark.
  Easy to check that this is how far I've got in the book.
  If not, then the bookmark is no good.

  Doorbell, but in a position to check whether there is someone at the door.

  Requests for a colleague to perform some task.
  I.e.\ spreadsheets.

  The key point with all of these examples is that the shortcut is only good if you think that the relevant \(\psi\) instance is the case.
  So, breaks the `\eit{}'.

  However, this goes to fast.
  What we're picking up is not that \(\psi\) needs to be the case --- that much is clear from \ref{nI:claimed-support} --- but that the agent is in a position to claim support for \(\psi\) without appeal to value of \(\phi\).
  The issue is not that \(\psi\) is required to be the case, such a result is the use of reasoning by value.
  No, the issue is with whether the claimed support for \(\phi\) really is any good.

  Hence, the problem highlighted here is roughly that things need to function as expected in order for shortcuts to be of any use.
  Still, there is a difference between \(\phi\) and \(\psi\) working together for the shortcut, and appealing to \(\phi\) and the shortcut requiring \(\psi\) to observe that \(\psi\) is the case and hence you were fine to appeal to the shortcut.

  The latter is intuitively problematic.
  Lots of things going on.
  Here, suggestion is that at least one, sufficient for failure, is that we've got no idea whether the shortcut works.
  It might, but we're appealing to success in order to argue that it does.
  This is what is repeated and expanded on.
  Issue is not that \(\psi\) is required by \(\phi\).
  Rather, that \(\psi\) is required in order to the agent to appeal to claimed support.
  Observing that \(\psi\) follows is then of no real interest, because if not \(\psi\) then no idea about \(\phi\).

  This doesn't fully resolve the query, though.
  We've shown that shortcuts are plausibly OK when \ref{nI:inclusion} doesn't hold.
  However, many cases in which it does seem to hold, and the shortcut seems to be fine.
  The shortcut is there because it's reduces effort.
  And, with a little more effort, one could check the \(\psi\) condition.

  Easy to deal with in the case of testimony.
  Conditional is truthful then something mundane.
  Here, if the \(\psi\) condition doesn't hold, then it's really not clear that one gets a problem with the claimed support for testimony.
  The issue is very local, and claim for testimony would need to be unreasonably strong.
  And, conversely, does seem problematic if the testimony claim is extremely narrow.
  So, the point is that there's no plausible instance of \ref{nI:inclusion} for testimony case, even though the \(\psi\) condition is true.

  So, \nI{} applies to these one-off cases, or when there is going to be some significant problem from a single point of failure.



  
  Still, the problem identified by \nI{} differs slightly.
  Latter is intuitively problematic because using the result of an assumption to discharge the use of the assumption.
  \nI{} doesn't require assuming claimed support for \(\psi\).
  Rather, 


  is that one doesn't get to use claimed support for \(\phi\) to claim support for \(\psi\) through \RBV{} when 
  




  Corollary is that one needs to expand as much as possible when one can.
  Commendable, but does not seem required for claiming support.
\end{note}

\newpage

\begin{note}
  Start with~\ref{nI:received-info}.
  If agent holds \(\phi\) then got to hold \(\psi\).
  Further, \(\lnot\psi\) then \(\lnot\phi\) --- \(\lnot\psi\) is a potential defeater.
  If the agent has claimed support for \(\phi\), then should expect \(\psi\) to be the case.
  However, in principle no different from \(\lnot\phi\) being a potential defeater.
  Broadly, if expect \(\phi\) given support, then relation may be sufficient to expect \(\psi\).

  The third condition.
  Second condition is relation between values.
  Potential defeater.
  This third condition highlights third potential defeater.

  Third condition relation between claiming support.
  From above, claim support for \(\phi\) then expect \(\lnot\psi\) to not hold, given potential defeater.
  However, 3 adds in that the agent may expect \(\lnot\psi\) to not hold regardless of whether \(\phi\) has value.
  So, not only expect \(\phi\) given support, but expect claim to \(\psi\) given claimed support to \(\phi\).

  Think about this is in terms of inclusion.
  Two different senses.

  First, inclusion as relation between support.
  So, tools taken to claim \(\phi\) should also allow for \(\psi\).
  If so, then potential defeater on tools that you don't establish an expectation against when reasoning by value.

  Second, inclusion in terms of claimed support for \(\phi\) (implicitly) includes a claim to support for \(\psi\).

  Expect claim support for \(\psi\).
  However, follows from 2.
  Added is further, expect claim support for \(\psi\) that does not require \(\phi\).

  Fourth condition prohibits.
  Caution is required.
  Fourth condition is a specific kind of reasoning.
  Reasoning-by-value, detail further below.
  Initial summary, however, is that reason with \(\phi\) having value \(v\), it is \(\phi\) having value \(v\) that does the work, nothing else.
  So, drawing consequences of \(\phi\) having value \(v\).
  That is, support that \(\psi\) has value \(v'\) is seen as a solely as consequence of \(\phi\) having value \(v\).

  Example is important here.
  Knowledge when layperson.
  Need value to go by factivity.

  Contrast, box, \(133\text{cm}^{2}\) then not a square.
  Well, here I appeal to measurements of sides, \(7\) and \(13\).
  Don't require that box has value.

  For, reasoning by value, noting that \(\psi\) holds when \(\phi\) holds.
  But this by itself does not provide the agent with expectation that \(\psi\) holds.

  Here, recall \eit{}.
\end{note}

\begin{note}[Structure of \nI{} and plan]
  Structure of \nI{} is two conditions that allow an agent to claim support in a certain way (\ref{nI:claimed-support} and~\ref{nI:received-info}), detailed by~\ref{nI:going-by-value}, but blocked when a defeater condition holds~\ref{nI:inclusion}.

  Conditions to be clarified.
  Inclusion, and reasoning by value.
  Roughly:
  \incl{} reapply (some of the) premises and steps of reasoning used in claimed support for \(\phi\) to claim support for \(\psi\).
  E.g.\ simple: \(p \rightarrow q\) and \(q \rightarrow r\), to claim support for \(p \rightarrow r\).
  Reapply, \(p \rightarrow (q \land r)\).

  \RBV{} is a type of reasoning where agent appeals to value of proposition claimed support for.
  E.g.\ \(K_{E}p\) to \(p\).

  As \nI{} depends on these, little intuition prior to clarifying.
  The gist, however, is that \nI{} captures intuitive constraint that agent is not in a position to claim support for some proposition \(\psi\) by information that \(\phi\) entails \(\psi\) if failure to establish support for \(\psi\) independently of the value of \(\phi\) would reveal problem with the support claim for \(\phi\).

  Possible defeater for support for \(\phi\).
  However, possible defeater isn't necessarily a defeater.
  Key part to explaining \nI{} is why reasoning by value is bad, given that the agent doesn't have a clear problem with the claimed support for \(\phi\).

  Clarifying \incl{} and \RBV{} will allow a clearer statement.
  \nI{} will then follow from \incl{} and \RBV{} together with basic constraint on support \eiS{}.

  Important clarification, \nI{} is sufficient condition.
  Further, \RBV{} is \emph{a way} of claiming support.
  So, \nI{} does not imply that the agent is not in a position to claim support for \(\psi\), only that one way of claiming support is ruled out given \ref{nI:claimed-support}--\ref{nI:inclusion}.
  Following, as \nI{} is about claiming support, this says nothing about whether the agent has support --- in particular, if claimed support for \(\phi\) is support, then by \incl{}, plausible that the agent has support for \(\psi\) even if not in a position to claim when \RBV{}.

  Finally, no appeal to what the values of \(\phi\) and \(\psi\) (actually) are.
  \nI{} is `internal' in this sense.

  Looking forward, argument will be that \gsi{} sets up \incl{} and \AR{} requires \RBV{}.
  Hence, \nI{} rules out agent claiming support for specific ability by \AR{}.
  However, primary motivation will be independent of ability.

  Begin with clarifying \incl{} and \RBV{}, then general account of \nI{}, followed by a handful of examples, and concluding with ability.

  More in Chapter~\ref{sec:inertia}.
  Including, related literature. (No Feedback and Wright.)
\end{note}



\subsubsection{Argument for \nI{}}
\label{sec:argument-ni}

\begin{note}[Review of \nI{}]
  \incl{} and \RBV{}, now turn to why conflict with \incl{} and \RBV{}, as stated by \nI{}.

  \ref{nI:going-by-value}, going by value.
  So, going from support for \(\phi\) to \(\phi\), and then from \ref{nI:received-info} to \(\psi\) by value.

  However, denied claim of support for \(\psi\) by \incl{}.
  Turn to argument for this.
\end{note}

\begin{note}[\nI{} argument, state]
  Start with three conditions describing state of agent.

  By~\ref{nI:claimed-support}, agent has claimed support for \(\phi\), though recognises the support may be fallible.
  It is possible that there's a different value of \(\phi\) (misled), or even if that value, the claimed support is not an indicator (mistaken).

  And, by~\ref{nI:received-info}, agent has information that value of \(\phi\) constrains value of \(\psi\).
  Use of `information' allows for arbitrarily strong support.
  May assume that this is something known, though do not require for failure.

  Finally, by~\ref{nI:inclusion}, the agent is aware that the claimed support for \(\phi\) includes support for \(\psi\).
  That is, agent may reapply premises and steps to claim support for \(\psi\).
  Hence, the agent does not need to go by value of \(\phi\) to get \(\psi\), as premises and steps used to claim support for \(\phi\) did not require value of \(\phi\) (by \eiS{}).
\end{note}


\begin{note}[\nI{} argument, \RBV{}]
  From the three conditions describing state, it is possible for agent to claim support for \(\psi\).
  In particular, by reapplying and establishing how claimed support for \(\phi\) includes support for \(\psi\).

  \ref{nI:going-by-value} describes a way of obtaining support that does not appeal to inclusion of support.
  Agent moves from claimed support for \(\phi\) to value of \(\phi\), and given information, this would constrain value for \(\psi\), hence leading to support for \(\psi\) if \RBV{} is permitted.

  With the background provided, from a certain perspective, agent would be bypassing reapplication.
  Possible to claim support for \(\psi\) regardless of value of \(\phi\), but with information, observe constraint on value of \(\phi\) and hence on \(\psi\).
  As agent doesn't need to do work to establish how value is constrained by reasoning by value, this is quite easy.

  Issue is that \incl{} blocks \RBV{}.
  \eiS{} again.
  If claimed support, then independent of value.
  However, because \incl{}, problem moving from support for \(\phi\) to value of \(\phi\).
  For, in moving support for \(\phi\) to value of \(\phi\), agent is implicitly requiring value of \(\psi\).
  For, given \incl{}, if \(\psi\) does not have value, then claimed support for \(\phi\) would be mistaken or misleading, and hence would block move to value.
  So, any further reasoning by value is required to already have \(\psi\), and this conflicts with \eiS{} when the agent moves to claiming support for \(\psi\) as the result of \RBV{}.

  From a broader perspective, the agent doesn't get to claim support for \(\psi\) through \RBV{} because any move to value requires \(\psi\) to already be the case given the information the agent has.
  Hence, failure of \eiS{} if agent were to claim support for \(\psi\).
  Because of \incl{}, \RBV{} does not preserve \eiS{}.

  Illustrate, possible that the agent is mistaken/misled, and claimed support for \(\phi\) does not include support for \(\psi\).
  However, if \RBV{}, then claim support for \(\psi\).
  Problematic, because whether inclusion is a test for whether the claimed support for \(\phi\) is any good, but bypassing test when reasoning by value.

  No claiming support by noting value consequence, if failure to show value independent consequence would lead to revision of support.
\end{note}

\subsubsection{Illustrations of \nI{}}
\label{sec:illustrations-ni}

\begin{note}
  Nothing particularly problematic about this, as given \incl{}, agent applies whatever support they have for \(\phi\) to get \(\psi\).

  Further, no issue with using \(\phi\) for other things.
  Here, only interest is in support.
  Hence, recognised by the agent that they may be misled.
  From this perspective, the issue is not ruling out potential defeaters.
  Similar to knowledge, etc.\ but no requirement that there are no defeaters.
\end{note}

\begin{note}[Abstract, so examples]
  The above highlights the problem.
  However, abstract.
  Turn to illustrations, and then to how \nI{} applies to \gsi{}.
\end{note}


\begin{note}
  May think that this restricts any application of \RBV{} to claimed support for \(\phi\) without value independent.
  This isn't quite right.
  \eiS{} keeps focus on \(\psi\).
  Only committed to \(\psi\) being a problem.
  Potential issue is no worse than any other instance of claim to support --- possibility of being mistaken or misled.
  If \(\psi\) ends up being used, then there's going to be a gap, where agent isn't in position to claim support by value, but unless eventual consequence is in turn used for \(\psi\), no clear problem --- at least not without stronger assumption.
\end{note}

\begin{note}
  \uRa{} is going to require the agent to reason from premises and steps `included' in claimed support for \(\phi\) in order to claim support for \(\psi\).
\end{note}


\begin{note}[Examples]
  Examples are somewhat difficult, due to complexities of state.
\end{note}

\begin{note}[Picture book]
  \begin{scenario}
    If not genuine, then missing serial number.
  \end{scenario}
  No need to reinspect, faults are support, so no serial number.
\end{note}

\begin{note}[Logic proof]
  \begin{scenario}
    If conjunction and negation are truth functionally complete, then disjunction and negation are truth functionally complete.

    And, claim of inclusion.
  \end{scenario}

  Here, in proving completeness, expressing other connectives.
  So, inclusion because agent will have shown how to switch between conjunction and disjunction.

  Well, claimed support for conjunction and negation.
  So, yes.
\end{note}

\begin{note}[Treasure]
  \begin{scenario}
    Claimed treasure only if learnt secret.
  \end{scenario}
  A little more interesting, as here, agent is going to have done something to learn secret when claiming support for treasure, but may not recognise that they've learnt the information.
  Of course, may be wrong treasure.
  Again, seems bad.
  But, if treasure then sell for \$X, seems fine.

  Useful, as earlier examples may seem to rely on easy checks, but putting pieces together to reveal secret may be quite difficult.
\end{note}

\begin{note}[Problematic]
  \begin{scenario}
    I walked \(15k\) yesterday, and it would not be true that I walked \(15k\) if I had only walked \(14k\).
  \end{scenario}
  In contrast to other cases, the conclusion is fine.
  Problem here is the reasoning.

  Going by value.
  No way to go to \(15k\) without having walked more than \(14k\).
  So, already require that not only \(14k\) is true when reasoning-by-value.
  Claim to support fails because I'm highlighting what's got to be true given support.

  However, clear to observe that claim to support includes not only \(15k\).
  Easy to reason that no matter whether I did walk \(15k\), that the support claimed for walking \(15k\) extends to cover not only \(14k\).

  Reasoning-by-value \emph{is} strange in this scenario.
  Do not need it to be the case that \(15k\) is true in order to deny only \(14k\).


  Useful to note, as there is still some reasoning with the value.
  However, the reasoning does not depend on specific value.
\end{note}

\begin{note}[Knaves]
  \begin{scenario}
    If X is speaking falsely, then Y is speaking truthfully.

    Knave says a bunch of things that you've got could support for being false, but could be true.
  \end{scenario}
  Variation on Knave problems.
  Again, there may be intuition that solving the problem is easily in reach, but I think this is a mistake.
  Knave problems are hard, and the difficulty doesn't seems to make a difference.
\end{note}

\newpage

\subsubsection{\nI{} applied to \AR{}}
\label{sec:ni-applies-ar}

\begin{note}[Applying to type of scenario]
  Our attention now turns to how \nI{} applies to the use of \aben{} in scenarios of interest.

  The focus of our attention is whether an agent may claim support for having a specific ability given the claimed support for having a general ability, given \gsi{}.
\end{note}

\begin{note}[Checking conditions]
  Conditions \ref{nI:claimed-support} and~\ref{nI:received-info} are provided by the scenario.
  Condition~\ref{nI:inclusion} is obtained by reflection on ability.
  So, then, condition~\ref{nI:going-by-value} rules out a way of claiming support for specific ability.

  To argue for is that \AR{} implies \RBV{}.
\end{note}

\begin{note}
  If argument is successful, then agent will not be in a position to claim support for specific ability.
  This is the antecedent of the relevant use of \aben{}.
  Pair \nI{} with following supplement.

  \begin{proposition}[\nIm{}]
    An agent must have claimed support for the antecedent of an entailment in order to claim support for the consequent of the entailment via the entailment.\nolinebreak
    \footnote{To clarify, entailment is only about value.
      Think of conditional.

      So, does not follow that there being an entailment is a required part of agent's reasoning.
      \nIm{} is talking about when the agent appeals to an entailment, rather than any understanding of entailment beyond it being the case.
    }
  \end{proposition}
  \nIm{} seems indisputable,\nolinebreak
  \footnote{
    An agent may have some other way of claiming support for the consequent of the entailment.
    However, if the agent is not in a position to claim support for the antecedent, then the agent is not in a position to claim support because there is an entailment from the antecedent to the consequent.\nolinebreak

    For example, that the coin landed heads is entailed by Sam knowing that the coin landed heads.
    Here, entailment from \(K\phi\) to \(\phi\).

    Second, this light being on entails that the printer is out of paper.
    If agent appeals to entailment, again, need the light to be on.
    However, could look in the paper drawer, or modify the wiring so that an alarm sounds.

    However, Taylor is not in a position to claim support for the coin landed heads because Sam knows if Taylor has no idea whether Sam knows --- though Taylor may claim support by looking at the coin.
  }
  and so not in a position to claim support for result of witnessing ability via \AR{}.
\end{note}

\begin{note}
  Note on two ways of reasoning.
  Getting support for specific ability by \RBV{} and also getting result by \RBV{}.
  \nI{} only explicitly rules out first.
  However, with \nIm{}, second is implicitly ruled out, as if agent claims for value, then need to be able to claim support for premise.
  And, definition of \AR{} is such that going for premise is attribute.
  This is not necessarily required --- e.g.\ \WR{}.
\end{note}

\newpage

\begin{note}[Notes for \AR{}]
    {
    \color{green}
    Well, with the first, it's getting to \(\phi\).
    Doesn't seem the agent is in a position to use factive inference.
    Because, the agent is going from not possible to have ability and for \(\phi\) to be false.

    With the second, different.
    Because, the agent is going from application of ability providing support for \(\phi\).
  }

  Use of \AR{} gets quick argument for \RBV{}.
\end{note}

\begin{note}[Application of \nI{} to \AR{}]
  \AR{}, working with attribute.
  So long as you have general ability, you have specific ability.
\end{note}

\newpage

\begin{note}[Application of \nI{} to \AR{} argument]
  \gsi{} information.
  For \AR{}, agent is required to claim support that they have the specific ability.
  That is, claim support for consequent because the agent claims support for specific ability.
  This is distinguishing feature of \AR{} --- the agent is only appealing to having attribute.
  General characterisation of \AR{}, all ability from appeal to attribute.
  Contrast to \WR{}, where some use of ability.

  So, this means attribute for general and specific in cases of interest.
  For, \AR{} is attribute for all instances of ability.




    If agent appeals to general and information, then agent is appealing to having general attribute, and not only support for general attribute.
\end{note}

\newpage

\begin{note}[Distinguishing features]
  Reasoning has distinguishing features that pair well.
  \begin{itemize}
  \item Extends support.
  \end{itemize}
\end{note}


\begin{note}[Important points]
  Two important points:

  The role of~\nI{} is to highlight that the agent is not in a position to obtain support for (specific) ability in a certain way.
  That is,~\nI{} does not state that the agent may not obtain support for (specific) ability some other way.

  Second, so long as agent holds that they have general ability, then committed to truth.

  May be tempted to say that the agent is not committed, but this seems implausible.
  Cases of transmission failure, it seems agent does remain committed, at least.

  May take issue with information provided, especially if ideal.
  If informer has information, then they should say.
  In turn, not problem with~\nI{} as the agent would have support (via testimony) for specific ability.
  However, informer may only have the conditional.

  Ordinary agents.
  Maxims are broken.
  And, interest effects.
  Up to the agent.

  Seems puzzling, but not paradoxical.
\end{note}

\begin{note}[Why this is important]
  The key idea, and the foundation of the objection, is that the agent is going indirectly.
  The agent fails to show how the general ability extends to specific ability.
  For, the only things available to the agent is the constraint.

  This is useful independently.
  For, even if not convinced by~\nI{}, clear that given \gsi{} and~\uRa{}, the agent goes directly.
  And, something a little puzzling about this.
  Or, so I think.
\end{note}

\begin{note}[Dogmatism]
  Continuing relation to issues with knowledge.
  \autoref{prem:ni} is quite close to dogmatism paradox.
  If one knows that \(\phi\), then any evidence for \(\lnot \phi\) is misleading.

  Distinct again, however.
  For, don't have knowledge in the antecedent.
  Get the dogmatism paradox from the factivity of knowledge.
  No requirement that support for (general) ability is factive.

  Hence, role of the informer is important again, because agent is not in a position to come to the conditional by themselves prior to reasoning.
\end{note}

\newpage

\begin{note}[Finding tension, still]
  We have outlined a type of scenario built primarily on an agent receiving information that the agent has some specific ability so long as the agent has some general ability.
  The agent has support for having the general ability, but there are two ways in which the agent's support for having the general ability may be used to establish support for {\color{red} the result of having the specific ability} --- \AR{} and \WR{}.

  The previous section argued that~\uRa{} constrains how an agent may use the received information.
  If an agent is required to traces support from premises to conclusion through reasoning, then an agent may not appeal to the support for the premises and steps of reasoning that the agent would use when witnessing the specific ability.
  {\color{red} This is summarised in~\ref{P:ab-and-dc:W}.}

  The (initial) plausibility of~\uRa{}, then, suggests that the agent may only establish support for having the {\color{red} result of the specific ability} from the support they have for the general ability by \AR{}:
  The support the agent has for the general ability is support that it is true that the agent has the general ability.
  In turn, given the information received it is true that the agent has the specific ability, and it is only possible for the agent to have the specific ability if the result of witnessing the specific ability is true.

  The argument of this section is that the sketch of \AR{} given conflicts with a different, but equally plausible, premise.
  The premise concerns the way in which the agent obtains support for having the specific ability from the support for the general ability.
  We state conditional, the proceed to the premise.
  The initial statement of the premise is abstract and after providing a handful of clarifications we then link the premise to the type of scenario of interest.
\end{note}

\subsubsection{Incompatibility of \AR{} and \nI{}}
\label{sec:ni-summary}

\begin{note}[Conditional B]
  \begin{proposition}[\mcB{}]
    \begin{enumerate}[label=(C\Alph*), ref=(C\Alph*), resume*=CC_counter]
    \item\label{P:ab-and-dc:A} If
      \begin{enumerate}[label=(\roman*), ref=(CB.\roman*), series=CCB_counter]
      \item\label{P:ab-and-dc:A:ab} an agent obtains support for some proposition \(\phi\) on the basis of the agent's ability to demonstrate that \(\phi\) is the case, and
      \item\label{P:ab-and-dc:A:ni} \nI{} is true,
      \end{enumerate}
      then
      \begin{enumerate}[label=(\roman*), ref=(CB.\roman*), resume*=CCB_counter]
      \item\label{P:ab-and-dc:A:AR} the support for \(\phi\) \emph{is not} claimed on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (in line with \AR{}).
      \end{enumerate}
    \end{enumerate}
  \end{proposition}
\end{note}

\begin{note}[Relating to other conditional]
  Given \mcA{}, the immediate interest with \mcB{} is that~\ref{P:ab-and-dc:W:AR} and~\ref{P:ab-and-dc:W:AR} are incompatible.
  So, if both conditionals are true, then (at least) one of the antecedents from either conditional is false.

  \ref{P:ab-and-dc:A:ab} repeats~\ref{P:ab-and-dc:W:ab}, roughly \eA{}.\nolinebreak
  \footnote{
    As with \mcA{}, could rephrase without \ref{P:ab-and-dc:A:ab}.
    If \nI{} is true, then not possible for agent to claim support for \(\phi\) on the basis of the agent having the attribute of being able to demonstrate that \(\phi\).
  }
  % Still,~\ref{P:ab-and-dc:A:ni} differs from~\ref{P:ab-and-dc:W:uRa}.
  \mcA{} assumed \uRa{}, principle we are proposing an exception for.
  \mcB{} assumes a principle, \nI{} to be argued for.
  Hence, if both \mcA{} and \mcB{} are true, either \eA{}, \uRa{}, or \nI{} is false.

  Before turning to \nI{}, observe general picture.
  If \eA{} and \nI{}, then \uRa{} is false.
  Hence, argument against \uRa{}.
  Further, \ref{either-AR-or-WR} then \WR{}.
  Motivates \rC{}.
\end{note}



\begin{note}[Established conditional 2]
  Something about, if \eA{} then agent does not obtain support for the attribute.
\end{note}

\subsection{Establishing tension/summary}
\label{sec:establishing-tension}

\begin{note}[Summary]
  Given the two established conditionals~\ref{P:ab-and-dc:W} and~\ref{P:ab-and-dc:A}, the combination of the key premises of \uRa{},~\eA{}, and~\nI{} are in tension.

  For, combining~\ref{P:ab-and-dc:W} and~\ref{P:ab-and-dc:A} we have:
  \begin{enumerate}[label=(CC), ref=(CC)]
  \item If \eA{} is the case an agent obtains support for some proposition \(\phi\) on the basis of the agent's ability to demonstrate that \(\phi\) is the case then:
    \begin{enumerate}[label=(C\arabic*\(\sim\)), ]
    \item If \uRa{} is true, then the support for \(\phi\) is obtained on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (in line with \AR{}).
    \item If \nI{} is true, then the support for \(\phi\) \emph{may not be} obtained (in line with \AR{}) on the basis of the agent having the attribute of being able to demonstrate that \(\phi\).
    \end{enumerate}
  \end{enumerate}
  In short, if~\eA{} is the case then~\uRa{} requires a certain interpretation of the scenarios identified by~\eA{} and~\nI{} denies that the interpretation is plausible.
\end{note}


\begin{note}[Creating tension]
  Have:
  \begin{enumerate}
  \item \(\eA{}\)
  \item \(\uRa{} \rightarrow \lnot\WR{}\)
  \item \(\nI{} \rightarrow \lnot\AR{}\)
  \end{enumerate}
  Argued for these.

  Then,
  \begin{enumerate}
  \item \(\eA{} \rightarrow (\AR{} \lor \WR{})\)
  \end{enumerate}
  If agent claims support, either \AR{} or \WR{}.

  Then use Propositions.
  \begin{enumerate}
  \item \(\eA{} \rightarrow ((\AR{} \land \lnot\nI{}) \lor (\WR{} \land \lnot\uRa{}))\)
  \end{enumerate}
  Simplify by exclusive proposition again.
    \begin{enumerate}
  \item \(\eA{} \rightarrow ((\lnot\nI{}) \lor (\lnot\uRa{}))\)
  \end{enumerate}

  So,
  \begin{enumerate}
  \item \(\lnot\eA{} \lor \lnot\uRa{} \lor \lnot\nI{}\)
  \end{enumerate}
\end{note}

\begin{note}[Weak points]
  \eA{} and \(\eA{} \rightarrow (\AR{} \lor \WR{})\).

  Perhaps there is a third option.
  Though unclear what this would be, even in outline.

  Hence, that the agent has the option of claiming support.
  If so, though, it seems surprising that \aben{} is never used to claim support.
\end{note}

\begin{note}[Tension, choices]
  In short, we have the following resolutions.
  \begin{enumerate}
  \item\label{ten:res:nS} Agent may not obtain support for result of witnessing ability, or
  \item\label{ten:res:nD} Agent obtains support for result on the basis on premises that the agent would use when witnessing ability --- incompatible with general application of~\uRa{}
  \item\label{ten:res:nI} Agent obtains support for result from attribute of having the ability on the basis that the support they have for general ability would be misleading --- incompatible with general application of~\nI{}
  \end{enumerate}
  \ref{ten:res:nS} is incompatible with~\ref{ten:res:nD} and~\ref{ten:res:nI}.
  However, \ref{ten:res:nI} and~\ref{ten:res:nD} are compatible, as both~\uRa{} and~\nI{} may be restricted.
\end{note}

\begin{note}[Argument sketch recap]
  Let us recap the main points of the argument so far.
  \begin{enumerate}
  \item Assume possibility of cases in which agent is provided with information that they have some specific ability so long as the agent has a general ability, such that the agent has support for having the general ability, but has not established support for possessing the specific ability.
  \item In such cases, it seems it is possible for the agent to obtain support for what follows from the agent witnessing their specific ability.
  \item If so, the agent appeals to having the specific ability in order to obtain support for what follows from the agent witnessing their specific ability.
  \item Attribution, and witnessing.
  \item If witnessing, then conflict with the requirement that an agent must access support for the premises appealed to in support of a conclusion.
  \item If attribution, then conflict with the restriction that an agent may not obtain support for some proposition on the basis that support the agent has for some other proposition would be misleading otherwise.
  \end{enumerate}

  To follow:
  \begin{enumerate}
  \item Restricting~\uRa{} in favour of~\rC{} works well.
  \end{enumerate}
\end{note}

\begin{note}[Meek outlook]
  This is not a clean argument.
  Take~\uRa{} and~\nI{} and hold the first.
  The agent may not obtain support.

  While there may be tension if the agent obtains support, this tension is never instantiated.

  I am sympathetic.

  Still, endorsing the restriction does not require the agent to obtain support in this case.
  Harbour some hope that that there is scope to restrict \uRa{}, and that the argument provided for resolving tension in favour of \rC{}, along with later arguments, may serve as a source for reflection.
\end{note}

\begin{note}[\WR{} isn't required for interest]
  \mcB{} is quite interesting itself.
\end{note}

\section{Positive argument overview}
\label{sec:posit-argumn-overv}

\subsection{Cases}
\label{sec:cases}

\begin{note}
  Main role of minor argument is cases.
\end{note}

\begin{note}[Beyond belief]
  Application in particular to desire.
\end{note}