%%% Local Variables:
%%% TeX-master: "master"
%%% End:

\chapter{Overview}
\label{cha:overview}

\section{Ability and access to support}
\label{sec:abil-access-supp}

\begin{note}[Introducing main topic]
  Our interest is in when an agent may claim support for some conclusion of some instance of reasoning on the basis of the support the agent may claim for the premises of the instances of reasoning.

  Consider:
  \begin{proposition}[\bP{}]\label{prem:bP}
    If an agent may claim support for premises and steps of reasoning, accesses those premises and traces support through those steps of reasoning, then agent may claim support for conclusion on basis of the claimed support for the steps and premises of reasoning.
  \end{proposition}

  \bP{} is about when an agent may claim support for a conclusions of reasoning from premises, steps used.
  We take~\bP{} as basic.
  {
    \color{red}
    Some notes on intuition.
  }

  For example, suppose an agent measures that the box in front of them has the dimensions of \(19\text{cm}\) by \(7\text{cm}\).
  The agent understands how to calculate the area of a box, and by performing some reasoning comes to hold that the area of the box is \(133\text{cm}^{2}\).
  The support the agent has for holding that the area of the box is \(133\text{cm}^{2}\) is obtained (at least in part) on the measurement of box, understanding how to calculate the area of box, and some grasp of arithmetic.

  {
    May say that the support the agent claims for the box depends on \dots if the agent were to discover they were mistaken about support (e.g.\ an inaccurate ruler) then the agent would not be in a position to claim support.
  }

  (Whether some (or all) of the required arithmetic is to be included as a premise or a step of reasoning may be set aside.)
\end{note}

\begin{note}[Support]
  The purpose of taking~\bP{} as basic is to fix a basic understanding of when an agent may claim support in core instances of reasoning.
  As~\bP{} is quite terse, let us provide some detail on how `support' is understood before continuing.

  {
    \color{red}
    Talking of `claiming support', maybe suggest that this is between `propositional' and `doxastic' support.
    However, even this isn't quite right, as both require the agent to have support.
  }
\end{note}

\begin{note}[Support]
  A general statement of support and claiming support is difficult.
  Instead, sketch an understanding of the role of support, and motivate a distinction between support and claiming support.

  Valid, but this only captures when premises are true and conclusion is true.
  Support that some proposition is false.

  There's some designated value, e.g.\ truth or desirability, and reasoning keeps appropriate value.

  In a deductive case, if the premises are true, then the conclusion is true.
  Means-end reasoning for desire.
  The value is important.
  If it is true that it past 6pm, then it is true the shop is closed.
  Provides designated value of shop being closed.

  However, if agent desires that it is past 6pm, then it doesn't follow that the agent desires that the shop is closed.
  Question an agent as to why they think their desires conform to truth --- is-ought problem.

  So, propositions and designated values.
  proposition has some instance of the value.
  Question is what the value is.
  Provides support when information contributes to fixing designated value.
  So, contributes to true rather than false, for example.
  Support for proposition, consider all the support provided.
  Truth as default, so speak of support, other cases specified, e.g.\ desirable or probable.

  Claiming is then that information does provide support.
  Claim for proposition is understood in the same way.

  So, independent of agent doing the reasoning, doesn't seem like too much of a big deal.

  Instead, for {may} claim support, subjectively sound.
  In the sense that for each premise or step of reasoning used, the agent has claimed support for the premise or step and does not have superior support for a conflicting premise or step.\nolinebreak
  \footnote{
    Might be read in normative terms as the agent being `blameless', but I don't think this is quite right.
    Seems there are cases in which an agent may be blameless for not performing reasoning that they were capable of doing.
    For example, native speaker and non-native speaker, both have good understanding of the other's language and customs.
    Non-native says something particularly charming, native speaker is blameless for being quite charmed, though with some reasoning they would have realised that the intention of the non-native speaker was to express something plainly factual.
  }
  Here, this is very unrestricted.
  Agent starts by mistakenly claiming support, then may claim support and then may claim support for seemingly any proposition.
  Well, understanding of claiming is only for the result of reasoning.
  May place restrictions on claiming support for propositions that are not the result of reasoning.

  Example.
  Teacher, so claim support for something.
  Use this.
  Fine for the agent to claim support, does not entail that the agent has support.

  Two important things, both of which will be used.
  Misleading.
  Mistakes.

  \emph{Misleading}.
  For, fixes designated value, but still room for variance.
  Hence, support claimed may be misleading.
  And agent may be mistaken in claiming support, though support is not mistaken.

  If mistaken, then requirements on when an agent may claim support.
  Even so, keeping the appropriate instance of designated value is quite restrictive, as relies on fixing the designated value.
  However this is for support, rather than claiming support.

  \emph{Mistake}
   An agent may be mistaken about support they have.
  Intuitive case, diary entry, speeding ticket.
  Entry was actually from previous year, and bug in the software.
  Agent didn't really have support, but was fine to claim as support.
  It's not the case that the diary continues to provide support, which is overshadowed by the discovery of the software bug and/or the CCTV footage.

  One may hold that the agent still has support as it was a bug.
  If redo as a mistake made by the agent by not checking the year, then agent isn't in a position to claim support.
  Generalising, not possible claim support and be mistaken.
  So, any `proper' claim of support is having support.

  So, significant assumption is that mistakes are possible but do not prevent agent from claiming support.
  Compatible with a directive to fix mistakes.

  Simple example, classical and intuitionist mathematicians.
  Each may deny that the other obtains support, but clear that each is in a position to claim support for conflicting theorems.
\end{note}

\begin{note}[Adequate reasoning]
  Term this \emph{adequate} reasoning.
  May be good, may involve mistakes, may be bad.
  Kind of reasoning that we, the folk, do.
  Distinction for claiming support is that this is different from whether the agent has support, and we may set issues about whether the agent has support.

  Our interest is what is required for an agent to \emph{claim} support for (premises and) steps of reasoning, rather than what is required for an agent to \emph{have} support for (premises and) steps of reasoning.

  Use support as opposed to justification.
  Initial focus is on epistemic/doxastic attitudes.
  However, practical reasoning.
  For example, means-end.
  Support considered quite general to also include this.
\end{note}

\begin{note}[Focus]
  Consider the converse of~\bP{}:

  \begin{proposition}[\uRa{}]\label{denied-claim}
    An agent may claim support for conclusion on basis of support the agent has for premises only if the agent has accessed support they have for premises and traces implication through (at least) adequate reasoning.
  \end{proposition}
  
  \uRa{} seems quite plausible.\nolinebreak
  \footnote{
    Three brief notes on~\uRa{}:

    First, the `has' in~\uRa{} only requires `at some point in the past'.
    Hence,~\uRa{} does not require the agent to reason from premises to conclusion each time the agent claims support for the conclusion.
    For example, if an agent proved the Deduction Theorem for propositional logic last week, then the agent would not be in conflict with~\uRa{} if they claimed support for the Deduction Theorem on the basis of the premises and reasoning they performed in the past.

    Second, and following from the first, the against~\uRa{} will also hold for any stronger statement --- for example if `has' is read as `has just'.
    For example, requiring that the agent's memory of proving the Deduction Theorem allows the agent to claim support, rather than the premises and steps used in the past.
    The argument (stated below) denies that, given certain information, the agent needs witnesses any reasoning in order to claim support for the result of witnessing the reasoning.

    Third, as~\uRa{} is about when an agent may \emph{claim} support, it is compatible with~\uRa{} to hold that the agent \emph{has} support --- regardless of whether the agent has witnessing the reasoning.
    }

  For example, if the agent did not measure the box, understand how to calculate the area of a box, or perform the arithmetic, the agent would not be in a position to claim support that area of the box is \(133\text{cm}^{2}\).
  A lucky guess that the area of the box is \(133\text{cm}^{2}\) would not allow the agent to hold that the area of the box is  \(133\text{cm}^{2}\) on the basis of the dimensions of the box, the agent's understanding of how to calculate the area of a box, and arithmetic.
  And, it seems the agent is not in a position to base their lucky guess in such a way because the agent did not reason from the dimensions of the box, the agent's understanding of how to calculate the area of a box, and arithmetic.

  Further,~\uRa{} not only seems quite plausible, but is either explicitly or implicitly appealed to when characterising the support an agent may claim, or reasons, an agent has for some (reasoned to) proposition.\nolinebreak
  {\color{red}
    Intuitive understand of doxastic support.
    Following, two prominent accounts of the basing relation.
    Other examples in rationality.
    For now, take intuitive plausibility.
    Chapter~\ref{cha:access} (will have) more detail.
  }
\end{note}

\begin{note}[Alternative]
  Our interest with \uRa{} is that it is a universal claim.
  \uRa{} applies to all instances in which an agent may claim support for conclusion on basis of support for premises and steps of reasoning --- an agent may only claim support if the reasoned from the premises via the steps.

  The goal is to motivate the following exception to \uRa{}:
  \begin{proposition}[\rC{}]\label{rC}
    If an agent has information that they have the ability to (adequately) reason to some conclusion, then the agent may claim support for the conclusion on basis of support for premises that the agent would access and steps used by witnessing their ability to reason to the conclusion.
  \end{proposition}
  
  \rC{} is an exception to~\uRa{}.
  For, if~\rC{} is true, then there are cases in which an agent is not required to reason from premises they may claim support for to some conclusion in order to obtain support for the conclusion on the basis the support the agent has for the premises.

  Stated~\rC{} as an exception to~\uRa{}, but we are not arguing that~\rC{} is an exception to~\uRa{}, which would require an argument that \uRa{} holds for other cases.
  Nor that \rC{} is the only exception, which would require a stronger argument that~\uRa{} holds for all other cases.
  Take~\uRa{} to be plausible, and suspect that there are few, if any, further exceptions, but~\rC{} may stand independently on any further statements about (claiming) support.

  As with~\uRa{}, \rC{} does not entail that the agent \emph{has} support.
  {
    \color{red}
    Some more notes on why this is important.
    Basically, this means that~\rC{} isn't too strong.
  }
\end{note}

\begin{note}[Normative/weakness]
  Consider~\rC{} somewhat weak as it's only about claiming support.
  Doesn't show that the agent has support.
  Agent may be mistaken, in the sense used above.
  So, in particular, normative conflict.
  Ought not use information about ability.
  I don't think this is correct, normative considerations distinguish good instances from bad instances.
  Not all cases are good, though I think the ones focused on are.
  In any case, normative is a separate argument, and need to get clear on what the phenomena is before going in for normative considerations.

  So, only dealing with `adequate' reasoning.
\end{note}

\begin{note}[Ability]
  The exception is motivated by the agent having information that they have the ability to (adequately) reason to the conclusion.

  Idealised agents have no need to appeal to ability.
  However, for limited agents, ability is abundant, while the resources required to witness abilities are scarce.
  That the exception to~\uRa{} is narrow does not entail that there are few occurrences of the exception.

  Information about ability may be abundant while the resources for witnessing abilities are either scarce or temporarily unavailable.
  So, for example, agent has the option of conserving or deferring use of resources.

  If~\rC{} then a novel perspective on limited agents.
  When and why limited agent may claim support for result of reasoning.
  Here, conflict with appeal to~\uRa{} it its unrestricted form.

  And, in between propositional and doxastic support (or more commonly justification).
  Propositional support doesn't allow agent to claim support.
  Doxastic support, agent does claim support.
  If ability allows agent to claim support, \dots

  Secondary motivation is with ability to reason itself.
  Even if arguments for~\rC{} fail to convince, not much has been said on ability to reason, and first steps are useful.
\end{note}

\begin{note}[Interest in ability]
  Broadening scope.
  Arguments involving~\uRa{}.
  Distinction between ideal and non-ideal.
  Potential alternative conclusions to arguments that appeal to~\uRa{} as a premise.
  Revise premises for arguments in which~\uRa{} is a conclusion.
\end{note}

\begin{note}[Examples]
  Need quick truth and desire examples.
  I don't think I need to make these examples compelling, as giving borderline examples may help motivate interest.
\end{note}

\begin{note}[Small corollary]
  Small corollary is that if the agent has reasoned, then don't need to rely on memory as premise for claiming support.
  Rather, memory works to provide information.

  To extent this is plausible, this is the `backwards' looking part of~\rC{}.
  It's the `forwards' looking part that we will focus on.
\end{note}

\begin{note}[\emph{Exception}]
  As an exception, this doesn't mean that the (appeal to) support is the same as would be if the agent had done the reasoning.
  One way to frame is that doxastic or no claim to support.
  See~\uRa{} as what it takes to obtain doxastic support.
  Deny this.
  There is some other kind of relation to support.
\end{note}

\begin{note}[No causality]
  Important to note, as seems easy to confuse.
  Not claiming that the agent's attitude is causally related to the premises.
  Cause and `basing' may come apart.
  What matters is relation, causation ensures this relation.
  Denied is that based only if caused.
\end{note}

\begin{note}[Motivating idea, designated value]
  Thinking about attitudes.
  Some kind of designated value on the attitude.
  Doxastic, truth, maybe.
  Why should it matter that the reasoning has been performed prior to forming the attitude?

  Arguing in this way requires some account.
  Perhaps, in hindsight, this would have been preferable.
  Here, a little different.
  Cases in which, whatever it turns out to be, agent is permitted to form such an attitude, constrain with additional condition which seems harder to give up.
\end{note}

\begin{note}[Motivating idea, normative]
  Seems as though there's a plausible normative dimension, in which an agent may be criticised on what they are able to do.
  In particular, ability to reason further, but did not do so.
  Difficult to understand this as a requirement to reason, given constraints on resources.
  Doesn't seem to excuse, or so one may think.

  That is, this is something in between
  \begin{enumerate}
  \item The agent not having the resources.
  \item The agent having the resources, but being unaware that they may use them.
  \item The agent having the resources, and being aware that they may use them.
  \item The agent using the resources.
  \end{enumerate}
\end{note}

\begin{note}[Not clear infinitsm is an exception]
  Infinitism is not clearly an exception to~\uRa{}.
  Indeed, sketch follows some infinist ideas, to a degree, that there is a path to be traced.
  Still, inifinist may require that the agent has done enough reasoning.
  (E.g.\ \textcite[10]{Klein:2007ve})
\end{note}

\newpage

\section{Structure of argument}
\label{sec:structure-argument}

\begin{note}[Structure of argument]
  Two lines of argument for endorsing~\rC{}, and hence denying~\uRa{}.
  \begin{enumerate}[label=(L\arabic*), ref=(L\arabic*)]
  \item\label{arg:line:1} Motivate~\rC{} as resolution to tension resulting from~\uRa{}.\newline
    Specifically:
    \begin{enumerate}[label=(L1\alph*)]
    \item\label{arg:line:1:a} Provide recipe for generating scenarios where~\uRa{} is in tension with particular scenarios involving information that an agent has the ability reason to some conclusion and a further claim regarding support.
    \item\label{arg:line:1:b} Motivate~\rC{} as a resolution to the tension.
    \end{enumerate}
  \item\label{arg:line:2} Argue that granting~\rC{} as an exception to~\uRa{} allows for an intuitive understanding of cases in which agent has the option of appealing to ability, even if there are alternative ways of interpreting the scenario in line with~\uRa{}.
  \end{enumerate}
  These two lines of argument work together.
  The tension of~\ref{arg:line:1} generates interest in witnessing that may be flatly rejected by prior endorsement of~\uRa{}.
  The intuitive understanding of scenarios involving ability of~\ref{arg:line:2} suggests there's more to witnessing than resolving the tension in narrow cases.
\end{note}

\begin{note}[Details of \ref{arg:line:1}]
  The initial focus is on the first line of argument,~\ref{arg:line:1}.
  The tension developed in part~\ref{arg:line:1:a} is delicate, but hopefully informative.
  We will establish a number of corollaries regarding ability and the interaction between~\uRa{} and ability.
\end{note}

\begin{note}[Before turning to the argument\dots]
  Before turning to the argument, we conclude this introduction with a handful of notes regarding~\uRa{} and~\rC{}.
\end{note}

\begin{note}[Scope of \mp{}]
  \mp{} does not say anything in particular about what the agent may claim support for, only what must be the case in order for an agent to appeal to support for some conclusion on the basis of support for premises.

  Talking in terms of (support for) premises and conclusions restricts attention to reasoning.
  There may be broader use of `premise' and `conclusion' where an agent is not required to reason from premise to conclusion in order for the premise to support the conclusion.
  For example, if visual perception is immediate.
  Perhaps it may be said that an agent's visual experience is a premise to the conclusion that a dog is sleeping.
  Still, for present purposes, `conclusion' refers to the output of some process of reasoning performed by an agent which is either actual or potential, and `premises' to the input of that process.

  Note, also, that in both cases the relation between premises and conclusion is important.
  If agent does not reason, then neither~\bP{} nor~\uRa{} apply.
  If there are multiple ways to obtain a conclusion, then~\uRa{} does not require the agent to reason from a particular set of premises.

  Likewise,~\uRa{} does not require that an agent is required to obtain support for a proposition by valid and subjectively sound reasoning from some premises.

  Rather,~\uRa{} requires that an agent reason from premises to conclusion in order to establishes support between premises and conclusion
  By contrast,~\bP{} holds that reasoning is sufficient to establish such a relation.
\end{note}

\begin{note}[\mp{} is intuitive]
  \uRa{} is intuitive, and is quite common, though not without exceptions.
(For example, there's views on testimony in which the testifier provides agent access to support the testifier has.
One may understand this as conflicting with~\uRa{}, or that the fact that these are accessible is the relevant piece of support.)
\end{note}

\begin{note}[Alternative]
  \rC{} restricts~\uRa{}.
  This is not to say the agent obtains support equivalent to that which would be obtained were the agent to do, or have done, the reasoning.
  Nor, that the agent is aware of the relevant premises.

  Intuitively, \rC{} states that the agent may appeal to the reasoning they are able to perform in support for the conclusion of that reasoning, and as that reasoning moves from premises to conclusion, it is on the basis of the support for those premises that the agent would identify by reasoning that the agent obtains (some) support for the conclusion.

  Hence, \rC{} is in line with the spirit of~\bP{}.
  For the exception to~\uRa{} is granted by the agent appealing to a witnessing event in which the antecedent (and consequent) of~\bP{} are satisfied.
\end{note}

\begin{note}[Ability ensures propositional?]
  Plausible that if the agent has the ability, then the agent already has propositional support for the relevant proposition.
\end{note}

\section{Negative argument overview}
\label{sec:broad-argum-overv}

\begin{note}[Overview]
  Tension resulting from the unrestricted scope of~\uRa{}.
  We begin by introducing a particular type of scenario involving ability, and observe how~\uRa{} requires a unique interpretation of the scenario.
  We then introduce an additional principle regarding support, which conflicts with the interpretation of the type of scenario introduction required by~\uRa{}.
\end{note}

\subsection{Type of scenario}
\label{sec:type-scenario}

\begin{note}[Tension, information]
  The tension arises when an agent receives (limited) information that:
  \begin{enumerate}[label=(\GSI{}), ref=(\GSI{})]
  \item If the agent has a general ability to \(\gamma\), then the agent has a specific ability to \(\varsigma\) (as an instance of the general ability).
  \end{enumerate}
  The information is limited because it does not directly provide the agent with the information that the agent has the specific ability, nor that the result of witnessing the specific ability is the case.

  \GSI{} as \gsi{}.
  Information is that if the agent has a general ability to \(\gamma\), then as an instance of the general ability the agent has the specific ability to \(\varsigma\).

  For example,
  \begin{enumerate}[label=(\GSI{}\arabic*), ref=(\GSI{}\arabic*)]
  \item\label{qe:cond} If you have the ability to reason with the rules of chess, you have the ability to demonstrating that there is a sequences of moves that will ensure a win for one of the players (as an instance of the general ability).
  \end{enumerate}
  The conditional structure\nolinebreak
  \footnote{
    Strictly speaking the formulation as a conditional isn't important.
    What matters is that the agent is required to endorse general ability.
    \begin{enumerate}[label=(\GSI{}\('\)), ref=(\GSI{}\('\))]
    \item Either the agent does not have the general ability to \(\gamma\), or the agent has a specific ability to \(\varsigma\).
    \end{enumerate}
  }
  of the information distinguishes \GSI{} from (\dSI{}):
  \begin{enumerate}[label=(\dSI{}), ref=(\dSI{})]
  \item You have the ability to \(\varsigma\).
  \end{enumerate}
  With respect to the example:
  \begin{enumerate}[label=(\dSI{}\arabic*), ref=(\dSI{}\arabic*)]
  \item\label{qe:cons} You have the ability to demonstrate that there is a sequences of moves that will ensure a win for one of the players.
  \end{enumerate}
  Where `\dSI{}' stands for direct specific ability information as the agent directly receives information that they have a specific ability.

  By contrast, with \GSI{} the agent is required to obtain~\ref{qe:cons} from~\ref{qe:cond} by endorsing the antecedent --- that they have the (general) ability to reason with the rules of chess --- and so it may not be the case that the agent has the specific ability.

  So, from \GSI{}, the agent is not provided with information that:
  \begin{enumerate}[label=(I\arabic*), ref=(I\arabic*), resume]
  \item\label{qe:result} There is a sequences of moves that will ensure a win for one of the players.
  \end{enumerate}
  For, it need not be the case that~\ref{qe:result} is true if~\ref{qe:cond} is true by virtue of a false antecedent.
  While, \ref{qe:result} does follow from~\ref{qe:cons}.

  Of course, the antecedent of~\ref{qe:cond} need not be false.
  Rather, the observation that the antecedent of~\ref{qe:cond} highlights how \GSI{} requires the agent to appeal to their general ability in order to obtain information about how the agent's general ability extends to a particular case.

  However, if the agent holds that they have the ability to demonstrate that there is a sequences of moves that will ensure a win for one of the players, then the agent may reason to~\ref{qe:result}.

  We term these \AR{} and \WR{}, respectively.
  Brief descriptions from third-person perspective.

  \begin{description}[left=\parindent]
  \item[\(\cdot\)\hspace{1em}\AR{}]\label{A:s}\mbox{}
    \begin{quote}
    A strategy must exist in order for it to be the case that an agent to possess the ability to demonstrate that a strategy exists.

    Therefore, if an agent may claim support for possessing the ability to demonstrate that a strategy exists, then the agent may claim support for the existence of a strategy, and support transmits over entailment.\nolinebreak
    \footnote{
      The justification is a little quick.
      Deny that support always transmits over entailment.
      Don't see a clear problem with this case.
    }

    Support for general, so support for specific, and hence support for conclusion.
  \end{quote}
\item[\(\cdot\)\hspace{1em}\WR{}]\label{W:s}\mbox{}
    \begin{quote} Agent has support for general ability, and specific ability is an instance of general ability.
    Specific ability involves premises and steps from general ability.
    So, given the \GSI{}, there is a potential event in which agent does reasoning, and given general ability, the agent is in a position to claim support for each premise and step of reasoning.
  \end{quote}
\end{description}

\begin{note}[Intuition for \AR{} and \WR{}]
  \AR{} relies on property attribution.
  \WR{} relies on extending support.
\end{note}

\end{note}

\begin{note}[Quite brief]
  Sketches of \AR{} and \WR{} are brief.
  Expand on these in the following sections (\ref{sec:first-conditional} and~\ref{sec:second-conditional}) to some extent, and chapter~\ref{cha:potent-infer-attr} will focus on a detailed account of both.
\end{note}

\begin{note}[No third option]
  \AR{} and \WR{} seem exhaustive.
  No alternative source of information about conclusion.
  Hence, specific ability is required, and is likewise novel.
  So general ability is a required premise.

  \AR{} focuses on the idea that the agent may claim support from having the attribute (or the truth) of the specific ability.
  \WR{} focuses on the idea that the agent may claim support from witnessing (or using) the specific ability.

  Ability is describing some action that may be witnessed by the agent.
  Unclear what else there is than mentioning or witnessing action.

  \begin{proposition}\label{either-AR-or-WR}
    Either \WR{} or \AR{}.
  \end{proposition}
\end{note}

\begin{note}[General ability]
  Both \AR{} and \WR{} may be stated without general ability.
  For our purposes, general ability has two purposes.
  \begin{enumerate}
  \item Prevents alternative route to conclusion.
  \item Provides agent with relevant information about why the agent may have the specific ability, without (directly) providing the agent with information that they have the specific ability.
  \end{enumerate}
  No claim that either 1 or 2 could be done some other way.

  Invoke general ability in explanation of \WR{}, but key is support for premises and steps.
  Possible to reformulate with anything that places agent in a position to claim support.
  Likewise, general will be used to develop tension for \AR{}, but may be possible to formulate without.
\end{note}

\begin{note}[Basic idea]
  We will return to \GSI in greater detail below.
  For now, the basic idea is that the agent is on the hook, so to speak, for holding that they have the specific ability.

  Scenarios of this kind are likely uncommon.
  If assume some Gricean maxims, then seems to require that the informer does not have stronger information, or that stronger information is not relevant.

  Perhaps the informer does not want the agent to rely on the informer's information for the existence of the strategy.
  Or, perhaps the agent only wants to appeal to their own understanding of chess.

  Or may be read as a slight challenge.
  The relevant interpretation of `if you're smart enough, you can solve this problem' seems clear.
  `If your ability to reason is of sufficient worth, then by extension of that ability, you have the ability to solve this problem.'
  Paraphrased, `if you're smart enough, you have the ability to solve this problem'.
  So challenged, and confident in one's smarts, one may expect to solve the problem.
  The slight difference with the limited information of interest is that the informer provides information about what the solution to the problem is if the agent is `smart enough'.

  Scenarios require the agent to use this information.
  May be the case that this kind of information is used when alternatives are available.
  E.g.\ hold \(\phi\) not only because testimony, but because ability.

  Main point is moving from general to specific.
  However, focus point is use of specific.
  How this works when the agent appeals to ability.
  Role of \GSI{} is to capture idea that agent may have reason to appeal to specific ability.
  Plausible that if agent appeals to specific then something like general in the background.
  Even if somewhat rare, then, fairly clean set-up for appeal to specific ability.

  Note, in particular with \ref{qe:cons} the agent may hold that \(\phi\) without holding that they have the specific ability to demonstrate that \(\phi\).
  For example, consider instructor telling a student that they have the ability to show that ? is the solution to the problem.
  Student may reason that the instructor is not wrong about the solution, but is wrong about the student's ability.

  If student is given \GSI{} then it's not clear that the agent gets the solution.
  Plausible that variant information, though.
  ? is the answer, and so long as general, then specific.
  Though, as before, agent doesn't need to consider ability with such a variant, as route to ? which is independent of the agent's ability.
\end{note}

\begin{note}[Scenario proposition]
  For ease of reference, we wrap scenarios involving the limited information as a proposition.
  \begin{proposition}[\eA{}]\label{prem:ab}
    It is possible for an agent to use information that they have some specific ability so long as the agent has some general ability to claim support for what follows from the specific ability.
    (Where the agent lacks doxastic support for what follows, and for \(A(\varsigma)\) without information).
  \end{proposition}
\end{note}

\begin{note}[Possible restrictions]
  The important aspect of premise~\eA{} is that there are cases in which the agent may appeal to ability to obtain support.
  This is quite weak.

  Understanding of support here is primarily for the agent.

  It allows that there may be cases in which the details of the cases outlined are satisfied, but where kind of support is unsuitable for certain purposes.

  In particular, some witness of ability may be demanded by a third-party.
  Perhaps due to lack of confidence in agent, or contextual features of the scenario.
  This is no different from memory.
  Memory of proving \(\phi\) provides support for \(\phi\).
  Still, one may still demand a demonstration of \(\phi\).
  Perhaps the third-party considers the agent's memory unreliable, or perhaps context has been set so that memory is insufficient to add a proposition to the common ground, etc.
\end{note}

\subsection{Conditional A}
\label{sec:first-conditional}

\begin{note}[Conditional A]
  The first conditional we establish highlights how \uRa{} constrains how an agent may use \gsi{} in the type of scenarios described by \eA{}.

  \begin{proposition}[\mcA{}]
  \begin{enumerate}[label=(C\Alph*), ref=(C\Alph*)]
  \item\label{P:ab-and-dc:W} If
    \begin{enumerate}[label=(\roman*), ref=(CA.\roman*)]
    \item\label{P:ab-and-dc:W:ab} an agent may claim support for the conclusion of reasoning they are able to do in cases described by~\eA{}, and
    \item\label{P:ab-and-dc:W:uRa} \uRa{} is true,
    \end{enumerate}
    then
    \begin{enumerate}[label=(\roman*), ref=(CA.\roman*), resume]
    \item\label{P:ab-and-dc:W:AR} the claimed support for \(\phi\) is obtained on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (i.e.\ \AR{}).
    \end{enumerate}
  \end{enumerate}
\end{proposition}

  The reasoning described in the consequent of the conditional, \ref{P:ab-and-dc:W:AR}, is in line with \AR{} --- the support the agent obtains for the conclusion of the reasoning that they are able to do is obtained from the support the agent has for having the attribute of being able to reason to the conclusion.
\end{note}

\begin{note}[Argument in brief]
  \mcA{} follows from \ref{either-AR-or-WR} and a further proposition:
  \begin{proposition}\label{mcA:WR-and-denied-claim}
    \WR{} is incompatible with~\uRa{}.
  \end{proposition}

  For,~\ref{P:ab-and-dc:W:ab} and~\ref{P:ab-and-dc:W:uRa}.
  Then, agent obtains support by~\ref{P:ab-and-dc:W:ab}.
  As \uRa{}, then from \ref{mcA:WR-and-denied-claim} not \WR{}.
  So, from~\ref{either-AR-or-WR}, must be \AR{}.
\end{note}

\begin{note}[To argument]
  {
    \color{red}
    We provided a brief argument for~\ref{either-AR-or-WR} in the previous section.
  }
  So, what follows is a brief argument for~\ref{mcA:WR-and-denied-claim}.
\end{note}

\begin{note}[Attribute]

  \WR{} is an instance of~\rC{}, as the agent obtains support for the conclusion of the reasoning is able to do on the basis of the reasoning that would be performed in a witnessing event.
  Hence, the supported obtained for the conclusion is obtained on the basis of the support the agent has for the premises that would be used.
  Again, this does not imply that the agent obtains support for the conclusion which is equivalent to the support the agent would obtain by witnessing their ability by performing the reasoning.

  However, \AR{} suggests an alternative way to obtain support for the conclusion of reasoning the agent is able to do.
  Specifically, if order for the agent to \emph{have} the attribute of being able to reason to the conclusion, the conclusion of the reasoning must be true.
  The relevant entailment is in part secured by the verb chosen, and in part by what the verb is applied to.
  Here, `demonstrate' is a factive verb, if an agent demonstrates that \(\phi\), then it is true that \(\phi\).
  And, the existence of a chess strategy does not depend on the agent demonstrating that the relevant strategy exists.

  To take another example, you only have the ability to identify a typo on this page if there is a typo on this page.
  So, if I were to provide you with testimony that you have the ability to identify a typo on this page, you may begin searching for the typo, or you may note that there must be a typo in order for me to be in a position to provide you with testimony that you have the ability.

  The reasoning is summarised with the following sketch.

  \begin{enumerate}[label=(\textsf{A}\arabic*), ref=(\textsf{A}\arabic*)]
  \item\label{WR:Sketch:1} I have the attribute of being able to \emph{V} that \(\phi\).
  \item\label{WR:Sketch:2} In order to have the attribute of being able to \emph{V} that \(\phi\), \(\phi\) must be the case independent of whether or not I witness the ability.
  \item\label{WR:Sketch:3} \(\phi\) is the case.
  \end{enumerate}

  To keep things simple, we will refer to the principle behind the pattern sketched as \AR{}.
  And agent may bundle~\ref{WR:Sketch:1} and~\ref{WR:Sketch:3} into a conditional, and avoid instantiating the reasoning pattern, but so long as the conditional is (implicitly) held on the basis of the intermediate premise~\ref{WR:Sketch:2}, we take use of such a conditional to be an instance of \AR{}.

  \AR{} is compatible with \uRa{}.
  For, the two premises~\ref{WR:Sketch:1} and~\ref{WR:Sketch:2} are accessible to the agent, and obtaining \ref{WR:Sketch:3} from~\ref{WR:Sketch:1} and~\ref{WR:Sketch:2} appears to be straightforwardly sound reasoning.
\end{note}

\begin{note}[Summarising]
  ???
\end{note}

\subsection{Conditional B}
\label{sec:second-conditional}

\begin{note}[Finding tension, still]
  We have outlined a type of scenario built primarily on an agent receiving information that the agent has some specific ability so long as the agent has some general ability.
  The agent has support for having the general ability, but there are two ways in which the agent's support for having the general ability may be used to establish support for {\color{red} the result of having the specific ability} --- \AR{} and \WR{}.

  The previous section argued that~\uRa{} constrains how an agent may use the received information.
  If an agent is required to traces support from premises to conclusion through reasoning, then an agent may not appeal to the support for the premises and steps of reasoning that the agent would use when witnessing the specific ability.
  {\color{red} This is summarised in~\ref{P:ab-and-dc:W}.}

  The (initial) plausibility of~\uRa{}, then, suggests that the agent may only establish support for having the {\color{red} result of the specific ability} from the support they have for the general ability by \AR{}:
  The support the agent has for the general ability is support that it is true that the agent has the general ability.
  In turn, given the information received it is true that the agent has the specific ability, and it is only possible for the agent to have the specific ability if the result of witnessing the specific ability is true.

  The argument of this section is that the sketch of \AR{} given conflicts with a different, but equally plausible, premise.
  The premise concerns the way in which the agent obtains support for having the specific ability from the support for the general ability.
  We state conditional, the proceed to the premise.
  The initial statement of the premise is abstract and after providing a handful of clarifications we then link the premise to the type of scenario of interest.
\end{note}

\begin{note}[Conditional B]
  \begin{proposition}[\mcB{}]
    \begin{enumerate}[label=(C\Alph*), ref=(C\Alph*)]
      \setcounter{enumi}{1}
    \item\label{P:ab-and-dc:A} If
      \begin{enumerate}[label=(\roman*), ref=(CB.\roman*)]
      \item\label{P:ab-and-dc:A:ab} an agent obtains support for some proposition \(\phi\) on the basis of the agent's ability to demonstrate that \(\phi\) is the case, and
      \item\label{P:ab-and-dc:A:ni} \nI{} is true,
      \end{enumerate}
      then
      \begin{enumerate}[label=(\roman*), ref=(CB.\roman*), resume]
      \item\label{P:ab-and-dc:A:AR} the support for \(\phi\) \emph{is not} claimed on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (in line with \AR{}).
      \end{enumerate}
    \end{enumerate}
  \end{proposition}

  Given \mcA{}, the immediate interest with \mcB{} is that~\ref{P:ab-and-dc:W:AR} and~\ref{P:ab-and-dc:W:AR} are incompatible.
  So, if both conditionals are true, then (at least) one of the antecedents from either conditional is false.

  \ref{P:ab-and-dc:A:ab} repeats~\ref{P:ab-and-dc:W:ab}, roughly \eA{}.
  Still,~\ref{P:ab-and-dc:A:ni} differs from~\ref{P:ab-and-dc:W:uRa}.
  \mcA{} assumed \uRa{}, principle we are proposing an exception for.
  \mcB{} assumes a principle, \nI{} to be argued for.
  Hence, if both \mcA{} and \mcB{} are true, either \eA{}, \mp{}, or \nI{} is false.

  Before turning to \nI{}, observe general picture.
  If \eA{} and \nI{}, then \uRa{} is false.
  Hence, argument against \uRa{}.
  Further, \ref{either-AR-or-WR} then \WR{}.
  Motivates \rC{}.
\end{note}

\begin{note}[Inertia]
  We now turn to \nI{}:
  \begin{proposition}[\nI{}]\label{prem:ni}
    An agent does not have the option of obtaining support for some proposition \(\psi\) from information that the support the agent has for the proposition that \(\phi\) is misleading if \(\psi\) is not the case.
  \end{proposition}

  \nI{} is about how the agent obtains support for some proposition \(\psi\) from some other proposition \(\phi\).
\end{note}

\begin{note}[Misleading, again]
  By the support that the agent has for some proposition being \emph{misleading} we mean that the support the agent has for \(\phi\) provides good reason for thinking that \(\phi\) is the case, even if \(\phi\) is not the case.\nolinebreak
  \footnote{
    Different from `mistaken', where \(\phi\) turns out to be true, but the support itself provides the wrong understanding of why \(\phi\) is true.

    Suspect that a variant of \nI{} holds for `mistaken'.
    However, `misleading' is sufficient.
  }
  For example, see someone entering a car by unlocking the drivers door with a coat-hanger.
  I take this to be good support for the proposition that the person is not the owner of the car.
  As it turns out, the person had accidentally locked their only set of keys in the car, and did not want to call a locksmith.
  The support for the proposition that the person is not the owner of the car was misleading, not only because the person owns the car, but because it continues to provide support even with the knowledge that the person is the owner.
  It would be clear to the owner why they would be stopped by a police officer, and why the owner is required to provide documentation to show that they are the owner (i.e.\ support to the contrary proposition).

  In this sense, the support is misleading.
  The support is `good', even though the proposition is false.

  `Misleading' support is distinct from an error made by the agent, such as taking the use of the coat-hanger to be support for the proposition that the someone had stolen the person's coat and locked the coat inside the car.\nolinebreak
  \footnote{
    No doubt there is additional background that could be added\dots
  }
  And, misleading support is distinct from `mistaken' in which an agent obtain support for some proposition which is true but where some part of the support is false.

  For example, person using the coat-hanger looks like the owner, but the car had recently been sold.
  In contrast to error, there seems no problem with the agent holding a positive attitude toward the proposition given mistaken and misleading support, the relevant difference is whether the proposition does hold.

  Intuitively, then, the trouble with misleading support is that it suggests, but does not ensure that the proposition holds.

  Misleading support, then, is not problematic.
\end{note}

\begin{note}[For \nI{}]
  However, the role of mistaken support in premise~\nI{} does lead to a problem.

  For, suppose an agent has information that support for \(\phi\) is misleading if \(\psi\) is not the case.
  Then, \(\phi\) is not the case if \(\psi\) is not the case.
  Hence, agent is relying on \(\phi\) holding, given support.
  Agent is not appealing to information that the support they have for \(\phi\) extends to \(\psi\) even if \(\psi\) also turns out to be false.
  So, it may be that the agent does not have support for \(\psi\).

  In short, focus on misleading support because the possibility of \(\phi\) not holding suggests that agent does not have the option of obtaining support for \(\psi\) only on the basis that \(\psi\) must hold if \(\phi\) holds, because the support the agent may have for \(\phi\) holding may be misleading (in part) because \(\psi\) does not hold, and hence \(\phi\) does not hold.

  An alternative characterisation is that the agent requires \(\phi\) to hold in order for \(\psi\) to hold, rather than extending support for \(\phi\) to \(\psi\).
  Spin provides something positive, but it's easier to be right about what's wrong, and it's not clear to me that support is so restrictive.
\end{note}


\begin{note}[Applying to scenario]
  With respect to the type scenario:

  \begin{enumerate}[label=\nI{}, ref=\nI{}]
  \item An agent does not have the option of obtaining support for having a specific ability from information that the support the agent has for having the general ability is misleading if it is not the case that the agent has the specific ability.
  \end{enumerate}

  \nI{} combines with a minor proposition.

  \begin{proposition}[\nIm{}]
    If an agent wishes to claim support for the consequent of an entailment in by virtue of the entailment, then the agent must have claimed support for the antecedent of the entailment.
  \end{proposition}
  \nIm{} seems indisputable.
  An agent may have some other way of claiming support for the consequent of the entailment.
  However, if the agent is not in a position to claim support for the antecedent, then the agent is not in a position to claim support because there is an entailment from the antecedent to the consequent.

  For example, that the coin landed heads is entailed by Sam knowing that the coin landed heads.
  However, Taylor is not in a position to claim support for the coin landed heads because Sam knows if Taylor has no idea whether Sam knows --- though Taylor may claim support by looking at the coin.

  \nI{} and \nIm{} combine:

  \begin{proposition}[\nIp{}]
    An agent does not have the option of claiming support for some proposition \(\xi\) from observing that \(\psi\) entails \(\xi\) and information that the support the agent claims for \(\phi\) is misleading if \(\psi\) is not the case.
  \end{proposition}

  With respect to scenarios of interest.
    \(\phi = \) general ability.
    \(\psi = \) specific ability.
    \(\xi = \) strategy exists.

    So, application of \nI{} (and \nIm{}) is that the agent does not have option of obtaining support for specific ability from information that the support they have for general ability is misleading if the agent does not have the specific ability.

    Stated independently, \nIp{} is a weaker proposition than \nI{} and \nIm{}.\nolinebreak
    \footnote{
      as \nIp{} makes no statement about whether the agent may claim support for \(\psi\) (though \nI{} does).

      From \nI{}, the agent does not get support for \(\psi\), and by \nIm{} agent requires support for \(\psi\) to get support for \(\xi\), and hence does not obtain support for \(\xi\).

    Still, as it is the result of interest, some room to pursue the present line of argument if either \nI{} or \nIm{} is rejected.
    }
    Suspect that any argument from \nIp{} follows from motivation for \nI{} and \nIm{}.

  If \nI{} (and \nIm{}) hold, then trouble if support for specific ability comes from general being misleading if general is not the case.
\end{note}

\begin{note}[A little more on \nI{}]
  Need \nIp{} but focus is on \nI{} to motivate \nIp{}.
  And, take \nIm{} as given.
  So, speak of \nI{} rather than \nIp{}, as \nI{} does the work.

  Begin with a broad characterisation of core idea, and then develop.
\end{note}

\begin{note}[Why this matters for \AR{}]
  Rough characterisation in hand, see how this matters for \AR{}.

  Focus is on the ??? step.
  Would not have general ability if not specific.

  Requires truth of general ability.
  Hence, fits in.

  Clarify a little more, then expand on this point in more detail.
\end{note}

\begin{note}[Relation to transmission]
  Here, difference to failure of transmission.
  In those cases, agent knows, hence \(\phi\) not being true is not much of an issue.
  In turn, \(\psi\).

  For us, \(\phi\) may be false.

  Whether there is a proper distinction, though, isn't quite so easy.
  Dogmatism gets thrown into the mix.
\end{note}


\begin{note}[Motivation in more detail]
  Question for scenarios of interest is why this is relevant.

  Focus on \AR{} and finial step.
  \begin{itemize}
  \item Have specific ability only if strategy exists.
  \end{itemize}
  Here, agent is appealing to entailment.
  This, then, requires the agent to have support for having the specific ability.

  It is not (`merely') the case that the agent would do some reasoning that leads them to conclusion.
  Agent may do reasoning and have support for premise even if they are misleading.

  Rather, because the agent is appealing to having ability, needs to be the case that it is true that they have the ability.

  
  Intuitive difference.
  In \AR{} case, the agent is relying on truth and entailment.
  If agent were to reason, the agent would be relying on support from premises and steps extending.

  Difference between appealing to having ability, and to instance of ability.

  Simple example.
  I am misleading, but I have the ability to demonstrate that \(\psi\) --- so support for \(\psi\).
  I am misleading, but this my demonstration of \(\psi\) --- so support for \(\psi\).

  First, misleading about being able to demonstrate that \(\psi\), so blocks what follows from ability by entailment, though the agent still retains some support for having the ability.
  Second, have shown how support extends, therefore granting there is a mistake, still retain support for \(\phi\).

  Distinction between appealing to \(\phi\) in order to get \(\psi\) and extending the support one has for \(\phi\) to \(\psi\).

  In turn, loops back to understanding of \nI{}.
  For, \nI{} doesn't extend support.
\end{note}


\begin{note}[Motivation: examples]
  Handful of examples from literature on failure of transmission.

  Don't need to hold that these are cases of transmission failure.
  Agent may get support.
  However, agent does not get support by denying~\nI{}.

  In part, the distinction above helps understand.
  The agent does not get that it's not a cleverly disguised mule from vision.
  Rather, it's the fact that the agent is seeing, and what follows from this.

  {
    \color{red}
    Here note important point that~\nI{} does not prevent the agent from obtaining support.
  }

  However, our interest in~\nI{}.
  Information.
  Hence, the agent may be in a position to claim support for \(\phi\), and the information need not be something that the agent is in a position to identify by themselves.

  ``If that's a zebra and that's a ?, then you're in a position to distinguish species X from species Y.''

  As above, may be that the agent obtains support, but not via denying~\nI{}.
\end{note}

\begin{note}[Distinguishing features]
  Reasoning has distinguishing features that pair well.
  \begin{itemize}
  \item Extends support.
  \end{itemize}
\end{note}

\begin{note}[Positive idea of support?]
  The key idea is that in order for support to go through, the agent needs extend the support the agent has for \(\phi\) is also support for \(\psi\).

  {
    \color{red}
    A different way of putting things is that \(\phi\) does not inherit support from \(\psi\).
    So, \(\phi\) may be supported, but no support is added.
  }


  {
    \color{green}
    Motivation here is that because (specific) ability would be application of general, this is a potential (and quite direct) counterexample --- assume that the agent receives testimony.
  }


  {
    \color{red}
    The agent may obtain support for \(\phi\) from some other premise.
  }

  I consider~\nI{} to be intuitive.
  However, argument may be provided.
\end{note}

\begin{note}[~\nI{} and \AR{}]
  Why, then, does \AR{} seem to require a violation of~\nI{}?

  First, need the conditions to match up.
  This is somewhat simple.

  The agent would be applying general ability.
  Therefore, if the agent does not have the specific ability, then something has gone with the support the agent has for the general.
  This is explicitly stated.
  Important, because do not hold the stronger position that there's a broad general to specific entailment.
  Some things may follow from rules of chess, but go beyond agent's ability, but be within some other agent's ability.
  More than simply understanding the rules.

  \AR{} fits in.
  Novel information --- no other resources for conclusion, so the agent is required to use the general ability as a premise.
  Premise is that the agent has the attribute of being able to \dots.
  Conclusion is that the agent has attribute of being able to\dots.

  So, one attribute from another.
  `Extends' type of support relation.
  However, agent isn't appealing to how support extends.
  There's no additional reasoning, other than the conditional.

  Observe that this is not compatible with the agent holding that they may be misleading.
  Support for general ability may be misleading, but given support, then this extends to specific ability.
  ? This seems bad.

  Contrast to.
  Support for general ability may be misleading, but given support and information, then reasoning I have support for extends to conclusion.
  Agent is not relying on support for general ability to provide support for specific ability.
  Instead, agent is appealing to support may appeal to as a use of the general ability.

  Compare with simple cases.
  


  Misleading on the first may involve no support for \(\phi\).
  Misleading on the second is mistake in use of support in demonstrating \(\phi\).
  {
    \color{green}
    Well, with the first, it's getting to \(\phi\).
    Doesn't seem the agent is in a position to use factive inference.
    Because, the agent is going from not possible to have ability and for \(\phi\) to be false.

    \textbf{
      This is the part I'm missing.
      It's the use of this particular inference that really characterises \AR{}.
      It's possible for appeal to attribute without this inference, but that doesn't matter to me.
    }

    With the second, different.
    Because, the agent is going from application of ability providing support for \(\phi\).
  }

  {
    \color{red}
    This is in contrast to \WR{}, where the agent may hold that they may be misleading, but the reasoning extends.
    Hence, may be misleading, but given the support I have, support for conclusion.
    Lack an account of how reasoning extends.
  }
\end{note}

\begin{note}[A little hyperbole]
  The use of \AR{} is a little hyperbolic.
  For, have not provided an argument that there's no way for reasoning via attributes to avoid~\nI{}.
  It's the other way round.
  And, that it's not clear that there's no other interpretation.
\end{note}

\begin{note}[Indirect]
  The really important idea is that in the cases of interest, if the agent goes from general ability, then it's \emph{indirect}.
  The agent is not using their general ability.
  Rather, the agent is relying on having the general ability.

  Further, the consequent is a potential counterexample.
  This is what really distinguishes things, I think.

  The idea, then, is that if \(\psi\) is not the case, then the agent has an counterexample to \(\phi\).
  Hence, as the agent doesn't `do' anything to show that \(\psi\) is the case, they can't simply transmit support for \(\phi\) to \(\psi\).
\end{note}

\begin{note}[More than indirect]
  Example.
  If not in London, then in Paris.

  This is a `is-also' support.
  Conditional states that support for not in London is also support for Paris.
  Does the agent obtain support for Paris on the basis that the support for not London is misleading if Paris is not the case?
  Well, would not show that the \emph{support} is misleading.
  Because, the conditional establishes something that doesn't follow from the antecedent without information.

  By contrast, the general-to-specific is such that the support the agent has for general must also extend to specific.

  So, not London to Paris has this `is-also' understanding.
  If not in Paris, then it seems the agent is still going to have support for not in London.
  Puzzle here is contraposition.
  For, it follows that if not in Paris then in London.
  However, this is not so obvious.
  May give up conditional.

  This contraposition observation is a really clear difference.
  For, contraposition does hold in the general-to-specific case.
  If agent doesn't have specific, then doesn't have general.
\end{note}


\begin{note}[`includes']
  General to specific is an `includes' conditional.
  If support for general, then extends to specific.
  Key idea here is that general and specific reduce down to similar things.

  So, the additional component of interest is that the agent should be, in some sense, committed to have support for any specific instance of general ability.
  Something like \(\forall S(G \rightarrow S)\).
  However, there's something puzzling about this.
  Because, the agent has no idea what those applications are.

  \nI{} suggests.
  For, agent would be relying on support for general not being misleading, and a specific may show that it is.


  
  So, it seems this doesn't provide the agent with support.
  So, something about support from some subset extending to other elements of set.

  Gives an intuitive example.
  Picking balls out of a bag.
  Well, it's the case that all the balls are red, otherwise I've picked out a non-representative sample.
  Quite possible that this is the case.
  Agent doesn't get support for next being red.
  Though, agent has support for a probability distribution.

  This really goes back to the idea that the agent has no idea whether the support they have will be shown to be misleading.

  If so, the LP example isn't so clear cut.
  For, if the agent's got enough support that wouldn't be shown to be misleading, the use of conditional goes through.
  Further support added, but what they have remains robust.
  Right, this seems correct.

  Same for balls in a bag.
  It's possible that the next ball revises the probability distribution, if the agent isn't aware of what's going on in the bag.
  No, this doesn't quite work.
  It only really works if the agent makes an assumption about the colours or something of the kind.
  See this would be a bad assumption to make, because the next ball would show the assumption to be misleading.

  Hence, because specific would be an application of general, then failure of specific would show that there's something wrong with general.
\end{note}

\begin{note}[\WR{} and \AR{}]
  Role of~\nI{} should be clearest with the difference between \AR{} and \WR{}.

  With \AR{}, the agent appeals to support they have for general ability.
  This support, we assume, is accessible to the agent.
  And, the difficulty is that the agent would find that some support is misleading if they don't have the general ability.
  The issue with~\nI{} is that the agent appeals to support for general ability, not the support for items of application of general ability.

  One way to look at this is in terms of whether the agent has the ability.
  For, with \AR{}, this seems to be how things go.
  Support for general ability, therefore one has the general ability, and so one has the specific ability, and hence one has support for specific ability.
  So, projection of belief.

  Another perspective is that the agent is not \emph{applying} general ability in order for specific ability.
  Which, is roughly what is meant by `indirectness'.
  There should be something here, as this really is the core difference between the two approaches.
  For, with \WR{}, then, the agent traces support through reasoning\dots
  Relying on the support that application provides for conclusion.
  Not, that there's something wrong if the agent doesn't get support for conclusion.
  And this ties in with the useful point.
  If lack, then the support is misleading.
  However, from agent's perspective, they've extended support from premises to conclusion, and have not relied on indirect claim that this can be done.
  Of course, the agent doesn't have access, and hence conflict with~\uRa{}.

  With \WR{} the agent relies on information, needs to be true that they may witness.
  Agent does not require support for this.
  Rather, it is true, and then support builds throughout the process.


  With \WR{}, the agent applies support as they would in reasoning.
  So, the agent is not appealing to support for general ability, but support general ability provides for premises and steps of reasoning.
  The difficult, and conflict with~\uRa{} is that the agent does not have access to what they are claiming support for.
  However, support functions the same way as if the agent were to witness the reasoning.

  Return to the idea of projection of belief.
  With \WR{}, the agent does not project belief.
  For, agent `witnesses' \dots but this is difficult, because agent still relies on information for \(W\) attitude.
  


  A useful point is that the support being misleading if the agent lacks the specific ability does not mean that the agent is obtaining support for specific ability on the basis that the support for the general ability is not misleading.

  This useful point is clearest to see when considering an instance of reasoning.
  
\end{note}

\begin{note}[Overview]
  From explanation:
  \begin{itemize}
  \item Indirect/\AR{} is bad.
  \item Reasoning would be fine.
  \item \WR{} mirrors reasoning for the most part.
  \item Information isn't used to transfer support, but provides structure for \WR{}.
  \end{itemize}
  
\end{note}

\begin{note}[Important points]
  Two important points:

  The role of~\nI{} is to highlight that the agent is not in a position to obtain support for (specific) ability in a certain way.
  That is,~\nI{} does not state that the agent may not obtain support for (specific) ability some other way.

  Second, some long as agent holds that they have general ability, then committed to truth.
  The \gen{} may be taken as testimony.
  So, either one or the other.
  A kind of transmission failure.
  Distinct from case of knowledge, as no factivity.
  In part, role of informer.

  May be tempted to say that the agent is not committed, but this seems implausible.
  Cases of transmission failure, it seems agent does remain committed, at least.

  May take issue with information provided, especially if ideal.
  If informer has information, then they should say.
  In turn, not problem with~\nI{} as the agent would have support (via testimony) for specific ability.
  However, informer may only have the conditional.

  Ordinary agents.
  Maxims are broken.
  And, interest effects.
  Up to the agent.

  Seems puzzling, but not paradoxical.
\end{note}

\begin{note}[Why this is important]
  The key idea, and the foundation of the objection, is that the agent is going indirectly.
  The agent is \emph{not} showing how the general ability extends to specific ability.
  For, the only things available to the agent is the constraint.

  This is useful independently.
  For, even if not convinced by~\nI{}, clear that given \gsi{} and~\uRa{}, the agent goes directly.
  And, something a little puzzling about this.
  Or, so I think.
\end{note}

\begin{note}[Aside]
  I don't see this as too different from simply stating that general ability extends.
  That is, the sort of \gsi{} is what is actually communicated in most cases of this kind.
  However, nothing rests on this.
\end{note}

\begin{note}[Dogmatism]
  Continuing relation to issues with knowledge.
  \autoref{prem:ni} is quite close to dogmatism paradox.
  If one knows that \(\phi\), then any evidence for \(\lnot \phi\) is misleading.

  Distinct again, however.
  For, don't have knowledge in the antecedent.
  Get the dogmatism paradox from the factivity of knowledge.
  No requirement that support for (general) ability is factive.

  Hence, role of the informer is important again, because agent is not in a position to come to the conditional by themselves prior to reasoning.
\end{note}


\begin{note}[Requires some care]
  \nI{} requires a little care.
  It is a constraint on whether the agent has the option of obtaining support.
  It does not constrain whether the agent is able to make use of the information in other ways.

  Useful example may be commitment.
  For example, committed to \(\psi\), but no support.

  In particular, support for \(\lnot\psi\) seems difficult.
  The agent doesn't have the option of obtaining support for \(\psi\).
  However, it seems that with the information there is some resistance to support for \(\lnot\psi\).

  This point will be important later.
\end{note}

\begin{note}[Inertia and attribution]
  \nI{} raises a problem for applying \AR{} to the specific ability of scenarios described by~\eA{}.

  For, the agent is required to obtain specific ability from general ability.
  \begin{enumerate}
  \item Agent has support for the general ability to reason with the rules of chess.
  \item However, the agent has not demonstrated the existence of the strategy, and so the agent relies on the information provided by the informer to hold that they have the specific ability to demonstrate the existence of the strategy.
  \item Still, the informer provided by the informer requires the agent to endorse having the general ability to reason with the rules of chess.
  \item In turn, that whatever support the agent has for having the general ability to reason with the rules of chess is not misleading.
  \item For, it may be the case that the agent does not have the ability to demonstrate the existence of the particular strategy.
  \item Therefore, the agent does not obtain support for the ability to demonstrate the existence of the strategy.
  \item Hence, it is not an option for the agent to obtain support for the existence of the strategy on the basis of support for the ability to demonstrate the strategy in line with \AR{}
  \end{enumerate}
\end{note}



\begin{note}[Established conditional 2]
  Something about, if \eA{} then agent does not obtain support for the attribute.
\end{note}

\subsection{Establishing tension/summary}
\label{sec:establishing-tension}

\begin{note}[Summary]
  Given the two established conditionals~\ref{P:ab-and-dc:W} and~\ref{P:ab-and-dc:A}, the combination of the key premises of \uRa{},~\eA{}, and~\nI{} are in tension.

  For, combining~\ref{P:ab-and-dc:W} and~\ref{P:ab-and-dc:A} we have:
  \begin{enumerate}[label=(CC), ref=(CC)]
  \item If \eA{} is the case an agent obtains support for some proposition \(\phi\) on the basis of the agent's ability to demonstrate that \(\phi\) is the case then:
    \begin{enumerate}[label=(C\arabic*\(\sim\)), ]
    \item If \uRa{} is true, then the support for \(\phi\) is obtained on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (in line with \AR{}).
    \item If \nI{} is true, then the support for \(\phi\) \emph{may not be} obtained (in line with \AR{}) on the basis of the agent having the attribute of being able to demonstrate that \(\phi\).
    \end{enumerate}
  \end{enumerate}
  In short, if~\eA{} is the case then~\uRa{} requires a certain interpretation of the scenarios identified by~\eA{} and~\nI{} denies that the interpretation is plausible.
\end{note}

\begin{note}[Tension, choices]
  The combination of~\ref{P:ab-and-dc:W} and~\ref{P:ab-and-dc:A} is complex.
  However, the basic structure is straightforward:
  \[\eA{} \rightarrow ((\uRa{} \rightarrow \AR{}) \land (\nI{} \rightarrow \lnot \AR{}))\]
  Rewriting:
  \[\eA{} \rightarrow ((\lnot \AR{} \rightarrow \lnot \uRa{}) \land (\AR{} \rightarrow \lnot \nI{}))\]
  Hence:
    \[\eA{} \rightarrow ((\WR{} \rightarrow \lnot \uRa{}) \land (\AR{} \rightarrow \lnot \nI{}))\]
  Simplifying:
  \[\eA{} \rightarrow ((\WR{} \land \lnot \uRa{}) \lor (\AR{} \land \lnot \nI{}))\]
  A reformulating as a distinction:
  \[\lnot \eA{} \lor (\WR{} \land \lnot \uRa{}) \lor (\AR{} \land\lnot \nI{})\]

  In short, we have the following resolutions.
  \begin{enumerate}
  \item\label{ten:res:nS} Agent may not obtain support for result of witnessing ability, or
  \item\label{ten:res:nD} Agent obtains support for result on the basis on premises that the agent would use when witnessing ability --- incompatible with general application of~\uRa{}
  \item\label{ten:res:nI} Agent obtains support for result from attribute of having the ability on the basis that the support they have for general ability would be misleading --- incompatible with general application of~\nI{}
  \end{enumerate}
  \ref{ten:res:nS} is incompatible with~\ref{ten:res:nD} and~\ref{ten:res:nI}.
  However, \ref{ten:res:nI} and~\ref{ten:res:nD} are compatible, as both~\uRa{} and~\nI{} may be restricted.
\end{note}

\begin{note}[Argument sketch recap]
  Let us recap the main points of the argument so far.
  \begin{enumerate}
  \item Assume possibility of cases in which agent is provided with information that they have some specific ability so long as the agent has a general ability, such that the agent has support for having the general ability, but has not established support for possessing the specific ability.
  \item In such cases, it seems it is possible for the agent to obtain support for what follows from the agent witnessing their specific ability.
  \item If so, the agent appeals to having the specific ability in order to obtain support for what follows from the agent witnessing their specific ability.
  \item Attribution, and witnessing.
  \item If witnessing, then conflict with the requirement that an agent must access support for the premises appealed to in support of a conclusion.
  \item If attribution, then conflict with the restriction that an agent may not obtain support for some proposition on the basis that support the agent has for some other proposition would be misleading otherwise.
  \end{enumerate}

  To follow:
  \begin{enumerate}
  \item Restricting~\uRa{} in favour of~\rC{} works well.
  \end{enumerate}
\end{note}

\begin{note}[Meek outlook]
  This is not a clean argument.
  Take~\uRa{} and~\nI{} and hold the first.
  The agent may not obtain support.

  While there may be tension if the agent obtains support, this tension is never instantiated.

  I am sympathetic.

  Still, endorsing the restriction does not require the agent to obtain support in this case.
  Harbour some hope that that there is scope to restrict \uRa{}, and that the argument provided for resolving tension in favour of \rC{}, along with later arguments, may serve as a source for reflection.
\end{note}

\section{Positive argumnet overview}
\label{sec:posit-argumn-overv}

\subsection{Cases}
\label{sec:cases}

\begin{note}
  Main role of positive argument is cases.
\end{note}

\begin{note}[Beyond belief]
  Application in particular to desire.
\end{note}