%%% Local Variables:
%%% TeX-master: "master"
%%% End:

\chapter{Overview}
\label{cha:overview}

\section{Ability and access to support}
\label{sec:abil-access-supp}

\begin{note}[Introducing main topic]
  Our interest is in when an agent may claim support for some conclusion of some instance of reasoning on the basis of the support the agent may claim for the premises of the instances of reasoning.

  Consider:
  \begin{proposition}[\bP{-} --- \bP{}]\label{prem:bP}
    If an agent may claim support for premises and steps of reasoning, accesses those premises and traces support through those steps of reasoning, then agent may claim support for conclusion on basis of the claimed support for the steps and premises of reasoning.
  \end{proposition}

  \bP{} is about when an agent may claim support for a conclusions of reasoning from premises, steps used.
  We take~\bP{} as basic.
  {
    \color{red}
    Some notes on intuition.
  }

  For example, suppose an agent measures that the box in front of them has the dimensions of \(19\text{cm}\) by \(7\text{cm}\).
  The agent understands how to calculate the area of a box, and by performing some reasoning comes to hold that the area of the box is \(133\text{cm}^{2}\).
  The support the agent has for holding that the area of the box is \(133\text{cm}^{2}\) is obtained (at least in part) on the measurement of box, understanding how to calculate the area of box, and some grasp of arithmetic.

  {
    May say that the support the agent claims for the box depends on \dots if the agent were to discover they were mistaken about support (e.g.\ an inaccurate ruler) then the agent would not be in a position to claim support.
  }

  (Whether some (or all) of the required arithmetic is to be included as a premise or a step of reasoning may be set aside.)
\end{note}

\begin{note}[Support]
  The purpose of taking~\bP{} as basic is to fix a basic understanding of when an agent may claim support in core instances of reasoning.
  As~\bP{} is quite terse, let us provide some detail on how `support' is understood before continuing.

  {
    \color{red}
    Talking of `claiming support', maybe suggest that this is between `propositional' and `doxastic' support.
    However, even this isn't quite right, as both require the agent to have support.
  }
\end{note}

\begin{note}[Support]
  A general statement of support and claiming support is difficult.
  Instead, sketch an understanding of the role of support, and motivate a distinction between support and claiming support.

  Valid, but this only captures when premises are true and conclusion is true.
  Support that some proposition is false.

  There's some designated value, e.g.\ truth or desirability, and reasoning keeps appropriate value.

  In a deductive case, if the premises are true, then the conclusion is true.
  Means-end reasoning for desire.
  The value is important.
  If it is true that it past 6pm, then it is true the shop is closed.
  Provides designated value of shop being closed.

  However, if agent desires that it is past 6pm, then it doesn't follow that the agent desires that the shop is closed.
  Question an agent as to why they think their desires conform to truth --- is-ought problem.

  So, propositions and designated values.
  proposition has some instance of the value.
  Question is what the value is.
  Provides support when information contributes to fixing designated value.
  So, contributes to true rather than false, for example.
  Support for proposition, consider all the support provided.
  Truth as default, so speak of support, other cases specified, e.g.\ desirable or probable.

  Claiming is then that information does provide support.
  Claim for proposition is understood in the same way.

  So, independent of agent doing the reasoning, doesn't seem like too much of a big deal.

  Instead, for {may} claim support, subjectively sound.
  In the sense that for each premise or step of reasoning used, the agent has claimed support for the premise or step and does not have superior support for a conflicting premise or step.\nolinebreak
  \footnote{
    Might be read in normative terms as the agent being `blameless', but I don't think this is quite right.
    Seems there are cases in which an agent may be blameless for not performing reasoning that they were capable of doing.
    For example, native speaker and non-native speaker, both have good understanding of the other's language and customs.
    Non-native says something particularly charming, native speaker is blameless for being quite charmed, though with some reasoning they would have realised that the intention of the non-native speaker was to express something plainly factual.
  }
  Here, this is very unrestricted.
  Agent starts by mistakenly claiming support, then may claim support and then may claim support for seemingly any proposition.
  Well, understanding of claiming is only for the result of reasoning.
  May place restrictions on claiming support for propositions that are not the result of reasoning.

  Example.
  Teacher, so claim support for something.
  Use this.
  Fine for the agent to claim support, does not entail that the agent has support.

  Two important things, both of which will be used.
  Misleading.
  Mistakes.
\end{note}


\begin{note}[Misleading]
  \emph{Misleading}.
  For, fixes designated value, but still room for variance.
  Hence, support claimed may be misleading.
  And agent may be mistaken in claiming support, though support is not mistaken.

  If mistaken, then requirements on when an agent may claim support.
  Even so, keeping the appropriate instance of designated value is quite restrictive, as relies on fixing the designated value.
  However this is for support, rather than claiming support.
\end{note}


\begin{note}[Mistaken]
  \emph{Mistake} --- relies on distinction between support and claiming support.
  An agent may be mistaken about support they have.
  Intuitive case, diary entry, speeding ticket.
  Entry was actually from previous year, and bug in the software.
  Agent didn't really have support, but was fine to claim as support.
  It's not the case that the diary continues to provide support, which is overshadowed by the discovery of the software bug and/or the CCTV footage.

  One may hold that the agent still has support as it was a bug.
  If redo as a mistake made by the agent by not checking the year, then agent isn't in a position to claim support.
  Generalising, not possible claim support and be mistaken.
  So, any `proper' claim of support is having support.

  So, significant assumption is that mistakes are possible but do not prevent agent from claiming support.
  Compatible with a directive to fix mistakes.

  Simple example, classical and intuitionist mathematicians.
  Each may deny that the other obtains support, but clear that each is in a position to claim support for conflicting theorems.

  \begin{note}[M \& M]
    If agent claims support for some proposition, then from the perspective of the agent, the support claimed is neither misleading nor mistaken.
  \end{note}

  Key thing about this proposition is that it's somewhat weak.
  It does not state the support claimed is not misleading or mistaken.
  Possibility of receiving information that would lead to some revision.

  From this an important corollary.
  Claiming support is independent from how things actually are.

  \begin{proposition}[\eiS{-} --- \eiS{}]\label{prop:supp:independence}
    If agent claims support for some proposition, \(\phi\), then the support claimed indicates value of \(\phi\) independent the value of \(\phi\) or support relations.\nolinebreak
    \footnote{
      \emph{Not}, were the agent to learn that \(\phi\) does not have value.
      Then, misleading, so no claim to support.
      In turn, no possibility of misleading support.

      Possibly goes against externalism, but I don't think this is right.
      External circumstances may impact the support the agent has.
      However, as these are external, it seems this condition plausibly holds for \emph{claiming} support.
      This is how you get puzzles for externalism.
      In both cases, it's fine for the agent to claim support, but the external circumstances impact whether the agent \emph{has} support.
      The internalist/externalist divide would seem to affect the conditions on claiming.

      Way to expand on this is reconstructing bootstrapping examples with and without \eiS{}.
      If the agent would only get basic support if reliable, then it's not clear that bootstrapping is a problem.
    }\nolinebreak
    \footnote{
      One way independence.
      Not clear that value is independent of support.
      So long as sufficiently strong support, not possible for proposition to have value other than claimed support.
    }
  \end{proposition}

  No link to attitudes.
\end{note}

\begin{note}[The `Even if\dots' test]
  Basic idea of support, and two ways in which support may be flawed.
  Use these two types of flaw to illustrate understanding of support by introducing a test.
  The \eit{}.

  Even if support claimed for proposition is [], something.

  Interest is in support claimed, not support agent has.
  The \eit{} highlights how support claimed is robust against whether the support claimed is flawed, and so falls short of securing value of proposition.
\end{note}


\begin{note}[Even if: misled]
  \eit{misled}

  Sunday afternoon: Even if not sleeping, eyes have been closed for a long time and breathing is slow.

  Even if it is a forgery, it seems impossible to detect any thing that would suggest so.

  Even if you're telling the truth, the scientific consensus is against you.

  Another for misled is the preface paradox.


  Fault:
  Even if not trustworthy, told me that they are.
  So, here, if support claimed is on testimony, then things don't look too good.

  Here, variation with `two people'.
  Then, discovering co-reference would lead to a revision to claimed support.
\end{note}

\begin{note}[Even if: mistaken]
  \eit{mistaken}

  Idea here is that support claimed is robust against having made mistakes.
  So, it should be the case that I can take any instance of good support, and highlight some possible mistake, and argue against this.
  The difficulty, of course, is that may be good support because it avoids possibility of being mistaken, so not so clear.

  Even if fake wound, support for calling ambulance.
  In a sense, the person got lucky, fake would and real wound.


  Newspaper may have quoted the wrong person.
  So, it would be a mistake to take word of person to support proposition.
  Even if one is mistaken, newspaper is proofread and checked, etc.
  So, there is no problem with claiming support from person and quote in newspaper.

  Recognise that this would be a problem, but it doesn't block claiming support.

  Fault:
  Even if it's not the second hand that's broken \dots still time.
  Bad, it may be the time stated on the clock, but a broken clock is a bad guide to the time.

  Relative to agent, may not have given attention to second hand, highlighting this would then lead to revision of support.
\end{note}

\begin{note}[Even if: revision]
  In each of the cases, were the agent to learn, then they would not claim support.
\end{note}

\begin{note}[Even if: more]
  Primary observation from these examples is that claiming support is robust against being misled and being mistaken.
  So, key idea here is that something to be said apart from value, and whether premises cited really do support.

  Test is for single propositions.
  And, examples given have been single propositions.

  Silent on whether or not the agent is in a position to claim support for each of the test conditions holding.

  Cases of entailment, preface paradox.
  Mistake somewhere.
  Here, support is good for each of the claims made in the preface, but these do not combine to make a case that no mistake has been made across any of the claims.
  May come down to familiar concerns, too significant possibility of being misled.
  May also think that support claimed for each might require a mistake in one.
  I.e. source for claim includes further claims which state that source for some other claim is mistaken.
  Problem with using both sources, even if for distinct propositions.

  Interesting problem later.
  For now, simple example.


  {
    This goes with \eit{}.

    To illustrate, consider a smoke detector, designed to sound an alarm if and only if sufficient levels of smoke are detected.
    Hence, if the alarm sounds, one may claim support there being smoke in the room where the alarm is installed.
    One may be misled; the alarm may have Malfunctioned.
    Or, one may be mistaken; the same type of alarm may be installed in a different room.

    Suppose the alarm sounds, and support is claimed for there being smoke in the room on the basis of the alarm sounding.
    It doesn't matter that that there may not be smoke in the room.

    Even if there is no smoke in the room, alarm sounding suggests that there is.
  }

  \emph{Subjective} test.
  Relative to information the agent has.
  Different information goes on to change support.
  Possibility in many cases that support is either misleading or mistaken.
  Key issue is that the agent needs something more.

  Point of these tests is not to argue that support passes every instance, right.
  Idea is that there's going to be some.

  Ah, so important point here is that in these cases, it doesn't follow that the agent is getting support for the problematic instance.
  Rather, the observation is that from the agent's perspective these do not impact claiming support.
\end{note}

\begin{note}[Adequate reasoning]
  Term this \emph{adequate} reasoning.
  May be good, may involve mistakes, may be bad.
  Kind of reasoning that we, the folk, do.
  Distinction for claiming support is that this is different from whether the agent has support, and we may set issues about whether the agent has support.

  Our interest is what is required for an agent to \emph{claim} support for (premises and) steps of reasoning, rather than what is required for an agent to \emph{have} support for (premises and) steps of reasoning.

  Use support as opposed to justification.
  Initial focus is on epistemic/doxastic attitudes.
  However, practical reasoning.
  For example, means-end.
  Support considered quite general to also include this.
\end{note}

\begin{note}[Closing support]
  To summarise, claim of support.
  Certain kind of independence.
  Only interested in support, and not how this relates to attitudes.
  Somewhat intuitive, but no claims that this is the only understanding of support.

  For the moment, this provides clarity for understanding of support.
  Below, use to argue for failure to claim support.
\end{note}

\begin{note}[Focus]
  Consider the converse of~\bP{}:

  \begin{proposition}[\uRa{-} --- \uRa{}]\label{denied-claim}
    An agent may claim support for conclusion on basis of support the agent has for premises only if \emph{some} agent has accessed support they have for premises and traces implication through (at least) adequate reasoning.
  \end{proposition}

  \uRa{} seems quite plausible.\nolinebreak
  \footnote{
    Three brief notes on~\uRa{}:

    First, the `has' in~\uRa{} only requires `at some point in the past'.
    Hence,~\uRa{} does not require the agent to reason from premises to conclusion each time the agent claims support for the conclusion.
    For example, if an agent proved the Deduction Theorem for propositional logic last week, then the agent would not be in conflict with~\uRa{} if they claimed support for the Deduction Theorem on the basis of the premises and reasoning they performed in the past.

    Second, and following from the first, the against~\uRa{} will also hold for any stronger statement --- for example if `has' is read as `has just'.
    For example, requiring that the agent's memory of proving the Deduction Theorem allows the agent to claim support, rather than the premises and steps used in the past.
    The argument (stated below) denies that, given certain information, the agent needs witnesses any reasoning in order to claim support for the result of witnessing the reasoning.

    Third, as~\uRa{} is about when an agent may \emph{claim} support, it is compatible with~\uRa{} to hold that the agent \emph{has} support --- regardless of whether the agent has witnessing the reasoning.
  }

  \uRa{} might not be obvious, for \emph{some} agent rather than \emph{the} agent.
  Stronger implies \uRa{}, so this isn't too much of a problem.
  Might want to go for the weaker if there's something social.
  Here, additional conditions, but our interest with \uRa{} is as a necessary condition.

  Start with stronger example.

  If the agent did not measure the box, understand how to calculate the area of a box, or perform the arithmetic, the agent would not be in a position to claim support that area of the box is \(133\text{cm}^{2}\).
  A lucky guess that the area of the box is \(133\text{cm}^{2}\) would not allow the agent to hold that the area of the box is  \(133\text{cm}^{2}\) on the basis of the dimensions of the box, the agent's understanding of how to calculate the area of a box, and arithmetic.
  And, it seems the agent is not in a position to base their lucky guess in such a way because the agent did not reason from the dimensions of the box, the agent's understanding of how to calculate the area of a box, and arithmetic.

  Moving to another agent, observe doing the work, get report.
  Easy to resist, by adding in additional premise.
  Still, no presupposing that this needs to be done.

  {
  Again, appealing to \eiS{}.
  Tracing support in this way identifies what there is `to be said' for \(\phi\)/conclusion.
  }

  Further,~\uRa{} not only seems quite plausible, but is either explicitly or implicitly appealed to when characterising the support an agent may claim, or reasons, an agent has for some (reasoned to) proposition.\nolinebreak
  {\color{red}
    Intuitive understand of doxastic support.
    Following, two prominent accounts of the basing relation.
    Other examples in rationality.
    For now, take intuitive plausibility.
    Chapter~\ref{cha:access} (will have) more detail.
  }
\end{note}

\begin{note}[Alternative]
  \uRa{} is that it is a universal claim, and so applies to all instances in which an agent may claim support for conclusion on basis of support for premises and steps of reasoning --- an agent may only claim support if the reasoned from the premises via the steps.

  Our goal is to motivate the following exception to \uRa{}:
  \begin{proposition}[\rC{-} --- \rC{}]\label{rC}
    If an agent has information that they have the ability to (adequately) reason to some conclusion, then the agent may claim support for the conclusion on basis of support for premises that the agent would access and steps used by witnessing their ability to reason to the conclusion.
  \end{proposition}

  If~\rC{} is true, then there are cases in which an agent is not required to reason from premises they may claim support for to some conclusion in order to obtain support for the conclusion on the basis the support the agent has for the premises.

  Stated~\rC{} as an exception to~\uRa{}, but we are not arguing that~\rC{} is an exception to~\uRa{}, which would require an argument that \uRa{} holds for other cases.
  Nor that \rC{} is the only exception, which would require a stronger argument that~\uRa{} holds for all other cases.
  Take~\uRa{} to be plausible, and suspect that there are few, if any, further exceptions, but~\rC{} may stand independently on any further statements about (claiming) support.

  As with~\uRa{}, \rC{} does not entail that the agent \emph{has} support.
  {
    \color{red}
    Some more notes on why this is important.
    Basically, this means that~\rC{} isn't too strong.
  }
\end{note}

\begin{note}[Normative/weakness]
  Consider~\rC{} somewhat weak as it's only about claiming support.
  Doesn't show that the agent has support.
  Agent may be mistaken, in the sense used above.
  So, in particular, normative conflict.
  Ought not use information about ability.
  I don't think this is correct, normative considerations distinguish good instances from bad instances.
  Not all cases are good, though I think the ones focused on are.
  In any case, normative is a separate argument, and need to get clear on what the phenomena is before going in for normative considerations.

  So, only dealing with `adequate' reasoning.
\end{note}

\begin{note}[Ability]
  The exception is motivated by the agent having information that they have the ability to (adequately) reason to the conclusion.

  Idealised agents have no need to appeal to ability.
  However, for limited agents, ability is abundant, while the resources required to witness abilities are scarce.
  That the exception to~\uRa{} is narrow does not entail that there are few occurrences of the exception.

  Information about ability may be abundant while the resources for witnessing abilities are either scarce or temporarily unavailable.
  So, for example, agent has the option of conserving or deferring use of resources.

  If~\rC{} then a novel perspective on limited agents.
  When and why limited agent may claim support for result of reasoning.
  Here, conflict with appeal to~\uRa{} it its unrestricted form.

  And, in between propositional and doxastic support (or more commonly justification).
  Propositional support doesn't allow agent to claim support.
  Doxastic support, agent does claim support.
  If ability allows agent to claim support, \dots

  Secondary motivation is with ability to reason itself.
  Even if arguments for~\rC{} fail to convince, not much has been said on ability to reason, and first steps are useful.
\end{note}

\begin{note}[Interest in ability]
  Broadening scope.
  Arguments involving~\uRa{}.
  Distinction between ideal and non-ideal.
  Potential alternative conclusions to arguments that appeal to~\uRa{} as a premise.
  Revise premises for arguments in which~\uRa{} is a conclusion.
\end{note}

\begin{note}[Examples]
  Need quick truth and desire examples.
  I don't think I need to make these examples compelling, as giving borderline examples may help motivate interest.

  \uRa{} is common in basing literature.
  Support is general, extends to desires.\nolinebreak
  \footnote{
    Strong view on which an agent may be mistaken about desires in the same way as an agent may be mistaken about evidence.
    View on which desires are independent of representation.
    Hence, misleading or mistaken support when an agent fails to represent desire.
  }
  Here, temptation.
  Rely on ability to demonstrate that abstaining from a \(\text{n}^{\text{th}}\) glass of wine, even though the reasoning the agent performs after the \(\text{n-1}^{\text{th}}\) glass supports drinking another glass.
\end{note}

\begin{note}[Small corollary]
  Small corollary is that if the agent has reasoned, then don't need to rely on memory as premise for claiming support.
  Rather, memory works to provide information.

  To extent this is plausible, this is the `backwards' looking part of~\rC{}.
  It's the `forwards' looking part that we will focus on.
\end{note}

\begin{note}[\emph{Exception}]
  As an exception, this doesn't mean that the (appeal to) support is the same as would be if the agent had done the reasoning.
  One way to frame is that doxastic or no claim to support.
  See~\uRa{} as what it takes to obtain doxastic support.
  Deny this.
  There is some other kind of relation to support.
\end{note}

\begin{note}[No causality]
  Important to note, as seems easy to confuse.
  Not claiming that the agent's attitude is causally related to the premises.
  Cause and `basing' may come apart.
  What matters is relation, causation ensures this relation.
  Denied is that based only if caused.
  Information about ability identified as cause, but argue that this is insufficient in certain cases.
\end{note}

\begin{note}[Motivating idea, designated value]
  Thinking about attitudes.
  Some kind of designated value on the attitude.
  Doxastic, truth, maybe.
  Why should it matter that the reasoning has been performed prior to forming the attitude?

  Well, providing support regardless of what the designated value turns out to be.

  Here, a little different.
  Cases in which, whatever it turns out to be, agent is permitted to form such an attitude, constrain with additional condition which seems harder to give up.
\end{note}

\begin{note}[Motivating idea, normative]
  Seems as though there's a plausible normative dimension, in which an agent may be criticised on what they are able to do.
  In particular, ability to reason further, but did not do so.
  Difficult to understand this as a requirement to reason, given constraints on resources.
  Doesn't seem to excuse, or so one may think.

  That is, this is something in between
  \begin{enumerate}
  \item The agent not having the resources.
  \item The agent having the resources, but being unaware that they may use them.
  \item The agent having the resources, and being aware that they may use them.
  \item The agent using the resources.
  \end{enumerate}
\end{note}

\newpage

\section{Structure of argument}
\label{sec:structure-argument}

\begin{note}[Structure of argument]
  Two lines of argument for endorsing~\rC{}, and hence denying~\uRa{}.
  \begin{enumerate}[label=(L\arabic*), ref=(L\arabic*)]
  \item\label{arg:line:1} Motivate~\rC{} as resolution to tension resulting from~\uRa{}.\newline
    Specifically:
    \begin{enumerate}[label=(L1\alph*)]
    \item\label{arg:line:1:a} Provide recipe for generating scenarios where~\uRa{} is in tension with particular scenarios involving information that an agent has the ability reason to some conclusion and a further claim regarding support.
    \item\label{arg:line:1:b} Motivate~\rC{} as a resolution to the tension.
    \end{enumerate}
  \item\label{arg:line:2} Argue that granting~\rC{} as an exception to~\uRa{} allows for an intuitive understanding of cases in which agent has the option of appealing to ability, even if there are alternative ways of interpreting the scenario in line with~\uRa{}.
  \end{enumerate}
  These two lines of argument work together.
  The tension of~\ref{arg:line:1} generates interest in witnessing that may be flatly rejected by prior endorsement of~\uRa{}.
  The intuitive understanding of scenarios involving ability of~\ref{arg:line:2} suggests there's more to witnessing than resolving the tension in narrow cases.
\end{note}

\begin{note}[Details of \ref{arg:line:1}]
  The initial focus is on the first line of argument,~\ref{arg:line:1}.
  The tension developed in part~\ref{arg:line:1:a} is delicate, but hopefully informative.
  We will establish a number of corollaries regarding ability and the interaction between~\uRa{} and ability.
\end{note}

\begin{note}[Before turning to the argument\dots]
  Before turning to the argument, we conclude this introduction with a handful of notes regarding~\uRa{} and~\rC{}.
\end{note}

\begin{note}[Scope of \uRa{}]
  \uRa{} does not say anything in particular about what the agent may claim support for, only what must be the case in order for an agent to appeal to support for some conclusion on the basis of support for premises.

  Talking in terms of (support for) premises and conclusions restricts attention to reasoning.
  There may be broader use of `premise' and `conclusion' where an agent is not required to reason from premise to conclusion in order for the premise to support the conclusion.
  For example, if visual perception is immediate.
  Perhaps it may be said that an agent's visual experience is a premise to the conclusion that a dog is sleeping.
  Still, for present purposes, `conclusion' refers to the output of some process of reasoning performed by an agent which is either actual or potential, and `premises' to the input of that process.

  Note, also, that in both cases the relation between premises and conclusion is important.
  If agent does not reason, then neither~\bP{} nor~\uRa{} apply.
  If there are multiple ways to obtain a conclusion, then~\uRa{} does not require the agent to reason from a particular set of premises.

  Likewise,~\uRa{} does not require that an agent is required to obtain support for a proposition by valid and subjectively sound reasoning from some premises.

  Rather,~\uRa{} requires that an agent reason from premises to conclusion in order to establishes support between premises and conclusion
  By contrast,~\bP{} holds that reasoning is sufficient to establish such a relation.
\end{note}

\begin{note}[\uRa{} is intuitive]
  \uRa{} is intuitive, and is quite common, though not without exceptions.
(For example, there's views on testimony in which the testifier provides agent access to support the testifier has.
One may understand this as conflicting with~\uRa{}, or that the fact that these are accessible is the relevant piece of support.)
\end{note}

\begin{note}[Alternative]
  \rC{} restricts~\uRa{}.
  This is not to say the agent obtains support equivalent to that which would be obtained were the agent to do, or have done, the reasoning.
  Nor, that the agent is aware of the relevant premises.

  Intuitively, \rC{} states that the agent may appeal to the reasoning they are able to perform in support for the conclusion of that reasoning, and as that reasoning moves from premises to conclusion, it is on the basis of the support for those premises that the agent would identify by reasoning that the agent obtains (some) support for the conclusion.

  Hence, \rC{} is in line with the spirit of~\bP{}.
  For the exception to~\uRa{} is granted by the agent appealing to a witnessing event in which the antecedent (and consequent) of~\bP{} are satisfied.
\end{note}

\begin{note}[Ability ensures propositional?]
  Plausible that if the agent has the ability, then the agent already has propositional support for the relevant proposition.
\end{note}

\section{Negative argument overview}
\label{sec:broad-argum-overv}

\begin{note}[Overview]
  Tension resulting from the unrestricted scope of~\uRa{}.
  We begin by introducing a particular type of scenario involving ability, and observe how~\uRa{} requires a unique interpretation of the scenario.
  We then introduce an additional principle regarding support, which conflicts with the interpretation of the type of scenario introduction required by~\uRa{}.
\end{note}

\begin{note}[Introducing key parts]
  Type of information and entailment.
  Two ways to understand entailment.
  Then, if information and entailment \dots
  Principles constrain understanding.
  \uRa{} and a second principle.
\end{note}

\subsection{Type of scenario}
\label{sec:type-scenario}

\begin{note}[Tension, information]
  The tension arises when an agent receives (limited) information that:
  \begin{enumerate}[label=(\GSI{}), ref=(\GSI{})]
  \item If the agent has a general ability to \(\gamma\), then the agent has a specific ability to \(\varsigma\) (as an instance of the general ability).
  \end{enumerate}
  The information is limited because it does not directly provide the agent with the information that the agent has the specific ability, nor that the result of witnessing the specific ability is the case.

  \GSI{} as \gsi{}.
  Information is that if the agent has a general ability to \(\gamma\), then as an instance of the general ability the agent has the specific ability to \(\varsigma\).

  For example,
  \begin{enumerate}[label=(\GSI{}\arabic*), ref=(\GSI{}\arabic*)]
  \item\label{qe:cond} If you have the ability to reason with the rules of chess, you have the ability to demonstrating that there is a sequences of moves that will ensure a win for one of the players (as an instance of the general ability).
  \end{enumerate}
  The conditional structure\nolinebreak
  \footnote{
    Strictly speaking the formulation as a conditional isn't important.
    What matters is that the agent is required to endorse general ability.
    \begin{enumerate}[label=(\GSI{}\('\)), ref=(\GSI{}\('\))]
    \item Either the agent does not have the general ability to \(\gamma\), or the agent has a specific ability to \(\varsigma\).
    \end{enumerate}
  }
  of the information distinguishes \GSI{} from (\dSI{}):
  \begin{enumerate}[label=(\dSI{}), ref=(\dSI{})]
  \item You have the ability to \(\varsigma\).
  \end{enumerate}
  With respect to the example:
  \begin{enumerate}[label=(\dSI{}\arabic*), ref=(\dSI{}\arabic*)]
  \item\label{qe:cons} You have the ability to demonstrate that there is a sequences of moves that will ensure a win for one of the players.
  \end{enumerate}
  Where `\dSI{}' stands for direct specific ability information as the agent directly receives information that they have a specific ability.

  By contrast, with \GSI{} the agent is required to obtain~\ref{qe:cons} from~\ref{qe:cond} by endorsing the antecedent --- that they have the (general) ability to reason with the rules of chess --- and so it may not be the case that the agent has the specific ability.

  So, from \GSI{}, the agent is not provided with information that:
  \begin{enumerate}[label=(I\arabic*), ref=(I\arabic*), resume]
  \item\label{qe:result} There is a sequences of moves that will ensure a win for one of the players.
  \end{enumerate}
  For, it need not be the case that~\ref{qe:result} is true if~\ref{qe:cond} is true by virtue of a false antecedent.
  While, \ref{qe:result} does follow from~\ref{qe:cons}.

  Of course, the antecedent of~\ref{qe:cond} need not be false.
  Rather, the observation that the antecedent of~\ref{qe:cond} highlights how \GSI{} requires the agent to appeal to their general ability in order to obtain information about how the agent's general ability extends to a particular case.

  However, if the agent holds that they have the ability to demonstrate that there is a sequences of moves that will ensure a win for one of the players, then the agent may reason to~\ref{qe:result}.
\end{note}

\begin{note}[\aben{}]
  Note here on \aben{}.
  Then  ways of understanding \aben{}.

  \begin{proposition}[Ability entailment]
    Entailment of the from `S has (specific) ability to \emph{V} that \(\phi\)' and so `\(\phi\) is the case'.
  \end{proposition}

  \aben{} links ability and result.

  Intuitive that \aben{} holds.

  Cases of interest, \aben{} applies to obtaining result.
  Hence, specific ability to demonstrate the existence of a strategy, so a strategy exists.

  Focus is on why it holds.
  Distinguish two ways in which ability is used in some instance of reasoning, and then use these to elaborate on \aben{}.

  Outline two interpretations, and argue that these are exhaustive.

  Argue that only one understanding is compatible with \GSI{} and \aben{}.
\end{note}

\begin{note}[\WR{} and \AR{}]
  We term these \AR{} and \WR{}, respectively.
  Brief descriptions from detached perspective.

  \begin{proposition}[\AR{}]\label{A:s}
    Appal to attribute of ability for each use of ability.
  \end{proposition}

  \AR{} applies to use of ability in some reasoning.
  In all cases, appeal the attribute.

  Support for general, so support for specific, and hence support for conclusion.
  With this, apply to \aben{}.

  \begin{proposition}[\WR{}]
    Appeal to witnessing ability at some point in reasoning.
  \end{proposition}

  Key idea of witnessing is that there is \emph{some} use.
  And, existential to allow use of attributes, as with use of general.

  \AR{} is always in line with \uRa{}, the role of witnessing in \WR{} is in conflict with \uRa{}.
\end{note}

\begin{note}[\PA{} and \PW{}]
  \begin{proposition}[\PA{}]
    A strategy must exist in order for it to be the case that an agent to possess the ability to demonstrate that a strategy exists.

    Therefore, if an agent may claim support for possessing the ability to demonstrate that a strategy exists, then the agent may claim support for the existence of a strategy, and support transmits over entailment.

    So, the attribute is sufficient to grant the entailment.
  \end{proposition}

  Applying to scenarios of interest, \AR{}, attribute of specific ability, and in turn from attribute of general ability.
  Agent claims support for general, so allows agent to claim support for specific, and in turn claim support for result.

  \begin{proposition}[\PW{}]\label{W:s}
    Event of reasoning from premises to conclusion.
    Specific ability, requires being in a position to claim support for premises and steps.
    Hence, appeal to support for premises and steps.
    (Rather than attribute.)
  \end{proposition}

  There is a slight alternative.
  Here, the agent diverges and claims that they have the attribute.
  Then, in line with \PA{}.
  Remains a case of \WR{}, as witnessing from general to specific.
\end{note}

\begin{note}[Applied to scenarios]
  With scenarios, \gsi{}.
  \AR{} is attributions all the way through, finish with \PA{}.

  \WR{} is witnessing at some point.
  General and information, to instance of specific.
  Claim support for each premise or step used, given attribute, and so claim support for conclusion, finish with \PW{}.
\end{note}

\begin{note}[Terminology]
  Use \AR{} and \WR{}, as these imply \PA{} and \PW{}.
  \PA{} and \PW{} to further disambiguate if needed.
\end{note}

\begin{note}[Intuition for \AR{} and \WR{}]
  Both \AR{} and \WR{} are ways to understand \aben{}, which is in turn about what is entailed by an agent having a (certain kind of) specific ability.

  \AR{} focuses on the idea that the agent may claim support from having the attribute (or the truth) of the specific ability.
  \WR{} focuses on the idea that the agent may claim support from witnessing (or using) the specific ability.

  \AR{} requires support for attribute, which in turn suggests in a position to claim support for premises and steps.
  \WR{} requires support for premises and steps, which in turn suggests in a position to claim support for attribute.

  \AR{} doesn't require agent to claim support for premises and steps.
  \WR{} doesn't require agent to claim support for attribute.

  Intuitive example.
  Answer on a test.
  Student puts in the correct answer.
  What matters is that the answer is correct, attribute of the student.
  What matters is that the student has performed the reasoning correctly, the result of some process.

  It seems there is some difference to strength of support claimed.
  However, interest is not in reasoning that has been witnessed.
  Rather, reasoning that the agent has the ability to witness.\nolinebreak
  \footnote{
    \uRa{} provides an explanation here.
    For, if agent did not reason, then wasn't in a position to claim support.
    Hence, trace of the process suggests this condition has been met.

    Arguing against \uRa{}, however.
    This doesn't block the observation, as we're restricting \uRa{} rather than denying \uRa{}.

    Imagine student being provided with information about what to use.
    Student clarifies their understanding.
    To me, this does seem distinct form the two mentioned observations.
  }

  Shortly distinguish these with \uRa{} --- bad for \WR{}.
\end{note}

\begin{note}[Quite brief]
  Sketches of \AR{} and \WR{} are brief.
  Expand on these in the following sections (\ref{sec:first-conditional} and~\ref{sec:second-conditional}) to some extent, and chapter~\ref{cha:potent-infer-attr} will focus on a detailed account of both.
\end{note}

\begin{note}[No third option]
  \AR{} and \WR{} seem exhaustive.
  No alternative source of information about conclusion.
  Hence, specific ability is required, and is likewise novel.
  So general ability is a required premise.

  Ability is describing some action that may be witnessed by the agent.
  Unclear what else there is than mentioning or witnessing action.

  \begin{proposition}\label{either-AR-or-WR}
    Either \WR{} or \AR{} for \aben{}.
  \end{proposition}
\end{note}

\begin{note}[\WR{} alternative]
  Key is support for premises and steps, so invoke general ability in understanding of \WR{}.

  \begin{enumerate}
  \item Agent has support for general ability, and specific ability is an instance of general ability.
  \item So, given the \GSI{}, there is a potential event in which agent does reasoning, and given general ability, the agent is in a position to claim support for each premise and step of reasoning.
  \end{enumerate}

  Possible to reformulate with anything that places agent in a position to claim support.
  Likewise, general will be used to develop tension for \AR{}, but may be possible to formulate without.

  Hence, given \label{either-AR-or-WR}, if problem with \AR{} then \WR{} and not \uRa{}.
\end{note}

\begin{note}[Basic idea]
  We will return to \GSI{} in greater detail below.
  For now, the basic idea is that the agent is on the hook, so to speak, for holding that they have the specific ability.

  Scenarios of this kind are likely uncommon.
  If assume some Gricean maxims, then seems to require that the informer does not have stronger information, or that stronger information is not relevant.

  Perhaps the informer does not want the agent to rely on the informer's information for the existence of the strategy.
  Or, perhaps the agent only wants to appeal to their own understanding of chess.

  Or may be read as a slight challenge.
  The relevant interpretation of `if you're smart enough, you can solve this problem' seems clear.
  `If your ability to reason is of sufficient worth, then by extension of that ability, you have the ability to solve this problem.'
  Paraphrased, `if you're smart enough, you have the ability to solve this problem'.
  So challenged, and confident in one's smarts, one may expect to solve the problem.
  The slight difference with the limited information of interest is that the informer provides information about what the solution to the problem is if the agent is `smart enough'.

  Scenarios require the agent to use this information.
  May be the case that this kind of information is used when alternatives are available.
  E.g.\ hold \(\phi\) not only because testimony, but because ability.

  Main point is moving from general to specific.
  However, focus point is use of specific.
  How this works when the agent appeals to ability.
  Role of \GSI{} is to capture idea that agent may have reason to appeal to specific ability.
  Plausible that if agent appeals to specific then something like general in the background.
  Even if somewhat rare, then, fairly clean set-up for appeal to specific ability.

  Note, in particular with \ref{qe:cons} the agent may hold that \(\phi\) without holding that they have the specific ability to demonstrate that \(\phi\).
  For example, consider instructor telling a student that they have the ability to show that ? is the solution to the problem.
  Student may reason that the instructor is not wrong about the solution, but is wrong about the student's ability.

  If student is given \GSI{} then it's not clear that the agent gets the solution.
  Plausible that variant information, though.
  ? is the answer, and so long as general, then specific.
  Though, as before, agent doesn't need to consider ability with such a variant, as route to ? which is independent of the agent's ability.
\end{note}

\begin{note}[Scenario proposition]
  For ease of reference, we wrap scenarios involving the limited information as a proposition.
  \begin{proposition}[\eA{-} --- \eA{}]\label{prem:ab}
    {
      {\color{red}
        Reform this with \aben{}.
      }
      Interest in cases is an instance of \aben{} with certain type of support for specific ability.
    }
    It is possible for an agent to use information that they have some specific ability so long as the agent has some general ability to claim support for what follows from the specific ability.
    (Where the agent lacks doxastic support for what follows, and for \(A(\varsigma)\) without information).
  \end{proposition}
\end{note}

\begin{note}[Possible restrictions]
  The important aspect of premise~\eA{} is that there are cases in which the agent may appeal to ability to obtain support.
  This is quite weak.

  Understanding of support here is primarily for the agent.

  It allows that there may be cases in which the details of the cases outlined are satisfied, but where kind of support is unsuitable for certain purposes.
\end{note}

\begin{note}[Normative, again]
  In particular, some witness of ability may be demanded by a third-party.
  Perhaps due to lack of confidence in agent, or contextual features of the scenario.
  This is no different from memory.
  Memory of proving \(\phi\) provides support for \(\phi\).
  Still, one may still demand a demonstration of \(\phi\).
  Perhaps the third-party considers the agent's memory unreliable, or perhaps context has been set so that memory is insufficient to add a proposition to the common ground, etc.
\end{note}

\subsection{\uRa{} and \WR{}}
\label{sec:first-conditional}

\begin{note}[Summary]
  In this section, argue that \uRa{} conflicts with \WR{} understanding of \aben{}.
  And, show that \AR{} is compatible with \uRa{}.
  So, as long as disjunction holds, \uRa{} requires \AR{}.

  That's the main takeaway.
  Secondary takeaway is that \gsi{} needs allow the agent to claim support for having attribute for specific ability from support claimed for general ability.
  This will be important in the following section.
\end{note}

\begin{note}[Proposition]
   \begin{proposition}\label{mcA:WR-and-denied-claim}
    \WR{} is incompatible with~\uRa{}.
  \end{proposition}
    For,~\ref{P:ab-and-dc:W:ab} and~\ref{P:ab-and-dc:W:uRa}.
  Then, agent obtains support by~\ref{P:ab-and-dc:W:ab}.
  As \uRa{}, then from \ref{mcA:WR-and-denied-claim} not \WR{}.
  So, from~\ref{either-AR-or-WR}, must be \AR{}.
\end{note}

\begin{note}[To argument]
  {
    \color{red}
    We provided a brief argument for~\ref{either-AR-or-WR} in the previous section.
  }
  So, what follows is a brief argument for~\ref{mcA:WR-and-denied-claim}.
\end{note}

\begin{note}[Attribute]
  \WR{} is an instance of~\rC{}, as the agent obtains support for the conclusion of the reasoning is able to do on the basis of the reasoning that would be performed in a witnessing event.
  Hence, the supported obtained for the conclusion is obtained on the basis of the support the agent has for the premises that would be used.
  Again, this does not imply that the agent obtains support for the conclusion which is equivalent to the support the agent would obtain by witnessing their ability by performing the reasoning.
\end{note}


\begin{note}[Compatibility]
  However, \AR{} suggests an alternative way to obtain support for the conclusion of reasoning the agent is able to do.
  Specifically, if order for the agent to \emph{have} the attribute of being able to reason to the conclusion, the conclusion of the reasoning must be true.
  The relevant entailment is in part secured by the verb chosen, and in part by what the verb is applied to.
  Here, `demonstrate' is a factive verb, if an agent demonstrates that \(\phi\), then it is true that \(\phi\).
  And, the existence of a chess strategy does not depend on the agent demonstrating that the relevant strategy exists.

  To take another example, you only have the ability to identify a typo on this page if there is a typo on this page.
  So, if I were to provide you with testimony that you have the ability to identify a typo on this page, you may begin searching for the typo, or you may note that there must be a typo in order for me to be in a position to provide you with testimony that you have the ability.

  The reasoning is summarised with the following sketch.

  \begin{enumerate}[label=(\textsf{A}\arabic*), ref=(\textsf{A}\arabic*)]
  \item\label{WR:Sketch:1} I have the attribute of being able to \emph{V} that \(\phi\).
  \item\label{WR:Sketch:2} In order to have the attribute of being able to \emph{V} that \(\phi\), \(\phi\) must be the case independent of whether or not I witness the ability.
  \item\label{WR:Sketch:3} \(\phi\) is the case.
  \end{enumerate}

  To keep things simple, we will refer to the principle behind the pattern sketched as \AR{}.
  And agent may bundle~\ref{WR:Sketch:1} and~\ref{WR:Sketch:3} into a conditional, and avoid instantiating the reasoning pattern, but so long as the conditional is (implicitly) held on the basis of the intermediate premise~\ref{WR:Sketch:2}, we take use of such a conditional to be an instance of \AR{}.

  \AR{} is compatible with \uRa{}.
  For, the two premises~\ref{WR:Sketch:1} and~\ref{WR:Sketch:2} are accessible to the agent, and obtaining \ref{WR:Sketch:3} from~\ref{WR:Sketch:1} and~\ref{WR:Sketch:2} appears to be straightforwardly sound reasoning.
\end{note}

\begin{note}[Conditional A]
  The first conditional we establish highlights how \uRa{} constrains how an agent may use \gsi{} in the type of scenarios described by \eA{}.

  \begin{proposition}[\mcA{}]
  \begin{enumerate}[label=(C\Alph*), ref=(C\Alph*)]
  \item\label{P:ab-and-dc:W} If
    \begin{enumerate}[label=(\roman*), ref=(CA.\roman*)]
    \item\label{P:ab-and-dc:W:ab} an agent may claim support for the conclusion of reasoning they are able to do in cases described by~\eA{}, and
    \item\label{P:ab-and-dc:W:uRa} \uRa{} is true,
    \end{enumerate}
    then
    \begin{enumerate}[label=(\roman*), ref=(CA.\roman*), resume]
    \item\label{P:ab-and-dc:W:AR} the claimed support for \(\phi\) is obtained on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (i.e.\ \AR{}).
    \end{enumerate}
  \end{enumerate}
\end{proposition}

  The reasoning described in the consequent of the conditional, \ref{P:ab-and-dc:W:AR}, is in line with \AR{} --- the support the agent obtains for the conclusion of the reasoning that they are able to do is obtained from the support the agent has for having the attribute of being able to reason to the conclusion.
\end{note}

\begin{note}[Summarising]
  ???
\end{note}

\begin{note}[Note on why \AR{} does not conflict with \uRa{}]
  \AR{} and \uRa{} are compatible.
  For, \AR{} is attribute.
  So, if instance of \AR{} agent is claiming support for attribute.
  This is accessed.
\end{note}

\subsection{\nI{} and \AR{}}
\label{sec:second-conditional}

\begin{note}[Redo of section]
  Seen \uRa{} and \WR{}.
  Turn to \AR{}.
  Also saw in last section certain kind of support required.

  Introduce a general constraint on claiming support.
  The general constraint will relate to moving from general to specific ability information --- agent is not in a position to claim support for having specific ability from information and support claimed for general ability.
  However, initial statement and motivation apply to all instances of claiming support.
  After statement and motivation, show how the constraint relates to \AR{}.
  If so, agent lacks support for having specific ability, and does not have the option of claiming support for result of specific ability by \AR{}.
\end{note}

\begin{note}[\nI{}]
  We turn to the general constraint on claiming support.
  \begin{proposition}[\nI{-}  --- \nI{}]\label{prem:ni}
    Suppose an agent:
    \begin{enumerate}
    \item\label{nI:claimed-support} Has claimed support for \(\phi\) (recognised that may be misleading given information that agent has).
    \item\label{nI:received-info} Received novel information that if \(\phi\) then \(\psi\) is (also) the case/\(\psi\) has some value so long as \(\phi\) has so value.
    \item\label{nI:inclusion} If support for \(\phi\) does not also extend (independent of value) to support for \(\psi\), then mistaken or misled. (Inclusion)
    \end{enumerate}
    Then:
    \begin{enumerate}[resume]
    \item\label{nI:going-by-value} No claim to support for \(\psi\) by appeal to value of \(\phi\) from \ref{nI:claimed-support}, and relation between \(\phi\) and \(\psi\) from \ref{nI:received-info}.
    \end{enumerate}
  \end{proposition}
\end{note}


\begin{note}[Structure of \nI{} and plan]
  Structure of \nI{} is two conditions that allow an agent to claim support in a certain way (\ref{nI:claimed-support} and~\ref{nI:received-info}), detailed by~\ref{nI:going-by-value}, but blocked when a defeater condition holds (~\ref{nI:inclusion}).

  Two conditions to be clarified.
  Inclusion, and reasoning by value.
  Roughly:
  \incl{} reapply (some of the) premises and steps of reasoning used in claimed support for \(\phi\) to claim support for \(\psi\).
  E.g.\ simple: \(p \rightarrow q\) and \(q \rightarrow r\), to claim support for \(p \rightarrow r\).
  Reapply, \(p \rightarrow (q \land r)\).

  \RBV{} is a type of reasoning where agent appeals to value of proposition claimed support for.
  E.g.\ \(K_{E}p\) to \(p\).

  As \nI{} depends on these, little intuition prior to clarifying.
  The gist, however, is that \nI{} captures intuitive constraint that agent is not in a position to claim support for some proposition \(\psi\) by information that \(\phi\) entails \(\psi\) if failure to establish support for \(\psi\) independently of the value of \(\phi\) would reveal problem with the support claim for \(\phi\).

  Clarifying \incl{} and \RBV{} will allow a clearer statement.
  \nI{} will then follow from \incl{} and \RBV{} together with basic constraint on support \eiS{}.

  Important clarification, \nI{} is sufficient condition.
  Further, \RBV{} is \emph{a way} of claiming support.
  So, \nI{} does not imply that the agent is not in a position to claim support for \(\psi\), only that one way of claiming support is ruled out given \ref{nI:claimed-support}--\ref{nI:inclusion}.
  Following, as \nI{} is about claiming support, this says nothing about whether the agent has support --- in particular, if claimed support for \(\phi\) is support, then by \incl{}, plausible that the agent has support for \(\psi\) even if not in a position to claim when \RBV{}.

  Looking forward, argument will be that \gsi{} sets up \incl{} and \AR{} requires \RBV{}.
  Hence, \nI{} rules out agent claiming support for specific ability by \AR{}.
  However, primary motivation will be independent of ability.

  Begin with clarifying \incl{} and \RBV{}, then general account of \nI{}, followed by a handful of examples, and concluding with ability.
\end{note}

\begin{note}[Inclusion of support]
  \begin{proposition}[Inclusion of support --- \incl{}]
    Support for \(\phi\) includes/requires support for \(\psi\).
    If, possible to reapply premises that establish \(\phi\) to establish \(\psi\) (without appealing to value of \(\phi\)).
  \end{proposition}
  Basic idea of \incl{} is reapplication.
  Hence, \incl{}\dots

  Without going by \(\phi\).
  This is not an additional condition, but clarification.
  For, given \eiS{}, agent did not need value of \(\phi\) in order to claim support for \(\phi\), and as agent is reapplying support claimed for \(\phi\), such reapplication does not require value of \(\phi\) either.

    \begin{figure}[H]
    \begin{subfigure}{.45\textwidth}
      \centering
      \begin{tikzpicture}[->, >=stealth', node distance=0cm, every text node part/.style={align=center}, scale=0.75]
        \node [] (1) at (-1,4) {};
        \node [] (2) at (-1,-1) {};
        \node [] (3) at (4,-1) {};
        \node [] (4) at (4,4) {};

        \node [] (a) at (1.5,3) {\(P/S\)};
        \node [] (b) at (1.5,0) {\(S(\phi)\)};
        \node [] (c) at (3,0) {};
        \node [] (d) at (3,3) {};

        \draw [->,-{Square[open]}, xshift=4] (a) to  node[right] {} (b);
        \draw [rounded corners=5pt, opacity=.1] (-.75,3.75) -- (-.75,-.75) -- (3.75,-.75) -- (3.75,3.75) -- cycle;
      \end{tikzpicture}
      \caption{Support for \(S(\phi)\) from premises/steps}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.45\textwidth}
      \centering
      \begin{tikzpicture}[->, >=stealth', node distance=0cm, every text node part/.style={align=center}, scale=0.75]
        \node [] (1) at (-1,4) {};
        \node [] (2) at (-1,-1) {};
        \node [] (3) at (4,-1) {};
        \node [] (4) at (4,4) {};

        \node [opacity=.33] (a) at (0,3) {\(P/S\)};
        \node [opacity=.33] (b) at (0,0) {\(S(\phi)\)};
        \node [] (x) at (1.5,3) {\(\supseteq\)};
        \node [] (c) at (3,0) {\(S(\psi)\)};
        \node [] (d) at (3,3) {\(P/S\)};

        \draw [->,-{Square[open]}, opacity=.33] (a) to  node[right] {} (b);
        \draw [->,-{Square[open]},] (d) to  node[right] {} (c);
        \draw [rounded corners=5pt, opacity=.1] (-.75,3.75) -- (-.75,-.75) -- (3.75,-.75) -- (3.75,3.75) -- cycle;
      \end{tikzpicture}
      \caption{Reapply premises/steps to claim support for \(\psi\)}
    \end{subfigure}
    \caption{\incl{} diagram}
  \end{figure}

  Examples:
  \begin{itemize}
  \item \(p \rightarrow (q \land r)\), includes support for \(p \rightarrow q\).
  \item More complex example of entailment.
  \item Combining support for novel entailments.
  \item If understand language, then parse: some sentence.
  \item Optimal route to some place, then stop at some intermediate point at some time.
  \end{itemize}
  In these cases, some consequence.
  However, it's not simply any consequence.
  Rather, there is some resource that the agent will have used which may be refined.

  Clear failures for arbitrary entailment.
  Things used for proving completeness do not necessarily ensure finite model property, though in certain cases they may.

  And, finally, cases of ability.
  Ability is quite natural here, as when looking at the agent doing something, so perform some action.

  \begin{quote}
    If you've done X, then in a position to do Y.
  \end{quote}

  Doesn't hold for many cases.
  Two examples:
  \begin{itemize}
  \item Knowledge, support that \(S\) knows \(p\) does not include support for \(p\).
  \item Going by a supplied conditional.
    E.g.\ If not in London then in Paris.
    Searched London, but this doesn't already establish that the person is in Paris, the person could be anywhere other than London.
  \end{itemize}
\end{note}

\begin{note}[\incl{} and \nI{}]
  So, with respect to \nI{}, \incl{} highlights tight relation between support for \(\phi\) and support for \(\psi\).

  Because focus is on inclusion, issue of \(\psi\) is something of an (indirect, partial) test on the support claimed for \(\phi\).\nolinebreak
  \footnote{
    Partial, because it doesn't say too much about mistaken or misleading support that allows the agent to claim support for too much.
    However, pair with `not claim support for \(\psi\)' type conditions.
  }
  This is why issue of support for \(\psi\) is significant.
\end{note}


\begin{note}[\RBV{}]
  Second point is reasoning-by-value.

  \begin{proposition}[Reasoning by value (\RBV{})]
    An agent \emph{reasons by value} if the agent moves from claimed support for propositions \(\phi_{i}\) to \(\phi_{i}\) having value \(v_{i}\), which constrains value of \(\psi\).
  \end{proposition}

  \RBV{} is common.
  Agent has claimed support for \(\phi\) having value \(v\), then reason about what follows from \(\phi\) having value \(v\).
  Distinguishing feature is that it is \(\phi\) having value \(v\) which constrains value of \(\phi\).
  Purpose of going by value is that support claimed for \(\phi\) may not be sufficient to provide constraint of value of \(\psi\) without value of \(\phi\).

  First, entailments sometimes require value.
  Example with knowledge.
  It is true that an agent knows that \(p\) only if \(p\) is true.
  So, agent knowing \(p\) constrains value of \(p\).

  Support for agent knowing \(p\) without independent support for \(p\).
  For example, novice and an expert.
  Novice in position to claim support for expertise of expert, but not in a position to reason to \(p\) independently of expert.
  Appeal to claim of support.
  Factivity.
  Factivity requires that the expert knows, not merely that the agent has claimed support that the expert knows.
  Claimed support won't do this alone, for claimed support doesn't get \(p\) without \(K_{E}p\), nor does it need to be the case that \(K_{E}p\) in order to claim support for \(p\).\nolinebreak
  \footnote{
    Decline to link support to attitudes, but for clearer intuition, consider belief.
    \(B(K_{E}p)\) gets to \(B(p)\), but simply believing \(K_{E}p\) isn't enough to get \(K_{E}p\) and hence \(p\).
    So, \(K_{E}p\) given belief, hence \(p\), resulting in \(B(p)\).
  }
  Probe and find issues.

  Second, following entailment, information provided to agents is often about values.
  Information provides to an officer worker by company secretary that if their manager is not in the London office today, they are in the Paris office.
  Secretary does not provide information other than constraints on location.
  Employee searches London office, doesn't find manager.
  So, claim support that manager is not in the London office, and with the secretary's information, claim support that the manager is in the Paris office.

  As secretary doesn't provide information other than constraints, need not in London office to go to Paris office.

  Similarly, condition~\ref{nI:received-info} is about value, though abstract stated.

  \begin{figure}[H]
    \begin{subfigure}{.45\textwidth}
      \centering
      \begin{tikzpicture}[->, >=stealth', node distance=0cm, every text node part/.style={align=center}, scale=0.75]
        \node [] (1) at (-1,4) {};
        \node [] (2) at (-1,-1) {};
        \node [] (3) at (4,-1) {};
        \node [] (4) at (4,4) {};

        \node [] (a) at (0,3) {\(S(\phi)\)};
        \node [] (b) at (0,0) {\(\phi\)};
        \node [] (c) at (3,0) {\(\psi\)};
        \node [] (d) at (3,3) {};

        \draw [->, xshift=4] (b) to  node[right] {} (c);
        \draw [rounded corners=5pt, opacity=.1] (-.75,3.75) -- (-.75,-.75) -- (3.75,-.75) -- (3.75,3.75) -- cycle;
      \end{tikzpicture}
      \caption{Support for \(S(\phi)\) and info}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.45\textwidth}
      \centering
      \begin{tikzpicture}[->, >=stealth', node distance=0cm, every text node part/.style={align=center}, scale=0.75]
        \node [] (1) at (-1,4) {};
        \node [] (2) at (-1,-1) {};
        \node [] (3) at (4,-1) {};
        \node [] (4) at (4,4) {};

        \node [] (a) at (0,3) {\(S(\phi)\)};
        \node [] (b) at (0,0) {\(\phi\)};
        \node [] (c) at (3,0) {\(\psi\)};
        \node [] (d) at (3,3) {};

        \draw [->] (b) to  node[right] {} (c);
        \draw [->, -{Square[open]}] (a) to  node[right] {} (b);
        \draw [rounded corners=5pt, opacity=.1] (-.75,3.75) -- (-.75,-.75) -- (3.75,-.75) -- (3.75,3.75) -- cycle;
      \end{tikzpicture}
      \caption{Move to value of \(\phi\)}
    \end{subfigure}

    \begin{subfigure}{.45\textwidth}
      \centering
      \begin{tikzpicture}[>=stealth', node distance=0cm, every text node part/.style={align=center}, scale=0.75]
        \node [] (1) at (-1,4) {};
        \node [] (2) at (-1,-1) {};
        \node [] (3) at (4,-1) {};
        \node [] (4) at (4,4) {};

        \node [] (a) at (0,3) {\(S(\phi)\)};
        \node [opacity=0.33] (b) at (0,0) {\(\phi\)};
        \node [] (c) at (3,0) {\(\psi\)};
        \node [] (d) at (3,3) {};

        \draw [->, opacity=0.33] (b) to  node[right] {} (c);
        \draw [->,-{Square[open]}, opacity=0.33] (a) to  node[right] {} (b);
        \draw [->,-{Square[open]}] (a) to  node[right] {} (c);
        \draw [rounded corners=5pt, opacity=.1] (-.75,3.75) -- (-.75,-.75) -- (3.75,-.75) -- (3.75,3.75) -- cycle;
      \end{tikzpicture}
      \caption{Given support, value of \(\psi\) is determined}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.45\textwidth}
      \centering
      \begin{tikzpicture}[>=stealth', node distance=0cm, every text node part/.style={align=center}, scale=0.75]
        \node [] (1) at (-1,4) {};
        \node [] (2) at (-1,-1) {};
        \node [] (3) at (4,-1) {};
        \node [] (4) at (4,4) {};

        \node [opacity=0.66] (a) at (0,3) {\(S(\phi)\)};
        \node [opacity=0.33] (b) at (0,0) {\(\phi\)};
        \node [opacity=0.66] (c) at (3,0) {\(\psi\)};
        \node [] (d) at (3,3) {\(S(\psi)\)};

        \draw [->, opacity=0.33] (b) to  node[right] {} (c);
        \draw [->,-{Square[open]}, opacity=0.33] (a) to  node[right] {} (b);

        \draw [rounded corners=10pt] (-.5,3.5) -- (-.5,-.5) -- (3.5,-.5) -- (3.5,.5) -- (.5,.5) -- (.5,3.5) -- cycle;
        \draw [->,-{Square[open]}] (.64,.64) to node[right] {} (d);

        % Previous `diagonal' depiction %
        % \draw [->,-{Square[open]}, opacity=0.66] (a) to  node[right] {} (c);
        % \draw [rounded corners=2.5pt] (-.5,3) -- (0,3.5) -- (3.5,0) -- (3,-.5) -- cycle;
        % \draw [->,-{Square[open]}] (1.75,1.75) to node[right] {} (d);

        \draw [rounded corners=5pt, opacity=.1] (-.75,3.75) -- (-.75,-.75) -- (3.75,-.75) -- (3.75,3.75) -- cycle;
      \end{tikzpicture}
      \caption{Support for \(\psi\) from constraint on \(\psi\) following from support for \(\phi\)}
    \end{subfigure}
    \caption{\RBV{} diagram}
  \end{figure}
\end{note}


\begin{note}[Non-\RBV{} reasoning]
  Not all reasoning is like this.

  Return to examples used to illustrate inclusion of support.
  \begin{itemize}
  \item Conjunction elimination.
    Here, working with the logical form, it doesn't matter what \(p\), \(q\), nor \(r\) are.
  \item Same for efficient route example.
    Agent doesn't need to appeal to having found the most efficient route to produce variation.
  \end{itemize}

  Some instance of reasoning may go either way.
  For example.
  Machine.
  Told that the machine is designed to perform some function, but not told what the function is.

  Question, \(f(X,Y)\)

  One option is to input into machine.
  So, relying on machine implementing function.
  Going by value.

  Second option, abstract function from machine by inspection.
  Then, calculate \(f(X,Y)\).
  Not going by value, doesn't matter what the machine produced.

  Risks for each.
  For the first, potential malfunction on specific input, but without malfunction then that's the result.
  For the second, no concern about potential malfunction, but possible that abstracted function is faulty.

  So, difference is not tied to proposition.

  And, complex chain of reasoning may include both.
  \(p \rightarrow (q \land K_{S}r)\) so \(p \rightarrow q \land r\).
\end{note}

\begin{note}[Review of \nI{}]
  \incl{} and \RBV{}, now turn to why conflict with \incl{} and \RBV{}, as stated by \nI{}.

  \ref{nI:going-by-value}, going by value.
  So, going from support for \(\phi\) to \(\phi\), and then from \ref{nI:received-info} to \(\psi\) by value.

  However, denied claim of support for \(\psi\) by \incl{}.
  Turn to argument for this.
\end{note}

\begin{note}[\nI{} argument, state]
  Start with three conditions describing state of agent.

  By~\ref{nI:claimed-support}, agent has claimed support for \(\phi\), though recognises the support may be fallible.
  It is possible that there's a different value of \(\phi\) (misled), or even if that value, the support claimed is not an indicator (mistaken).

  And, by~\ref{nI:received-info}, agent has information that value of \(\phi\) constrains value of \(\psi\).
  Use of `information' allows for arbitrarily strong support.
  May assume that this is something known, though do not require for failure.

  Finally, by~\ref{nI:inclusion}, the agent is aware that the support claimed for \(\phi\) includes support for \(\psi\).
  That is, agent may reapply premises and steps to claim support for \(\psi\).
  Hence, the agent does not need to go by value of \(\phi\) to get \(\psi\), as premises and steps used to claim support for \(\phi\) did not require value of \(\phi\) (by \eiS{}).
\end{note}


\begin{note}[\nI{} argument, \RBV{}]
  From the three conditions describing state, it is possible for agent to claim support for \(\psi\).
  In particular, by reapplying and establishing how support claimed for \(\phi\) includes support for \(\psi\).

  \ref{nI:going-by-value} describes a way of obtaining support that does not appeal to inclusion of support.
  Agent moves from support claimed for \(\phi\) to value of \(\phi\), and given information, this would constrain value for \(\psi\), hence leading to support for \(\psi\) if \RBV{} is permitted.

  With the background provided, from a certain perspective, agent would be bypassing reapplication.
  Possible to claim support for \(\psi\) regardless of value of \(\phi\), but with information, observe constraint on value of \(\phi\) and hence on \(\psi\).
  As agent doesn't need to do work to establish how value is constrained by reasoning by value, this is quite easy.

  Issue is that \incl{} blocks \RBV{}.
  \eiS{} again.
  If claimed support, then independent of value.
  However, because \incl{}, problem moving from support for \(\phi\) to value of \(\phi\).
  For, in moving support for \(\phi\) to value of \(\phi\), agent is implicitly requiring value of \(\psi\).
  For, given \incl{}, if \(\psi\) does not have value, then support claimed for \(\phi\) would be mistaken or misleading, and hence would block move to value.
  So, any further reasoning by value is required to already have \(\psi\), and this conflicts with \eiS{} when the agent moves to claiming support for \(\psi\) as the result of \RBV{}.

  From a broader perspective, the agent doesn't get to claim support for \(\psi\) through \RBV{} because any move to value requires \(\psi\) to already be the case given the information the agent has.
  Hence, failure of \eiS{} if agent were to claim support for \(\psi\).
  Because of \incl{}, \RBV{} does not preserve \eiS{}.

  Illustrate, possible that the agent is mistaken/misled, and support claimed for \(\phi\) does not include support for \(\psi\).
  However, if \RBV{}, then claim support for \(\psi\).
  Problematic, because whether inclusion is a test for whether the support claimed for \(\phi\) is any good, but bypassing test when reasoning by value.

  No claiming support by noting value consequence, if failure to show value independent consequence would lead to revision of support.
\end{note}


\begin{note}
  Nothing particularly problematic about this, as given \incl{}, agent applies whatever support they have for \(\phi\) to get \(\psi\).

  Further, no issue with using \(\phi\) for other things.
  Here, only interest is in support.
  Hence, recognised by the agent that they may be misled.
  From this perspective, the issue is not ruling out potential defeaters.
  Similar to knowledge, etc.\ but no requirement that there are no defeaters.
\end{note}

\begin{note}[Abstract, so examples]
  The above highlights the problem.
  However, abstract.
  Turn to illustrations, and then to how \nI{} applies to \gsi{}.
\end{note}


\begin{note}
  May think that this restricts any application of \RBV{} to support claimed for \(\phi\) without value independent.
  This isn't quite right.
  \eiS{} keeps focus on \(\psi\).
  Only committed to \(\psi\) being a problem.
  Potential issue is no worse than any other instance of claim to support --- possibility of being mistaken or misled.
  If \(\psi\) ends up being used, then there's going to be a gap, where agent isn't in position to claim support by value, but unless eventual consequence is in turn used for \(\psi\), no clear problem --- at least not without stronger assumption.
\end{note}

\begin{note}
  \uRa{} is going to require the agent to reason from premises and steps `included' in support claimed for \(\phi\) in order to claim support for \(\psi\).
\end{note}


\begin{note}[Examples]
  Examples are somewhat difficult, due to complexities of state.
\end{note}


\begin{note}[Picture book]
  \begin{scenario}
    Picture book.
    Finding a particular character.
    Go through, and claim support.
    Then receive information that if found character, then wearing a striped shirt.
    So, visual support, relation of inclusion.
    Intuitively problematic, because, if not wearing striped shirt, then support claimed is bad.
  \end{scenario}
  Observe, here, that other things by value are fine.
  If found, then actually one of a number of solutions are the author made a mistake.
  Inclusion fails here, because may have moved on after single solution.

  Another visual
  \begin{scenario}
    If not genuine, then missing serial number.
  \end{scenario}
  No need to reinspect, faults are support, so no serial number.
\end{note}

\begin{note}[Logic proof]
  \begin{scenario}
    If conjunction and negation are truth functionally complete, then disjunction and negation are truth functionally complete.

    And, claim of inclusion.
  \end{scenario}

  Here, in proving completeness, expressing other connectives.
  So, inclusion because agent will have shown how to switch between conjunction and disjunction.

  Well, claimed support for conjunction and negation.
  So, yes.
\end{note}

\begin{note}[Treasure]
  \begin{scenario}
    Claimed treasure only if learnt secret.
  \end{scenario}
  A little more interesting, as here, agent is going to have done something to learn secret when claiming support for treasure, but may not recognise that they've learnt the information.
  Of course, may be wrong treasure.
  Again, seems bad.
  But, if treasure then sell for \$X, seems fine.

  Useful, as earlier examples may seem to rely on easy checks, but putting pieces together to reveal secret may be quite difficult.
\end{note}

\begin{note}[Problematic]
  \begin{scenario}
    If walked \(15k\), then walked \(13k\).
  \end{scenario}
  Doesn't seem so much of a problem, but at the same time, it seems \RBV{} traces \incl{}.
  Well, no, this is ruled out by some earlier condition.
  For, plausible that it's not really possible to have claimed support for \(15\) without already claiming support for \(13\).
\end{note}

\begin{note}[Knaves]
  \begin{scenario}
    If X is speaking falsely, then Y is speaking truthfully.

    Knave says a bunch of things that you've got could support for being false, but could be true.
  \end{scenario}
  Variation on Knave problems.
  Again, there may be intuition that solving the problem is easily in reach, but I think this is a mistake.
  Knave problems are hard, and the difficulty doesn't seems to make a difference.
\end{note}

\newpage


\begin{note}
  Important points
  \begin{itemize}
  \item No interest in whether \(\phi\) or \(\psi\) have valued supported. --- As noted, support isn't absolute in this sense. And, further, support for \(\phi\) needs to have some wiggle.
  \end{itemize}
  And, potential defeaters aren't defeaters.
  These don't show that there's anything problematic with the support claimed for \(\phi\).
  However, at the same time it doesn't follow that the agent can easily claim support.

  Don't get to respond to an `inclusion defeater' by `factive reasoning'.
\end{note}

\begin{note}[Interest and name]
  Name, support isn't inherit by \(\psi\), the squire.\nolinebreak
  \footnote{
    Squire, `a landed gentleman who did not have to work, but could live a comfortable if not luxurious life off the rents from his land', or, in terms of a shied.
    Something like this.

    Mnemonic `squire' --- `psiquire' --- `\(\psi\)quire'.
  }
\end{note}


\begin{note}[Clarifying \nI{}]
  Initial clarification is with \ref{nI:going-by-value}.
  Obtaining value of \(\psi\) by value of \(\phi\) given support.

  Example of, and then example of not.

  Simple example of.
  Knowledge and factivity.
  Support that agent knows.
  It seems this only works by going through the value.


  Simple example of not.
  Opening example with calculating the area.
  Support for the dimensions of the box, but reasoning through is independent of whether the box has the dimensions.
  If the box doesn't have the dimensions, then the result is not of interest, but there's no fault with figuring out the particular area.


  A second pair of examples.
  Some kind of mechanism.
  Demonstration of why the mechanism performs the function.
  So, put something in, and this is why we're going to get the result.
  If something goes wrong, then there's a fault in the mechanism.

  However, for end user, relying on value.

  Second example.

  Consider a note counting machine.
  User places stack of notes in certain orientation, and machine reports total of all the notes.

  Claim support for proposition that the machine will calculate this stack of notes should be Y.

  Two ways.

  First, going by value.
  Support that the machine counts, therefore, given this an total, machine will calculate Y.

  Second, not going by value.
  Designer of the machine.
  Stack of notes.
  Different amounts have different sizes, mechanism to detect, count in various quantities, which will lead to the result.
  Here, machine is implementing some function, support claimed goes via execution of function, rather than the machine doing the function.

  Suppose machine has fault.
  Going by value, the agent would no longer have a route to Y.
  Going by implementation, retain, expectation, because not relying on the proper functioning of the machine.


  If it gets the value wrong, then this wouldn't show support claimed is misleading or mistaken.
  For, doesn't show that there is a problem with following the claims.
  Support is typically consistent with both.
\end{note}

\begin{note}[Conditions]
  The initial conditions are a little more straightforward.

  First three conditions are background, but are not the primary focus of failure in \nI{}.

  So, \ref{nI:claimed-support}, possibility of defeaters.
  Mistaken alone isn't enough, as mistaken doesn't require that the value is different.
  Possible cases where the agent is on the mark about the value, but has some error.
  Difficult, as going via value, by \ref{nI:received-info}.
  Don't see a particular clear intuition here, but idea used don't extend to these type of cases.


  \ref{nI:received-info} then sets the agent up for information about \(\phi\) and \(\psi\).

  \ref{nI:not-then-MandM}, recognition that if not \(\psi\) then a mistake.
  Mistake is the key part here.
  Misled comes for free, given the relationship between \(\phi\) and \(\psi\).

  Key is \ref{nI:going-by-value}, which details how the agent would claim support for \(\psi\) from \(\phi\).
  What is meant is that support, so \(\phi\) has value, then given \ref{nI:received-info}, requirements of values.
  Key here is that the agent is limited to claim that \(\psi\) is required to be true given the support they have.
  Basic idea illustrated above.

  \nI{} is silent on other cases.
  In particular, when agent extends support.
  Detail some examples to make this clear.

  So, difference with witnessing is that doesn't go by value.
  This blocks the initial instance, which may be independently motivated by any instance of reasoning.

  Key intuition, then, is that because relying on value, lack resources to maintain \(\psi\) if it isn't the case.

  From this way of looking at things, support for \(\phi\) is fragile with respect to \(\psi\).

  Still no requirement of assuming \(\psi\)
\end{note}

\begin{note}
  So, this is the difference captures by \ref{nI:going-by-value}.
  Cases used to illustrate value do not (clearly) satisfy \ref{nI:not-then-MandM}.
  Knowledge, getting this is distinct from getting value.
  Note machine, again, doesn't show a problem with claiming support ---- e.g.\ have on good authority, malfunction is quite unexpected.

  Not going by value is different.
  The area does suggest some mistake, likewise for machine.
  Important thing is that not going by value.
  Intuitively pass the \eit{} test.
\end{note}

\begin{note}
  So, going by value is where focus is.
  Independence of value is key claim about support.

  Here, support claimed is primary for \(\phi\).
  Information allows to go via value.
  Question is whether properties of mistaken and misleading also extend to \(\psi\), given this.

  Roughly, the idea is to show that if there's some property of \(\psi\), then this causes problems with the incoming support, and as a result, \(\psi\) doesn't inherit these properties, from which it follows that the agent isn't in a position to claim support for \(\psi\).

  Here, the observation is that because going by value, the support claimed for \(\phi\) is doing a fair amount of the work and that there's no way to extend these attributes going in to \(\psi\) by value alone, given particular relation between \(\phi\) and \(\psi\).
\end{note}

\begin{note}[Moving to failure examples]
  Have some examples that seem okay.
  Support looks good.
\end{note}

\begin{note}[Moving to \nI{} failure examples]
  Handful of examples to clarify how \nI{} is applied.
\end{note}

\begin{note}[\nI{} example]
  To illustrate, consider agent named \nagent{1}.

  Suppose \nagent{1} meets an acquaintance who is wearing a new a watch.
  The watch looks like a Rolex, the acquaintance says the watch is a Rolex, and the acquaintance has a letter from Rolex thanking them for their purchase with a matching serial number.
  Hence, \nagent{1} claims support for the proposition that `the watch is a Rolex'.
  Later, \nagent{1} meets with an informer, who states that if the acquaintance's watch is a Rolex, then the jewellery shop in town has stopped selling counterfeits.

  If the watch is not a Rolex, then the support claimed by the agent is misleading.
  For, while the appearance of the watch, what the acquaintance said, and the letter suggest that the watch is genuine, the watch is counterfeit.
  Intuitively, however, this does not seem to allow the agent to claim support that the jewellery shops has stopped selling counterfeits because of the support they have claimed from the watch being genuine.\nolinebreak
  \footnote{
    Can't simply have that misleading is implied, for this will hold for many fine instances of reasoning.
    Any necessary condition is going to have this feature.
  }
\end{note}

\begin{note}[Key parts of \nI{}]
  If acquaintance purchased a counterfeit, then `the watch is a Rolex' is false rather than true.
  Still, agent is going to continue to hold the watch is a Rolex, it seems.
  Strange for either `shop stopped' or `they purchased a counterfeit'.

  The illustration given above is a case in which intuitively the agent is not in a position to claim support for the relevant \(\psi\) instance.

  Apply the `even if' test.
  Even if the watch is not genuine, \dots
  Then support is misleading, and so no account of why shop has stopped selling counterfeits.
\end{note}

\begin{note}[Moving to second illustration]
  First seems intuitively problematic, may be other issues.
  Ease of creating plausible background in which the support claimed isn't sufficiently strong.
  Higher to shop than acquaintance, as acquaintance wouldn't note the difference, and without further, supplemental materials also in doubt if acquaintance isn't careful.

  So, to clarify further, consider a structurally similar scenario in which intuitively the agent is in a position to claim support for the relevant \(\psi\) instance.
  Develop background conditions, and see if intuition still holds.
\end{note}

\begin{note}[Second illustration of \nI{}]
  Consider an agent named \nagent{2}.

  \nagent{2} is looking at a painting in gallery.
  \nagent{2} has studied the the French Baroque and considers the painting to be a Poussin.
  The plaque beside identifies the painting as `Et in Arcadia'.
  Claim support that the painting is a genuine Poussin.

  A donor walks over and states:
  ``If you're looking at a genuine Poussin, then the gallery has a new director.''

  So, implies that unless there is a new director, then painting is not genuine.
  So, then support would be misleading.

  However, less clear that the support is mistaken.
  Given expertise, unclear that the agent has made a mistake.

  In addition, background setting.

  Seems plausible, background support for gallery not purchasing counterfeits.
  Claimed support extends to painting being genuine.
  Background for gallery, so plaque is truthful, and so new director.
  Background for gallery extends through.
\end{note}

\begin{note}[Single agent]
  Previous two, structurally similar and multiple agents.
  Here, single agent, source of information.
\end{note}

\begin{note}[Ball scenario]
  \nagent{3} picking balls from a bag of 1000.
  \nagent{3} has picked 600 from the bag, all have been red or green, even split.
  \nagent{3} doesn't have support for next ball red with 50.
  Unlucky to not pick any of the blue balls, or to have an even split.
  Still, may claim support for it being unlikely that, i.e.\ some weaker claim which is compatible with the agent having picked a non-representative sample.
\end{note}

\begin{note}[K scenario]
  Illustrate that there's no issue with going via the value, rather than support.

  Importance of K is the appealing to 2 clause.
  For, with knowledge, the agent is not relying on support not being mistaken to get to \(\phi\).
  \(\lnot\phi\) would show mistaken, but always a move from K to \(\phi\).
  The `Even if\dots' test works with this.
\end{note}

\begin{note}[Knowledge scenarios]
  Observe, when conditional is strengthened.

  Support claimed is mistaken if \(q\) isn't also the case.
  So, \(p \land q\).
  This seems problematic.
\end{note}


\newpage

\begin{note}[Moving on from illustrations]
  Range of illustrations in hand.
  Turn to general argument for \nI{}.
\end{note}


\begin{note}[Two observations]

  If \(\lnot\psi\) then support for \(\phi\) is misleading.
  So, would not move from support for \(\phi\) to \(\phi\), and hence would not move on to \(\psi\) from values.


  If \(\lnot\psi\), then support for \(\phi\) is mistaken.
  So, whether or not \(\phi\) is the case, would not have indication for \(\phi\), and hence would not have indication for \(\psi\).

  In both of these cases, applying the \eit{} blocks any thing in favour of \(\psi\).
  
\end{note}

\begin{note}[Observation: support]
  First, note the importance of support not being misleading.

  Example where \(\phi\) then \(\psi\), and support goes through.

  E.g., knowledge.

  Expand with information to create cleaner parallel.
  So, if not in london, then in paris.
  In paris.

  The paris is somewhat difficult.
  Looks as though not in london, so somewhere else, and paris expands on this.
  In a sense, the conditional is boosting some very weak support the agent already has.
  {
    But this is difficult, as agent is going to get some support for all specific from general, and information then narrows down application\dots
    And, this seems to pass the test.
    Even if not specific, still general, which suggests each instance.
    I mean, this is intuitively the case, but it doesn't follow that this holds on the basis of having the attribute.
  }

  In both cases presented as fine, conditional is about value.
  Hesitant to claim that this is always fine, but given that \nI{} is general, a pair of examples are sufficient to highlight the importance of the distinction between information about what follows from value, and what follows from information so long as agent is not mistaken about value.
\end{note}

\begin{note}[Observation: mistaken]
  Appeal to the `even if\dots' test.

  If agent does not consider possibility of being mistaken about \(\phi\), then test breaks.
  When introducing, only noted for misleading.
\end{note}

\begin{note}[Summarising two clauses]
  So, seems if either of the initial two clauses fails, then there's no getting to the conclusion.
\end{note}

\begin{note}[Two clauses together]
  So, two clauses together.

  Possibility of misleading, and that information about not misleading.

  \(\psi\) traces back to \(\psi\) not being misleading.
  Failure of even if test.

  Even if test works because it's about misleading support.
  The agent would still be in a position to give an account of \(\phi\).
  However, given information, it's clear that this is going to dead end.
  There's no option to move to \(\psi\) if the agent grants that the support claimed for \(\phi\) is misleading.

  Insight here, is that the agent has not show how support claimed for \(\phi\) extends to \(\psi\).
\end{note}

\begin{note}
  If focusing on value, rather than support, then things seem  different.
  As noted above.
  Assumption about support is that it holds independently of value.
\end{note}


\begin{note}[Related to\dots]
  Focus is on support.
  A pair of related things to illustrate interesting parts of \nI{}.
\end{note}

\begin{note}[No feedback/Bootstrapping]
  No feedback by \citeauthor{Weisberg:2010to}.

  \begin{quote}
    \textbf{No Feedback} If
    \begin{enumerate*}[label=(\roman*), ref=(\roman*)]
    \item\label{WB:NF:1} \(L_{1}-L_{n}\) are inferred from \(P_{1}-P_{m}\), and
    \item\label{WB:NF:2} \(C\) is inferred from \(L_{1}-L_{n}\) (and possibly some of \(P_{1}-P_{m}\) by an argument whose justificatory power depends on making \(C\) at least \(x\) probable, and
    \item\label{WB:NF:3} \(P_{1}-P_{m}\) do not make \(C\) at least \(x\) probable without the help of \(L_{1}-L_{n}\), then the argument for \(C\) is defeated.\nolinebreak
      \mbox{}\hfill\mbox{(\citeyear[533--534]{Weisberg:2010to})}
    \end{enumerate*}
  \end{quote}

  Some similarities.
  Stated in probabilistic terms, so no easy application.
  And, addition of \(C\) condition.
  Expand to add this.

  Somewhat different.
  For, inclusion of support, which (at least without further work) is qualitative rather than quantitative.
  So, it seems \ref{WB:NF:3} isn't going to hold.

  Still, reform No Feedback a little.
  Consider \ref{WB:NF:3} from the agent's point of view, independent of whether \(P_{1}-P_{m}\) not make \(C\) at least \(x\) probable.
  Plausibly problematic if agent doesn't have response to~\ref{WB:NF:3}.
  And, this would be issue of not showing how \(P_{1}-P_{m}\) relate to \(L_{1}-L_{n}\).
\end{note}

\begin{note}[Bootstrapping and reliabilism]
  \nI{} is distinct from No Feedback, but shares some similarities.
  Attempted to keep to weak principles regarding support --- primarily \eiS{}.
  Given relation to No Feedback, may question, as No Feedback applies to bootstrapping, following from reliabislim.
  Hence, worry, as something sufficient to deny reliabilism is somewhat strong.

  Quick argument is that \nI{} is silent with respect to (at least some) instances of reasoning ruled out by anti-bootstrapping principles.
  Hence, \nI{} will not entail bootstrapping, and seems compatible with reliabilism.

  Focus on knowledge.
  However, justification also.
  Here, work with example from \textcite{Cohen:2010ux}, as this is designed for justification.\nolinebreak
  \footnote{
    Though, structurally similar to instance from \cite{Vogel:2000tl}.
  }

  \begin{quote}
    Suppose, having no idea whether my color vision is reliable, I decide to test it. I have someone stand across the room from me and hold up colored cards one at a time. I look at the first card and reason:
    \begin{enumerate}[label=(\arabic*)]
      \setcounter{enumi}{3}
    \item Card 1 looks red.
    \item Card 1 is red.
    \item Card 1 looks red and is red.
    \item So my color vision worked correctly.
    \end{enumerate}
    \[\vdots\]
    I reason the same way for each of the other cards: card 2 looks green, car 2 is green, so so card 2 looks green and is green, etc. I then infer

    \begin{enumerate}[label=(\arabic*), resume]
    \item My color vision worked correctly every time, i.e., I made no errors.
    \end{enumerate}

    Then I infer inductively that

    \begin{enumerate}[label=(\arabic*), resume]
    \item My color vision is reliable.\nolinebreak
      \mbox{}\hfill\mbox{(\citeyear[142]{Cohen:2010ux})}
    \end{enumerate}
  \end{quote}

  Two questions.
  Whether final step is \RBV{} and if so, whether support is included.

  Final step is induction.
  Plausible that it is.
  Issue, then, is whether inclusion.
  Induction is required, but unclear if not induction, so unclear that there's a plausible account of inclusion.

  If not by value, then the agent isn't required to go by value, and hence \nI{} doesn't apply.

  So, it seems \nI{} does not entail other bootstrapping principles.
  Of course, principles may hold.
  Still, \nI{} is sufficient rather than necessary.

  Simple upshot is that assumed principles about support seem quite weak.
\end{note}

\begin{note}[Wright on transmission failure]
  {
    \color{red}
    Given details on bootstrapping, may be best to leave \citeauthor{Wright:2011wn} to a later chapter.
  }
  The key idea behind \citeauthor{Wright:2011wn}'s account of transmission failure is whether something is a presupposition of a cognitive project.
  Failure when agent uses result of cognitive project to claim warrant for something that was presupposed.
  Hence, a kind of circularity.

  \nI{} is different.
  Does not require \(\psi\) to be a presupposition.
  Agent does not need to presuppose novel application of basis of support for some proposition in order to claim support for some other proposition --- or to be diligent, it is not clear to me that this is the case.

  To illustrate, different readings on Moore's proof.
  For \citeauthor{Wright:2011wn}, presupposition of cognitive project that sight is factive.
  So, this already gets that there's an external world.

  For \nI{}, problem if one thinks that appearance of hand also applies to existence of external world.

  Here, if follow \citeauthor{Wright:2011wn}, then support won't also extend, as presupposed.
  Alternatively, one may argue that the support is for world and hands.
  Hence, that support for world comes from a reapplication of the support used for hands.

  So, this distinguishes \nI{} from transmission failure.
  More is said in chapter~\ref{cha:inertia}.
\end{note}

\newpage

\begin{note}[Applying to type of scenario]
  We have worked through details on \nI{} to some extent.
  Our attention now turns to how \nI{} applies to the use of \aben{} in scenarios of interest.

  The focus of our attention is whether an agent may claim support for having a specific ability given the support claimed for having a general ability, given \gsi{}.

  Apply this to the \nI{} template.
  \(\phi\) and \(\psi\) are general and specific abilities, respectively.

  \begin{enumerate}[label=\nI{}, ref=\nI{}]
  \item An agent does not have the option of obtaining support for having a specific ability from information that the support the agent has for having the general ability is misleading if it is not the case that the agent has the specific ability.
  \end{enumerate}

  Have the first condition sorted.
  \gsi{} does imply \dots
  Issue is whether agent makes use of this.
  Argue that the agent does if interpreted in line with \AR{}.

  Distinctive about \AR{} is that focuses on having attribute.
\end{note}

\begin{note}
  If argument is successful, then agent will not be in a position to claim support for specific ability.
  This is the antecedent of the relevant use of \aben{}.
  Pair \nI{} with following supplement.

  \begin{proposition}[\nIm{}]
    An agent must have claimed support for the antecedent of an entailment in order to claim support for the consequent of the entailment via the entailment.\nolinebreak
    \footnote{To clarify, entailment is only about value.
      Think of conditional.

      So, does not follow that there being an entailment is a required part of agent's reasoning.
      \nIm{} is talking about when the agent appeals to an entailment, rather than any understanding of entailment beyond it being the case.
    }
  \end{proposition}
  \nIm{} seems indisputable,\nolinebreak
  \footnote{
    An agent may have some other way of claiming support for the consequent of the entailment.
    However, if the agent is not in a position to claim support for the antecedent, then the agent is not in a position to claim support because there is an entailment from the antecedent to the consequent.\nolinebreak

    For example, that the coin landed heads is entailed by Sam knowing that the coin landed heads.
    Here, entailment from \(K\phi\) to \(\phi\).

    Second, this light being on entails that the printer is out of paper.
    If agent appeals to entailment, again, need the light to be on.
    However, could look in the paper drawer, or modify the wiring so that an alarm sounds.

    However, Taylor is not in a position to claim support for the coin landed heads because Sam knows if Taylor has no idea whether Sam knows --- though Taylor may claim support by looking at the coin.
  }
  and so not in a position to claim support for result of witnessing ability via \AR{}.
\end{note}

\begin{note}[Application of \nI{} to \AR{}]
  \AR{}, working with attribute.
  So long as you have general ability, you have specific ability.

  \nI{} is a little different.
  Not misled about \(\phi\), so \(\psi\).

  Implication.
  If misled about general ability, unless specific.

  This holds for all fact-fact propositions, so there's nothing too interesting about this.

  Whether agent appeals to implication.
  Focus here is on reasoning with the attributes.

  Relying on not being mistaken about general ability?

  Agent appeals to attribute of general ability.
  Support allows them to do this.

  Moving to specific.

  Moving between attributes.
  No clear problem with noting that specific, given support for general and information.

  Still, appealing to attribute alone.
  If mistaken about attribute, then would not move to specific.
  Intuitively, this would be a dead end.

  This is because, no attribute.
  Hence, to the extent the agent is relying on attribute, the agent loses path from attribute.

  The problem is that with attribution, things follow from the value, rather than anything else.
  This is why the argument only appeals to attribution.

  This requires a little more argument.
  Why doesn't the agent get to consequences of attribution?
  Because all of these consequences follow from value?

  However, if it's true that follow from value, it seems there should be a parallel problem in the case of knowledge.
  Surely factive only goes from value?

  Then, if only going via value, this leads to requirement that support is not misleading.
  For, need value, and in turn, this requires that support is not misleading.

  {
    This suggests a problem for knowledge.
    If relying on agent knowing, and that this is factive, then it's not clear that one gets support for fact.
    Same issue.
    This doesn't seem to arise for cases of one's own knowledge, with assumption that this includes support.

    Still something of a problem.
    Without \(\phi\), mislead about \(S\) knowing that \(\phi\), so can't use factivity of knowledge to establish \(\phi\).

    Two options:
    Agent isn't in a position to claim support, only get to requirement of \(\phi\).
    There's some other reasoning than factivity of mental state.

    Unclear.
    Role of factivity suggests first.
    However, the `even if\dots' test suggests the second.
    Consistent is that intuitions from test don't apply to all cases of knowledge.
    But this is difficult.
    Example, experts.
    Seems that there's little more than factivity to go on.

    Really unclear.
    Difficulty is that this suggests absence of a clear intuitive grasps on what this notion of support is.
    To some degree, there is now motivation, but considering that it gets complex in this simple case, it's then not clear what the upshot for ability is.
    For, if factive is okay for other-person knowledge, might it not also be okay for ability?

    Well, I don't have support, but someone else does.

    This keeps up issue with ability, because it's not clear that someone else does, given that it's the agent's ability that's at issue.

    Still strange with ability, because appealing to one's own ability\dots
  }

  {
    This fixes a difference with the paris case.
    For, there's no interpretation where not being in london is sufficient to fix paris, given all the other places the operative could be.
    So, there's some additional stuff that can be supplemented.
  }
\end{note}

\begin{note}[Application of \nI{} to \AR{} argument]
  \gsi{} information.
  For \AR{}, agent is required to claim support that they have the specific ability.
  That is, claim support for consequent because the agent claims support for specific ability.
  This is distinguishing feature of \AR{} --- the agent is only appealing to having attribute.
  General characterisation of \AR{}, all ability from appeal to attribute.
  Contrast to \WR{}, where some use of ability.

  So, this means attribute for general and specific in cases of interest.
  For, \AR{} is attribute for all instances of ability.

  {
    \color{green}
    So, having the attribute, key point.
    Agent ends up going to having value, rather than merely claiming support.
    Agent uses specific, but would show misleading, which is a flag.
    Further, need specific to get to result.
    Hence, there's no possibility of showing result whether or not specific holds.
  }

  {
    \color{red}
    Appeal to general is misleading if specific is not the case.
  }
  Structure of \gsi{} is important.
  Relates attributes, rather than support.
  Hence, agent goes from support claimed for general to general in order to get specific.
  However, as agent recognises that support may be misleading, move to general goes beyond what agent has support for.
  Not in a position to discharge for move to having attribute, because it's not clear that the assumption made does not rely on specific being the case.



  Support claimed for general is misleading if specific is not the case.
  Agent appeals to claimed support for general.
  Possibility of support being misleading.
  






  Specific ability is novel information, so agent needs to use information provided.
  That is, if general then specific.
  And, agent claimed support for general.

  \gsi{} does imply that support for \(\phi\) is misleading if \(\psi\) is not also the case.
  Given information, if not specific, then agent has been misled if they don't also have the specific ability.

    If agent appeals to general and information, then agent is appealing to having general attribute, and not only support for general attribute.
    
\end{note}

\newpage


\begin{note}[Once again]
  \color{red}
  So, this is where the problem is.
  As before, with assumption, this is going to be a problem if consider possibility of being misled.
  And also as before, agent hasn't established how support claimed extends to \(\psi\).

  Here, perhaps important to note, that same issues does not extend, at least without restriction, to \aben{}.
  For, in cases of \aben{} plausible that entailment details how support extends.
  E.g.\ there is an event in which demonstrate that result holds.

  The main observation is that because information doesn't detail how support extends, 
\end{note}



\begin{note}[Why this matters for \AR{}]
  Rough characterisation in hand, see how this matters for \AR{}.

  Focus is on the ??? step.
  Would not have general ability if not specific.

  Requires truth of general ability.
  Hence, fits in.

  Clarify a little more, then expand on this point in more detail.
\end{note}


\begin{note}[Motivation in more detail]
  Question for scenarios of interest is why this is relevant.

  Focus on \AR{} and finial step.
  \begin{itemize}
  \item Have specific ability only if strategy exists.
  \end{itemize}
  Here, agent is appealing to entailment.
  This, then, requires the agent to have support for having the specific ability.

  It is not (`merely') the case that the agent would do some reasoning that leads them to conclusion.
  Agent may do reasoning and have support for premise even if they are misleading.

  Rather, because the agent is appealing to having ability, needs to be the case that it is true that they have the ability.

  Intuitive difference.
  In \AR{} case, the agent is relying on truth and entailment.
  If agent were to reason, the agent would be relying on support from premises and steps extending.

  Difference between appealing to having ability, and to instance of ability.

  Simple example.
  I am misleading, but I have the ability to demonstrate that \(\psi\) --- so support for \(\psi\).
  I am misleading, but this my demonstration of \(\psi\) --- so support for \(\psi\).

  First, misleading about being able to demonstrate that \(\psi\), so blocks what follows from ability by entailment, though the agent still retains some support for having the ability.
  Second, have shown how support extends, therefore granting there is a mistake, still retain support for \(\phi\).

  Distinction between appealing to \(\phi\) in order to get \(\psi\) and extending the support one has for \(\phi\) to \(\psi\).

  In turn, loops back to understanding of \nI{}.
  For, \nI{} doesn't extend support.
\end{note}

\begin{note}[Distinguishing features]
  Reasoning has distinguishing features that pair well.
  \begin{itemize}
  \item Extends support.
  \end{itemize}
\end{note}

\begin{note}[Positive idea of support?]
  The key idea is that in order for support to go through, the agent needs extend the support the agent has for \(\phi\) is also support for \(\psi\).

  {
    \color{red}
    A different way of putting things is that \(\phi\) does not inherit support from \(\psi\).
    So, \(\phi\) may be supported, but no support is added.
  }


  {
    \color{green}
    Motivation here is that because (specific) ability would be application of general, this is a potential (and quite direct) counterexample --- assume that the agent receives testimony.
  }


  {
    \color{red}
    The agent may obtain support for \(\phi\) from some other premise.
  }
\end{note}

\begin{note}[~\nI{} and \AR{}]
  Why, then, does \AR{} seem to require a violation of~\nI{}?

  First, need the conditions to match up.
  This is somewhat simple.

  The agent would be applying general ability.
  Therefore, if the agent does not have the specific ability, then something has gone with the support the agent has for the general.
  This is explicitly stated.
  Important, because do not hold the stronger position that there's a broad general to specific entailment.
  Some things may follow from rules of chess, but go beyond agent's ability, but be within some other agent's ability.
  More than simply understanding the rules.

  \AR{} fits in.
  Novel information --- no other resources for conclusion, so the agent is required to use the general ability as a premise.
  Premise is that the agent has the attribute of being able to \dots.
  Conclusion is that the agent has attribute of being able to\dots.

  So, one attribute from another.
  `Extends' type of support relation.
  However, agent isn't appealing to how support extends.
  There's no additional reasoning, other than the conditional.

  Observe that this is not compatible with the agent holding that they may be misleading.
  Support for general ability may be misleading, but given support, then this extends to specific ability.
  ? This seems bad.

  Contrast to.
  Support for general ability may be misleading, but given support and information, then reasoning I have support for extends to conclusion.
  Agent is not relying on support for general ability to provide support for specific ability.
  Instead, agent is appealing to support may appeal to as a use of the general ability.

  Compare with simple cases.
 
  Misleading on the first may involve no support for \(\phi\).
  Misleading on the second is mistake in use of support in demonstrating \(\phi\).
  {
    \color{green}
    Well, with the first, it's getting to \(\phi\).
    Doesn't seem the agent is in a position to use factive inference.
    Because, the agent is going from not possible to have ability and for \(\phi\) to be false.

    \textbf{
      This is the part I'm missing.
      It's the use of this particular inference that really characterises \AR{}.
      It's possible for appeal to attribute without this inference, but that doesn't matter to me.
    }

    With the second, different.
    Because, the agent is going from application of ability providing support for \(\phi\).
  }

  {
    \color{red}
    This is in contrast to \WR{}, where the agent may hold that they may be misleading, but the reasoning extends.
    Hence, may be misleading, but given the support I have, support for conclusion.
    Lack an account of how reasoning extends.
  }
\end{note}


\begin{note}[Overview]
  From explanation:
  \begin{itemize}
  \item Indirect/\AR{} is bad.
  \item Reasoning would be fine.
  \item \WR{} mirrors reasoning for the most part.
  \item Information isn't used to transfer support, but provides structure for \WR{}.
  \end{itemize}
\end{note}

\begin{note}[Important points]
  Two important points:

  The role of~\nI{} is to highlight that the agent is not in a position to obtain support for (specific) ability in a certain way.
  That is,~\nI{} does not state that the agent may not obtain support for (specific) ability some other way.

  Second, some long as agent holds that they have general ability, then committed to truth.
  The \gen{} may be taken as testimony.
  So, either one or the other.
  A kind of transmission failure.
  Distinct from case of knowledge, as no factivity.
  In part, role of informer.

  May be tempted to say that the agent is not committed, but this seems implausible.
  Cases of transmission failure, it seems agent does remain committed, at least.

  May take issue with information provided, especially if ideal.
  If informer has information, then they should say.
  In turn, not problem with~\nI{} as the agent would have support (via testimony) for specific ability.
  However, informer may only have the conditional.

  Ordinary agents.
  Maxims are broken.
  And, interest effects.
  Up to the agent.

  Seems puzzling, but not paradoxical.
\end{note}

\begin{note}[Why this is important]
  The key idea, and the foundation of the objection, is that the agent is going indirectly.
  The agent is \emph{not} showing how the general ability extends to specific ability.
  For, the only things available to the agent is the constraint.

  This is useful independently.
  For, even if not convinced by~\nI{}, clear that given \gsi{} and~\uRa{}, the agent goes directly.
  And, something a little puzzling about this.
  Or, so I think.
\end{note}

\begin{note}[Aside]
  I don't see this as too different from simply stating that general ability extends.
  That is, the sort of \gsi{} is what is actually communicated in most cases of this kind.
  However, nothing rests on this.
\end{note}

\begin{note}[Dogmatism]
  Continuing relation to issues with knowledge.
  \autoref{prem:ni} is quite close to dogmatism paradox.
  If one knows that \(\phi\), then any evidence for \(\lnot \phi\) is misleading.

  Distinct again, however.
  For, don't have knowledge in the antecedent.
  Get the dogmatism paradox from the factivity of knowledge.
  No requirement that support for (general) ability is factive.

  Hence, role of the informer is important again, because agent is not in a position to come to the conditional by themselves prior to reasoning.
\end{note}

\newpage

\begin{note}[Finding tension, still]
  We have outlined a type of scenario built primarily on an agent receiving information that the agent has some specific ability so long as the agent has some general ability.
  The agent has support for having the general ability, but there are two ways in which the agent's support for having the general ability may be used to establish support for {\color{red} the result of having the specific ability} --- \AR{} and \WR{}.

  The previous section argued that~\uRa{} constrains how an agent may use the received information.
  If an agent is required to traces support from premises to conclusion through reasoning, then an agent may not appeal to the support for the premises and steps of reasoning that the agent would use when witnessing the specific ability.
  {\color{red} This is summarised in~\ref{P:ab-and-dc:W}.}

  The (initial) plausibility of~\uRa{}, then, suggests that the agent may only establish support for having the {\color{red} result of the specific ability} from the support they have for the general ability by \AR{}:
  The support the agent has for the general ability is support that it is true that the agent has the general ability.
  In turn, given the information received it is true that the agent has the specific ability, and it is only possible for the agent to have the specific ability if the result of witnessing the specific ability is true.

  The argument of this section is that the sketch of \AR{} given conflicts with a different, but equally plausible, premise.
  The premise concerns the way in which the agent obtains support for having the specific ability from the support for the general ability.
  We state conditional, the proceed to the premise.
  The initial statement of the premise is abstract and after providing a handful of clarifications we then link the premise to the type of scenario of interest.
\end{note}

\begin{note}[Conditional B]
  \begin{proposition}[\mcB{}]
    \begin{enumerate}[label=(C\Alph*), ref=(C\Alph*)]
      \setcounter{enumi}{1}
    \item\label{P:ab-and-dc:A} If
      \begin{enumerate}[label=(\roman*), ref=(CB.\roman*)]
      \item\label{P:ab-and-dc:A:ab} an agent obtains support for some proposition \(\phi\) on the basis of the agent's ability to demonstrate that \(\phi\) is the case, and
      \item\label{P:ab-and-dc:A:ni} \nI{} is true,
      \end{enumerate}
      then
      \begin{enumerate}[label=(\roman*), ref=(CB.\roman*), resume]
      \item\label{P:ab-and-dc:A:AR} the support for \(\phi\) \emph{is not} claimed on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (in line with \AR{}).
      \end{enumerate}
    \end{enumerate}
  \end{proposition}

  Given \mcA{}, the immediate interest with \mcB{} is that~\ref{P:ab-and-dc:W:AR} and~\ref{P:ab-and-dc:W:AR} are incompatible.
  So, if both conditionals are true, then (at least) one of the antecedents from either conditional is false.

  \ref{P:ab-and-dc:A:ab} repeats~\ref{P:ab-and-dc:W:ab}, roughly \eA{}.\nolinebreak
  \footnote{
    As with \mcA{}, could rephrase without \ref{P:ab-and-dc:A:ab}.
    If \nI{} is true, then not possible for agent to claim support for \(\phi\) on the basis of the agent having the attribute of being able to demonstrate that \(\phi\).
  }
  % Still,~\ref{P:ab-and-dc:A:ni} differs from~\ref{P:ab-and-dc:W:uRa}.
  \mcA{} assumed \uRa{}, principle we are proposing an exception for.
  \mcB{} assumes a principle, \nI{} to be argued for.
  Hence, if both \mcA{} and \mcB{} are true, either \eA{}, \uRa{}, or \nI{} is false.

  Before turning to \nI{}, observe general picture.
  If \eA{} and \nI{}, then \uRa{} is false.
  Hence, argument against \uRa{}.
  Further, \ref{either-AR-or-WR} then \WR{}.
  Motivates \rC{}.
\end{note}



\begin{note}[Established conditional 2]
  Something about, if \eA{} then agent does not obtain support for the attribute.
\end{note}

\subsection{Establishing tension/summary}
\label{sec:establishing-tension}

\begin{note}[Summary]
  Given the two established conditionals~\ref{P:ab-and-dc:W} and~\ref{P:ab-and-dc:A}, the combination of the key premises of \uRa{},~\eA{}, and~\nI{} are in tension.

  For, combining~\ref{P:ab-and-dc:W} and~\ref{P:ab-and-dc:A} we have:
  \begin{enumerate}[label=(CC), ref=(CC)]
  \item If \eA{} is the case an agent obtains support for some proposition \(\phi\) on the basis of the agent's ability to demonstrate that \(\phi\) is the case then:
    \begin{enumerate}[label=(C\arabic*\(\sim\)), ]
    \item If \uRa{} is true, then the support for \(\phi\) is obtained on the basis of the agent having the attribute of being able to demonstrate that \(\phi\) (in line with \AR{}).
    \item If \nI{} is true, then the support for \(\phi\) \emph{may not be} obtained (in line with \AR{}) on the basis of the agent having the attribute of being able to demonstrate that \(\phi\).
    \end{enumerate}
  \end{enumerate}
  In short, if~\eA{} is the case then~\uRa{} requires a certain interpretation of the scenarios identified by~\eA{} and~\nI{} denies that the interpretation is plausible.
\end{note}


\begin{note}[Creating tension]
  Have:
  \begin{enumerate}
  \item \(\eA{}\)
  \item \(\uRa{} \rightarrow \lnot\WR{}\)
  \item \(\nI{} \rightarrow \lnot\AR{}\)
  \end{enumerate}
  Argued for these.

  Then,
  \begin{enumerate}
  \item \(\eA{} \rightarrow (\AR{} \lor \WR{})\)
  \end{enumerate}
  If agent claims support, either \AR{} or \WR{}.

  Then use Propositions.
  \begin{enumerate}
  \item \(\eA{} \rightarrow ((\AR{} \land \lnot\nI{}) \lor (\WR{} \land \lnot\uRa{}))\)
  \end{enumerate}
  Simplify by exclusive proposition again.
    \begin{enumerate}
  \item \(\eA{} \rightarrow ((\lnot\nI{}) \lor (\lnot\uRa{}))\)
  \end{enumerate}

  So,
  \begin{enumerate}
  \item \(\lnot\eA{} \lor \lnot\uRa{} \lor \lnot\nI{}\)
  \end{enumerate}
\end{note}

\begin{note}[Weak points]
  \eA{} and \(\eA{} \rightarrow (\AR{} \lor \WR{})\).

  Perhaps there is a third option.
  Though unclear what this would be, even in outline.

  Hence, that the agent has the option of claiming support.
  If so, though, it seems surprising that \aben{} is never used to claim support.
\end{note}

\begin{note}[Tension, choices]
  In short, we have the following resolutions.
  \begin{enumerate}
  \item\label{ten:res:nS} Agent may not obtain support for result of witnessing ability, or
  \item\label{ten:res:nD} Agent obtains support for result on the basis on premises that the agent would use when witnessing ability --- incompatible with general application of~\uRa{}
  \item\label{ten:res:nI} Agent obtains support for result from attribute of having the ability on the basis that the support they have for general ability would be misleading --- incompatible with general application of~\nI{}
  \end{enumerate}
  \ref{ten:res:nS} is incompatible with~\ref{ten:res:nD} and~\ref{ten:res:nI}.
  However, \ref{ten:res:nI} and~\ref{ten:res:nD} are compatible, as both~\uRa{} and~\nI{} may be restricted.
\end{note}

\begin{note}[Argument sketch recap]
  Let us recap the main points of the argument so far.
  \begin{enumerate}
  \item Assume possibility of cases in which agent is provided with information that they have some specific ability so long as the agent has a general ability, such that the agent has support for having the general ability, but has not established support for possessing the specific ability.
  \item In such cases, it seems it is possible for the agent to obtain support for what follows from the agent witnessing their specific ability.
  \item If so, the agent appeals to having the specific ability in order to obtain support for what follows from the agent witnessing their specific ability.
  \item Attribution, and witnessing.
  \item If witnessing, then conflict with the requirement that an agent must access support for the premises appealed to in support of a conclusion.
  \item If attribution, then conflict with the restriction that an agent may not obtain support for some proposition on the basis that support the agent has for some other proposition would be misleading otherwise.
  \end{enumerate}

  To follow:
  \begin{enumerate}
  \item Restricting~\uRa{} in favour of~\rC{} works well.
  \end{enumerate}
\end{note}

\begin{note}[Meek outlook]
  This is not a clean argument.
  Take~\uRa{} and~\nI{} and hold the first.
  The agent may not obtain support.

  While there may be tension if the agent obtains support, this tension is never instantiated.

  I am sympathetic.

  Still, endorsing the restriction does not require the agent to obtain support in this case.
  Harbour some hope that that there is scope to restrict \uRa{}, and that the argument provided for resolving tension in favour of \rC{}, along with later arguments, may serve as a source for reflection.
\end{note}

\begin{note}[\WR{} isn't required for interest]
  \mcB{} is quite interesting itself.
\end{note}

\section{Positive argumnet overview}
\label{sec:posit-argumn-overv}

\subsection{Cases}
\label{sec:cases}

\begin{note}
  Main role of positive argument is cases.
\end{note}

\begin{note}[Beyond belief]
  Application in particular to desire.
\end{note}